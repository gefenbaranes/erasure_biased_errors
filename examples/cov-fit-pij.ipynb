{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "from BiasedErasure.main_code.Simulator import *\n",
    "from BiasedErasure.main_code.noise_channels import atom_array\n",
    "from BiasedErasure.delayed_erasure_decoders.HeraldedCircuit_SWAP_LD import HeraldedCircuit_SWAP_LD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(noise_params={}, chunk_size=10000, noise_scales=[1.,1.,1.,1.]):\n",
    "    cycles = 4\n",
    "    decoder_basis = 'Z'\n",
    "    num_rounds = 5\n",
    "    gate_ordering = ['N', 'Z', 'Zr', 'Nr']\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis, 'bias_preserving_gates': 'False', \n",
    "        'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '100', 'LD_method': 'FREE', 'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'ML',\n",
    "        'circuit_type': 'memory', 'Steane_type': 'regular', 'printing': 'False', 'num_logicals': '1', 'loss_decoder': 'independent', 'obs_pos': 'd-1', 'n_r': '0'}\n",
    "    bloch_point_params = {'erasure_ratio': '1', 'bias_ratio': '0.5'}\n",
    "    \n",
    "    # Example data, change this:\n",
    "    dx = 5\n",
    "    dy = 5\n",
    "    \n",
    "    output_dir = \"\"\n",
    "    simulator = Simulator(Meta_params=Meta_params, atom_array_sim=True, \n",
    "                                bloch_point_params=bloch_point_params, noise=atom_array , \n",
    "                                phys_err_vec=None, loss_detection_method=HeraldedCircuit_SWAP_LD, \n",
    "                                cycles = cycles, output_dir=output_dir, save_filename=None, save_data_during_sim=False)\n",
    "    \n",
    "    meas, det = simulator.sampling_with_loss(chunk_size, dx, dy, None, noise_params=noise_params)\n",
    "    return torch.Tensor(meas).int(), torch.Tensor(det).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_ij_matrix(detections: np.ndarray) -> np.ndarray:\n",
    "    num_ancillas = 24\n",
    "    num_time_steps = 4\n",
    "    total_steps = num_ancillas * num_time_steps\n",
    "    \n",
    "    p_ij = np.zeros((total_steps, total_steps))\n",
    "    x_avg = np.mean(detections, axis=0)\n",
    "    xixj_avg_matrix = np.dot(detections.T, detections) / detections.shape[0]\n",
    "    for idx_i in range(total_steps):\n",
    "        for idx_j in range(idx_i + 1, total_steps):\n",
    "            xi_avg = x_avg[idx_i]\n",
    "            xj_avg = x_avg[idx_j]\n",
    "            xixj_avg = xixj_avg_matrix[idx_i, idx_j]\n",
    "            numerator = 4 * (xixj_avg - xi_avg * xj_avg)\n",
    "            denominator = 1 - 2 * xi_avg - 2 * xj_avg + 4 * xixj_avg\n",
    "            if denominator > 0 and 1 - numerator / denominator >= 0:\n",
    "                value = 0.5 - 0.5 * np.sqrt(1 - numerator / denominator)\n",
    "                p_ij[idx_i, idx_j] = value\n",
    "                p_ij[idx_j, idx_i] = value  # The matrix is symmetric\n",
    "    return np.round(p_ij, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97912ccb044d4136abd817cca9fc8137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n",
      "entangling Pauli error rate = None, entangling loss rate = None\n",
      "Using orderings: ['N', 'Z', 'Zr', 'Nr']\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import *\n",
    "maximums = np.array([\n",
    "        3e-6, *[8e-6]*3, *[0.05/4]*3, *[0.05/4]*15, 0.05/4, *[1e-3]*3, 0.03, 0.04 \n",
    "    ])\n",
    "to_dict = lambda noise_params: dict(\n",
    "        idle_loss_rate=noise_params[0],\n",
    "        idle_error_rate=noise_params[1:4],\n",
    "        entangling_zone_error_rate=noise_params[4:7],\n",
    "        entangling_gate_error_rate=noise_params[7:22],\n",
    "        entangling_gate_loss_rate=noise_params[22],\n",
    "        single_qubit_error_rate=noise_params[23:26],\n",
    "        reset_error_rate=noise_params[26],\n",
    "        measurement_error_rate=noise_params[27]\n",
    "    )\n",
    "keys = ['idle_loss_rate', *['idle_error_rate']*3, *['entangling_zone_error_rate']*3, \n",
    "        *['entangling_gate_error_rate']*15, 'entangling_gate_loss_rate', *['single_qubit_error_rate']*3,\n",
    "        'reset_error_rate', 'measurement_error_rate'\n",
    "        ]\n",
    "fig, axes = plt.subplots(4,7,figsize=(10,5))\n",
    "axes = axes.flatten()\n",
    "for i in trange(28):\n",
    "    x = np.zeros(28)\n",
    "    x[i] = maximums[i]/5\n",
    "    meas, det = simulate(noise_params=to_dict(x), chunk_size=20000)\n",
    "    cov_ = p_ij_matrix(det.numpy()).flatten()\n",
    "    cov_ /= np.linalg.norm(cov_)\n",
    "    tmp = int(np.sqrt(len(cov_)))\n",
    "    axes[i].imshow(cov_.reshape((tmp,tmp)))\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'{keys[i]}', fontsize=5)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
