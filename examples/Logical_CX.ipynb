{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer_list = [1]\n",
      "logical_CX__Nlayers1__NCX1\n",
      "final measurement_index = 18\n",
      "logical_CX__Nlayers1__NCX1\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.0335644347532662729) D0\n",
      "error(0.01707372961976187306) D0 D2 D4\n",
      "error(0.01707372961976187306) D0 D3 D4\n",
      "error(0.01707372961976187306) D1\n",
      "error(0.01707372961976187306) D1 D3 D4\n",
      "error(0.01707372961976187306) D2\n",
      "error(0.0335644347532662729) D3\n",
      "final measurement_index = 18\n",
      "Preprocessing is done! it took 0.34s\n",
      "0 100 200 300 400 500 600 700 800 900 Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-24\n",
      "0 100 200 300 400 500 600 700 800 900 MLE decoder took 3.475127s.\n",
      "logical error 0.029\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "distance = 3\n",
    "num_CX_per_layer_list = [1]\n",
    "num_layers = len(num_CX_per_layer_list)\n",
    "assert len(num_CX_per_layer_list) ==  num_layers\n",
    "\n",
    "print(f\"num_CX_per_layer_list = {num_CX_per_layer_list}\")\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "noise_params = noise_params = {'idle_loss_rate': 5.346010002745036e-08, \n",
    "                                'idle_error_rate': array([7.89314494e-09, 2.81702046e-08, 1.15650507e-07]), \n",
    "                                'entangling_zone_error_rate': array([4.50103659e-04, 5.60439308e-06, 3.29645358e-03]), \n",
    "                                'entangling_gate_error_rate': [2.393750964812938e-05, 0.00015294459572299472, 0.0016575839127290178, 2.393750964812938e-05, 0, 0, 0, 0.00015294459572299472, 0, 0, 0, 0.0016575839127290178, 0, 0, 0.00081117655901964], \n",
    "                                'entangling_gate_loss_rate': 0.0021310662492619475, 'single_qubit_error_rate': array([9.82517752e-06, 1.04167102e-03, 1.64424262e-05]), \n",
    "                                'reset_error_rate': 6.484420123608033e-05, 'measurement_error_rate': 0.002234264216316982, 'reset_loss_rate': 0.0007072757126485622,\n",
    "                                'measurement_loss_rate': 0.03422498167847147, 'ancilla_idle_loss_rate': 1.569889741718561e-07, \n",
    "                                'ancilla_idle_error_rate': array([1.30972461e-07, 4.04213096e-08, 4.08181939e-06]),\n",
    "                                'ancilla_reset_error_rate': 0.021408069221550766, 'ancilla_measurement_error_rate': 0.0015628602753064648, \n",
    "                                'ancilla_reset_loss_rate': 5.5115512820230125e-05, 'ancilla_measurement_loss_rate': 0.0005409239922594136,\n",
    "                                'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': '0',\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX', 'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0', 'num_CX_per_layer_list':num_CX_per_layer_list}\n",
    "\n",
    "noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "            'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "\n",
    "simulate_data = True\n",
    "num_shots = 1000\n",
    "if simulate_data:\n",
    "    detection_events_signs = None\n",
    "    measurement_events, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)\n",
    "\n",
    "\n",
    "else:\n",
    "    # measurement_events, detection_events, observable_flips, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "    # detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)    \n",
    "    # detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int) # Find detection event signs (not needed anymore)\n",
    "    detection_events_signs = None\n",
    "    exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "    measurement_events = exp_measurements[:num_shots]\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "logical_gap = True\n",
    "# circuit = get_lossless_circuit(Meta_params, distance, distance, noise_params)\n",
    "\n",
    "# DO IT\n",
    "if not logical_gap:\n",
    "    predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        measurement_events,\n",
    "                                                                        detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots=num_shots)\n",
    "    logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "    \n",
    "else:\n",
    "    predictions, log_probabilities, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        measurement_events,\n",
    "                                                                        detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        logical_gaps=True, \n",
    "                                                                        noise_params=noise_params, num_shots=num_shots)\n",
    "\n",
    "    logical_probability = np.mean(np.logical_xor(observable_flips.flatten(), predictions[:, 0]))\n",
    "\n",
    "\n",
    "print('logical error',logical_probability)\n",
    "\n",
    "\n",
    "# error bar: (np.sqrt(P*(1-P)/num_shots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical error: 0.012\n"
     ]
    }
   ],
   "source": [
    "logical_probability = np.mean(np.logical_xor(observable_flips.flatten(), predictions[:, 0]))\n",
    "print('Logical error:', logical_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "final measurement_index = 146\n",
      "[[0 0 0 ... 0 1 0]\n",
      " [0 1 0 ... 0 2 0]\n",
      " [0 0 0 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 2 1 0]\n",
      " [1 1 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]]\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.02877793606046901917) D0\n",
      "error(0.008689897102474961055) D0 D3\n",
      "error(0.006324350070450102633) D0 D3 D16\n",
      "error(0.01202750782914281495) D0 D4\n",
      "error(0.006324350070450102633) D0 D4 D14 D16\n",
      "error(0.0009641219999999999825) D0 D4 D14 D38 D62\n",
      "error(0.0009641219999999999825) D0 D4 D14 D62\n",
      "error(0.00119432355693597776) D0 D4 D16 D38 D62\n",
      "error(0.00119432355693597776) D0 D4 D16 D62\n",
      "error(0.006324350070450102633) D0 D12\n",
      "error(0.008387372117264965676) D0 D12 D14\n",
      "error(0.002823868213805612315) D0 D12 D36 D60\n",
      "error(0.001199944231680439037) D0 D12 D38 D62\n",
      "error(0.002823868213805612315) D0 D12 D60\n",
      "error(0.001199944231680439037) D0 D12 D62\n",
      "error(0.0008111769999999999484) D0 D14 D38 D62\n",
      "error(0.0008111769999999999484) D0 D14 D62\n",
      "error(0.0009641219999999999825) D0 D16 D24\n",
      "error(0.001202373919938061562) D0 D16 D24 D36 D60\n",
      "error(0.0008111769999999999484) D0 D16 D24 D38 D62\n",
      "error(0.0009641219999999999825) D0 D16 D24 D48\n",
      "error(0.001202373919938061562) D0 D16 D24 D48 D60\n",
      "error(0.0008111769999999999484) D0 D16 D24 D48 D62\n",
      "error(0.001199944231680439037) D0 D16 D28 D38 D62\n",
      "error(0.001199944231680439037) D0 D16 D28 D52 D62\n",
      "error(0.03462211211382151127) D0 D24\n",
      "error(0.0009719279513609105489) D0 D24 D36 D38 D60 D62\n",
      "error(0.0008111769999999999484) D0 D24 D36 D60\n",
      "error(0.03462211211382151127) D0 D24 D48\n",
      "error(0.0008111769999999999484) D0 D24 D48 D60\n",
      "error(0.0009719279513609105489) D0 D24 D48 D60 D62\n",
      "error(3.533390243903300872e-05) D0 D28\n",
      "error(3.533390243903300872e-05) D0 D28 D52\n",
      "error(0.001199944231680439037) D0 D36 D38 D60 D62\n",
      "error(0.00119432355693597776) D0 D36 D60\n",
      "error(0.00119432355693597776) D0 D60\n",
      "error(0.001199944231680439037) D0 D60 D62\n",
      "error(0.02877793606046901917) D1\n",
      "error(0.008689897102474961055) D1 D4\n",
      "error(0.006324350070450102633) D1 D4 D14 D17\n",
      "error(0.01202750782914281495) D1 D5\n",
      "error(0.006324350070450102633) D1 D5 D15 D17\n",
      "error(0.0009641219999999999825) D1 D5 D15 D39 D63\n",
      "error(0.0009641219999999999825) D1 D5 D15 D63\n",
      "error(0.00119432355693597776) D1 D5 D17 D39 D63\n",
      "error(0.00119432355693597776) D1 D5 D17 D63\n",
      "error(0.006324350070450102633) D1 D13 D14\n",
      "error(0.008387372117264965676) D1 D13 D15\n",
      "error(0.002823868213805612315) D1 D13 D37 D61\n",
      "error(0.001199944231680439037) D1 D13 D39 D63\n",
      "error(0.002823868213805612315) D1 D13 D61\n",
      "error(0.001199944231680439037) D1 D13 D63\n",
      "error(0.0009641219999999999825) D1 D14 D17 D25\n",
      "error(0.0009641219999999999825) D1 D14 D17 D25 D49\n",
      "error(0.0008111769999999999484) D1 D14 D25 D37 D61\n",
      "error(0.0008111769999999999484) D1 D14 D25 D49 D61\n",
      "error(0.00119432355693597776) D1 D14 D37 D61\n",
      "error(0.00119432355693597776) D1 D14 D61\n",
      "error(0.0008111769999999999484) D1 D15 D39 D63\n",
      "error(0.0008111769999999999484) D1 D15 D63\n",
      "error(0.001202373919938061562) D1 D17 D25 D37 D61\n",
      "error(0.0008111769999999999484) D1 D17 D25 D39 D63\n",
      "error(0.001202373919938061562) D1 D17 D25 D49 D61\n",
      "error(0.0008111769999999999484) D1 D17 D25 D49 D63\n",
      "error(0.001199944231680439037) D1 D17 D29 D39 D63\n",
      "error(0.001199944231680439037) D1 D17 D29 D53 D63\n",
      "error(0.03462211211382151127) D1 D25\n",
      "error(0.0009719279513609105489) D1 D25 D37 D39 D61 D63\n",
      "error(0.03462211211382151127) D1 D25 D49\n",
      "error(0.0009719279513609105489) D1 D25 D49 D61 D63\n",
      "error(3.533390243903300872e-05) D1 D29\n",
      "error(3.533390243903300872e-05) D1 D29 D53\n",
      "error(0.001199944231680439037) D1 D37 D39 D61 D63\n",
      "error(0.001199944231680439037) D1 D61 D63\n",
      "error(0.01518812029307977512) D2\n",
      "error(0.008689897102474961055) D2 D5\n",
      "error(0.006324350070450102633) D2 D5 D15\n",
      "error(0.008387372117264965676) D2 D15\n",
      "error(0.002811736665244366114) D2 D15 D26\n",
      "error(0.002811736665244366114) D2 D15 D26 D50\n",
      "error(0.03672910311271491979) D2 D26\n",
      "error(0.03672910311271491979) D2 D26 D50\n",
      "error(0.0009641219999999999825) D3 D6 D16 D40 D64 D120\n",
      "error(0.0009641219999999999825) D3 D6 D16 D64 D120\n",
      "error(0.006324350070450102633) D3 D6 D16 D120\n",
      "error(0.00119432355693597776) D3 D6 D40 D64 D120\n",
      "error(0.00119432355693597776) D3 D6 D64 D120\n",
      "error(0.01202750782914281495) D3 D6 D120\n",
      "error(0.00119432355693597776) D3 D16 D24\n",
      "error(0.0008111769999999999484) D3 D16 D24 D40 D64\n",
      "error(0.00119432355693597776) D3 D16 D24 D48\n",
      "error(0.0008111769999999999484) D3 D16 D24 D48 D64\n",
      "error(0.00505638560191517053) D3 D24\n",
      "error(0.002248862417431721477) D3 D24 D40 D64\n",
      "error(0.00505638560191517053) D3 D24 D48\n",
      "error(0.002248862417431721477) D3 D24 D48 D64\n",
      "error(0.03867423549876519706) D3 D27\n",
      "error(0.002819760924368204524) D3 D27 D40 D64\n",
      "error(0.03867423549876519706) D3 D27 D51\n",
      "error(0.002819760924368204524) D3 D27 D51 D64\n",
      "error(0.001199944231680439037) D3 D30 D40 D64 D120\n",
      "error(0.001199944231680439037) D3 D30 D54 D64 D120\n",
      "error(3.533390243903300872e-05) D3 D30 D54 D120\n",
      "error(3.533390243903300872e-05) D3 D30 D120\n",
      "error(0.000119918626875832005) D4\n",
      "error(0.006324350070450102633) D4 D6 D16 D18 D120\n",
      "error(0.008689897102474961055) D4 D6 D120\n",
      "error(0.006324350070450102633) D4 D7 D17 D18 D120\n",
      "error(0.0009641219999999999825) D4 D7 D17 D41 D65 D120\n",
      "error(0.0009641219999999999825) D4 D7 D17 D65 D120\n",
      "error(0.00119432355693597776) D4 D7 D18 D41 D65 D120\n",
      "error(0.00119432355693597776) D4 D7 D18 D65 D120\n",
      "error(0.01202750782914281495) D4 D7 D120\n",
      "error(0.00119432355693597776) D4 D14 D17 D25\n",
      "error(0.00119432355693597776) D4 D14 D17 D25 D49\n",
      "error(0.0008111769999999999484) D4 D14 D25 D38 D62\n",
      "error(0.001199944231680439037) D4 D14 D25 D41 D65\n",
      "error(0.0008111769999999999484) D4 D14 D25 D49 D62\n",
      "error(0.001199944231680439037) D4 D14 D25 D49 D65\n",
      "error(0.001202373919938061562) D4 D14 D38 D62\n",
      "error(0.001202373919938061562) D4 D14 D62\n",
      "error(0.0009641219999999999825) D4 D16 D18 D28\n",
      "error(0.0009641219999999999825) D4 D16 D18 D28 D52\n",
      "error(0.0008111769999999999484) D4 D16 D28 D38 D62\n",
      "error(0.0008111769999999999484) D4 D16 D28 D52 D62\n",
      "error(0.0008111769999999999484) D4 D17 D25 D41 D65\n",
      "error(0.0008111769999999999484) D4 D17 D25 D49 D65\n",
      "error(0.001202373919938061562) D4 D18 D28 D38 D62\n",
      "error(0.0008111769999999999484) D4 D18 D28 D41 D65\n",
      "error(0.001202373919938061562) D4 D18 D28 D52 D62\n",
      "error(0.0008111769999999999484) D4 D18 D28 D52 D65\n",
      "error(0.001199944231680439037) D4 D18 D31 D41 D65 D120\n",
      "error(0.001199944231680439037) D4 D18 D31 D55 D65 D120\n",
      "error(0.003421821825422323611) D4 D25\n",
      "error(0.001199944231680439037) D4 D25 D38 D41 D62 D65\n",
      "error(0.003421821825422323611) D4 D25 D49\n",
      "error(0.001199944231680439037) D4 D25 D49 D62 D65\n",
      "error(0.03462211211382151127) D4 D28\n",
      "error(0.0009719279513609105489) D4 D28 D38 D41 D62 D65\n",
      "error(0.03462211211382151127) D4 D28 D52\n",
      "error(0.0009719279513609105489) D4 D28 D52 D62 D65\n",
      "error(3.533390243903300872e-05) D4 D31 D55 D120\n",
      "error(3.533390243903300872e-05) D4 D31 D120\n",
      "error(0.000119918626875832005) D5\n",
      "error(0.006324350070450102633) D5 D7 D17 D19 D120\n",
      "error(0.008689897102474961055) D5 D7 D120\n",
      "error(0.008387372117264965676) D5 D8 D19 D120\n",
      "error(0.01518812029307977512) D5 D8 D120\n",
      "error(0.00224325356230894524) D5 D15 D26\n",
      "error(0.0008111769999999999484) D5 D15 D26 D39 D63\n",
      "error(0.00224325356230894524) D5 D15 D26 D50\n",
      "error(0.0008111769999999999484) D5 D15 D26 D50 D63\n",
      "error(0.001202373919938061562) D5 D15 D39 D63\n",
      "error(0.001202373919938061562) D5 D15 D63\n",
      "error(0.0009641219999999999825) D5 D17 D19 D29\n",
      "error(0.0009641219999999999825) D5 D17 D19 D29 D53\n",
      "error(0.0008111769999999999484) D5 D17 D29 D39 D63\n",
      "error(0.0008111769999999999484) D5 D17 D29 D53 D63\n",
      "error(0.0008111769999999999484) D5 D19 D29\n",
      "error(0.001202373919938061562) D5 D19 D29 D39 D63\n",
      "error(0.0008111769999999999484) D5 D19 D29 D53\n",
      "error(0.001202373919938061562) D5 D19 D29 D53 D63\n",
      "error(0.001199944231680439037) D5 D19 D32 D56 D120\n",
      "error(0.001199944231680439037) D5 D19 D32 D120\n",
      "error(0.00505638560191517053) D5 D26\n",
      "error(0.001199944231680439037) D5 D26 D39 D63\n",
      "error(0.00505638560191517053) D5 D26 D50\n",
      "error(0.001199944231680439037) D5 D26 D50 D63\n",
      "error(0.03462211211382151127) D5 D29\n",
      "error(0.0009719279513609105489) D5 D29 D39 D63\n",
      "error(0.03462211211382151127) D5 D29 D53\n",
      "error(0.0009719279513609105489) D5 D29 D53 D63\n",
      "error(3.533390243903300872e-05) D5 D32 D56 D120\n",
      "error(3.533390243903300872e-05) D5 D32 D120\n",
      "error(0.008689897102474961055) D6 D9\n",
      "error(0.006324350070450102633) D6 D9 D20\n",
      "error(0.01202750782914281495) D6 D10\n",
      "error(0.006324350070450102633) D6 D10 D18 D20\n",
      "error(0.0009641219999999999825) D6 D10 D18 D42 D66\n",
      "error(0.0009641219999999999825) D6 D10 D18 D66\n",
      "error(0.00119432355693597776) D6 D10 D20 D42 D66\n",
      "error(0.00119432355693597776) D6 D10 D20 D66\n",
      "error(0.00119432355693597776) D6 D16 D18 D28 D52 D120\n",
      "error(0.00119432355693597776) D6 D16 D18 D28 D120\n",
      "error(0.001202373919938061562) D6 D16 D24 D40 D64 D120\n",
      "error(0.001202373919938061562) D6 D16 D24 D48 D64 D120\n",
      "error(0.0008111769999999999484) D6 D16 D28 D40 D64 D120\n",
      "error(0.001199944231680439037) D6 D16 D28 D42 D66 D120\n",
      "error(0.0008111769999999999484) D6 D16 D28 D52 D64 D120\n",
      "error(0.001199944231680439037) D6 D16 D28 D52 D66 D120\n",
      "error(0.0008111769999999999484) D6 D18 D28 D42 D66 D120\n",
      "error(0.0008111769999999999484) D6 D18 D28 D52 D66 D120\n",
      "error(0.0009641219999999999825) D6 D20 D30\n",
      "error(0.001202373919938061562) D6 D20 D30 D40 D64\n",
      "error(0.0008111769999999999484) D6 D20 D30 D42 D66\n",
      "error(0.0009641219999999999825) D6 D20 D30 D54\n",
      "error(0.001202373919938061562) D6 D20 D30 D54 D64\n",
      "error(0.0008111769999999999484) D6 D20 D30 D54 D66\n",
      "error(0.001199944231680439037) D6 D20 D34 D42 D66\n",
      "error(0.001199944231680439037) D6 D20 D34 D58 D66\n",
      "error(5.996290898837034546e-05) D6 D24 D48 D120\n",
      "error(5.996290898837034546e-05) D6 D24 D120\n",
      "error(0.001199944231680439037) D6 D28 D40 D42 D64 D66 D120\n",
      "error(0.001199944231680439037) D6 D28 D52 D64 D66 D120\n",
      "error(0.003421821825422323611) D6 D28 D52 D120\n",
      "error(0.003421821825422323611) D6 D28 D120\n",
      "error(0.03462211211382151127) D6 D30\n",
      "error(0.0009719279513609105489) D6 D30 D40 D42 D64 D66\n",
      "error(0.0008111769999999999484) D6 D30 D40 D64\n",
      "error(0.03462211211382151127) D6 D30 D54\n",
      "error(0.0008111769999999999484) D6 D30 D54 D64\n",
      "error(0.0009719279513609105489) D6 D30 D54 D64 D66\n",
      "error(3.533390243903300872e-05) D6 D34\n",
      "error(3.533390243903300872e-05) D6 D34 D58\n",
      "error(0.008689897102474961055) D7 D10\n",
      "error(0.006324350070450102633) D7 D10 D18 D21\n",
      "error(0.01202750782914281495) D7 D11\n",
      "error(0.006324350070450102633) D7 D11 D19 D21\n",
      "error(0.0009641219999999999825) D7 D11 D19 D43 D67\n",
      "error(0.0009641219999999999825) D7 D11 D19 D67\n",
      "error(0.00119432355693597776) D7 D11 D21 D43 D67\n",
      "error(0.00119432355693597776) D7 D11 D21 D67\n",
      "error(0.00119432355693597776) D7 D17 D19 D29 D53 D120\n",
      "error(0.00119432355693597776) D7 D17 D19 D29 D120\n",
      "error(0.001202373919938061562) D7 D17 D25 D41 D65 D120\n",
      "error(0.001202373919938061562) D7 D17 D25 D49 D65 D120\n",
      "error(0.0008111769999999999484) D7 D17 D29 D41 D65 D120\n",
      "error(0.001199944231680439037) D7 D17 D29 D43 D67 D120\n",
      "error(0.0008111769999999999484) D7 D17 D29 D53 D65 D120\n",
      "error(0.001199944231680439037) D7 D17 D29 D53 D67 D120\n",
      "error(0.0009641219999999999825) D7 D18 D21 D31\n",
      "error(0.0009641219999999999825) D7 D18 D21 D31 D55\n",
      "error(0.0008111769999999999484) D7 D18 D31 D41 D65\n",
      "error(0.0008111769999999999484) D7 D18 D31 D55 D65\n",
      "error(0.0008111769999999999484) D7 D19 D29 D43 D67 D120\n",
      "error(0.0008111769999999999484) D7 D19 D29 D53 D67 D120\n",
      "error(0.001202373919938061562) D7 D21 D31 D41 D65\n",
      "error(0.0008111769999999999484) D7 D21 D31 D43 D67\n",
      "error(0.001202373919938061562) D7 D21 D31 D55 D65\n",
      "error(0.0008111769999999999484) D7 D21 D31 D55 D67\n",
      "error(0.001199944231680439037) D7 D21 D35 D43 D67\n",
      "error(0.001199944231680439037) D7 D21 D35 D59 D67\n",
      "error(5.996290898837034546e-05) D7 D25 D49 D120\n",
      "error(5.996290898837034546e-05) D7 D25 D120\n",
      "error(0.001199944231680439037) D7 D29 D41 D43 D65 D67 D120\n",
      "error(0.001199944231680439037) D7 D29 D53 D65 D67 D120\n",
      "error(0.003421821825422323611) D7 D29 D53 D120\n",
      "error(0.003421821825422323611) D7 D29 D120\n",
      "error(0.03462211211382151127) D7 D31\n",
      "error(0.0009719279513609105489) D7 D31 D41 D43 D65 D67\n",
      "error(0.03462211211382151127) D7 D31 D55\n",
      "error(0.0009719279513609105489) D7 D31 D55 D65 D67\n",
      "error(3.533390243903300872e-05) D7 D35\n",
      "error(3.533390243903300872e-05) D7 D35 D59\n",
      "error(0.008689897102474961055) D8 D11\n",
      "error(0.006324350070450102633) D8 D11 D19\n",
      "error(0.002811736665244366114) D8 D19 D32\n",
      "error(0.002811736665244366114) D8 D19 D32 D56\n",
      "error(0.03672910311271491979) D8 D32\n",
      "error(0.03672910311271491979) D8 D32 D56\n",
      "error(0.0129307524305464043) D9\n",
      "error(0.006324350070450102633) D9 D20\n",
      "error(0.00119432355693597776) D9 D20 D30\n",
      "error(0.0008111769999999999484) D9 D20 D30 D44 D68\n",
      "error(0.00119432355693597776) D9 D20 D30 D54\n",
      "error(0.0008111769999999999484) D9 D20 D30 D54 D68\n",
      "error(0.0009641219999999999825) D9 D20 D44 D68\n",
      "error(0.0009641219999999999825) D9 D20 D68\n",
      "error(0.00505638560191517053) D9 D30\n",
      "error(0.002248862417431721477) D9 D30 D44 D68\n",
      "error(0.00505638560191517053) D9 D30 D54\n",
      "error(0.002248862417431721477) D9 D30 D54 D68\n",
      "error(0.03867423549876519706) D9 D33\n",
      "error(0.002819760924368204524) D9 D33 D44 D68\n",
      "error(0.03867423549876519706) D9 D33 D57\n",
      "error(0.002819760924368204524) D9 D33 D57 D68\n",
      "error(0.00224325356230894524) D9 D44 D68\n",
      "error(0.00224325356230894524) D9 D68\n",
      "error(0.02139591571686330629) D10\n",
      "error(0.00119432355693597776) D10 D18 D21 D31\n",
      "error(0.00119432355693597776) D10 D18 D21 D31 D55\n",
      "error(0.001202373919938061562) D10 D18 D28 D42 D66 D120\n",
      "error(0.001202373919938061562) D10 D18 D28 D52 D66 D120\n",
      "error(0.0008111769999999999484) D10 D18 D31 D42 D66\n",
      "error(0.001199944231680439037) D10 D18 D31 D45 D69\n",
      "error(0.0008111769999999999484) D10 D18 D31 D55 D66\n",
      "error(0.001199944231680439037) D10 D18 D31 D55 D69\n",
      "error(0.006324350070450102633) D10 D20 D22\n",
      "error(0.0009641219999999999825) D10 D20 D22 D34\n",
      "error(0.0009641219999999999825) D10 D20 D22 D34 D58\n",
      "error(0.0008111769999999999484) D10 D20 D34 D42 D66\n",
      "error(0.0008111769999999999484) D10 D20 D34 D58 D66\n",
      "error(0.006324350070450102633) D10 D21 D22\n",
      "error(0.0008111769999999999484) D10 D21 D31 D45 D69\n",
      "error(0.0008111769999999999484) D10 D21 D31 D55 D69\n",
      "error(0.0009641219999999999825) D10 D21 D45 D69\n",
      "error(0.0009641219999999999825) D10 D21 D69\n",
      "error(0.001202373919938061562) D10 D22 D34 D42 D66\n",
      "error(0.0008111769999999999484) D10 D22 D34 D45 D69\n",
      "error(0.001202373919938061562) D10 D22 D34 D58 D66\n",
      "error(0.0008111769999999999484) D10 D22 D34 D58 D69\n",
      "error(0.00224325356230894524) D10 D22 D45 D69\n",
      "error(0.00224325356230894524) D10 D22 D69\n",
      "error(5.996290898837034546e-05) D10 D28 D52 D120\n",
      "error(5.996290898837034546e-05) D10 D28 D120\n",
      "error(0.003421821825422323611) D10 D31\n",
      "error(0.001199944231680439037) D10 D31 D42 D45 D66 D69\n",
      "error(0.003421821825422323611) D10 D31 D55\n",
      "error(0.001199944231680439037) D10 D31 D55 D66 D69\n",
      "error(0.03462211211382151127) D10 D34\n",
      "error(0.0009719279513609105489) D10 D34 D42 D45 D66 D69\n",
      "error(0.03462211211382151127) D10 D34 D58\n",
      "error(0.0009719279513609105489) D10 D34 D58 D66 D69\n",
      "error(0.02449584872199421157) D11\n",
      "error(0.001202373919938061562) D11 D19 D29 D43 D67 D120\n",
      "error(0.001202373919938061562) D11 D19 D29 D53 D67 D120\n",
      "error(0.00224325356230894524) D11 D19 D32\n",
      "error(0.0008111769999999999484) D11 D19 D32 D43 D67\n",
      "error(0.00224325356230894524) D11 D19 D32 D56\n",
      "error(0.0008111769999999999484) D11 D19 D32 D56 D67\n",
      "error(0.006324350070450102633) D11 D21 D23\n",
      "error(0.0009641219999999999825) D11 D21 D23 D35\n",
      "error(0.0009641219999999999825) D11 D21 D23 D35 D59\n",
      "error(0.0008111769999999999484) D11 D21 D35 D43 D67\n",
      "error(0.0008111769999999999484) D11 D21 D35 D59 D67\n",
      "error(0.01045280587949759359) D11 D23\n",
      "error(0.0008111769999999999484) D11 D23 D35\n",
      "error(0.001202373919938061562) D11 D23 D35 D43 D67\n",
      "error(0.0008111769999999999484) D11 D23 D35 D59\n",
      "error(0.001202373919938061562) D11 D23 D35 D59 D67\n",
      "error(5.996290898837034546e-05) D11 D29 D53 D120\n",
      "error(5.996290898837034546e-05) D11 D29 D120\n",
      "error(0.00505638560191517053) D11 D32\n",
      "error(0.001199944231680439037) D11 D32 D43 D67\n",
      "error(0.00505638560191517053) D11 D32 D56\n",
      "error(0.001199944231680439037) D11 D32 D56 D67\n",
      "error(0.03462211211382151127) D11 D35\n",
      "error(0.0009719279513609105489) D11 D35 D43 D67\n",
      "error(0.03462211211382151127) D11 D35 D59\n",
      "error(0.0009719279513609105489) D11 D35 D59 D67\n",
      "error(0.008689897102474961055) D12\n",
      "error(0.01518812029307977339) D12 D14\n",
      "error(0.03769207688554708502) D12 D36 D60\n",
      "error(3.533390243903300872e-05) D12 D38 D62\n",
      "error(0.03769207688554708502) D12 D60\n",
      "error(3.533390243903300872e-05) D12 D62\n",
      "error(0.008689897102474961055) D13 D14\n",
      "error(0.01518812029307977339) D13 D15\n",
      "error(0.03769207688554708502) D13 D37 D61\n",
      "error(3.533390243903300872e-05) D13 D39 D63\n",
      "error(0.03769207688554708502) D13 D61\n",
      "error(3.533390243903300872e-05) D13 D63\n",
      "error(0.008689897102474961055) D14 D16\n",
      "error(0.01202750782914281495) D14 D17\n",
      "error(0.002248862417431721477) D14 D25 D37 D61\n",
      "error(0.0009719279513609105489) D14 D25 D38 D62\n",
      "error(0.002248862417431721477) D14 D25 D49 D61\n",
      "error(0.0009719279513609105489) D14 D25 D49 D62\n",
      "error(0.00505638560191517053) D14 D37 D61\n",
      "error(0.03462211211382151127) D14 D38 D62\n",
      "error(3.533390243903300872e-05) D14 D41 D65\n",
      "error(0.00505638560191517053) D14 D61\n",
      "error(0.03462211211382151127) D14 D62\n",
      "error(3.533390243903300872e-05) D14 D65\n",
      "error(0.03184729296249200203) D15\n",
      "error(0.008689897102474961055) D15 D17\n",
      "error(0.002248862417431721477) D15 D26\n",
      "error(0.0009719279513609105489) D15 D26 D39 D63\n",
      "error(0.002248862417431721477) D15 D26 D50\n",
      "error(0.0009719279513609105489) D15 D26 D50 D63\n",
      "error(0.03462211211382151127) D15 D39 D63\n",
      "error(0.03462211211382151127) D15 D63\n",
      "error(0.02050836932074884614) D16\n",
      "error(0.01202750782914281495) D16 D18\n",
      "error(0.001199944231680439037) D16 D24 D28 D38 D62\n",
      "error(0.0009719279513609105489) D16 D24 D28 D40 D64\n",
      "error(0.001199944231680439037) D16 D24 D28 D48 D52 D62\n",
      "error(0.0009719279513609105489) D16 D24 D28 D48 D52 D64\n",
      "error(5.996290898837034546e-05) D16 D36 D60\n",
      "error(0.003421821825422323611) D16 D38 D62\n",
      "error(0.03462211211382151127) D16 D40 D64\n",
      "error(3.533390243903300872e-05) D16 D42 D66\n",
      "error(5.996290898837034546e-05) D16 D60\n",
      "error(0.003421821825422323611) D16 D62\n",
      "error(0.03462211211382151127) D16 D64\n",
      "error(3.533390243903300872e-05) D16 D66\n",
      "error(0.008689897102474961055) D17 D18\n",
      "error(0.01202750782914281495) D17 D19\n",
      "error(0.001199944231680439037) D17 D25 D29 D39 D63\n",
      "error(0.0009719279513609105489) D17 D25 D29 D41 D65\n",
      "error(0.001199944231680439037) D17 D25 D29 D49 D53 D63\n",
      "error(0.0009719279513609105489) D17 D25 D29 D49 D53 D65\n",
      "error(5.996290898837034546e-05) D17 D37 D61\n",
      "error(0.003421821825422323611) D17 D39 D63\n",
      "error(0.03462211211382151127) D17 D41 D65\n",
      "error(3.533390243903300872e-05) D17 D43 D67\n",
      "error(5.996290898837034546e-05) D17 D61\n",
      "error(0.003421821825422323611) D17 D63\n",
      "error(0.03462211211382151127) D17 D65\n",
      "error(3.533390243903300872e-05) D17 D67\n",
      "error(0.008689897102474961055) D18 D20\n",
      "error(0.01202750782914281495) D18 D21\n",
      "error(0.001199944231680439037) D18 D28 D31 D41 D65 D120\n",
      "error(0.0009719279513609105489) D18 D28 D31 D42 D66 D120\n",
      "error(0.001199944231680439037) D18 D28 D31 D52 D55 D65 D120\n",
      "error(0.0009719279513609105489) D18 D28 D31 D52 D55 D66 D120\n",
      "error(5.996290898837034546e-05) D18 D38 D62\n",
      "error(0.003421821825422323611) D18 D41 D65\n",
      "error(0.03462211211382151127) D18 D42 D66\n",
      "error(3.533390243903300872e-05) D18 D45 D69\n",
      "error(5.996290898837034546e-05) D18 D62\n",
      "error(0.003421821825422323611) D18 D65\n",
      "error(0.03462211211382151127) D18 D66\n",
      "error(3.533390243903300872e-05) D18 D69\n",
      "error(0.02875001471630827393) D19\n",
      "error(0.008689897102474961055) D19 D21\n",
      "error(0.0009719279513609105489) D19 D29 D32 D43 D67 D120\n",
      "error(0.0009719279513609105489) D19 D29 D32 D53 D56 D67 D120\n",
      "error(0.001199944231680439037) D19 D29 D32 D53 D56 D120\n",
      "error(0.001199944231680439037) D19 D29 D32 D120\n",
      "error(5.996290898837034546e-05) D19 D39 D63\n",
      "error(0.03462211211382151127) D19 D43 D67\n",
      "error(5.996290898837034546e-05) D19 D63\n",
      "error(0.03462211211382151127) D19 D67\n",
      "error(0.02050836932074884614) D20\n",
      "error(0.01202750782914281495) D20 D22\n",
      "error(0.00119432355693597776) D20 D22 D34\n",
      "error(0.00119432355693597776) D20 D22 D34 D58\n",
      "error(0.001199944231680439037) D20 D30 D34 D42 D66\n",
      "error(0.0009719279513609105489) D20 D30 D34 D44 D68\n",
      "error(0.001199944231680439037) D20 D30 D34 D54 D58 D66\n",
      "error(0.0009719279513609105489) D20 D30 D34 D54 D58 D68\n",
      "error(0.001202373919938061562) D20 D30 D44 D68\n",
      "error(0.001202373919938061562) D20 D30 D54 D68\n",
      "error(0.0008111769999999999484) D20 D34 D44 D68\n",
      "error(0.001199944231680439037) D20 D34 D46 D70\n",
      "error(0.0008111769999999999484) D20 D34 D58 D68\n",
      "error(0.001199944231680439037) D20 D34 D58 D70\n",
      "error(5.996290898837034546e-05) D20 D40 D64\n",
      "error(0.003421821825422323611) D20 D42 D66\n",
      "error(0.03462211211382151127) D20 D44 D68\n",
      "error(3.533390243903300872e-05) D20 D46 D70\n",
      "error(5.996290898837034546e-05) D20 D64\n",
      "error(0.003421821825422323611) D20 D66\n",
      "error(0.03462211211382151127) D20 D68\n",
      "error(3.533390243903300872e-05) D20 D70\n",
      "error(0.008689897102474961055) D21 D22\n",
      "error(0.01202750782914281495) D21 D23\n",
      "error(0.00119432355693597776) D21 D23 D35\n",
      "error(0.00119432355693597776) D21 D23 D35 D59\n",
      "error(0.001199944231680439037) D21 D31 D35 D43 D67\n",
      "error(0.0009719279513609105489) D21 D31 D35 D45 D69\n",
      "error(0.001199944231680439037) D21 D31 D35 D55 D59 D67\n",
      "error(0.0009719279513609105489) D21 D31 D35 D55 D59 D69\n",
      "error(0.001202373919938061562) D21 D31 D45 D69\n",
      "error(0.001202373919938061562) D21 D31 D55 D69\n",
      "error(0.0008111769999999999484) D21 D35 D45 D69\n",
      "error(0.001199944231680439037) D21 D35 D47 D71\n",
      "error(0.0008111769999999999484) D21 D35 D59 D69\n",
      "error(0.001199944231680439037) D21 D35 D59 D71\n",
      "error(5.996290898837034546e-05) D21 D41 D65\n",
      "error(0.003421821825422323611) D21 D43 D67\n",
      "error(0.03462211211382151127) D21 D45 D69\n",
      "error(3.533390243903300872e-05) D21 D47 D71\n",
      "error(5.996290898837034546e-05) D21 D65\n",
      "error(0.003421821825422323611) D21 D67\n",
      "error(0.03462211211382151127) D21 D69\n",
      "error(3.533390243903300872e-05) D21 D71\n",
      "error(0.001199944231680439037) D22 D34 D45 D69\n",
      "error(0.002831892277135027083) D22 D34 D46 D70\n",
      "error(0.001199944231680439037) D22 D34 D58 D69\n",
      "error(0.002831892277135027083) D22 D34 D58 D70\n",
      "error(5.996290898837034546e-05) D22 D42 D66\n",
      "error(0.00505638560191517053) D22 D45 D69\n",
      "error(0.03768461544947518393) D22 D46 D70\n",
      "error(5.996290898837034546e-05) D22 D66\n",
      "error(0.00505638560191517053) D22 D69\n",
      "error(0.03768461544947518393) D22 D70\n",
      "error(0.01939986355008675029) D23\n",
      "error(0.001199944231680439037) D23 D35\n",
      "error(0.002831892277135027083) D23 D35 D47 D71\n",
      "error(0.001199944231680439037) D23 D35 D59\n",
      "error(0.002831892277135027083) D23 D35 D59 D71\n",
      "error(5.996290898837034546e-05) D23 D43 D67\n",
      "error(0.03768461544947518393) D23 D47 D71\n",
      "error(5.996290898837034546e-05) D23 D67\n",
      "error(0.03768461544947518393) D23 D71\n",
      "error(0.02507861867728015254) D24\n",
      "error(0.006187131910145781018) D24 D27\n",
      "error(0.002479270967218732621) D24 D27 D40\n",
      "error(0.003614660733537251782) D24 D27 D40 D64\n",
      "error(0.0001216513276332629453) D24 D27 D48 D51\n",
      "error(0.002578335221013760854) D24 D27 D48 D51 D64\n",
      "error(0.002429585086292254323) D24 D27 D64\n",
      "error(0.00956429784429518523) D24 D28\n",
      "error(0.0009641219999999999825) D24 D28 D38\n",
      "error(0.001440575051525734996) D24 D28 D38 D40\n",
      "error(0.002578335221013760854) D24 D28 D38 D40 D62 D64\n",
      "error(0.00119432355693597776) D24 D28 D40\n",
      "error(0.001884617003200650572) D24 D28 D48 D52\n",
      "error(0.003614660733537251782) D24 D28 D48 D52 D62 D64\n",
      "error(0.002429585086292254323) D24 D28 D62 D64\n",
      "error(0.004244210681387279929) D24 D36\n",
      "error(0.003519904408972179821) D24 D36 D38\n",
      "error(0.003614660733537251782) D24 D36 D38 D60 D62\n",
      "error(0.004668174745529686358) D24 D36 D60\n",
      "error(0.002009174497356395507) D24 D38\n",
      "error(0.001202373919938061562) D24 D38 D73 D97\n",
      "error(0.001773734852816811862) D24 D40 D72 D96\n",
      "error(0.004054888927391973527) D24 D48\n",
      "error(0.00570014629808382467) D24 D48 D60\n",
      "error(0.002578335221013760854) D24 D48 D60 D62\n",
      "error(0.002429585086292254323) D24 D60\n",
      "error(0.002429585086292254323) D24 D60 D62\n",
      "error(0.0374018142016616234) D24 D72 D96\n",
      "error(5.996290898837034546e-05) D24 D73 D97\n",
      "error(0.02141027830717885314) D25\n",
      "error(0.006187131910145781018) D25 D28\n",
      "error(0.002479270967218732621) D25 D28 D38 D41\n",
      "error(0.003614660733537251782) D25 D28 D38 D41 D62 D65\n",
      "error(0.0001216513276332629453) D25 D28 D49 D52\n",
      "error(0.002578335221013760854) D25 D28 D49 D52 D62 D65\n",
      "error(0.002429585086292254323) D25 D28 D62 D65\n",
      "error(0.00956429784429518523) D25 D29\n",
      "error(0.0009641219999999999825) D25 D29 D39\n",
      "error(0.001440575051525734996) D25 D29 D39 D41\n",
      "error(0.002578335221013760854) D25 D29 D39 D41 D63 D65\n",
      "error(0.00119432355693597776) D25 D29 D41\n",
      "error(0.001884617003200650572) D25 D29 D49 D53\n",
      "error(0.003614660733537251782) D25 D29 D49 D53 D63 D65\n",
      "error(0.002429585086292254323) D25 D29 D63 D65\n",
      "error(0.002811736665244366114) D25 D37\n",
      "error(0.001440575051525734996) D25 D37 D38\n",
      "error(0.002578335221013760854) D25 D37 D38 D61 D62\n",
      "error(0.003519904408972179821) D25 D37 D39\n",
      "error(0.003614660733537251782) D25 D37 D39 D61 D63\n",
      "error(0.00224325356230894524) D25 D38\n",
      "error(0.0009641219999999999825) D25 D38 D41 D73 D97\n",
      "error(0.002011600243799554436) D25 D38 D73 D97\n",
      "error(0.002009174497356395507) D25 D39\n",
      "error(0.001202373919938061562) D25 D39 D74 D98\n",
      "error(0.0008111769999999999484) D25 D41 D73 D97\n",
      "error(0.002466920737643780743) D25 D49\n",
      "error(0.003614660733537251782) D25 D49 D61 D62\n",
      "error(0.002578335221013760854) D25 D49 D61 D63\n",
      "error(0.002429585086292254323) D25 D61 D62\n",
      "error(0.002429585086292254323) D25 D61 D63\n",
      "error(0.03552995535965992879) D25 D73 D97\n",
      "error(5.996290898837034546e-05) D25 D74 D98\n",
      "error(0.012060020749347573) D26\n",
      "error(0.006187131910145781018) D26 D29\n",
      "error(0.002479270967218732621) D26 D29 D39\n",
      "error(0.003614660733537251782) D26 D29 D39 D63\n",
      "error(0.0001216513276332629453) D26 D29 D50 D53\n",
      "error(0.002578335221013760854) D26 D29 D50 D53 D63\n",
      "error(0.002429585086292254323) D26 D29 D63\n",
      "error(0.003529600337672062112) D26 D39\n",
      "error(0.002578335221013760854) D26 D39 D63\n",
      "error(0.002823868213805612315) D26 D39 D74 D98\n",
      "error(0.002345840159150069069) D26 D50\n",
      "error(0.003614660733537251782) D26 D50 D63\n",
      "error(0.002429585086292254323) D26 D63\n",
      "error(0.03769207688554708502) D26 D74 D98\n",
      "error(0.003624354811708633238) D27 D30 D40 D64 D120\n",
      "error(0.00240191927132608115) D27 D30 D40 D120\n",
      "error(0.004658501052871038932) D27 D30 D51 D54 D64 D120\n",
      "error(0.003474443722251936446) D27 D30 D51 D54 D120\n",
      "error(0.002429585086292254323) D27 D30 D64 D120\n",
      "error(0.01229785584538853511) D27 D30 D120\n",
      "error(0.003050791210919119589) D27 D40 D72 D96\n",
      "error(0.001202373919938061562) D27 D40 D76 D100\n",
      "error(0.006244697596347516949) D27 D72 D96\n",
      "error(0.04030873898622133744) D27 D75 D99\n",
      "error(5.996290898837034546e-05) D27 D76 D100\n",
      "error(0.003614660733537251782) D28 D30 D40 D42 D64 D66 D120\n",
      "error(0.002479270967218732621) D28 D30 D40 D42 D120\n",
      "error(0.002578335221013760854) D28 D30 D52 D54 D64 D66 D120\n",
      "error(0.0001216513276332629453) D28 D30 D52 D54 D120\n",
      "error(0.002429585086292254323) D28 D30 D64 D66 D120\n",
      "error(0.006187131910145781018) D28 D30 D120\n",
      "error(0.002578335221013760854) D28 D31 D41 D42 D65 D66 D120\n",
      "error(0.001440575051525734996) D28 D31 D41 D42 D120\n",
      "error(0.0009641219999999999825) D28 D31 D41 D120\n",
      "error(0.00119432355693597776) D28 D31 D42 D120\n",
      "error(0.003614660733537251782) D28 D31 D52 D55 D65 D66 D120\n",
      "error(0.001884617003200650572) D28 D31 D52 D55 D120\n",
      "error(0.002429585086292254323) D28 D31 D65 D66 D120\n",
      "error(0.00956429784429518523) D28 D31 D120\n",
      "error(0.00119432355693597776) D28 D38 D41 D73 D97\n",
      "error(0.0008111769999999999484) D28 D38 D73 D97\n",
      "error(0.0009641219999999999825) D28 D40 D42 D76 D100\n",
      "error(0.001199944231680439037) D28 D40 D72 D96\n",
      "error(0.002011600243799554436) D28 D40 D76 D100\n",
      "error(0.002009174497356395507) D28 D41 D73 D97\n",
      "error(0.001202373919938061562) D28 D41 D77 D101\n",
      "error(0.0008111769999999999484) D28 D42 D76 D100\n",
      "error(3.533390243903300872e-05) D28 D72 D96\n",
      "error(0.004614058250203434235) D28 D73 D97\n",
      "error(0.03552995535965992879) D28 D76 D100\n",
      "error(5.996290898837034546e-05) D28 D77 D101\n",
      "error(0.003614660733537251782) D29 D31 D41 D43 D65 D67 D120\n",
      "error(0.002479270967218732621) D29 D31 D41 D43 D120\n",
      "error(0.002578335221013760854) D29 D31 D53 D55 D65 D67 D120\n",
      "error(0.0001216513276332629453) D29 D31 D53 D55 D120\n",
      "error(0.002429585086292254323) D29 D31 D65 D67 D120\n",
      "error(0.006187131910145781018) D29 D31 D120\n",
      "error(0.002578335221013760854) D29 D32 D43 D67 D120\n",
      "error(0.002483381069500848436) D29 D32 D43 D120\n",
      "error(0.003614660733537251782) D29 D32 D53 D56 D67 D120\n",
      "error(0.001884617003200650572) D29 D32 D53 D56 D120\n",
      "error(0.002429585086292254323) D29 D32 D67 D120\n",
      "error(0.01115516142130245844) D29 D32 D120\n",
      "error(0.00200356294133608847) D29 D39 D74 D98\n",
      "error(0.0009641219999999999825) D29 D41 D43 D77 D101\n",
      "error(0.001199944231680439037) D29 D41 D73 D97\n",
      "error(0.002011600243799554436) D29 D41 D77 D101\n",
      "error(0.0008111769999999999484) D29 D43 D77 D101\n",
      "error(3.533390243903300872e-05) D29 D73 D97\n",
      "error(0.007283007255725086268) D29 D74 D98\n",
      "error(0.03552995535965992879) D29 D77 D101\n",
      "error(5.996290898837034546e-05) D30\n",
      "error(0.006187131910145781018) D30 D33\n",
      "error(0.002479270967218732621) D30 D33 D44\n",
      "error(0.003614660733537251782) D30 D33 D44 D68\n",
      "error(0.0001216513276332629453) D30 D33 D54 D57\n",
      "error(0.002578335221013760854) D30 D33 D54 D57 D68\n",
      "error(0.002429585086292254323) D30 D33 D68\n",
      "error(0.00956429784429518523) D30 D34\n",
      "error(0.0009641219999999999825) D30 D34 D42\n",
      "error(0.001440575051525734996) D30 D34 D42 D44\n",
      "error(0.002578335221013760854) D30 D34 D42 D44 D66 D68\n",
      "error(0.00119432355693597776) D30 D34 D44\n",
      "error(0.001884617003200650572) D30 D34 D54 D58\n",
      "error(0.003614660733537251782) D30 D34 D54 D58 D66 D68\n",
      "error(0.002429585086292254323) D30 D34 D66 D68\n",
      "error(0.00119432355693597776) D30 D40 D42 D76 D100 D120\n",
      "error(0.0008111769999999999484) D30 D40 D76 D100 D120\n",
      "error(0.002009174497356395507) D30 D42 D76 D100 D120\n",
      "error(0.001202373919938061562) D30 D42 D79 D103\n",
      "error(0.001773734852816811862) D30 D44 D78 D102\n",
      "error(5.996290898837034546e-05) D30 D54\n",
      "error(0.001235200643432510497) D30 D75 D99 D120\n",
      "error(0.004614058250203434235) D30 D76 D100 D120\n",
      "error(0.0374018142016616234) D30 D78 D102\n",
      "error(5.996290898837034546e-05) D30 D79 D103\n",
      "error(5.996290898837034546e-05) D31\n",
      "error(0.006187131910145781018) D31 D34\n",
      "error(0.002479270967218732621) D31 D34 D42 D45\n",
      "error(0.003614660733537251782) D31 D34 D42 D45 D66 D69\n",
      "error(0.0001216513276332629453) D31 D34 D55 D58\n",
      "error(0.002578335221013760854) D31 D34 D55 D58 D66 D69\n",
      "error(0.002429585086292254323) D31 D34 D66 D69\n",
      "error(0.00956429784429518523) D31 D35\n",
      "error(0.0009641219999999999825) D31 D35 D43\n",
      "error(0.001440575051525734996) D31 D35 D43 D45\n",
      "error(0.002578335221013760854) D31 D35 D43 D45 D67 D69\n",
      "error(0.00119432355693597776) D31 D35 D45\n",
      "error(0.001884617003200650572) D31 D35 D55 D59\n",
      "error(0.003614660733537251782) D31 D35 D55 D59 D67 D69\n",
      "error(0.002429585086292254323) D31 D35 D67 D69\n",
      "error(0.00119432355693597776) D31 D41 D43 D77 D101 D120\n",
      "error(0.0008111769999999999484) D31 D41 D77 D101 D120\n",
      "error(0.0009641219999999999825) D31 D42 D45 D79 D103\n",
      "error(0.001199944231680439037) D31 D42 D76 D100 D120\n",
      "error(0.002011600243799554436) D31 D42 D79 D103\n",
      "error(0.002009174497356395507) D31 D43 D77 D101 D120\n",
      "error(0.001202373919938061562) D31 D43 D80 D104\n",
      "error(0.0008111769999999999484) D31 D45 D79 D103\n",
      "error(5.996290898837034546e-05) D31 D55\n",
      "error(3.533390243903300872e-05) D31 D76 D100 D120\n",
      "error(0.004614058250203434235) D31 D77 D101 D120\n",
      "error(0.03552995535965992879) D31 D79 D103\n",
      "error(5.996290898837034546e-05) D31 D80 D104\n",
      "error(0.006187131910145781018) D32 D35\n",
      "error(0.002479270967218732621) D32 D35 D43\n",
      "error(0.003614660733537251782) D32 D35 D43 D67\n",
      "error(0.0001216513276332629453) D32 D35 D56 D59\n",
      "error(0.002578335221013760854) D32 D35 D56 D59 D67\n",
      "error(0.002429585086292254323) D32 D35 D67\n",
      "error(0.001199944231680439037) D32 D43 D77 D101 D120\n",
      "error(0.002823868213805612315) D32 D43 D80 D104\n",
      "error(3.533390243903300872e-05) D32 D77 D101 D120\n",
      "error(0.03769207688554708502) D32 D80 D104\n",
      "error(0.01229785584538853511) D33\n",
      "error(0.00240191927132608115) D33 D44\n",
      "error(0.003624354811708633238) D33 D44 D68\n",
      "error(0.003050791210919119589) D33 D44 D78 D102\n",
      "error(0.001202373919938061562) D33 D44 D82 D106\n",
      "error(0.003474443722251936446) D33 D57\n",
      "error(0.004658501052871038932) D33 D57 D68\n",
      "error(0.002429585086292254323) D33 D68\n",
      "error(0.006244697596347516949) D33 D78 D102\n",
      "error(0.04030873898622133744) D33 D81 D105\n",
      "error(5.996290898837034546e-05) D33 D82 D106\n",
      "error(0.01982814529127310127) D34\n",
      "error(0.00119432355693597776) D34 D42 D45 D79 D103\n",
      "error(0.0008111769999999999484) D34 D42 D79 D103\n",
      "error(0.002479270967218732621) D34 D44 D46\n",
      "error(0.004658501052871038932) D34 D44 D46 D68 D70\n",
      "error(0.0009641219999999999825) D34 D44 D46 D82 D106\n",
      "error(0.001199944231680439037) D34 D44 D78 D102\n",
      "error(0.002011600243799554436) D34 D44 D82 D106\n",
      "error(0.0009641219999999999825) D34 D45\n",
      "error(0.001440575051525734996) D34 D45 D46\n",
      "error(0.002578335221013760854) D34 D45 D46 D69 D70\n",
      "error(0.002009174497356395507) D34 D45 D79 D103\n",
      "error(0.001202373919938061562) D34 D45 D83 D107\n",
      "error(0.00119432355693597776) D34 D46\n",
      "error(0.0008111769999999999484) D34 D46 D82 D106\n",
      "error(0.006318901264285537063) D34 D58\n",
      "error(0.003624354811708633238) D34 D58 D68 D70\n",
      "error(0.003614660733537251782) D34 D58 D69 D70\n",
      "error(0.002429585086292254323) D34 D68 D70\n",
      "error(0.002429585086292254323) D34 D69 D70\n",
      "error(3.533390243903300872e-05) D34 D78 D102\n",
      "error(0.004614058250203434235) D34 D79 D103\n",
      "error(0.03552995535965992879) D34 D82 D106\n",
      "error(5.996290898837034546e-05) D34 D83 D107\n",
      "error(0.02138571524591238379) D35\n",
      "error(0.00200356294133608847) D35 D43 D80 D104\n",
      "error(0.002479270967218732621) D35 D45 D47\n",
      "error(0.004658501052871038932) D35 D45 D47 D69 D71\n",
      "error(0.0009641219999999999825) D35 D45 D47 D83 D107\n",
      "error(0.001199944231680439037) D35 D45 D79 D103\n",
      "error(0.002011600243799554436) D35 D45 D83 D107\n",
      "error(0.002483381069500848436) D35 D47\n",
      "error(0.002578335221013760854) D35 D47 D71\n",
      "error(0.0008111769999999999484) D35 D47 D83 D107\n",
      "error(0.006318901264285537063) D35 D59\n",
      "error(0.003624354811708633238) D35 D59 D69 D71\n",
      "error(0.003614660733537251782) D35 D59 D71\n",
      "error(0.002429585086292254323) D35 D69 D71\n",
      "error(0.002429585086292254323) D35 D71\n",
      "error(3.533390243903300872e-05) D35 D79 D103\n",
      "error(0.007283007255725086268) D35 D80 D104\n",
      "error(0.03552995535965992879) D35 D83 D107\n",
      "error(0.03680690928492847541) D36\n",
      "error(0.003414047886023986299) D36 D38\n",
      "error(0.001884617003200650572) D36 D38 D60 D62\n",
      "error(0.005600043335568532024) D36 D60\n",
      "error(0.03672910311271491979) D37\n",
      "error(8.397481121340776011e-05) D37 D38\n",
      "error(0.0001216513276332629453) D37 D38 D61 D62\n",
      "error(0.003414047886023986299) D37 D39\n",
      "error(0.001884617003200650572) D37 D39 D61 D63\n",
      "error(0.03941616938767841111) D38\n",
      "error(8.397481121340776011e-05) D38 D40\n",
      "error(0.0001216513276332629453) D38 D40 D62 D64\n",
      "error(0.001797992152739562744) D38 D41\n",
      "error(0.001884617003200650572) D38 D41 D62 D65\n",
      "error(0.002169539664363660282) D38 D73 D97\n",
      "error(0.04193409893984378911) D39\n",
      "error(8.397481121340776011e-05) D39 D41\n",
      "error(0.0001216513276332629453) D39 D41 D63 D65\n",
      "error(0.002005809798512874203) D39 D63\n",
      "error(0.002169539664363660282) D39 D74 D98\n",
      "error(0.04002789725340444305) D40\n",
      "error(0.001797992152739562744) D40 D42\n",
      "error(0.001884617003200650572) D40 D42 D64 D66\n",
      "error(0.006304275425710917716) D40 D64\n",
      "error(0.002169539664363660282) D40 D72 D76 D96 D100\n",
      "error(0.03789507966421003238) D41\n",
      "error(8.397481121340776011e-05) D41 D42\n",
      "error(0.0001216513276332629453) D41 D42 D65 D66\n",
      "error(0.001797992152739562744) D41 D43\n",
      "error(0.001884617003200650572) D41 D43 D65 D67\n",
      "error(0.002169539664363660282) D41 D73 D77 D97 D101\n",
      "error(0.03789507966421003238) D42\n",
      "error(8.397481121340776011e-05) D42 D44\n",
      "error(0.0001216513276332629453) D42 D44 D66 D68\n",
      "error(0.001797992152739562744) D42 D45\n",
      "error(0.001884617003200650572) D42 D45 D66 D69\n",
      "error(0.002169539664363660282) D42 D76 D79 D100 D103 D120\n",
      "error(0.04042132474226160094) D43\n",
      "error(8.397481121340776011e-05) D43 D45\n",
      "error(0.0001216513276332629453) D43 D45 D67 D69\n",
      "error(0.002005809798512874203) D43 D67\n",
      "error(0.002169539664363660282) D43 D77 D80 D101 D104 D120\n",
      "error(0.04002789725340444305) D44\n",
      "error(0.001797992152739562744) D44 D46\n",
      "error(0.003474443722251936446) D44 D46 D68 D70\n",
      "error(0.00119432355693597776) D44 D46 D82 D106\n",
      "error(0.007929351160945542765) D44 D68\n",
      "error(0.002169539664363660282) D44 D78 D82 D102 D106\n",
      "error(0.0008111769999999999484) D44 D82 D106\n",
      "error(0.03789507966421003238) D45\n",
      "error(8.397481121340776011e-05) D45 D46\n",
      "error(0.0001216513276332629453) D45 D46 D69 D70\n",
      "error(0.001797992152739562744) D45 D47\n",
      "error(0.003474443722251936446) D45 D47 D69 D71\n",
      "error(0.00119432355693597776) D45 D47 D83 D107\n",
      "error(0.002169539664363660282) D45 D79 D83 D103 D107\n",
      "error(0.0008111769999999999484) D45 D83 D107\n",
      "error(0.04337178859947780907) D46\n",
      "error(0.00624375137066575641) D46 D82 D106\n",
      "error(0.04383898090107301443) D47\n",
      "error(0.0001216513276332629453) D47 D71\n",
      "error(0.00624375137066575641) D47 D83 D107\n",
      "error(0.00957744416619154583) D48\n",
      "error(8.397481121340776011e-05) D48 D51\n",
      "error(0.001440575051525734996) D48 D51 D64\n",
      "error(0.001797992152739562744) D48 D52\n",
      "error(0.0009641219999999999825) D48 D52 D62\n",
      "error(0.002479270967218732621) D48 D52 D62 D64\n",
      "error(0.00119432355693597776) D48 D52 D64\n",
      "error(0.005277065518299891775) D48 D60\n",
      "error(0.002483381069500848436) D48 D60 D62\n",
      "error(0.002009174497356395507) D48 D62\n",
      "error(0.001202373919938061562) D48 D62 D73 D85 D97 D109\n",
      "error(0.001773734852816811862) D48 D64 D72 D84 D96 D108\n",
      "error(0.0374018142016616234) D48 D72 D84 D96 D108\n",
      "error(5.996290898837034546e-05) D48 D73 D85 D97 D109\n",
      "error(0.007366735148907788133) D49\n",
      "error(8.397481121340776011e-05) D49 D52\n",
      "error(0.001440575051525734996) D49 D52 D62 D65\n",
      "error(0.001797992152739562744) D49 D53\n",
      "error(0.0009641219999999999825) D49 D53 D63\n",
      "error(0.002479270967218732621) D49 D53 D63 D65\n",
      "error(0.00119432355693597776) D49 D53 D65\n",
      "error(0.002811736665244366114) D49 D61\n",
      "error(0.002479270967218732621) D49 D61 D62\n",
      "error(0.002483381069500848436) D49 D61 D63\n",
      "error(0.00224325356230894524) D49 D62\n",
      "error(0.0009641219999999999825) D49 D62 D65 D73 D85 D97 D109\n",
      "error(0.002011600243799554436) D49 D62 D73 D85 D97 D109\n",
      "error(0.002009174497356395507) D49 D63\n",
      "error(0.001202373919938061562) D49 D63 D74 D86 D98 D110\n",
      "error(0.0008111769999999999484) D49 D65 D73 D85 D97 D109\n",
      "error(0.03552995535965992879) D49 D73 D85 D97 D109\n",
      "error(5.996290898837034546e-05) D49 D74 D86 D98 D110\n",
      "error(0.003873854886274020679) D50\n",
      "error(8.397481121340776011e-05) D50 D53\n",
      "error(0.001440575051525734996) D50 D53 D63\n",
      "error(0.004563943989775369296) D50 D63\n",
      "error(0.002823868213805612315) D50 D63 D74 D86 D98 D110\n",
      "error(0.03769207688554708502) D50 D74 D86 D98 D110\n",
      "error(0.002988534108710233679) D51 D54\n",
      "error(0.003438612327851819223) D51 D54 D64\n",
      "error(0.003050791210919119589) D51 D64 D72 D84 D96 D108\n",
      "error(0.001202373919938061562) D51 D64 D76 D88 D100 D112\n",
      "error(0.006244697596347516949) D51 D72 D84 D96 D108\n",
      "error(0.04030873898622133744) D51 D75 D87 D99 D111\n",
      "error(5.996290898837034546e-05) D51 D76 D88 D100 D112\n",
      "error(8.397481121340776011e-05) D52 D54\n",
      "error(0.001440575051525734996) D52 D54 D64 D66\n",
      "error(0.001797992152739562744) D52 D55\n",
      "error(0.0009641219999999999825) D52 D55 D65\n",
      "error(0.002479270967218732621) D52 D55 D65 D66\n",
      "error(0.00119432355693597776) D52 D55 D66\n",
      "error(0.00119432355693597776) D52 D62 D65 D73 D85 D97 D109\n",
      "error(0.0008111769999999999484) D52 D62 D73 D85 D97 D109\n",
      "error(0.0009641219999999999825) D52 D64 D66 D76 D88 D100 D112\n",
      "error(0.001199944231680439037) D52 D64 D72 D84 D96 D108\n",
      "error(0.002011600243799554436) D52 D64 D76 D88 D100 D112\n",
      "error(0.002009174497356395507) D52 D65 D73 D85 D97 D109\n",
      "error(0.001202373919938061562) D52 D65 D77 D89 D101 D113\n",
      "error(0.0008111769999999999484) D52 D66 D76 D88 D100 D112\n",
      "error(3.533390243903300872e-05) D52 D72 D84 D96 D108\n",
      "error(0.004614058250203434235) D52 D73 D85 D97 D109\n",
      "error(0.03552995535965992879) D52 D76 D88 D100 D112\n",
      "error(5.996290898837034546e-05) D52 D77 D89 D101 D113\n",
      "error(8.397481121340776011e-05) D53 D55\n",
      "error(0.001440575051525734996) D53 D55 D65 D67\n",
      "error(0.003414047886023986299) D53 D56\n",
      "error(0.003519904408972179821) D53 D56 D67\n",
      "error(0.00200356294133608847) D53 D63 D74 D86 D98 D110\n",
      "error(0.0009641219999999999825) D53 D65 D67 D77 D89 D101 D113\n",
      "error(0.001199944231680439037) D53 D65 D73 D85 D97 D109\n",
      "error(0.002011600243799554436) D53 D65 D77 D89 D101 D113\n",
      "error(0.0008111769999999999484) D53 D67 D77 D89 D101 D113\n",
      "error(3.533390243903300872e-05) D53 D73 D85 D97 D109\n",
      "error(0.007283007255725086268) D53 D74 D86 D98 D110\n",
      "error(0.03552995535965992879) D53 D77 D89 D101 D113\n",
      "error(8.397481121340776011e-05) D54 D57\n",
      "error(0.001440575051525734996) D54 D57 D68\n",
      "error(0.001797992152739562744) D54 D58\n",
      "error(0.0009641219999999999825) D54 D58 D66\n",
      "error(0.002479270967218732621) D54 D58 D66 D68\n",
      "error(0.00119432355693597776) D54 D58 D68\n",
      "error(0.00119432355693597776) D54 D64 D66 D76 D88 D100 D112\n",
      "error(0.0008111769999999999484) D54 D64 D76 D88 D100 D112\n",
      "error(0.002009174497356395507) D54 D66 D76 D88 D100 D112\n",
      "error(0.001202373919938061562) D54 D66 D79 D91 D103 D115\n",
      "error(0.001773734852816811862) D54 D68 D78 D90 D102 D114\n",
      "error(0.001235200643432510497) D54 D75 D87 D99 D111\n",
      "error(0.004614058250203434235) D54 D76 D88 D100 D112\n",
      "error(0.0374018142016616234) D54 D78 D90 D102 D114\n",
      "error(5.996290898837034546e-05) D54 D79 D91 D103 D115\n",
      "error(8.397481121340776011e-05) D55 D58\n",
      "error(0.001440575051525734996) D55 D58 D66 D69\n",
      "error(0.001797992152739562744) D55 D59\n",
      "error(0.0009641219999999999825) D55 D59 D67\n",
      "error(0.002479270967218732621) D55 D59 D67 D69\n",
      "error(0.00119432355693597776) D55 D59 D69\n",
      "error(0.00119432355693597776) D55 D65 D67 D77 D89 D101 D113\n",
      "error(0.0008111769999999999484) D55 D65 D77 D89 D101 D113\n",
      "error(0.0009641219999999999825) D55 D66 D69 D79 D91 D103 D115\n",
      "error(0.001199944231680439037) D55 D66 D76 D88 D100 D112\n",
      "error(0.002011600243799554436) D55 D66 D79 D91 D103 D115\n",
      "error(0.002009174497356395507) D55 D67 D77 D89 D101 D113\n",
      "error(0.001202373919938061562) D55 D67 D80 D92 D104 D116\n",
      "error(0.0008111769999999999484) D55 D69 D79 D91 D103 D115\n",
      "error(3.533390243903300872e-05) D55 D76 D88 D100 D112\n",
      "error(0.004614058250203434235) D55 D77 D89 D101 D113\n",
      "error(0.03552995535965992879) D55 D79 D91 D103 D115\n",
      "error(5.996290898837034546e-05) D55 D80 D92 D104 D116\n",
      "error(8.397481121340776011e-05) D56 D59\n",
      "error(0.001440575051525734996) D56 D59 D67\n",
      "error(0.001199944231680439037) D56 D67 D77 D89 D101 D113\n",
      "error(0.002823868213805612315) D56 D67 D80 D92 D104 D116\n",
      "error(3.533390243903300872e-05) D56 D77 D89 D101 D113\n",
      "error(0.03769207688554708502) D56 D80 D92 D104 D116\n",
      "error(0.002988534108710233679) D57\n",
      "error(0.003438612327851819223) D57 D68\n",
      "error(0.003050791210919119589) D57 D68 D78 D90 D102 D114\n",
      "error(0.001202373919938061562) D57 D68 D82 D94 D106 D118\n",
      "error(0.006244697596347516949) D57 D78 D90 D102 D114\n",
      "error(0.04030873898622133744) D57 D81 D93 D105 D117\n",
      "error(5.996290898837034546e-05) D57 D82 D94 D106 D118\n",
      "error(0.001881664991849791657) D58\n",
      "error(0.00119432355693597776) D58 D66 D69 D79 D91 D103 D115\n",
      "error(0.0008111769999999999484) D58 D66 D79 D91 D103 D115\n",
      "error(0.001440575051525734996) D58 D68 D70\n",
      "error(0.0009641219999999999825) D58 D68 D70 D82 D94 D106 D118\n",
      "error(0.001199944231680439037) D58 D68 D78 D90 D102 D114\n",
      "error(0.002011600243799554436) D58 D68 D82 D94 D106 D118\n",
      "error(0.0009641219999999999825) D58 D69\n",
      "error(0.002479270967218732621) D58 D69 D70\n",
      "error(0.002009174497356395507) D58 D69 D79 D91 D103 D115\n",
      "error(0.001202373919938061562) D58 D69 D83 D95 D107 D119\n",
      "error(0.00119432355693597776) D58 D70\n",
      "error(0.0008111769999999999484) D58 D70 D82 D94 D106 D118\n",
      "error(3.533390243903300872e-05) D58 D78 D90 D102 D114\n",
      "error(0.004614058250203434235) D58 D79 D91 D103 D115\n",
      "error(0.03552995535965992879) D58 D82 D94 D106 D118\n",
      "error(5.996290898837034546e-05) D58 D83 D95 D107 D119\n",
      "error(0.003497449309183989739) D59\n",
      "error(0.00200356294133608847) D59 D67 D80 D92 D104 D116\n",
      "error(0.001440575051525734996) D59 D69 D71\n",
      "error(0.0009641219999999999825) D59 D69 D71 D83 D95 D107 D119\n",
      "error(0.001199944231680439037) D59 D69 D79 D91 D103 D115\n",
      "error(0.002011600243799554436) D59 D69 D83 D95 D107 D119\n",
      "error(0.003519904408972179821) D59 D71\n",
      "error(0.0008111769999999999484) D59 D71 D83 D95 D107 D119\n",
      "error(3.533390243903300872e-05) D59 D79 D91 D103 D115\n",
      "error(0.007283007255725086268) D59 D80 D92 D104 D116\n",
      "error(0.03552995535965992879) D59 D83 D95 D107 D119\n",
      "error(0.04747610732035819486) D60\n",
      "error(0.01115516142130245844) D60 D62\n",
      "error(0.03672910311271491979) D61\n",
      "error(0.006187131910145781018) D61 D62\n",
      "error(0.01115516142130245844) D61 D63\n",
      "error(0.03941616938767841111) D62\n",
      "error(0.006187131910145781018) D62 D64\n",
      "error(0.00956429784429518523) D62 D65\n",
      "error(0.002169539664363660282) D62 D73 D85 D97 D109\n",
      "error(0.05457979621093496381) D63\n",
      "error(0.006187131910145781018) D63 D65\n",
      "error(0.002169539664363660282) D63 D74 D86 D98 D110\n",
      "error(0.05658688799035965084) D64\n",
      "error(0.00956429784429518523) D64 D66\n",
      "error(0.002169539664363660282) D64 D72 D76 D84 D88 D96 D100 D108 D112\n",
      "error(0.03789507966421003238) D65\n",
      "error(0.006187131910145781018) D65 D66\n",
      "error(0.00956429784429518523) D65 D67\n",
      "error(0.002169539664363660282) D65 D73 D77 D85 D89 D97 D101 D109 D113\n",
      "error(0.03789507966421003238) D66\n",
      "error(0.006187131910145781018) D66 D68\n",
      "error(0.00956429784429518523) D66 D69\n",
      "error(0.002169539664363660282) D66 D76 D79 D88 D91 D100 D103 D112 D115\n",
      "error(0.0531087847477057784) D67\n",
      "error(0.006187131910145781018) D67 D69\n",
      "error(0.002169539664363660282) D67 D77 D80 D89 D92 D101 D104 D113 D116\n",
      "error(0.05804645073952686279) D68\n",
      "error(0.01112961345164077513) D68 D70\n",
      "error(0.00119432355693597776) D68 D70 D82 D94 D106 D118\n",
      "error(0.002169539664363660282) D68 D78 D82 D90 D94 D102 D106 D114 D118\n",
      "error(0.0008111769999999999484) D68 D82 D94 D106 D118\n",
      "error(0.03789507966421003238) D69\n",
      "error(0.006187131910145781018) D69 D70\n",
      "error(0.01112961345164077513) D69 D71\n",
      "error(0.00119432355693597776) D69 D71 D83 D95 D107 D119\n",
      "error(0.002169539664363660282) D69 D79 D83 D91 D95 D103 D107 D115 D119\n",
      "error(0.0008111769999999999484) D69 D83 D95 D107 D119\n",
      "error(0.04337178859947780907) D70\n",
      "error(0.00624375137066575641) D70 D82 D94 D106 D118\n",
      "error(0.04940796093310637072) D71\n",
      "error(0.00624375137066575641) D71 D83 D95 D107 D119\n",
      "error(0.002699373803418128603) D72 D75 D84 D87 D96 D99 D108 D111\n",
      "error(0.0157191281912775517) D72 D75 D96 D99\n",
      "error(0.005486163775278861572) D72 D76 D84 D88 D96 D100 D108 D112\n",
      "error(0.01639467494406012665) D72 D76 D96 D100\n",
      "error(0.01075622856245490346) D72 D84 D96 D108\n",
      "error(0.03407475558007418137) D72 D96\n",
      "error(0.002699373803418128603) D73 D76 D85 D88 D97 D100 D109 D112\n",
      "error(0.0157191281912775517) D73 D76 D97 D100\n",
      "error(0.005486163775278861572) D73 D77 D85 D89 D97 D101 D109 D113\n",
      "error(0.01639467494406012665) D73 D77 D97 D101\n",
      "error(0.008155919165144492888) D73 D85 D97 D109\n",
      "error(0.03159838314113768559) D73 D97\n",
      "error(0.002699373803418128603) D74 D77 D86 D89 D98 D101 D110 D113\n",
      "error(0.0157191281912775517) D74 D77 D98 D101\n",
      "error(0.005486163775278861572) D74 D86 D98 D110\n",
      "error(0.01639467494406012665) D74 D98\n",
      "error(0.008100587787971048892) D75 D78 D87 D90 D99 D102 D111 D114\n",
      "error(0.01895142721644244715) D75 D78 D99 D102 D120\n",
      "error(0.002699373803418128603) D76 D78 D88 D90 D100 D102 D112 D114\n",
      "error(0.0157191281912775517) D76 D78 D100 D102 D120\n",
      "error(0.005486163775278861572) D76 D79 D88 D91 D100 D103 D112 D115\n",
      "error(0.01639467494406012665) D76 D79 D100 D103 D120\n",
      "error(0.002699373803418128603) D77 D79 D89 D91 D101 D103 D113 D115\n",
      "error(0.0157191281912775517) D77 D79 D101 D103 D120\n",
      "error(0.005486163775278861572) D77 D80 D89 D92 D101 D104 D113 D116\n",
      "error(0.01639467494406012665) D77 D80 D101 D104 D120\n",
      "error(0.002699373803418128603) D78 D81 D90 D93 D102 D105 D114 D117\n",
      "error(0.0157191281912775517) D78 D81 D102 D105\n",
      "error(0.005486163775278861572) D78 D82 D90 D94 D102 D106 D114 D118\n",
      "error(0.01639467494406012665) D78 D82 D102 D106\n",
      "error(0.002699373803418128603) D79 D82 D91 D94 D103 D106 D115 D118\n",
      "error(0.0157191281912775517) D79 D82 D103 D106\n",
      "error(0.005486163775278861572) D79 D83 D91 D95 D103 D107 D115 D119\n",
      "error(0.01639467494406012665) D79 D83 D103 D107\n",
      "error(0.002699373803418128603) D80 D83 D92 D95 D104 D107 D116 D119\n",
      "error(0.0157191281912775517) D80 D83 D104 D107\n",
      "error(0.009589504494735931472) D81 D93 D105 D117\n",
      "error(0.020407499817875277) D81 D105\n",
      "error(0.01342715807468520227) D82 D94 D106 D118\n",
      "error(0.03661838221053228398) D82 D106\n",
      "error(0.01342715807468520227) D83 D95 D107 D119\n",
      "error(0.03661838221053228398) D83 D107\n",
      "error(0.002705966499487236481) D84 D87 D108 D111\n",
      "error(0.002705966499487236481) D84 D88 D108 D112\n",
      "error(0.005397288489581777114) D84 D108\n",
      "error(0.002705966499487236481) D85 D88 D109 D112\n",
      "error(0.002705966499487236481) D85 D89 D109 D113\n",
      "error(0.005397288489581777114) D85 D109\n",
      "error(0.002705966499487236481) D86 D89 D110 D113\n",
      "error(0.002705966499487236481) D86 D110\n",
      "error(0.002705966499487236481) D87 D90 D111 D114 D120\n",
      "error(0.002705966499487236481) D88 D90 D112 D114 D120\n",
      "error(0.002705966499487236481) D88 D91 D112 D115 D120\n",
      "error(0.002705966499487236481) D89 D91 D113 D115 D120\n",
      "error(0.002705966499487236481) D89 D92 D113 D116 D120\n",
      "error(0.002705966499487236481) D90 D93 D114 D117\n",
      "error(0.002705966499487236481) D90 D94 D114 D118\n",
      "error(0.002705966499487236481) D91 D94 D115 D118\n",
      "error(0.002705966499487236481) D91 D95 D115 D119\n",
      "error(0.002705966499487236481) D92 D95 D116 D119\n",
      "error(0.002705966499487236481) D93 D117\n",
      "error(0.005397288489581777114) D94 D118\n",
      "error(0.005397288489581777114) D95 D119\n",
      "final measurement_index = 146\n",
      "Preprocessing is done! it took 105.19s\n",
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 Using detection events signs!\n",
      "infidelity 0.14249037227214378\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "num_rounds = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "num_CX_per_layer_list = [3, 3, 3]\n",
    "\n",
    "noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                  'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "            'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "noise_params = {'idle_loss_rate': 5.346010002745036e-08,\n",
    "                  'idle_error_rate': np.array([7.89314494e-09, 2.81702046e-08, 1.15650507e-07]),\n",
    "                  'entangling_zone_error_rate': np.array([4.50103659e-04, 5.60439308e-06, 3.29645358e-03]),\n",
    "                  'entangling_gate_error_rate': [2.393750964812938e-05, 0.00015294459572299472, 0.0016575839127290178,\n",
    "                                                   2.393750964812938e-05, 0, 0, 0, 0.00015294459572299472, 0, 0, 0,\n",
    "                                                   0.0016575839127290178, 0, 0, 0.00081117655901964],\n",
    "                  'entangling_gate_loss_rate': 0.0021310662492619475,\n",
    "                  'single_qubit_error_rate': np.array([9.82517752e-06, 1.04167102e-03, 1.64424262e-05]),\n",
    "                  'reset_error_rate': 6.484420123608033e-05, 'measurement_error_rate': 0.002234264216316982,\n",
    "                  'reset_loss_rate': 0.0007072757126485622, 'measurement_loss_rate': 0.03422498167847147,\n",
    "                  'ancilla_idle_loss_rate': 1.569889741718561e-07,\n",
    "                  'ancilla_idle_error_rate': np.array([1.30972461e-07, 4.04213096e-08, 4.08181939e-06]),\n",
    "                  'ancilla_reset_error_rate': 0.021408069221550766,\n",
    "                  'ancilla_measurement_error_rate': 0.0015628602753064648,\n",
    "                  'ancilla_reset_loss_rate': 5.5115512820230125e-05,\n",
    "                  'ancilla_measurement_loss_rate': 0.0005409239922594136,\n",
    "                  'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "                  'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "               'bias_preserving_gates': 'False',\n",
    "               'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "               'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "               'ordering': gate_ordering, 'circuit_index': '0',\n",
    "               'decoder': 'MLE',\n",
    "               'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "               'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "               'loss_decoder': 'independent',\n",
    "               'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "# Load the experimental measurements\n",
    "exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                 exp_measurements[:, 1, :distance**2-1],\n",
    "                                 exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                 exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                 exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                 exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "# Load the theory circuit\n",
    "simulated_measurements, simulated_detection_events, simulated_observable_flips, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "# Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "# Find detection event signs\n",
    "detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '.'\n",
    "simulate_data = False\n",
    "# DO IT\n",
    "print(exp_measurements)\n",
    "predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                  exp_measurements,\n",
    "                                                                  detection_events_signs, use_loss_decoding,\n",
    "                                                                  use_independent_decoder,\n",
    "                                                                  use_independent_and_first_comb_decoder,\n",
    "                                                                  logical_gaps=False,\n",
    "                                                                  noise_params=noise_params)\n",
    "\n",
    "\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "\n",
    "print('infidelity', 1-logical_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical error 0.439456\n"
     ]
    }
   ],
   "source": [
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions[:,0]))\n",
    "print('logical error',logical_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observable_flips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare theory and experimental measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer_list = [3, 3, 3]\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "final measurement_index = 146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd5a8644a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "distance = 5\n",
    "\n",
    "num_CX_per_layer_list = [3,3,3]\n",
    "num_layers = len(num_CX_per_layer_list)\n",
    "\n",
    "print(f\"num_CX_per_layer_list = {num_CX_per_layer_list}\")\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': '0',\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX', 'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0', 'num_CX_per_layer_list':num_CX_per_layer_list}\n",
    "\n",
    "\n",
    "num_shots = 1000\n",
    "measurement_events, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)\n",
    "measurement_events[measurement_events == 2] = 0 #change all values in detection_events from 2 to 0\n",
    "\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "exp_measurements = exp_measurements[:num_shots]\n",
    "\n",
    "exp_measurements[exp_measurements == 2] = 0 #change all values in detection_events from 2 to 0\n",
    "\n",
    "plt.plot(np.average(exp_measurements,axis=0), label='experiment')\n",
    "\n",
    "plt.plot(np.average(measurement_events,axis=0), label='theory')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical_CX__Nlayers3__NCX7_7_7\n",
      "final measurement_index = 146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc1b1374d00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder_basis = 'XX'\n",
    "# num_rounds = 3\n",
    "num_CX_per_layer_list = [7,7,7]\n",
    "d=5\n",
    "num_rounds = len(num_CX_per_layer_list)\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': '0',\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX', 'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0', 'num_CX_per_layer_list':num_CX_per_layer_list}\n",
    "\n",
    "noise_params = {}\n",
    "folder = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "qubit_states_nans_perlog = np.load(f'{folder}/2024_10_16_measurement_events_7CNOT_XX.npy').transpose(1,2,0).astype(float)\n",
    "qubit_states_nans_perlog[qubit_states_nans_perlog == 2.] = 1. #np.nan\n",
    "qubit_states_nans_perlog[qubit_states_nans_perlog == 0.] = -1\n",
    "qubit_states_nans_perlog.shape\n",
    "\n",
    "exp_measurements = 0.5*(np.concatenate([qubit_states_nans_perlog[0, :d**2-1],\n",
    "                                qubit_states_nans_perlog[1, :d**2-1],\n",
    "                                qubit_states_nans_perlog[0, d**2-1:2*(d**2-1)],\n",
    "                                qubit_states_nans_perlog[1, d**2-1:2*(d**2-1)],\n",
    "                                qubit_states_nans_perlog[0, 2*(d**2-1):],\n",
    "                                qubit_states_nans_perlog[1, 2*(d**2-1):]], axis=0)+1).T\n",
    "\n",
    "simulated_measurement_events, simulated_detector_events, _, circuit = get_simulated_measurement_events(Meta_params, d, d, 200, noise_params = noise_params)\n",
    "#detection_events_theory, observable_flips_theory = circuit.compile_m2d_converter().convert(measurements = exp_measurements.astype(bool), separate_observables = True)\n",
    "#detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events_theory.astype(int), axis = 0) -1).astype(int)\n",
    "\n",
    "#detection_events_theory = -1+2*detection_events_theory.T.astype(int)\n",
    "\n",
    "#detector_measurements_nans = detector_measurements_nans*detection_events_signs[:,None]\n",
    "#detection_events_theory = detection_events_theory*detection_events_signs_theory[:,None]\n",
    "\n",
    "plt.plot(np.mean(simulated_measurement_events,axis = 0), label = 'Sim.')\n",
    "plt.plot(np.mean(exp_measurements,axis = 0), label = 'Exp')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_xor(observable_flips, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical_CX__Nlayers1__NCX3\n",
      "final measurement_index = 18\n",
      "Pauli_DEM = error(0.01193448568232855118) D0 D1\n",
      "error(0.01193448568232855118) D0 D1 D2\n",
      "error(0.01193448568232855118) D1 D2 D5 D6 D8\n",
      "error(0.01193448568232855118) D1 D4 D5 D8\n",
      "error(0.01193448568232855118) D2 D3\n",
      "error(0.01193448568232855118) D2 D3 D6 D8\n",
      "error(0.01193448568232855118) D4 D5\n",
      "error(0.01193448568232855118) D5 D6 D7\n",
      "error(0.01193448568232855292) D6 D7\n",
      "final measurement_index = 18\n",
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_49449/126680247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/gefenbaranes/Documents/CX_experiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# DO IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     34\u001b[0m                                                                   \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                                   \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MLE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelated_decoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_gurobi_with_dem_loss_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_shots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservables_errors_interactions_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MLE decoder took {time.time() - start_time:.6f}s.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MLE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelated_decoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_gurobi_with_dem_loss_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_shots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservables_errors_interactions_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MLE decoder took {time.time() - start_time:.6f}s.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTATE_SUSPEND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# IFDEF CYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_CX_per_layer_list = [3]\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "\n",
    "noise_params = {}\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "               'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "simulate_data = True\n",
    "num_shots = 1000\n",
    "if simulate_data:\n",
    "   detection_events_signs = None\n",
    "   measurement_events = None\n",
    "\n",
    "\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "# DO IT\n",
    "predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                  None,\n",
    "                                                                  None, use_loss_decoding,\n",
    "                                                                  use_independent_decoder,\n",
    "                                                                  use_independent_and_first_comb_decoder,\n",
    "                                                                  simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                  noise_params=noise_params, num_shots=3000)\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "print('logical error',logical_probability)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1]\n",
      "logical_CX__Nlayers1__NCX1\n",
      "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.000131129) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "X_ERROR(0.000131129) 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.00322009) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "DETECTOR rec[-50] rec[-49] rec[-25] rec[-24]\n",
      "DETECTOR rec[-48] rec[-47] rec[-23] rec[-22]\n",
      "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-25] rec[-24] rec[-20] rec[-19]\n",
      "DETECTOR rec[-49] rec[-48] rec[-44] rec[-43] rec[-24] rec[-23] rec[-19] rec[-18]\n",
      "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-23] rec[-22] rec[-18] rec[-17]\n",
      "DETECTOR rec[-47] rec[-46] rec[-42] rec[-41] rec[-22] rec[-21] rec[-17] rec[-16]\n",
      "DETECTOR rec[-46] rec[-41] rec[-21] rec[-16]\n",
      "DETECTOR rec[-45] rec[-40] rec[-20] rec[-15]\n",
      "DETECTOR rec[-45] rec[-44] rec[-40] rec[-39] rec[-20] rec[-19] rec[-15] rec[-14]\n",
      "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-19] rec[-18] rec[-14] rec[-13]\n",
      "DETECTOR rec[-43] rec[-42] rec[-38] rec[-37] rec[-18] rec[-17] rec[-13] rec[-12]\n",
      "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-17] rec[-16] rec[-12] rec[-11]\n",
      "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-15] rec[-14] rec[-10] rec[-9]\n",
      "DETECTOR rec[-39] rec[-38] rec[-34] rec[-33] rec[-14] rec[-13] rec[-9] rec[-8]\n",
      "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-13] rec[-12] rec[-8] rec[-7]\n",
      "DETECTOR rec[-37] rec[-36] rec[-32] rec[-31] rec[-12] rec[-11] rec[-7] rec[-6]\n",
      "DETECTOR rec[-36] rec[-31] rec[-11] rec[-6]\n",
      "DETECTOR rec[-35] rec[-30] rec[-10] rec[-5]\n",
      "DETECTOR rec[-35] rec[-34] rec[-30] rec[-29] rec[-10] rec[-9] rec[-5] rec[-4]\n",
      "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-9] rec[-8] rec[-4] rec[-3]\n",
      "DETECTOR rec[-33] rec[-32] rec[-28] rec[-27] rec[-8] rec[-7] rec[-3] rec[-2]\n",
      "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-7] rec[-6] rec[-2] rec[-1]\n",
      "DETECTOR rec[-29] rec[-28] rec[-4] rec[-3]\n",
      "DETECTOR rec[-27] rec[-26] rec[-2] rec[-1]\n",
      "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
      "DEM from the lossless circuit: error(0.01425905179606385201) D0 D2\n",
      "error(0.01425905179606385201) D0 D2 D3\n",
      "error(0.01425905179606385201) D1 D3 D4\n",
      "error(0.01425905179606385201) D1 D4 D5\n",
      "error(0.01425905179606385201) D2 D3 D8 D9\n",
      "error(0.01425905179606385201) D2 D7 D8\n",
      "error(0.01425905179606385201) D3 D4 D9 D10\n",
      "error(0.01425905179606385201) D4 D5 D10 D11\n",
      "error(0.01425905179606385201) D5 D6\n",
      "error(0.01425905179606385201) D5 D6 D11\n",
      "error(0.01425905179606385201) D7 D8 D12 L0\n",
      "error(0.01425905179606385201) D8 D9 D12 D13 L0\n",
      "error(0.01425905179606385201) D9 D10 D13 D14 L0\n",
      "error(0.01425905179606385201) D10 D11 D14 D15 L0\n",
      "error(0.01425905179606385201) D11 D15 D16 L0\n",
      "error(0.01425905179606385201) D12 D13 D18 D19\n",
      "error(0.01425905179606385201) D12 D17 D18\n",
      "error(0.01425905179606385201) D13 D14 D19 D20\n",
      "error(0.01425905179606385201) D14 D15 D20 D21\n",
      "error(0.01425905179606385201) D15 D16 D21\n",
      "error(0.01425905179606385201) D17 D18\n",
      "error(0.01425905179606385201) D18 D19 D22\n",
      "error(0.01425905179606385201) D19 D20 D22\n",
      "error(0.01425905179606385201) D20 D21 D23\n",
      "error(0.01425905179606385201) D21 D23\n",
      "NOW DECODING\n",
      "logical_CX__Nlayers1__NCX1\n",
      "final measurement_index = 50\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.01425906097371744917) D0 D2\n",
      "error(0.01425906097371744917) D0 D2 D3\n",
      "error(0.01425906097371744917) D1 D3 D4\n",
      "error(0.01425906097371744917) D1 D4 D5\n",
      "error(0.01425906097371744917) D2 D3 D8 D9\n",
      "error(0.01425906097371744917) D2 D7 D8\n",
      "error(0.01425906097371744917) D3 D4 D9 D10\n",
      "error(0.01425906097371744917) D4 D5 D10 D11\n",
      "error(0.01425906097371744917) D5 D6\n",
      "error(0.01425906097371744917) D5 D6 D11\n",
      "error(0.01425906097371744917) D7 D8 D12 D24\n",
      "error(0.01425906097371744917) D8 D9 D12 D13 D24\n",
      "error(0.01425906097371744917) D9 D10 D13 D14 D24\n",
      "error(0.01425906097371744917) D10 D11 D14 D15 D24\n",
      "error(0.01425906097371744917) D11 D15 D16 D24\n",
      "error(0.01425906097371744917) D12 D13 D18 D19\n",
      "error(0.01425906097371744917) D12 D17 D18\n",
      "error(0.01425906097371744917) D13 D14 D19 D20\n",
      "error(0.01425906097371744917) D14 D15 D20 D21\n",
      "error(0.01425906097371744917) D15 D16 D21\n",
      "error(0.01425906097371744917) D17 D18\n",
      "error(0.01425906097371744917) D18 D19 D22\n",
      "error(0.01425906097371744917) D19 D20 D22\n",
      "error(0.01425906097371744917) D20 D21 D23\n",
      "error(0.01425906097371744917) D21 D23\n",
      "final measurement_index = 50\n",
      "0 fidelity 1.0\n",
      "all_fidelities [1.0]\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "num_rounds = 1\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "num_cxs_per_rounds = [1] #[1, 3, 5, 7, 9, 11, 13, 15, 17]\n",
    "#[0.96, 0.9, 0.848, 0.798, 0.742, 0.677, 0.638]\n",
    "num_CX_per_layer_lists = [[i, i+1] for i in range(1, 20)]\n",
    "num_CX_per_layer_lists = np.array([np.arange(3, 21, 2)]).T\n",
    "num_CX_per_layer_lists = [[1]]\n",
    "print(num_CX_per_layer_lists)\n",
    "#raise Exception\n",
    "logical_error_rates = []\n",
    "for num_CX_per_layer_list in num_CX_per_layer_lists:\n",
    "    noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                    'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "                'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "    print(num_CX_per_layer_list)\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                'bias_preserving_gates': 'False',\n",
    "                'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "                'ordering': gate_ordering,\n",
    "                'decoder': 'MLE',\n",
    "                'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "                   'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "                'loss_decoder': 'independent',\n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "    # Load the experimental measurements\n",
    "    exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                       exp_measurements[:, 1, :distance**2-1],\n",
    "                                       exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                       exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "    # Now let's decode!\n",
    "    use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "    use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "    use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "    output_dir = '.'\n",
    "    simulate_data = True\n",
    "    # simulated_measurements, simulated_detection_events, simulated_observable_flips, circuit = get_simulated_measurement_events(\n",
    "    #     Meta_params, distance, distance, 1, noise_params)\n",
    "    \n",
    "    circuit = get_lossless_circuit(Meta_params, distance, distance, noise_params)\n",
    "    print(circuit)\n",
    "    Pauli_DEM = circuit.detector_error_model(decompose_errors=False, approximate_disjoint_errors=True, ignore_decomposition_failures=True, allow_gauge_detectors=True) # GB: new Oct24, allow_gauge_detectors = True to allow DEM generation when meas basis is wrong. \n",
    "    print(f\"DEM from the lossless circuit: {Pauli_DEM}\")\n",
    "    \n",
    "    print(\"NOW DECODING\")\n",
    "    #raise Exception\n",
    "    # DO IT\n",
    "    predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        None,\n",
    "                                                                        None, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots=10)\n",
    "\n",
    "\n",
    "    logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "\n",
    "    print('fidelity', 1-logical_probability)\n",
    "    logical_error_rates.append(1-logical_probability)\n",
    "\n",
    "    print('all_fidelities', logical_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance = 3\n",
      "num_CX_per_layer_list = [1, 1, 1]\n",
      "logical_CX__Nlayers3__NCX1_1_1\n",
      "final measurement_index = 50\n",
      "logical_CX__Nlayers3__NCX1_1_1\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.01453929717779214002) D0\n",
      "error(0.00718332878957505909) D0 D2 D6 D40\n",
      "error(0.002465202426008964755) D0 D2 D40\n",
      "error(0.00718332878957505909) D0 D3 D5 D6 D40\n",
      "error(0.002831414999999999887) D0 D3 D5 D13 D21 D40\n",
      "error(0.002831414999999999887) D0 D3 D5 D21 D40\n",
      "error(0.001010783130056933663) D0 D3 D6 D13 D21 D40\n",
      "error(0.001010783130056933663) D0 D3 D6 D21 D40\n",
      "error(0.005213970599049886148) D0 D3 D40\n",
      "error(0.00718332878957505909) D0 D4\n",
      "error(0.008857923348190079385) D0 D4 D5\n",
      "error(0.006330146405388720893) D0 D4 D12 D20\n",
      "error(0.001015965840252101588) D0 D4 D13 D21\n",
      "error(0.006330146405388720893) D0 D4 D20\n",
      "error(0.001015965840252101588) D0 D4 D21\n",
      "error(0.002665439999999999823) D0 D5 D13 D21\n",
      "error(0.002665439999999999823) D0 D5 D21\n",
      "error(0.002831414999999999887) D0 D6 D8\n",
      "error(0.001018345769905341881) D0 D6 D8 D12 D20\n",
      "error(0.002665439999999999823) D0 D6 D8 D13 D21\n",
      "error(0.002831414999999999887) D0 D6 D8 D16\n",
      "error(0.001018345769905341881) D0 D6 D8 D16 D20\n",
      "error(0.002665439999999999823) D0 D6 D8 D16 D21\n",
      "error(0.001015965840252101588) D0 D6 D11 D13 D21 D40\n",
      "error(0.001015965840252101588) D0 D6 D11 D19 D21 D40\n",
      "error(0.0432087996420145587) D0 D8\n",
      "error(0.002838065267102216072) D0 D8 D12 D13 D20 D21\n",
      "error(0.002665439999999999823) D0 D8 D12 D20\n",
      "error(0.0432087996420145587) D0 D8 D16\n",
      "error(0.002665439999999999823) D0 D8 D16 D20\n",
      "error(0.002838065267102216072) D0 D8 D16 D20 D21\n",
      "error(2.879825239673086635e-05) D0 D11 D19 D40\n",
      "error(2.879825239673086635e-05) D0 D11 D40\n",
      "error(0.001015965840252101588) D0 D12 D13 D20 D21\n",
      "error(0.001010783130056933663) D0 D12 D20\n",
      "error(0.001010783130056933663) D0 D20\n",
      "error(0.001015965840252101588) D0 D20 D21\n",
      "error(0.005062995401453437155) D1\n",
      "error(0.00718332878957505909) D1 D3 D5 D40\n",
      "error(0.002465202426008964755) D1 D3 D40\n",
      "error(0.008857923348190079385) D1 D5\n",
      "error(0.006317584575443702458) D1 D5 D9\n",
      "error(0.006317584575443702458) D1 D5 D9 D17\n",
      "error(0.04234524506783991782) D1 D9\n",
      "error(0.04234524506783991782) D1 D9 D17\n",
      "error(0.005873487080242408356) D2\n",
      "error(0.00718332878957505909) D2 D6\n",
      "error(0.002665439999999999823) D2 D6 D8 D14 D22 D40\n",
      "error(0.002665439999999999823) D2 D6 D8 D16 D22 D40\n",
      "error(0.001010783130056933663) D2 D6 D8 D16 D40\n",
      "error(0.001010783130056933663) D2 D6 D8 D40\n",
      "error(0.002831414999999999887) D2 D6 D14 D22\n",
      "error(0.002831414999999999887) D2 D6 D22\n",
      "error(0.001869636747823257353) D2 D8 D14 D22 D40\n",
      "error(0.001869636747823257353) D2 D8 D16 D22 D40\n",
      "error(0.002792729717509890783) D2 D8 D16 D40\n",
      "error(0.002792729717509890783) D2 D8 D40\n",
      "error(0.04390978330455011514) D2 D10\n",
      "error(0.006325066785842492489) D2 D10 D14 D22\n",
      "error(0.04390978330455011514) D2 D10 D18\n",
      "error(0.006325066785842492489) D2 D10 D18 D22\n",
      "error(0.001864462904302397611) D2 D14 D22\n",
      "error(0.001864462904302397611) D2 D22\n",
      "error(0.008159700255888127293) D3\n",
      "error(0.002665439999999999823) D3 D5 D9 D13 D21 D40\n",
      "error(0.002665439999999999823) D3 D5 D9 D17 D21 D40\n",
      "error(0.001864462904302397611) D3 D5 D9 D17 D40\n",
      "error(0.001864462904302397611) D3 D5 D9 D40\n",
      "error(0.001018345769905341881) D3 D5 D13 D21 D40\n",
      "error(0.001018345769905341881) D3 D5 D21 D40\n",
      "error(0.00718332878957505909) D3 D6 D7\n",
      "error(0.002831414999999999887) D3 D6 D7 D11\n",
      "error(0.002831414999999999887) D3 D6 D7 D11 D19\n",
      "error(0.002665439999999999823) D3 D6 D11 D13 D21\n",
      "error(0.002665439999999999823) D3 D6 D11 D19 D21\n",
      "error(0.01053699531493879071) D3 D7\n",
      "error(0.002665439999999999823) D3 D7 D11\n",
      "error(0.001018345769905341881) D3 D7 D11 D13 D21\n",
      "error(0.002665439999999999823) D3 D7 D11 D19\n",
      "error(0.001018345769905341881) D3 D7 D11 D19 D21\n",
      "error(0.001015965840252101588) D3 D9 D13 D21 D40\n",
      "error(0.001015965840252101588) D3 D9 D17 D21 D40\n",
      "error(0.002792729717509890349) D3 D9 D17 D40\n",
      "error(0.002792729717509890349) D3 D9 D40\n",
      "error(0.0432087996420145587) D3 D11\n",
      "error(0.002838065267102216072) D3 D11 D13 D21\n",
      "error(0.0432087996420145587) D3 D11 D19\n",
      "error(0.002838065267102216072) D3 D11 D19 D21\n",
      "error(0.0001074957233508252151) D3 D40\n",
      "error(0.002465202426008964755) D4\n",
      "error(0.005062995401453437155) D4 D5\n",
      "error(0.04311536755819837807) D4 D12 D20\n",
      "error(2.879825239673086635e-05) D4 D13 D21\n",
      "error(0.04311536755819837807) D4 D20\n",
      "error(2.879825239673086635e-05) D4 D21\n",
      "error(0.01439667007012129622) D5\n",
      "error(0.002465202426008964755) D5 D6\n",
      "error(0.001869636747823257353) D5 D9\n",
      "error(0.002838065267102216072) D5 D9 D13 D21\n",
      "error(0.001869636747823257353) D5 D9 D17\n",
      "error(0.002838065267102216072) D5 D9 D17 D21\n",
      "error(0.0432087996420145587) D5 D13 D21\n",
      "error(0.0432087996420145587) D5 D21\n",
      "error(0.007653466039119012979) D6\n",
      "error(0.005213970599049887016) D6 D7\n",
      "error(0.001010783130056933663) D6 D7 D11\n",
      "error(0.001010783130056933663) D6 D7 D11 D19\n",
      "error(0.001015965840252101588) D6 D8 D11 D13 D21 D40\n",
      "error(0.002838065267102216072) D6 D8 D11 D14 D22 D40\n",
      "error(0.001015965840252101588) D6 D8 D11 D16 D19 D21 D40\n",
      "error(0.002838065267102216072) D6 D8 D11 D16 D19 D22 D40\n",
      "error(0.001018345769905341881) D6 D8 D14 D22 D40\n",
      "error(0.001018345769905341881) D6 D8 D16 D22 D40\n",
      "error(0.002665439999999999823) D6 D11 D14 D22\n",
      "error(0.001015965840252101588) D6 D11 D15 D23\n",
      "error(0.002665439999999999823) D6 D11 D19 D22\n",
      "error(0.001015965840252101588) D6 D11 D19 D23\n",
      "error(5.375075081862617642e-05) D6 D12 D20\n",
      "error(0.002849896465810894831) D6 D13 D21\n",
      "error(0.0432087996420145587) D6 D14 D22\n",
      "error(2.879825239673086635e-05) D6 D15 D23\n",
      "error(5.375075081862617642e-05) D6 D20\n",
      "error(0.002849896465810894831) D6 D21\n",
      "error(0.0432087996420145587) D6 D22\n",
      "error(2.879825239673086635e-05) D6 D23\n",
      "error(0.008606790840629869113) D7\n",
      "error(0.001015965840252101588) D7 D11\n",
      "error(0.006337628425401439433) D7 D11 D15 D23\n",
      "error(0.001015965840252101588) D7 D11 D19\n",
      "error(0.006337628425401439433) D7 D11 D19 D23\n",
      "error(5.375075081862617642e-05) D7 D13 D21\n",
      "error(0.04310844294704657687) D7 D15 D23\n",
      "error(5.375075081862617642e-05) D7 D21\n",
      "error(0.04310844294704657687) D7 D23\n",
      "error(0.01225372096842798977) D8\n",
      "error(0.001864511231830490688) D8 D10 D14 D22 D40\n",
      "error(0.002696118176924125909) D8 D10 D14 D40\n",
      "error(0.001021148496617479279) D8 D10 D16 D18 D22 D40\n",
      "error(2.986018364957227354e-05) D8 D10 D16 D18 D40\n",
      "error(0.002665439999999999823) D8 D10 D22 D40\n",
      "error(0.001478969471745447293) D8 D10 D40\n",
      "error(0.001021148496617479279) D8 D11 D13 D14 D21 D22 D40\n",
      "error(0.001854163384577362395) D8 D11 D13 D14 D40\n",
      "error(0.002831414999999999887) D8 D11 D13 D40\n",
      "error(0.001010783130056933663) D8 D11 D14 D40\n",
      "error(0.001864511231830490688) D8 D11 D16 D19 D21 D22 D40\n",
      "error(0.001506680709392006984) D8 D11 D16 D19 D40\n",
      "error(0.002665439999999999823) D8 D11 D21 D22 D40\n",
      "error(0.004284518053672076512) D8 D11 D40\n",
      "error(0.008148320292023548267) D8 D12\n",
      "error(0.003541758227067706103) D8 D12 D13\n",
      "error(0.001864511231830490688) D8 D12 D13 D20 D21\n",
      "error(0.002727012118140913731) D8 D12 D20\n",
      "error(0.003675989848273618615) D8 D13\n",
      "error(0.001018345769905341881) D8 D13 D25 D33\n",
      "error(0.005481761066404799987) D8 D14 D24 D32\n",
      "error(0.001766904925337182443) D8 D16\n",
      "error(0.003567491641359241215) D8 D16 D20\n",
      "error(0.001021148496617479279) D8 D16 D20 D21\n",
      "error(5.375075081862617642e-05) D8 D16 D40\n",
      "error(0.002665439999999999823) D8 D20\n",
      "error(0.002665439999999999823) D8 D20 D21\n",
      "error(0.049158419805032251) D8 D24 D32\n",
      "error(5.375075081862617642e-05) D8 D25 D33\n",
      "error(5.375075081862617642e-05) D8 D40\n",
      "error(0.00486975060034565508) D9\n",
      "error(0.001864511231830490688) D9 D11 D13 D21 D40\n",
      "error(0.002696118176924125909) D9 D11 D13 D40\n",
      "error(0.001021148496617479279) D9 D11 D17 D19 D21 D40\n",
      "error(2.986018364957227354e-05) D9 D11 D17 D19 D40\n",
      "error(0.002665439999999999823) D9 D11 D21 D40\n",
      "error(0.001478969471745447293) D9 D11 D40\n",
      "error(0.003552022854568235351) D9 D13\n",
      "error(0.001021148496617479279) D9 D13 D21\n",
      "error(0.006330146405388720893) D9 D13 D25 D33\n",
      "error(0.001839020517540080691) D9 D17\n",
      "error(0.001864511231830490688) D9 D17 D21\n",
      "error(0.002665439999999999823) D9 D21\n",
      "error(0.04311536755819837807) D9 D25 D33\n",
      "error(0.005185920509368709651) D10\n",
      "error(0.004675078572538276384) D10 D14\n",
      "error(0.001874810537606419209) D10 D14 D22\n",
      "error(0.004519963676295111164) D10 D14 D24 D32 D40\n",
      "error(0.001018345769905341881) D10 D14 D27 D35\n",
      "error(0.001404740714453617603) D10 D18\n",
      "error(0.002716730432603525151) D10 D18 D22\n",
      "error(0.002665439999999999823) D10 D22\n",
      "error(0.003803463737702784692) D10 D24 D32 D40\n",
      "error(0.04891386968098601629) D10 D26 D34\n",
      "error(5.375075081862617642e-05) D10 D27 D35\n",
      "error(0.009144383045262705761) D11\n",
      "error(0.003670834766484575885) D11 D13 D25 D33 D40\n",
      "error(0.002696118176924125909) D11 D14 D15\n",
      "error(0.002716730432603525151) D11 D14 D15 D22 D23\n",
      "error(0.002831414999999999887) D11 D14 D15 D27 D35\n",
      "error(0.001015965840252101588) D11 D14 D24 D32 D40\n",
      "error(0.003678357090807468904) D11 D14 D27 D35\n",
      "error(0.002701235136179231701) D11 D15\n",
      "error(0.001021148496617479279) D11 D15 D23\n",
      "error(0.002665439999999999823) D11 D15 D27 D35\n",
      "error(0.005034465280013796992) D11 D19\n",
      "error(0.001874810537606419209) D11 D19 D22 D23\n",
      "error(0.001864511231830490688) D11 D19 D23\n",
      "error(0.002665439999999999823) D11 D22 D23\n",
      "error(0.002665439999999999823) D11 D23\n",
      "error(2.879825239673086635e-05) D11 D24 D32 D40\n",
      "error(0.004652365743471347306) D11 D25 D33 D40\n",
      "error(0.04580936623556411402) D11 D27 D35\n",
      "error(0.04237887617123105993) D12\n",
      "error(0.001357748790366670099) D12 D13\n",
      "error(0.001506680709392006984) D12 D13 D20 D21\n",
      "error(0.003125267488098796773) D12 D20\n",
      "error(0.04772232134189638431) D13\n",
      "error(3.674287552866961886e-05) D13 D14\n",
      "error(2.986018364957227354e-05) D13 D14 D21 D22\n",
      "error(0.001536450913516211863) D13 D21\n",
      "error(0.003848264352626754731) D13 D25 D33\n",
      "error(0.04749869143850916908) D14\n",
      "error(0.001433807312582543667) D14 D15\n",
      "error(0.001404740714453617603) D14 D15 D22 D23\n",
      "error(0.001010783130056933663) D14 D15 D27 D35\n",
      "error(0.004961760818282177216) D14 D22\n",
      "error(0.003848264352626754731) D14 D24 D27 D32 D35 D40\n",
      "error(0.002665439999999999823) D14 D27 D35\n",
      "error(0.04679293518973928756) D15\n",
      "error(2.986018364957227354e-05) D15 D23\n",
      "error(0.009170415199135256365) D15 D27 D35\n",
      "error(0.007802111820677886354) D16\n",
      "error(3.674287552866961886e-05) D16 D18\n",
      "error(0.001854163384577362395) D16 D18 D22\n",
      "error(0.001433807312582543667) D16 D19\n",
      "error(0.002831414999999999887) D16 D19 D21\n",
      "error(0.002696118176924125909) D16 D19 D21 D22\n",
      "error(0.001010783130056933663) D16 D19 D22\n",
      "error(0.008979636843151611938) D16 D20\n",
      "error(0.002701235136179231701) D16 D20 D21\n",
      "error(0.003675989848273618615) D16 D21\n",
      "error(0.001018345769905341881) D16 D21 D25 D29 D33 D37\n",
      "error(0.005481761066404799987) D16 D22 D24 D28 D32 D36\n",
      "error(0.049158419805032251) D16 D24 D28 D32 D36\n",
      "error(5.375075081862617642e-05) D16 D25 D29 D33 D37\n",
      "error(0.001690187889725839991) D17\n",
      "error(3.674287552866961886e-05) D17 D19\n",
      "error(0.001854163384577362395) D17 D19 D21\n",
      "error(0.004391107963355657395) D17 D21\n",
      "error(0.006330146405388720893) D17 D21 D25 D29 D33 D37\n",
      "error(0.04311536755819837807) D17 D25 D29 D33 D37\n",
      "error(0.00244214215948672592) D18\n",
      "error(0.005512265518028294439) D18 D22\n",
      "error(0.004519963676295111164) D18 D22 D24 D28 D32 D36\n",
      "error(0.001018345769905341881) D18 D22 D27 D31 D35 D39\n",
      "error(0.003803463737702784692) D18 D24 D28 D32 D36\n",
      "error(0.04891386968098601629) D18 D26 D30 D34 D38\n",
      "error(5.375075081862617642e-05) D18 D27 D31 D35 D39\n",
      "error(0.001394391890705732728) D19\n",
      "error(0.003670834766484575885) D19 D21 D25 D29 D33 D37\n",
      "error(0.001854163384577362395) D19 D22 D23\n",
      "error(0.002831414999999999887) D19 D22 D23 D27 D31 D35 D39\n",
      "error(0.001015965840252101588) D19 D22 D24 D28 D32 D36\n",
      "error(0.003678357090807468904) D19 D22 D27 D31 D35 D39\n",
      "error(0.003541758227067706103) D19 D23\n",
      "error(0.002665439999999999823) D19 D23 D27 D31 D35 D39\n",
      "error(2.879825239673086635e-05) D19 D24 D28 D32 D36\n",
      "error(0.004652365743471347306) D19 D25 D29 D33 D37\n",
      "error(0.04580936623556411402) D19 D27 D31 D35 D39\n",
      "error(0.04652400374795213206) D20\n",
      "error(0.004208894420242112293) D20 D21\n",
      "error(0.05160557259018355714) D21\n",
      "error(0.001478969471745447293) D21 D22\n",
      "error(0.003848264352626754731) D21 D25 D29 D33 D37\n",
      "error(0.05446663442194162041) D22\n",
      "error(0.004183146115945002297) D22 D23\n",
      "error(0.001010783130056933663) D22 D23 D27 D31 D35 D39\n",
      "error(0.003848264352626754731) D22 D24 D27 D28 D31 D32 D35 D36 D39\n",
      "error(0.002665439999999999823) D22 D27 D31 D35 D39\n",
      "error(0.04810028582630811872) D23\n",
      "error(0.009170415199135256365) D23 D27 D31 D35 D39\n",
      "error(0.001050953903419058399) D24 D26 D28 D30 D32 D34 D36 D38\n",
      "error(0.01098687334218738897) D24 D26 D32 D34 D40\n",
      "error(0.003366016701327173739) D24 D27 D28 D31 D32 D35 D36 D39\n",
      "error(0.01157874093050522551) D24 D27 D32 D35 D40\n",
      "error(0.005156151692878106763) D24 D28 D32 D36\n",
      "error(0.02303048645843821032) D24 D32\n",
      "error(0.001050953903419058399) D25 D27 D29 D31 D33 D35 D37 D39\n",
      "error(0.01098687334218738897) D25 D27 D33 D35 D40\n",
      "error(0.003366016701327173739) D25 D29 D33 D37\n",
      "error(0.01157874093050522551) D25 D33\n",
      "error(0.00529225175455057522) D26 D30 D34 D38\n",
      "error(0.01347312226887080813) D26 D34\n",
      "error(0.008714429018742557084) D27 D31 D35 D39\n",
      "error(0.02646023467288944817) D27 D35\n",
      "error(0.004251871653758736332) D28 D30 D36 D38 D40\n",
      "error(0.004251871653758736332) D28 D31 D36 D39 D40\n",
      "error(0.008467586482397400707) D28 D36\n",
      "error(0.004251871653758736332) D29 D31 D37 D39 D40\n",
      "error(0.004251871653758736332) D29 D37\n",
      "error(0.004251871653758736332) D30 D38\n",
      "error(0.008467586482397400707) D31 D39\n",
      "final measurement_index = 50\n",
      "0 observables_errors_interactions_lists.shape = 10 and shape of first element: 1\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-24\n",
      "0 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "MLE decoder took 0.296666s.\n",
      "fidelity 0.5\n",
      "all_fidelities [0.5]\n",
      "distance = 5\n",
      "num_CX_per_layer_list = [1, 1, 1]\n",
      "logical_CX__Nlayers3__NCX1_1_1\n",
      "final measurement_index = 146\n",
      "logical_CX__Nlayers3__NCX1_1_1\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.01453929717779214002) D0\n",
      "error(0.002465202426008964755) D0 D3\n",
      "error(0.00718332878957505909) D0 D3 D16\n",
      "error(0.005213970599049886148) D0 D4\n",
      "error(0.00718332878957505909) D0 D4 D14 D16\n",
      "error(0.002831414999999999887) D0 D4 D14 D38 D62\n",
      "error(0.002831414999999999887) D0 D4 D14 D62\n",
      "error(0.001010783130056933663) D0 D4 D16 D38 D62\n",
      "error(0.001010783130056933663) D0 D4 D16 D62\n",
      "error(0.00718332878957505909) D0 D12\n",
      "error(0.008857923348190079385) D0 D12 D14\n",
      "error(0.006330146405388720893) D0 D12 D36 D60\n",
      "error(0.001015965840252101588) D0 D12 D38 D62\n",
      "error(0.006330146405388720893) D0 D12 D60\n",
      "error(0.001015965840252101588) D0 D12 D62\n",
      "error(0.002665439999999999823) D0 D14 D38 D62\n",
      "error(0.002665439999999999823) D0 D14 D62\n",
      "error(0.002831414999999999887) D0 D16 D24\n",
      "error(0.001018345769905341881) D0 D16 D24 D36 D60\n",
      "error(0.002665439999999999823) D0 D16 D24 D38 D62\n",
      "error(0.002831414999999999887) D0 D16 D24 D48\n",
      "error(0.001018345769905341881) D0 D16 D24 D48 D60\n",
      "error(0.002665439999999999823) D0 D16 D24 D48 D62\n",
      "error(0.001015965840252101588) D0 D16 D28 D38 D62\n",
      "error(0.001015965840252101588) D0 D16 D28 D52 D62\n",
      "error(0.0432087996420145587) D0 D24\n",
      "error(0.002838065267102216072) D0 D24 D36 D38 D60 D62\n",
      "error(0.002665439999999999823) D0 D24 D36 D60\n",
      "error(0.0432087996420145587) D0 D24 D48\n",
      "error(0.002665439999999999823) D0 D24 D48 D60\n",
      "error(0.002838065267102216072) D0 D24 D48 D60 D62\n",
      "error(2.879825239673086635e-05) D0 D28\n",
      "error(2.879825239673086635e-05) D0 D28 D52\n",
      "error(0.001015965840252101588) D0 D36 D38 D60 D62\n",
      "error(0.001010783130056933663) D0 D36 D60\n",
      "error(0.001010783130056933663) D0 D60\n",
      "error(0.001015965840252101588) D0 D60 D62\n",
      "error(0.01453929717779214002) D1\n",
      "error(0.002465202426008964755) D1 D4\n",
      "error(0.00718332878957505909) D1 D4 D14 D17\n",
      "error(0.005213970599049886148) D1 D5\n",
      "error(0.00718332878957505909) D1 D5 D15 D17\n",
      "error(0.002831414999999999887) D1 D5 D15 D39 D63\n",
      "error(0.002831414999999999887) D1 D5 D15 D63\n",
      "error(0.001010783130056933663) D1 D5 D17 D39 D63\n",
      "error(0.001010783130056933663) D1 D5 D17 D63\n",
      "error(0.00718332878957505909) D1 D13 D14\n",
      "error(0.008857923348190079385) D1 D13 D15\n",
      "error(0.006330146405388720893) D1 D13 D37 D61\n",
      "error(0.001015965840252101588) D1 D13 D39 D63\n",
      "error(0.006330146405388720893) D1 D13 D61\n",
      "error(0.001015965840252101588) D1 D13 D63\n",
      "error(0.002831414999999999887) D1 D14 D17 D25\n",
      "error(0.002831414999999999887) D1 D14 D17 D25 D49\n",
      "error(0.002665439999999999823) D1 D14 D25 D37 D61\n",
      "error(0.002665439999999999823) D1 D14 D25 D49 D61\n",
      "error(0.001010783130056933663) D1 D14 D37 D61\n",
      "error(0.001010783130056933663) D1 D14 D61\n",
      "error(0.002665439999999999823) D1 D15 D39 D63\n",
      "error(0.002665439999999999823) D1 D15 D63\n",
      "error(0.001018345769905341881) D1 D17 D25 D37 D61\n",
      "error(0.002665439999999999823) D1 D17 D25 D39 D63\n",
      "error(0.001018345769905341881) D1 D17 D25 D49 D61\n",
      "error(0.002665439999999999823) D1 D17 D25 D49 D63\n",
      "error(0.001015965840252101588) D1 D17 D29 D39 D63\n",
      "error(0.001015965840252101588) D1 D17 D29 D53 D63\n",
      "error(0.0432087996420145587) D1 D25\n",
      "error(0.002838065267102216072) D1 D25 D37 D39 D61 D63\n",
      "error(0.0432087996420145587) D1 D25 D49\n",
      "error(0.002838065267102216072) D1 D25 D49 D61 D63\n",
      "error(2.879825239673086635e-05) D1 D29\n",
      "error(2.879825239673086635e-05) D1 D29 D53\n",
      "error(0.001015965840252101588) D1 D37 D39 D61 D63\n",
      "error(0.001015965840252101588) D1 D61 D63\n",
      "error(0.005062995401453437155) D2\n",
      "error(0.002465202426008964755) D2 D5\n",
      "error(0.00718332878957505909) D2 D5 D15\n",
      "error(0.008857923348190079385) D2 D15\n",
      "error(0.006317584575443702458) D2 D15 D26\n",
      "error(0.006317584575443702458) D2 D15 D26 D50\n",
      "error(0.04234524506783991782) D2 D26\n",
      "error(0.04234524506783991782) D2 D26 D50\n",
      "error(0.002831414999999999887) D3 D6 D16 D40 D64 D120\n",
      "error(0.002831414999999999887) D3 D6 D16 D64 D120\n",
      "error(0.00718332878957505909) D3 D6 D16 D120\n",
      "error(0.001010783130056933663) D3 D6 D40 D64 D120\n",
      "error(0.001010783130056933663) D3 D6 D64 D120\n",
      "error(0.005213970599049886148) D3 D6 D120\n",
      "error(0.001010783130056933663) D3 D16 D24\n",
      "error(0.002665439999999999823) D3 D16 D24 D40 D64\n",
      "error(0.001010783130056933663) D3 D16 D24 D48\n",
      "error(0.002665439999999999823) D3 D16 D24 D48 D64\n",
      "error(0.002792729717509890783) D3 D24\n",
      "error(0.001869636747823257353) D3 D24 D40 D64\n",
      "error(0.002792729717509890783) D3 D24 D48\n",
      "error(0.001869636747823257353) D3 D24 D48 D64\n",
      "error(0.04390978330455011514) D3 D27\n",
      "error(0.006325066785842492489) D3 D27 D40 D64\n",
      "error(0.04390978330455011514) D3 D27 D51\n",
      "error(0.006325066785842492489) D3 D27 D51 D64\n",
      "error(0.001015965840252101588) D3 D30 D40 D64 D120\n",
      "error(0.001015965840252101588) D3 D30 D54 D64 D120\n",
      "error(2.879825239673086635e-05) D3 D30 D54 D120\n",
      "error(2.879825239673086635e-05) D3 D30 D120\n",
      "error(0.0001074957233508252151) D4\n",
      "error(0.00718332878957505909) D4 D6 D16 D18 D120\n",
      "error(0.002465202426008964755) D4 D6 D120\n",
      "error(0.00718332878957505909) D4 D7 D17 D18 D120\n",
      "error(0.002831414999999999887) D4 D7 D17 D41 D65 D120\n",
      "error(0.002831414999999999887) D4 D7 D17 D65 D120\n",
      "error(0.001010783130056933663) D4 D7 D18 D41 D65 D120\n",
      "error(0.001010783130056933663) D4 D7 D18 D65 D120\n",
      "error(0.005213970599049886148) D4 D7 D120\n",
      "error(0.001010783130056933663) D4 D14 D17 D25\n",
      "error(0.001010783130056933663) D4 D14 D17 D25 D49\n",
      "error(0.002665439999999999823) D4 D14 D25 D38 D62\n",
      "error(0.001015965840252101588) D4 D14 D25 D41 D65\n",
      "error(0.002665439999999999823) D4 D14 D25 D49 D62\n",
      "error(0.001015965840252101588) D4 D14 D25 D49 D65\n",
      "error(0.001018345769905341881) D4 D14 D38 D62\n",
      "error(0.001018345769905341881) D4 D14 D62\n",
      "error(0.002831414999999999887) D4 D16 D18 D28\n",
      "error(0.002831414999999999887) D4 D16 D18 D28 D52\n",
      "error(0.002665439999999999823) D4 D16 D28 D38 D62\n",
      "error(0.002665439999999999823) D4 D16 D28 D52 D62\n",
      "error(0.002665439999999999823) D4 D17 D25 D41 D65\n",
      "error(0.002665439999999999823) D4 D17 D25 D49 D65\n",
      "error(0.001018345769905341881) D4 D18 D28 D38 D62\n",
      "error(0.002665439999999999823) D4 D18 D28 D41 D65\n",
      "error(0.001018345769905341881) D4 D18 D28 D52 D62\n",
      "error(0.002665439999999999823) D4 D18 D28 D52 D65\n",
      "error(0.001015965840252101588) D4 D18 D31 D41 D65 D120\n",
      "error(0.001015965840252101588) D4 D18 D31 D55 D65 D120\n",
      "error(0.002849896465810894831) D4 D25\n",
      "error(0.001015965840252101588) D4 D25 D38 D41 D62 D65\n",
      "error(0.002849896465810894831) D4 D25 D49\n",
      "error(0.001015965840252101588) D4 D25 D49 D62 D65\n",
      "error(0.0432087996420145587) D4 D28\n",
      "error(0.002838065267102216072) D4 D28 D38 D41 D62 D65\n",
      "error(0.0432087996420145587) D4 D28 D52\n",
      "error(0.002838065267102216072) D4 D28 D52 D62 D65\n",
      "error(2.879825239673086635e-05) D4 D31 D55 D120\n",
      "error(2.879825239673086635e-05) D4 D31 D120\n",
      "error(0.0001074957233508252151) D5\n",
      "error(0.00718332878957505909) D5 D7 D17 D19 D120\n",
      "error(0.002465202426008964755) D5 D7 D120\n",
      "error(0.008857923348190079385) D5 D8 D19 D120\n",
      "error(0.005062995401453437155) D5 D8 D120\n",
      "error(0.001864462904302397611) D5 D15 D26\n",
      "error(0.002665439999999999823) D5 D15 D26 D39 D63\n",
      "error(0.001864462904302397611) D5 D15 D26 D50\n",
      "error(0.002665439999999999823) D5 D15 D26 D50 D63\n",
      "error(0.001018345769905341881) D5 D15 D39 D63\n",
      "error(0.001018345769905341881) D5 D15 D63\n",
      "error(0.002831414999999999887) D5 D17 D19 D29\n",
      "error(0.002831414999999999887) D5 D17 D19 D29 D53\n",
      "error(0.002665439999999999823) D5 D17 D29 D39 D63\n",
      "error(0.002665439999999999823) D5 D17 D29 D53 D63\n",
      "error(0.002665439999999999823) D5 D19 D29\n",
      "error(0.001018345769905341881) D5 D19 D29 D39 D63\n",
      "error(0.002665439999999999823) D5 D19 D29 D53\n",
      "error(0.001018345769905341881) D5 D19 D29 D53 D63\n",
      "error(0.001015965840252101588) D5 D19 D32 D56 D120\n",
      "error(0.001015965840252101588) D5 D19 D32 D120\n",
      "error(0.002792729717509890349) D5 D26\n",
      "error(0.001015965840252101588) D5 D26 D39 D63\n",
      "error(0.002792729717509890349) D5 D26 D50\n",
      "error(0.001015965840252101588) D5 D26 D50 D63\n",
      "error(0.0432087996420145587) D5 D29\n",
      "error(0.002838065267102216072) D5 D29 D39 D63\n",
      "error(0.0432087996420145587) D5 D29 D53\n",
      "error(0.002838065267102216072) D5 D29 D53 D63\n",
      "error(2.879825239673086635e-05) D5 D32 D56 D120\n",
      "error(2.879825239673086635e-05) D5 D32 D120\n",
      "error(0.002465202426008964755) D6 D9\n",
      "error(0.00718332878957505909) D6 D9 D20\n",
      "error(0.005213970599049886148) D6 D10\n",
      "error(0.00718332878957505909) D6 D10 D18 D20\n",
      "error(0.002831414999999999887) D6 D10 D18 D42 D66\n",
      "error(0.002831414999999999887) D6 D10 D18 D66\n",
      "error(0.001010783130056933663) D6 D10 D20 D42 D66\n",
      "error(0.001010783130056933663) D6 D10 D20 D66\n",
      "error(0.001010783130056933663) D6 D16 D18 D28 D52 D120\n",
      "error(0.001010783130056933663) D6 D16 D18 D28 D120\n",
      "error(0.001018345769905341881) D6 D16 D24 D40 D64 D120\n",
      "error(0.001018345769905341881) D6 D16 D24 D48 D64 D120\n",
      "error(0.002665439999999999823) D6 D16 D28 D40 D64 D120\n",
      "error(0.001015965840252101588) D6 D16 D28 D42 D66 D120\n",
      "error(0.002665439999999999823) D6 D16 D28 D52 D64 D120\n",
      "error(0.001015965840252101588) D6 D16 D28 D52 D66 D120\n",
      "error(0.002665439999999999823) D6 D18 D28 D42 D66 D120\n",
      "error(0.002665439999999999823) D6 D18 D28 D52 D66 D120\n",
      "error(0.002831414999999999887) D6 D20 D30\n",
      "error(0.001018345769905341881) D6 D20 D30 D40 D64\n",
      "error(0.002665439999999999823) D6 D20 D30 D42 D66\n",
      "error(0.002831414999999999887) D6 D20 D30 D54\n",
      "error(0.001018345769905341881) D6 D20 D30 D54 D64\n",
      "error(0.002665439999999999823) D6 D20 D30 D54 D66\n",
      "error(0.001015965840252101588) D6 D20 D34 D42 D66\n",
      "error(0.001015965840252101588) D6 D20 D34 D58 D66\n",
      "error(5.375075081862617642e-05) D6 D24 D48 D120\n",
      "error(5.375075081862617642e-05) D6 D24 D120\n",
      "error(0.001015965840252101588) D6 D28 D40 D42 D64 D66 D120\n",
      "error(0.001015965840252101588) D6 D28 D52 D64 D66 D120\n",
      "error(0.002849896465810894831) D6 D28 D52 D120\n",
      "error(0.002849896465810894831) D6 D28 D120\n",
      "error(0.0432087996420145587) D6 D30\n",
      "error(0.002838065267102216072) D6 D30 D40 D42 D64 D66\n",
      "error(0.002665439999999999823) D6 D30 D40 D64\n",
      "error(0.0432087996420145587) D6 D30 D54\n",
      "error(0.002665439999999999823) D6 D30 D54 D64\n",
      "error(0.002838065267102216072) D6 D30 D54 D64 D66\n",
      "error(2.879825239673086635e-05) D6 D34\n",
      "error(2.879825239673086635e-05) D6 D34 D58\n",
      "error(0.002465202426008964755) D7 D10\n",
      "error(0.00718332878957505909) D7 D10 D18 D21\n",
      "error(0.005213970599049886148) D7 D11\n",
      "error(0.00718332878957505909) D7 D11 D19 D21\n",
      "error(0.002831414999999999887) D7 D11 D19 D43 D67\n",
      "error(0.002831414999999999887) D7 D11 D19 D67\n",
      "error(0.001010783130056933663) D7 D11 D21 D43 D67\n",
      "error(0.001010783130056933663) D7 D11 D21 D67\n",
      "error(0.001010783130056933663) D7 D17 D19 D29 D53 D120\n",
      "error(0.001010783130056933663) D7 D17 D19 D29 D120\n",
      "error(0.001018345769905341881) D7 D17 D25 D41 D65 D120\n",
      "error(0.001018345769905341881) D7 D17 D25 D49 D65 D120\n",
      "error(0.002665439999999999823) D7 D17 D29 D41 D65 D120\n",
      "error(0.001015965840252101588) D7 D17 D29 D43 D67 D120\n",
      "error(0.002665439999999999823) D7 D17 D29 D53 D65 D120\n",
      "error(0.001015965840252101588) D7 D17 D29 D53 D67 D120\n",
      "error(0.002831414999999999887) D7 D18 D21 D31\n",
      "error(0.002831414999999999887) D7 D18 D21 D31 D55\n",
      "error(0.002665439999999999823) D7 D18 D31 D41 D65\n",
      "error(0.002665439999999999823) D7 D18 D31 D55 D65\n",
      "error(0.002665439999999999823) D7 D19 D29 D43 D67 D120\n",
      "error(0.002665439999999999823) D7 D19 D29 D53 D67 D120\n",
      "error(0.001018345769905341881) D7 D21 D31 D41 D65\n",
      "error(0.002665439999999999823) D7 D21 D31 D43 D67\n",
      "error(0.001018345769905341881) D7 D21 D31 D55 D65\n",
      "error(0.002665439999999999823) D7 D21 D31 D55 D67\n",
      "error(0.001015965840252101588) D7 D21 D35 D43 D67\n",
      "error(0.001015965840252101588) D7 D21 D35 D59 D67\n",
      "error(5.375075081862617642e-05) D7 D25 D49 D120\n",
      "error(5.375075081862617642e-05) D7 D25 D120\n",
      "error(0.001015965840252101588) D7 D29 D41 D43 D65 D67 D120\n",
      "error(0.001015965840252101588) D7 D29 D53 D65 D67 D120\n",
      "error(0.002849896465810894831) D7 D29 D53 D120\n",
      "error(0.002849896465810894831) D7 D29 D120\n",
      "error(0.0432087996420145587) D7 D31\n",
      "error(0.002838065267102216072) D7 D31 D41 D43 D65 D67\n",
      "error(0.0432087996420145587) D7 D31 D55\n",
      "error(0.002838065267102216072) D7 D31 D55 D65 D67\n",
      "error(2.879825239673086635e-05) D7 D35\n",
      "error(2.879825239673086635e-05) D7 D35 D59\n",
      "error(0.002465202426008964755) D8 D11\n",
      "error(0.00718332878957505909) D8 D11 D19\n",
      "error(0.006317584575443702458) D8 D19 D32\n",
      "error(0.006317584575443702458) D8 D19 D32 D56\n",
      "error(0.04234524506783991782) D8 D32\n",
      "error(0.04234524506783991782) D8 D32 D56\n",
      "error(0.005873487080242408356) D9\n",
      "error(0.00718332878957505909) D9 D20\n",
      "error(0.001010783130056933663) D9 D20 D30\n",
      "error(0.002665439999999999823) D9 D20 D30 D44 D68\n",
      "error(0.001010783130056933663) D9 D20 D30 D54\n",
      "error(0.002665439999999999823) D9 D20 D30 D54 D68\n",
      "error(0.002831414999999999887) D9 D20 D44 D68\n",
      "error(0.002831414999999999887) D9 D20 D68\n",
      "error(0.002792729717509890783) D9 D30\n",
      "error(0.001869636747823257353) D9 D30 D44 D68\n",
      "error(0.002792729717509890783) D9 D30 D54\n",
      "error(0.001869636747823257353) D9 D30 D54 D68\n",
      "error(0.04390978330455011514) D9 D33\n",
      "error(0.006325066785842492489) D9 D33 D44 D68\n",
      "error(0.04390978330455011514) D9 D33 D57\n",
      "error(0.006325066785842492489) D9 D33 D57 D68\n",
      "error(0.001864462904302397611) D9 D44 D68\n",
      "error(0.001864462904302397611) D9 D68\n",
      "error(0.008309730837052683658) D10\n",
      "error(0.001010783130056933663) D10 D18 D21 D31\n",
      "error(0.001010783130056933663) D10 D18 D21 D31 D55\n",
      "error(0.001018345769905341881) D10 D18 D28 D42 D66 D120\n",
      "error(0.001018345769905341881) D10 D18 D28 D52 D66 D120\n",
      "error(0.002665439999999999823) D10 D18 D31 D42 D66\n",
      "error(0.001015965840252101588) D10 D18 D31 D45 D69\n",
      "error(0.002665439999999999823) D10 D18 D31 D55 D66\n",
      "error(0.001015965840252101588) D10 D18 D31 D55 D69\n",
      "error(0.00718332878957505909) D10 D20 D22\n",
      "error(0.002831414999999999887) D10 D20 D22 D34\n",
      "error(0.002831414999999999887) D10 D20 D22 D34 D58\n",
      "error(0.002665439999999999823) D10 D20 D34 D42 D66\n",
      "error(0.002665439999999999823) D10 D20 D34 D58 D66\n",
      "error(0.00718332878957505909) D10 D21 D22\n",
      "error(0.002665439999999999823) D10 D21 D31 D45 D69\n",
      "error(0.002665439999999999823) D10 D21 D31 D55 D69\n",
      "error(0.002831414999999999887) D10 D21 D45 D69\n",
      "error(0.002831414999999999887) D10 D21 D69\n",
      "error(0.001018345769905341881) D10 D22 D34 D42 D66\n",
      "error(0.002665439999999999823) D10 D22 D34 D45 D69\n",
      "error(0.001018345769905341881) D10 D22 D34 D58 D66\n",
      "error(0.002665439999999999823) D10 D22 D34 D58 D69\n",
      "error(0.001864462904302397611) D10 D22 D45 D69\n",
      "error(0.001864462904302397611) D10 D22 D69\n",
      "error(5.375075081862617642e-05) D10 D28 D52 D120\n",
      "error(5.375075081862617642e-05) D10 D28 D120\n",
      "error(0.002849896465810894831) D10 D31\n",
      "error(0.001015965840252101588) D10 D31 D42 D45 D66 D69\n",
      "error(0.002849896465810894831) D10 D31 D55\n",
      "error(0.001015965840252101588) D10 D31 D55 D66 D69\n",
      "error(0.0432087996420145587) D10 D34\n",
      "error(0.002838065267102216072) D10 D34 D42 D45 D66 D69\n",
      "error(0.0432087996420145587) D10 D34 D58\n",
      "error(0.002838065267102216072) D10 D34 D58 D66 D69\n",
      "error(0.008159700255888127293) D11\n",
      "error(0.001018345769905341881) D11 D19 D29 D43 D67 D120\n",
      "error(0.001018345769905341881) D11 D19 D29 D53 D67 D120\n",
      "error(0.001864462904302397611) D11 D19 D32\n",
      "error(0.002665439999999999823) D11 D19 D32 D43 D67\n",
      "error(0.001864462904302397611) D11 D19 D32 D56\n",
      "error(0.002665439999999999823) D11 D19 D32 D56 D67\n",
      "error(0.00718332878957505909) D11 D21 D23\n",
      "error(0.002831414999999999887) D11 D21 D23 D35\n",
      "error(0.002831414999999999887) D11 D21 D23 D35 D59\n",
      "error(0.002665439999999999823) D11 D21 D35 D43 D67\n",
      "error(0.002665439999999999823) D11 D21 D35 D59 D67\n",
      "error(0.01053699531493879071) D11 D23\n",
      "error(0.002665439999999999823) D11 D23 D35\n",
      "error(0.001018345769905341881) D11 D23 D35 D43 D67\n",
      "error(0.002665439999999999823) D11 D23 D35 D59\n",
      "error(0.001018345769905341881) D11 D23 D35 D59 D67\n",
      "error(5.375075081862617642e-05) D11 D29 D53 D120\n",
      "error(5.375075081862617642e-05) D11 D29 D120\n",
      "error(0.002792729717509890349) D11 D32\n",
      "error(0.001015965840252101588) D11 D32 D43 D67\n",
      "error(0.002792729717509890349) D11 D32 D56\n",
      "error(0.001015965840252101588) D11 D32 D56 D67\n",
      "error(0.0432087996420145587) D11 D35\n",
      "error(0.002838065267102216072) D11 D35 D43 D67\n",
      "error(0.0432087996420145587) D11 D35 D59\n",
      "error(0.002838065267102216072) D11 D35 D59 D67\n",
      "error(0.002465202426008964755) D12\n",
      "error(0.005062995401453437155) D12 D14\n",
      "error(0.04311536755819837807) D12 D36 D60\n",
      "error(2.879825239673086635e-05) D12 D38 D62\n",
      "error(0.04311536755819837807) D12 D60\n",
      "error(2.879825239673086635e-05) D12 D62\n",
      "error(0.002465202426008964755) D13 D14\n",
      "error(0.005062995401453437155) D13 D15\n",
      "error(0.04311536755819837807) D13 D37 D61\n",
      "error(2.879825239673086635e-05) D13 D39 D63\n",
      "error(0.04311536755819837807) D13 D61\n",
      "error(2.879825239673086635e-05) D13 D63\n",
      "error(0.002465202426008964755) D14 D16\n",
      "error(0.005213970599049887016) D14 D17\n",
      "error(0.001869636747823257353) D14 D25 D37 D61\n",
      "error(0.002838065267102216072) D14 D25 D38 D62\n",
      "error(0.001869636747823257353) D14 D25 D49 D61\n",
      "error(0.002838065267102216072) D14 D25 D49 D62\n",
      "error(0.002792729717509890783) D14 D37 D61\n",
      "error(0.0432087996420145587) D14 D38 D62\n",
      "error(2.879825239673086635e-05) D14 D41 D65\n",
      "error(0.002792729717509890783) D14 D61\n",
      "error(0.0432087996420145587) D14 D62\n",
      "error(2.879825239673086635e-05) D14 D65\n",
      "error(0.01439667007012129622) D15\n",
      "error(0.002465202426008964755) D15 D17\n",
      "error(0.001869636747823257353) D15 D26\n",
      "error(0.002838065267102216072) D15 D26 D39 D63\n",
      "error(0.001869636747823257353) D15 D26 D50\n",
      "error(0.002838065267102216072) D15 D26 D50 D63\n",
      "error(0.0432087996420145587) D15 D39 D63\n",
      "error(0.0432087996420145587) D15 D63\n",
      "error(0.007653466039119012979) D16\n",
      "error(0.005213970599049887016) D16 D18\n",
      "error(0.001015965840252101588) D16 D24 D28 D38 D62\n",
      "error(0.002838065267102216072) D16 D24 D28 D40 D64\n",
      "error(0.001015965840252101588) D16 D24 D28 D48 D52 D62\n",
      "error(0.002838065267102216072) D16 D24 D28 D48 D52 D64\n",
      "error(5.375075081862617642e-05) D16 D36 D60\n",
      "error(0.002849896465810894831) D16 D38 D62\n",
      "error(0.0432087996420145587) D16 D40 D64\n",
      "error(2.879825239673086635e-05) D16 D42 D66\n",
      "error(5.375075081862617642e-05) D16 D60\n",
      "error(0.002849896465810894831) D16 D62\n",
      "error(0.0432087996420145587) D16 D64\n",
      "error(2.879825239673086635e-05) D16 D66\n",
      "error(0.002465202426008964755) D17 D18\n",
      "error(0.005213970599049887016) D17 D19\n",
      "error(0.001015965840252101588) D17 D25 D29 D39 D63\n",
      "error(0.002838065267102216072) D17 D25 D29 D41 D65\n",
      "error(0.001015965840252101588) D17 D25 D29 D49 D53 D63\n",
      "error(0.002838065267102216072) D17 D25 D29 D49 D53 D65\n",
      "error(5.375075081862617642e-05) D17 D37 D61\n",
      "error(0.002849896465810894831) D17 D39 D63\n",
      "error(0.0432087996420145587) D17 D41 D65\n",
      "error(2.879825239673086635e-05) D17 D43 D67\n",
      "error(5.375075081862617642e-05) D17 D61\n",
      "error(0.002849896465810894831) D17 D63\n",
      "error(0.0432087996420145587) D17 D65\n",
      "error(2.879825239673086635e-05) D17 D67\n",
      "error(0.002465202426008964755) D18 D20\n",
      "error(0.005213970599049887016) D18 D21\n",
      "error(0.001015965840252101588) D18 D28 D31 D41 D65 D120\n",
      "error(0.002838065267102216072) D18 D28 D31 D42 D66 D120\n",
      "error(0.001015965840252101588) D18 D28 D31 D52 D55 D65 D120\n",
      "error(0.002838065267102216072) D18 D28 D31 D52 D55 D66 D120\n",
      "error(5.375075081862617642e-05) D18 D38 D62\n",
      "error(0.002849896465810894831) D18 D41 D65\n",
      "error(0.0432087996420145587) D18 D42 D66\n",
      "error(2.879825239673086635e-05) D18 D45 D69\n",
      "error(5.375075081862617642e-05) D18 D62\n",
      "error(0.002849896465810894831) D18 D65\n",
      "error(0.0432087996420145587) D18 D66\n",
      "error(2.879825239673086635e-05) D18 D69\n",
      "error(0.01450832880526816901) D19\n",
      "error(0.002465202426008964755) D19 D21\n",
      "error(0.002838065267102216072) D19 D29 D32 D43 D67 D120\n",
      "error(0.002838065267102216072) D19 D29 D32 D53 D56 D67 D120\n",
      "error(0.001015965840252101588) D19 D29 D32 D53 D56 D120\n",
      "error(0.001015965840252101588) D19 D29 D32 D120\n",
      "error(5.375075081862617642e-05) D19 D39 D63\n",
      "error(0.0432087996420145587) D19 D43 D67\n",
      "error(5.375075081862617642e-05) D19 D63\n",
      "error(0.0432087996420145587) D19 D67\n",
      "error(0.007653466039119012979) D20\n",
      "error(0.005213970599049887016) D20 D22\n",
      "error(0.001010783130056933663) D20 D22 D34\n",
      "error(0.001010783130056933663) D20 D22 D34 D58\n",
      "error(0.001015965840252101588) D20 D30 D34 D42 D66\n",
      "error(0.002838065267102216072) D20 D30 D34 D44 D68\n",
      "error(0.001015965840252101588) D20 D30 D34 D54 D58 D66\n",
      "error(0.002838065267102216072) D20 D30 D34 D54 D58 D68\n",
      "error(0.001018345769905341881) D20 D30 D44 D68\n",
      "error(0.001018345769905341881) D20 D30 D54 D68\n",
      "error(0.002665439999999999823) D20 D34 D44 D68\n",
      "error(0.001015965840252101588) D20 D34 D46 D70\n",
      "error(0.002665439999999999823) D20 D34 D58 D68\n",
      "error(0.001015965840252101588) D20 D34 D58 D70\n",
      "error(5.375075081862617642e-05) D20 D40 D64\n",
      "error(0.002849896465810894831) D20 D42 D66\n",
      "error(0.0432087996420145587) D20 D44 D68\n",
      "error(2.879825239673086635e-05) D20 D46 D70\n",
      "error(5.375075081862617642e-05) D20 D64\n",
      "error(0.002849896465810894831) D20 D66\n",
      "error(0.0432087996420145587) D20 D68\n",
      "error(2.879825239673086635e-05) D20 D70\n",
      "error(0.002465202426008964755) D21 D22\n",
      "error(0.005213970599049887016) D21 D23\n",
      "error(0.001010783130056933663) D21 D23 D35\n",
      "error(0.001010783130056933663) D21 D23 D35 D59\n",
      "error(0.001015965840252101588) D21 D31 D35 D43 D67\n",
      "error(0.002838065267102216072) D21 D31 D35 D45 D69\n",
      "error(0.001015965840252101588) D21 D31 D35 D55 D59 D67\n",
      "error(0.002838065267102216072) D21 D31 D35 D55 D59 D69\n",
      "error(0.001018345769905341881) D21 D31 D45 D69\n",
      "error(0.001018345769905341881) D21 D31 D55 D69\n",
      "error(0.002665439999999999823) D21 D35 D45 D69\n",
      "error(0.001015965840252101588) D21 D35 D47 D71\n",
      "error(0.002665439999999999823) D21 D35 D59 D69\n",
      "error(0.001015965840252101588) D21 D35 D59 D71\n",
      "error(5.375075081862617642e-05) D21 D41 D65\n",
      "error(0.002849896465810894831) D21 D43 D67\n",
      "error(0.0432087996420145587) D21 D45 D69\n",
      "error(2.879825239673086635e-05) D21 D47 D71\n",
      "error(5.375075081862617642e-05) D21 D65\n",
      "error(0.002849896465810894831) D21 D67\n",
      "error(0.0432087996420145587) D21 D69\n",
      "error(2.879825239673086635e-05) D21 D71\n",
      "error(0.001015965840252101588) D22 D34 D45 D69\n",
      "error(0.006337628425401439433) D22 D34 D46 D70\n",
      "error(0.001015965840252101588) D22 D34 D58 D69\n",
      "error(0.006337628425401439433) D22 D34 D58 D70\n",
      "error(5.375075081862617642e-05) D22 D42 D66\n",
      "error(0.002792729717509890349) D22 D45 D69\n",
      "error(0.04310844294704657687) D22 D46 D70\n",
      "error(5.375075081862617642e-05) D22 D66\n",
      "error(0.002792729717509890349) D22 D69\n",
      "error(0.04310844294704657687) D22 D70\n",
      "error(0.008606790840629869113) D23\n",
      "error(0.001015965840252101588) D23 D35\n",
      "error(0.006337628425401439433) D23 D35 D47 D71\n",
      "error(0.001015965840252101588) D23 D35 D59\n",
      "error(0.006337628425401439433) D23 D35 D59 D71\n",
      "error(5.375075081862617642e-05) D23 D43 D67\n",
      "error(0.04310844294704657687) D23 D47 D71\n",
      "error(5.375075081862617642e-05) D23 D67\n",
      "error(0.04310844294704657687) D23 D71\n",
      "error(0.01225372096842798977) D24\n",
      "error(0.001478969471745447293) D24 D27\n",
      "error(0.002696118176924125909) D24 D27 D40\n",
      "error(0.001864511231830490688) D24 D27 D40 D64\n",
      "error(2.986018364957227354e-05) D24 D27 D48 D51\n",
      "error(0.001021148496617479279) D24 D27 D48 D51 D64\n",
      "error(0.002665439999999999823) D24 D27 D64\n",
      "error(0.004284518053672076512) D24 D28\n",
      "error(0.002831414999999999887) D24 D28 D38\n",
      "error(0.001854163384577362395) D24 D28 D38 D40\n",
      "error(0.001021148496617479279) D24 D28 D38 D40 D62 D64\n",
      "error(0.001010783130056933663) D24 D28 D40\n",
      "error(0.001506680709392006984) D24 D28 D48 D52\n",
      "error(0.001864511231830490688) D24 D28 D48 D52 D62 D64\n",
      "error(0.002665439999999999823) D24 D28 D62 D64\n",
      "error(0.008148320292023548267) D24 D36\n",
      "error(0.003541758227067706103) D24 D36 D38\n",
      "error(0.001864511231830490688) D24 D36 D38 D60 D62\n",
      "error(0.002727012118140913731) D24 D36 D60\n",
      "error(0.003675989848273618615) D24 D38\n",
      "error(0.001018345769905341881) D24 D38 D73 D97\n",
      "error(0.005481761066404799987) D24 D40 D72 D96\n",
      "error(0.001766904925337182443) D24 D48\n",
      "error(0.003567491641359241215) D24 D48 D60\n",
      "error(0.001021148496617479279) D24 D48 D60 D62\n",
      "error(0.002665439999999999823) D24 D60\n",
      "error(0.002665439999999999823) D24 D60 D62\n",
      "error(0.049158419805032251) D24 D72 D96\n",
      "error(5.375075081862617642e-05) D24 D73 D97\n",
      "error(0.01052779602327227372) D25\n",
      "error(0.001478969471745447293) D25 D28\n",
      "error(0.002696118176924125909) D25 D28 D38 D41\n",
      "error(0.001864511231830490688) D25 D28 D38 D41 D62 D65\n",
      "error(2.986018364957227354e-05) D25 D28 D49 D52\n",
      "error(0.001021148496617479279) D25 D28 D49 D52 D62 D65\n",
      "error(0.002665439999999999823) D25 D28 D62 D65\n",
      "error(0.004284518053672076512) D25 D29\n",
      "error(0.002831414999999999887) D25 D29 D39\n",
      "error(0.001854163384577362395) D25 D29 D39 D41\n",
      "error(0.001021148496617479279) D25 D29 D39 D41 D63 D65\n",
      "error(0.001010783130056933663) D25 D29 D41\n",
      "error(0.001506680709392006984) D25 D29 D49 D53\n",
      "error(0.001864511231830490688) D25 D29 D49 D53 D63 D65\n",
      "error(0.002665439999999999823) D25 D29 D63 D65\n",
      "error(0.006317584575443702458) D25 D37\n",
      "error(0.001854163384577362395) D25 D37 D38\n",
      "error(0.001021148496617479279) D25 D37 D38 D61 D62\n",
      "error(0.003541758227067706103) D25 D37 D39\n",
      "error(0.001864511231830490688) D25 D37 D39 D61 D63\n",
      "error(0.001864462904302397611) D25 D38\n",
      "error(0.002831414999999999887) D25 D38 D41 D73 D97\n",
      "error(0.003678357090807468904) D25 D38 D73 D97\n",
      "error(0.003675989848273618615) D25 D39\n",
      "error(0.001018345769905341881) D25 D39 D74 D98\n",
      "error(0.002665439999999999823) D25 D41 D73 D97\n",
      "error(0.001868770874208873761) D25 D49\n",
      "error(0.001864511231830490688) D25 D49 D61 D62\n",
      "error(0.001021148496617479279) D25 D49 D61 D63\n",
      "error(0.002665439999999999823) D25 D61 D62\n",
      "error(0.002665439999999999823) D25 D61 D63\n",
      "error(0.04580936623556411402) D25 D73 D97\n",
      "error(5.375075081862617642e-05) D25 D74 D98\n",
      "error(0.00486975060034565508) D26\n",
      "error(0.001478969471745447293) D26 D29\n",
      "error(0.002696118176924125909) D26 D29 D39\n",
      "error(0.001864511231830490688) D26 D29 D39 D63\n",
      "error(2.986018364957227354e-05) D26 D29 D50 D53\n",
      "error(0.001021148496617479279) D26 D29 D50 D53 D63\n",
      "error(0.002665439999999999823) D26 D29 D63\n",
      "error(0.003552022854568235351) D26 D39\n",
      "error(0.001021148496617479279) D26 D39 D63\n",
      "error(0.006330146405388720893) D26 D39 D74 D98\n",
      "error(0.001839020517540080691) D26 D50\n",
      "error(0.001864511231830490688) D26 D50 D63\n",
      "error(0.002665439999999999823) D26 D63\n",
      "error(0.04311536755819837807) D26 D74 D98\n",
      "error(0.001874810537606419209) D27 D30 D40 D64 D120\n",
      "error(0.004675078572538276384) D27 D30 D40 D120\n",
      "error(0.002716730432603525151) D27 D30 D51 D54 D64 D120\n",
      "error(0.001404740714453617603) D27 D30 D51 D54 D120\n",
      "error(0.002665439999999999823) D27 D30 D64 D120\n",
      "error(0.005185920509368709651) D27 D30 D120\n",
      "error(0.004519963676295111164) D27 D40 D72 D96\n",
      "error(0.001018345769905341881) D27 D40 D76 D100\n",
      "error(0.003803463737702784692) D27 D72 D96\n",
      "error(0.04891386968098601629) D27 D75 D99\n",
      "error(5.375075081862617642e-05) D27 D76 D100\n",
      "error(0.001864511231830490688) D28 D30 D40 D42 D64 D66 D120\n",
      "error(0.002696118176924125909) D28 D30 D40 D42 D120\n",
      "error(0.001021148496617479279) D28 D30 D52 D54 D64 D66 D120\n",
      "error(2.986018364957227354e-05) D28 D30 D52 D54 D120\n",
      "error(0.002665439999999999823) D28 D30 D64 D66 D120\n",
      "error(0.001478969471745447293) D28 D30 D120\n",
      "error(0.001021148496617479279) D28 D31 D41 D42 D65 D66 D120\n",
      "error(0.001854163384577362395) D28 D31 D41 D42 D120\n",
      "error(0.002831414999999999887) D28 D31 D41 D120\n",
      "error(0.001010783130056933663) D28 D31 D42 D120\n",
      "error(0.001864511231830490688) D28 D31 D52 D55 D65 D66 D120\n",
      "error(0.001506680709392006984) D28 D31 D52 D55 D120\n",
      "error(0.002665439999999999823) D28 D31 D65 D66 D120\n",
      "error(0.004284518053672076512) D28 D31 D120\n",
      "error(0.001010783130056933663) D28 D38 D41 D73 D97\n",
      "error(0.002665439999999999823) D28 D38 D73 D97\n",
      "error(0.002831414999999999887) D28 D40 D42 D76 D100\n",
      "error(0.001015965840252101588) D28 D40 D72 D96\n",
      "error(0.003678357090807468904) D28 D40 D76 D100\n",
      "error(0.003675989848273618615) D28 D41 D73 D97\n",
      "error(0.001018345769905341881) D28 D41 D77 D101\n",
      "error(0.002665439999999999823) D28 D42 D76 D100\n",
      "error(2.879825239673086635e-05) D28 D72 D96\n",
      "error(0.003860514276163778263) D28 D73 D97\n",
      "error(0.04580936623556411402) D28 D76 D100\n",
      "error(5.375075081862617642e-05) D28 D77 D101\n",
      "error(0.001864511231830490688) D29 D31 D41 D43 D65 D67 D120\n",
      "error(0.002696118176924125909) D29 D31 D41 D43 D120\n",
      "error(0.001021148496617479279) D29 D31 D53 D55 D65 D67 D120\n",
      "error(2.986018364957227354e-05) D29 D31 D53 D55 D120\n",
      "error(0.002665439999999999823) D29 D31 D65 D67 D120\n",
      "error(0.001478969471745447293) D29 D31 D120\n",
      "error(0.001021148496617479279) D29 D32 D43 D67 D120\n",
      "error(0.002701235136179231701) D29 D32 D43 D120\n",
      "error(0.001864511231830490688) D29 D32 D53 D56 D67 D120\n",
      "error(0.001506680709392006984) D29 D32 D53 D56 D120\n",
      "error(0.002665439999999999823) D29 D32 D67 D120\n",
      "error(0.004208894420242112293) D29 D32 D120\n",
      "error(0.003670834766484575885) D29 D39 D74 D98\n",
      "error(0.002831414999999999887) D29 D41 D43 D77 D101\n",
      "error(0.001015965840252101588) D29 D41 D73 D97\n",
      "error(0.003678357090807468904) D29 D41 D77 D101\n",
      "error(0.002665439999999999823) D29 D43 D77 D101\n",
      "error(2.879825239673086635e-05) D29 D73 D97\n",
      "error(0.004652365743471347306) D29 D74 D98\n",
      "error(0.04580936623556411402) D29 D77 D101\n",
      "error(5.375075081862617642e-05) D30\n",
      "error(0.001478969471745447293) D30 D33\n",
      "error(0.002696118176924125909) D30 D33 D44\n",
      "error(0.001864511231830490688) D30 D33 D44 D68\n",
      "error(2.986018364957227354e-05) D30 D33 D54 D57\n",
      "error(0.001021148496617479279) D30 D33 D54 D57 D68\n",
      "error(0.002665439999999999823) D30 D33 D68\n",
      "error(0.004284518053672076512) D30 D34\n",
      "error(0.002831414999999999887) D30 D34 D42\n",
      "error(0.001854163384577362395) D30 D34 D42 D44\n",
      "error(0.001021148496617479279) D30 D34 D42 D44 D66 D68\n",
      "error(0.001010783130056933663) D30 D34 D44\n",
      "error(0.001506680709392006984) D30 D34 D54 D58\n",
      "error(0.001864511231830490688) D30 D34 D54 D58 D66 D68\n",
      "error(0.002665439999999999823) D30 D34 D66 D68\n",
      "error(0.001010783130056933663) D30 D40 D42 D76 D100 D120\n",
      "error(0.002665439999999999823) D30 D40 D76 D100 D120\n",
      "error(0.003675989848273618615) D30 D42 D76 D100 D120\n",
      "error(0.001018345769905341881) D30 D42 D79 D103\n",
      "error(0.005481761066404799987) D30 D44 D78 D102\n",
      "error(5.375075081862617642e-05) D30 D54\n",
      "error(0.001044711783160383149) D30 D75 D99 D120\n",
      "error(0.003860514276163778263) D30 D76 D100 D120\n",
      "error(0.049158419805032251) D30 D78 D102\n",
      "error(5.375075081862617642e-05) D30 D79 D103\n",
      "error(5.375075081862617642e-05) D31\n",
      "error(0.001478969471745447293) D31 D34\n",
      "error(0.002696118176924125909) D31 D34 D42 D45\n",
      "error(0.001864511231830490688) D31 D34 D42 D45 D66 D69\n",
      "error(2.986018364957227354e-05) D31 D34 D55 D58\n",
      "error(0.001021148496617479279) D31 D34 D55 D58 D66 D69\n",
      "error(0.002665439999999999823) D31 D34 D66 D69\n",
      "error(0.004284518053672076512) D31 D35\n",
      "error(0.002831414999999999887) D31 D35 D43\n",
      "error(0.001854163384577362395) D31 D35 D43 D45\n",
      "error(0.001021148496617479279) D31 D35 D43 D45 D67 D69\n",
      "error(0.001010783130056933663) D31 D35 D45\n",
      "error(0.001506680709392006984) D31 D35 D55 D59\n",
      "error(0.001864511231830490688) D31 D35 D55 D59 D67 D69\n",
      "error(0.002665439999999999823) D31 D35 D67 D69\n",
      "error(0.001010783130056933663) D31 D41 D43 D77 D101 D120\n",
      "error(0.002665439999999999823) D31 D41 D77 D101 D120\n",
      "error(0.002831414999999999887) D31 D42 D45 D79 D103\n",
      "error(0.001015965840252101588) D31 D42 D76 D100 D120\n",
      "error(0.003678357090807468904) D31 D42 D79 D103\n",
      "error(0.003675989848273618615) D31 D43 D77 D101 D120\n",
      "error(0.001018345769905341881) D31 D43 D80 D104\n",
      "error(0.002665439999999999823) D31 D45 D79 D103\n",
      "error(5.375075081862617642e-05) D31 D55\n",
      "error(2.879825239673086635e-05) D31 D76 D100 D120\n",
      "error(0.003860514276163778263) D31 D77 D101 D120\n",
      "error(0.04580936623556411402) D31 D79 D103\n",
      "error(5.375075081862617642e-05) D31 D80 D104\n",
      "error(0.001478969471745447293) D32 D35\n",
      "error(0.002696118176924125909) D32 D35 D43\n",
      "error(0.001864511231830490688) D32 D35 D43 D67\n",
      "error(2.986018364957227354e-05) D32 D35 D56 D59\n",
      "error(0.001021148496617479279) D32 D35 D56 D59 D67\n",
      "error(0.002665439999999999823) D32 D35 D67\n",
      "error(0.001015965840252101588) D32 D43 D77 D101 D120\n",
      "error(0.006330146405388720893) D32 D43 D80 D104\n",
      "error(2.879825239673086635e-05) D32 D77 D101 D120\n",
      "error(0.04311536755819837807) D32 D80 D104\n",
      "error(0.005185920509368709651) D33\n",
      "error(0.004675078572538276384) D33 D44\n",
      "error(0.001874810537606419209) D33 D44 D68\n",
      "error(0.004519963676295111164) D33 D44 D78 D102\n",
      "error(0.001018345769905341881) D33 D44 D82 D106\n",
      "error(0.001404740714453617603) D33 D57\n",
      "error(0.002716730432603525151) D33 D57 D68\n",
      "error(0.002665439999999999823) D33 D68\n",
      "error(0.003803463737702784692) D33 D78 D102\n",
      "error(0.04891386968098601629) D33 D81 D105\n",
      "error(5.375075081862617642e-05) D33 D82 D106\n",
      "error(0.009219253862479605266) D34\n",
      "error(0.001010783130056933663) D34 D42 D45 D79 D103\n",
      "error(0.002665439999999999823) D34 D42 D79 D103\n",
      "error(0.002696118176924125909) D34 D44 D46\n",
      "error(0.002716730432603525151) D34 D44 D46 D68 D70\n",
      "error(0.002831414999999999887) D34 D44 D46 D82 D106\n",
      "error(0.001015965840252101588) D34 D44 D78 D102\n",
      "error(0.003678357090807468904) D34 D44 D82 D106\n",
      "error(0.002831414999999999887) D34 D45\n",
      "error(0.001854163384577362395) D34 D45 D46\n",
      "error(0.001021148496617479279) D34 D45 D46 D69 D70\n",
      "error(0.003675989848273618615) D34 D45 D79 D103\n",
      "error(0.001018345769905341881) D34 D45 D83 D107\n",
      "error(0.001010783130056933663) D34 D46\n",
      "error(0.002665439999999999823) D34 D46 D82 D106\n",
      "error(0.005034465280013796992) D34 D58\n",
      "error(0.001874810537606419209) D34 D58 D68 D70\n",
      "error(0.001864511231830490688) D34 D58 D69 D70\n",
      "error(0.002665439999999999823) D34 D68 D70\n",
      "error(0.002665439999999999823) D34 D69 D70\n",
      "error(2.879825239673086635e-05) D34 D78 D102\n",
      "error(0.003860514276163778263) D34 D79 D103\n",
      "error(0.04580936623556411402) D34 D82 D106\n",
      "error(5.375075081862617642e-05) D34 D83 D107\n",
      "error(0.009144383045262705761) D35\n",
      "error(0.003670834766484575885) D35 D43 D80 D104\n",
      "error(0.002696118176924125909) D35 D45 D47\n",
      "error(0.002716730432603525151) D35 D45 D47 D69 D71\n",
      "error(0.002831414999999999887) D35 D45 D47 D83 D107\n",
      "error(0.001015965840252101588) D35 D45 D79 D103\n",
      "error(0.003678357090807468904) D35 D45 D83 D107\n",
      "error(0.002701235136179231701) D35 D47\n",
      "error(0.001021148496617479279) D35 D47 D71\n",
      "error(0.002665439999999999823) D35 D47 D83 D107\n",
      "error(0.005034465280013796992) D35 D59\n",
      "error(0.001874810537606419209) D35 D59 D69 D71\n",
      "error(0.001864511231830490688) D35 D59 D71\n",
      "error(0.002665439999999999823) D35 D69 D71\n",
      "error(0.002665439999999999823) D35 D71\n",
      "error(2.879825239673086635e-05) D35 D79 D103\n",
      "error(0.004652365743471347306) D35 D80 D104\n",
      "error(0.04580936623556411402) D35 D83 D107\n",
      "error(0.04237887617123105993) D36\n",
      "error(0.001357748790366670099) D36 D38\n",
      "error(0.001506680709392006984) D36 D38 D60 D62\n",
      "error(0.003125267488098796773) D36 D60\n",
      "error(0.04234524506783991782) D37\n",
      "error(3.674287552866961886e-05) D37 D38\n",
      "error(2.986018364957227354e-05) D37 D38 D61 D62\n",
      "error(0.001357748790366670099) D37 D39\n",
      "error(0.001506680709392006984) D37 D39 D61 D63\n",
      "error(0.0458351796367094666) D38\n",
      "error(3.674287552866961886e-05) D38 D40\n",
      "error(2.986018364957227354e-05) D38 D40 D62 D64\n",
      "error(0.001433807312582543667) D38 D41\n",
      "error(0.001506680709392006984) D38 D41 D62 D65\n",
      "error(0.003848264352626754731) D38 D73 D97\n",
      "error(0.04772232134189638431) D39\n",
      "error(3.674287552866961886e-05) D39 D41\n",
      "error(2.986018364957227354e-05) D39 D41 D63 D65\n",
      "error(0.001536450913516211863) D39 D63\n",
      "error(0.003848264352626754731) D39 D74 D98\n",
      "error(0.04749869143850916908) D40\n",
      "error(0.001433807312582543667) D40 D42\n",
      "error(0.001506680709392006984) D40 D42 D64 D66\n",
      "error(0.005018678180738674402) D40 D64\n",
      "error(0.003848264352626754731) D40 D72 D76 D96 D100\n",
      "error(0.04588739754968995666) D41\n",
      "error(3.674287552866961886e-05) D41 D42\n",
      "error(2.986018364957227354e-05) D41 D42 D65 D66\n",
      "error(0.001433807312582543667) D41 D43\n",
      "error(0.001506680709392006984) D41 D43 D65 D67\n",
      "error(0.003848264352626754731) D41 D73 D77 D97 D101\n",
      "error(0.04588739754968995666) D42\n",
      "error(3.674287552866961886e-05) D42 D44\n",
      "error(2.986018364957227354e-05) D42 D44 D66 D68\n",
      "error(0.001433807312582543667) D42 D45\n",
      "error(0.001506680709392006984) D42 D45 D66 D69\n",
      "error(0.003848264352626754731) D42 D76 D79 D100 D103 D120\n",
      "error(0.04777432227945975496) D43\n",
      "error(3.674287552866961886e-05) D43 D45\n",
      "error(2.986018364957227354e-05) D43 D45 D67 D69\n",
      "error(0.001536450913516211863) D43 D67\n",
      "error(0.003848264352626754731) D43 D77 D80 D101 D104 D120\n",
      "error(0.04749869143850916908) D44\n",
      "error(0.001433807312582543667) D44 D46\n",
      "error(0.001404740714453617603) D44 D46 D68 D70\n",
      "error(0.001010783130056933663) D44 D46 D82 D106\n",
      "error(0.004961760818282177216) D44 D68\n",
      "error(0.003848264352626754731) D44 D78 D82 D102 D106\n",
      "error(0.002665439999999999823) D44 D82 D106\n",
      "error(0.04588739754968995666) D45\n",
      "error(3.674287552866961886e-05) D45 D46\n",
      "error(2.986018364957227354e-05) D45 D46 D69 D70\n",
      "error(0.001433807312582543667) D45 D47\n",
      "error(0.001404740714453617603) D45 D47 D69 D71\n",
      "error(0.001010783130056933663) D45 D47 D83 D107\n",
      "error(0.003848264352626754731) D45 D79 D83 D103 D107\n",
      "error(0.002665439999999999823) D45 D83 D107\n",
      "error(0.04648337918539993674) D46\n",
      "error(0.009170415199135256365) D46 D82 D106\n",
      "error(0.04679293518973928756) D47\n",
      "error(2.986018364957227354e-05) D47 D71\n",
      "error(0.009170415199135256365) D47 D83 D107\n",
      "error(0.007802111820677886354) D48\n",
      "error(3.674287552866961886e-05) D48 D51\n",
      "error(0.001854163384577362395) D48 D51 D64\n",
      "error(0.001433807312582543667) D48 D52\n",
      "error(0.002831414999999999887) D48 D52 D62\n",
      "error(0.002696118176924125909) D48 D52 D62 D64\n",
      "error(0.001010783130056933663) D48 D52 D64\n",
      "error(0.008979636843151611938) D48 D60\n",
      "error(0.002701235136179231701) D48 D60 D62\n",
      "error(0.003675989848273618615) D48 D62\n",
      "error(0.001018345769905341881) D48 D62 D73 D85 D97 D109\n",
      "error(0.005481761066404799987) D48 D64 D72 D84 D96 D108\n",
      "error(0.049158419805032251) D48 D72 D84 D96 D108\n",
      "error(5.375075081862617642e-05) D48 D73 D85 D97 D109\n",
      "error(0.005959425769978807241) D49\n",
      "error(3.674287552866961886e-05) D49 D52\n",
      "error(0.001854163384577362395) D49 D52 D62 D65\n",
      "error(0.001433807312582543667) D49 D53\n",
      "error(0.002831414999999999887) D49 D53 D63\n",
      "error(0.002696118176924125909) D49 D53 D63 D65\n",
      "error(0.001010783130056933663) D49 D53 D65\n",
      "error(0.006317584575443702458) D49 D61\n",
      "error(0.002696118176924125909) D49 D61 D62\n",
      "error(0.002701235136179231701) D49 D61 D63\n",
      "error(0.001864462904302397611) D49 D62\n",
      "error(0.002831414999999999887) D49 D62 D65 D73 D85 D97 D109\n",
      "error(0.003678357090807468904) D49 D62 D73 D85 D97 D109\n",
      "error(0.003675989848273618615) D49 D63\n",
      "error(0.001018345769905341881) D49 D63 D74 D86 D98 D110\n",
      "error(0.002665439999999999823) D49 D65 D73 D85 D97 D109\n",
      "error(0.04580936623556411402) D49 D73 D85 D97 D109\n",
      "error(5.375075081862617642e-05) D49 D74 D86 D98 D110\n",
      "error(0.001690187889725839991) D50\n",
      "error(3.674287552866961886e-05) D50 D53\n",
      "error(0.001854163384577362395) D50 D53 D63\n",
      "error(0.004391107963355657395) D50 D63\n",
      "error(0.006330146405388720893) D50 D63 D74 D86 D98 D110\n",
      "error(0.04311536755819837807) D50 D74 D86 D98 D110\n",
      "error(0.00244214215948672592) D51 D54\n",
      "error(0.005512265518028294439) D51 D54 D64\n",
      "error(0.004519963676295111164) D51 D64 D72 D84 D96 D108\n",
      "error(0.001018345769905341881) D51 D64 D76 D88 D100 D112\n",
      "error(0.003803463737702784692) D51 D72 D84 D96 D108\n",
      "error(0.04891386968098601629) D51 D75 D87 D99 D111\n",
      "error(5.375075081862617642e-05) D51 D76 D88 D100 D112\n",
      "error(3.674287552866961886e-05) D52 D54\n",
      "error(0.001854163384577362395) D52 D54 D64 D66\n",
      "error(0.001433807312582543667) D52 D55\n",
      "error(0.002831414999999999887) D52 D55 D65\n",
      "error(0.002696118176924125909) D52 D55 D65 D66\n",
      "error(0.001010783130056933663) D52 D55 D66\n",
      "error(0.001010783130056933663) D52 D62 D65 D73 D85 D97 D109\n",
      "error(0.002665439999999999823) D52 D62 D73 D85 D97 D109\n",
      "error(0.002831414999999999887) D52 D64 D66 D76 D88 D100 D112\n",
      "error(0.001015965840252101588) D52 D64 D72 D84 D96 D108\n",
      "error(0.003678357090807468904) D52 D64 D76 D88 D100 D112\n",
      "error(0.003675989848273618615) D52 D65 D73 D85 D97 D109\n",
      "error(0.001018345769905341881) D52 D65 D77 D89 D101 D113\n",
      "error(0.002665439999999999823) D52 D66 D76 D88 D100 D112\n",
      "error(2.879825239673086635e-05) D52 D72 D84 D96 D108\n",
      "error(0.003860514276163778263) D52 D73 D85 D97 D109\n",
      "error(0.04580936623556411402) D52 D76 D88 D100 D112\n",
      "error(5.375075081862617642e-05) D52 D77 D89 D101 D113\n",
      "error(3.674287552866961886e-05) D53 D55\n",
      "error(0.001854163384577362395) D53 D55 D65 D67\n",
      "error(0.001357748790366670099) D53 D56\n",
      "error(0.003541758227067706103) D53 D56 D67\n",
      "error(0.003670834766484575885) D53 D63 D74 D86 D98 D110\n",
      "error(0.002831414999999999887) D53 D65 D67 D77 D89 D101 D113\n",
      "error(0.001015965840252101588) D53 D65 D73 D85 D97 D109\n",
      "error(0.003678357090807468904) D53 D65 D77 D89 D101 D113\n",
      "error(0.002665439999999999823) D53 D67 D77 D89 D101 D113\n",
      "error(2.879825239673086635e-05) D53 D73 D85 D97 D109\n",
      "error(0.004652365743471347306) D53 D74 D86 D98 D110\n",
      "error(0.04580936623556411402) D53 D77 D89 D101 D113\n",
      "error(3.674287552866961886e-05) D54 D57\n",
      "error(0.001854163384577362395) D54 D57 D68\n",
      "error(0.001433807312582543667) D54 D58\n",
      "error(0.002831414999999999887) D54 D58 D66\n",
      "error(0.002696118176924125909) D54 D58 D66 D68\n",
      "error(0.001010783130056933663) D54 D58 D68\n",
      "error(0.001010783130056933663) D54 D64 D66 D76 D88 D100 D112\n",
      "error(0.002665439999999999823) D54 D64 D76 D88 D100 D112\n",
      "error(0.003675989848273618615) D54 D66 D76 D88 D100 D112\n",
      "error(0.001018345769905341881) D54 D66 D79 D91 D103 D115\n",
      "error(0.005481761066404799987) D54 D68 D78 D90 D102 D114\n",
      "error(0.001044711783160383149) D54 D75 D87 D99 D111\n",
      "error(0.003860514276163778263) D54 D76 D88 D100 D112\n",
      "error(0.049158419805032251) D54 D78 D90 D102 D114\n",
      "error(5.375075081862617642e-05) D54 D79 D91 D103 D115\n",
      "error(3.674287552866961886e-05) D55 D58\n",
      "error(0.001854163384577362395) D55 D58 D66 D69\n",
      "error(0.001433807312582543667) D55 D59\n",
      "error(0.002831414999999999887) D55 D59 D67\n",
      "error(0.002696118176924125909) D55 D59 D67 D69\n",
      "error(0.001010783130056933663) D55 D59 D69\n",
      "error(0.001010783130056933663) D55 D65 D67 D77 D89 D101 D113\n",
      "error(0.002665439999999999823) D55 D65 D77 D89 D101 D113\n",
      "error(0.002831414999999999887) D55 D66 D69 D79 D91 D103 D115\n",
      "error(0.001015965840252101588) D55 D66 D76 D88 D100 D112\n",
      "error(0.003678357090807468904) D55 D66 D79 D91 D103 D115\n",
      "error(0.003675989848273618615) D55 D67 D77 D89 D101 D113\n",
      "error(0.001018345769905341881) D55 D67 D80 D92 D104 D116\n",
      "error(0.002665439999999999823) D55 D69 D79 D91 D103 D115\n",
      "error(2.879825239673086635e-05) D55 D76 D88 D100 D112\n",
      "error(0.003860514276163778263) D55 D77 D89 D101 D113\n",
      "error(0.04580936623556411402) D55 D79 D91 D103 D115\n",
      "error(5.375075081862617642e-05) D55 D80 D92 D104 D116\n",
      "error(3.674287552866961886e-05) D56 D59\n",
      "error(0.001854163384577362395) D56 D59 D67\n",
      "error(0.001015965840252101588) D56 D67 D77 D89 D101 D113\n",
      "error(0.006330146405388720893) D56 D67 D80 D92 D104 D116\n",
      "error(2.879825239673086635e-05) D56 D77 D89 D101 D113\n",
      "error(0.04311536755819837807) D56 D80 D92 D104 D116\n",
      "error(0.00244214215948672592) D57\n",
      "error(0.005512265518028294439) D57 D68\n",
      "error(0.004519963676295111164) D57 D68 D78 D90 D102 D114\n",
      "error(0.001018345769905341881) D57 D68 D82 D94 D106 D118\n",
      "error(0.003803463737702784692) D57 D78 D90 D102 D114\n",
      "error(0.04891386968098601629) D57 D81 D93 D105 D117\n",
      "error(5.375075081862617642e-05) D57 D82 D94 D106 D118\n",
      "error(0.001470444823703976125) D58\n",
      "error(0.001010783130056933663) D58 D66 D69 D79 D91 D103 D115\n",
      "error(0.002665439999999999823) D58 D66 D79 D91 D103 D115\n",
      "error(0.001854163384577362395) D58 D68 D70\n",
      "error(0.002831414999999999887) D58 D68 D70 D82 D94 D106 D118\n",
      "error(0.001015965840252101588) D58 D68 D78 D90 D102 D114\n",
      "error(0.003678357090807468904) D58 D68 D82 D94 D106 D118\n",
      "error(0.002831414999999999887) D58 D69\n",
      "error(0.002696118176924125909) D58 D69 D70\n",
      "error(0.003675989848273618615) D58 D69 D79 D91 D103 D115\n",
      "error(0.001018345769905341881) D58 D69 D83 D95 D107 D119\n",
      "error(0.001010783130056933663) D58 D70\n",
      "error(0.002665439999999999823) D58 D70 D82 D94 D106 D118\n",
      "error(2.879825239673086635e-05) D58 D78 D90 D102 D114\n",
      "error(0.003860514276163778263) D58 D79 D91 D103 D115\n",
      "error(0.04580936623556411402) D58 D82 D94 D106 D118\n",
      "error(5.375075081862617642e-05) D58 D83 D95 D107 D119\n",
      "error(0.001394391890705732728) D59\n",
      "error(0.003670834766484575885) D59 D67 D80 D92 D104 D116\n",
      "error(0.001854163384577362395) D59 D69 D71\n",
      "error(0.002831414999999999887) D59 D69 D71 D83 D95 D107 D119\n",
      "error(0.001015965840252101588) D59 D69 D79 D91 D103 D115\n",
      "error(0.003678357090807468904) D59 D69 D83 D95 D107 D119\n",
      "error(0.003541758227067706103) D59 D71\n",
      "error(0.002665439999999999823) D59 D71 D83 D95 D107 D119\n",
      "error(2.879825239673086635e-05) D59 D79 D91 D103 D115\n",
      "error(0.004652365743471347306) D59 D80 D92 D104 D116\n",
      "error(0.04580936623556411402) D59 D83 D95 D107 D119\n",
      "error(0.04652400374795213206) D60\n",
      "error(0.004208894420242112293) D60 D62\n",
      "error(0.04234524506783991782) D61\n",
      "error(0.001478969471745447293) D61 D62\n",
      "error(0.004208894420242112293) D61 D63\n",
      "error(0.0458351796367094666) D62\n",
      "error(0.001478969471745447293) D62 D64\n",
      "error(0.004284518053672076512) D62 D65\n",
      "error(0.003848264352626754731) D62 D73 D85 D97 D109\n",
      "error(0.05160557259018355714) D63\n",
      "error(0.001478969471745447293) D63 D65\n",
      "error(0.003848264352626754731) D63 D74 D86 D98 D110\n",
      "error(0.05451785992746415593) D64\n",
      "error(0.004284518053672076512) D64 D66\n",
      "error(0.003848264352626754731) D64 D72 D76 D84 D88 D96 D100 D108 D112\n",
      "error(0.04588739754968995666) D65\n",
      "error(0.001478969471745447293) D65 D66\n",
      "error(0.004284518053672076512) D65 D67\n",
      "error(0.003848264352626754731) D65 D73 D77 D85 D89 D97 D101 D109 D113\n",
      "error(0.04588739754968995666) D66\n",
      "error(0.001478969471745447293) D66 D68\n",
      "error(0.004284518053672076512) D66 D69\n",
      "error(0.003848264352626754731) D66 D76 D79 D88 D91 D100 D103 D112 D115\n",
      "error(0.0516571270482604622) D67\n",
      "error(0.001478969471745447293) D67 D69\n",
      "error(0.003848264352626754731) D67 D77 D80 D89 D92 D101 D104 D113 D116\n",
      "error(0.05446663442194162041) D68\n",
      "error(0.004183146115945002297) D68 D70\n",
      "error(0.001010783130056933663) D68 D70 D82 D94 D106 D118\n",
      "error(0.003848264352626754731) D68 D78 D82 D90 D94 D102 D106 D114 D118\n",
      "error(0.002665439999999999823) D68 D82 D94 D106 D118\n",
      "error(0.04588739754968995666) D69\n",
      "error(0.001478969471745447293) D69 D70\n",
      "error(0.004183146115945002297) D69 D71\n",
      "error(0.001010783130056933663) D69 D71 D83 D95 D107 D119\n",
      "error(0.003848264352626754731) D69 D79 D83 D91 D95 D103 D107 D115 D119\n",
      "error(0.002665439999999999823) D69 D83 D95 D107 D119\n",
      "error(0.04648337918539993674) D70\n",
      "error(0.009170415199135256365) D70 D82 D94 D106 D118\n",
      "error(0.04810028582630810484) D71\n",
      "error(0.009170415199135256365) D71 D83 D95 D107 D119\n",
      "error(0.001050953903419058399) D72 D75 D84 D87 D96 D99 D108 D111\n",
      "error(0.01098687334218738897) D72 D75 D96 D99\n",
      "error(0.003366016701327173739) D72 D76 D84 D88 D96 D100 D108 D112\n",
      "error(0.01157874093050522551) D72 D76 D96 D100\n",
      "error(0.005156151692878106763) D72 D84 D96 D108\n",
      "error(0.02303048645843821032) D72 D96\n",
      "error(0.001050953903419058399) D73 D76 D85 D88 D97 D100 D109 D112\n",
      "error(0.01098687334218738897) D73 D76 D97 D100\n",
      "error(0.003366016701327173739) D73 D77 D85 D89 D97 D101 D109 D113\n",
      "error(0.01157874093050522551) D73 D77 D97 D101\n",
      "error(0.004409895547963766857) D73 D85 D97 D109\n",
      "error(0.02231118595256168652) D73 D97\n",
      "error(0.001050953903419058399) D74 D77 D86 D89 D98 D101 D110 D113\n",
      "error(0.01098687334218738897) D74 D77 D98 D101\n",
      "error(0.003366016701327173739) D74 D86 D98 D110\n",
      "error(0.01157874093050522551) D74 D98\n",
      "error(0.004113844711774847576) D75 D78 D87 D90 D99 D102 D111 D114\n",
      "error(0.01231420227772162326) D75 D78 D99 D102 D120\n",
      "error(0.001050953903419058399) D76 D78 D88 D90 D100 D102 D112 D114\n",
      "error(0.01098687334218738897) D76 D78 D100 D102 D120\n",
      "error(0.003366016701327173739) D76 D79 D88 D91 D100 D103 D112 D115\n",
      "error(0.01157874093050522551) D76 D79 D100 D103 D120\n",
      "error(0.001050953903419058399) D77 D79 D89 D91 D101 D103 D113 D115\n",
      "error(0.01098687334218738897) D77 D79 D101 D103 D120\n",
      "error(0.003366016701327173739) D77 D80 D89 D92 D101 D104 D113 D116\n",
      "error(0.01157874093050522551) D77 D80 D101 D104 D120\n",
      "error(0.001050953903419058399) D78 D81 D90 D93 D102 D105 D114 D117\n",
      "error(0.01098687334218738897) D78 D81 D102 D105\n",
      "error(0.003366016701327173739) D78 D82 D90 D94 D102 D106 D114 D118\n",
      "error(0.01157874093050522551) D78 D82 D102 D106\n",
      "error(0.001050953903419058399) D79 D82 D91 D94 D103 D106 D115 D118\n",
      "error(0.01098687334218738897) D79 D82 D103 D106\n",
      "error(0.003366016701327173739) D79 D83 D91 D95 D103 D107 D115 D119\n",
      "error(0.01157874093050522551) D79 D83 D103 D107\n",
      "error(0.001050953903419058399) D80 D83 D92 D95 D104 D107 D116 D119\n",
      "error(0.01098687334218738897) D80 D83 D104 D107\n",
      "error(0.00529225175455057522) D81 D93 D105 D117\n",
      "error(0.01347312226887080813) D81 D105\n",
      "error(0.008714429018742557084) D82 D94 D106 D118\n",
      "error(0.02646023467288944817) D82 D106\n",
      "error(0.008714429018742557084) D83 D95 D107 D119\n",
      "error(0.02646023467288944817) D83 D107\n",
      "error(0.004251871653758736332) D84 D87 D108 D111\n",
      "error(0.004251871653758736332) D84 D88 D108 D112\n",
      "error(0.008467586482397400707) D84 D108\n",
      "error(0.004251871653758736332) D85 D88 D109 D112\n",
      "error(0.004251871653758736332) D85 D89 D109 D113\n",
      "error(0.008467586482397400707) D85 D109\n",
      "error(0.004251871653758736332) D86 D89 D110 D113\n",
      "error(0.004251871653758736332) D86 D110\n",
      "error(0.004251871653758736332) D87 D90 D111 D114 D120\n",
      "error(0.004251871653758736332) D88 D90 D112 D114 D120\n",
      "error(0.004251871653758736332) D88 D91 D112 D115 D120\n",
      "error(0.004251871653758736332) D89 D91 D113 D115 D120\n",
      "error(0.004251871653758736332) D89 D92 D113 D116 D120\n",
      "error(0.004251871653758736332) D90 D93 D114 D117\n",
      "error(0.004251871653758736332) D90 D94 D114 D118\n",
      "error(0.004251871653758736332) D91 D94 D115 D118\n",
      "error(0.004251871653758736332) D91 D95 D115 D119\n",
      "error(0.004251871653758736332) D92 D95 D116 D119\n",
      "error(0.004251871653758736332) D93 D117\n",
      "error(0.008467586482397400707) D94 D118\n",
      "error(0.008467586482397400707) D95 D119\n",
      "final measurement_index = 146\n",
      "0 observables_errors_interactions_lists.shape = 10 and shape of first element: 1\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-24\n",
      "0 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "MLE decoder took 1.580945s.\n",
      "fidelity 0.5\n",
      "all_fidelities [0.5, 0.5]\n",
      "distance = 3\n",
      "num_CX_per_layer_list = [3, 3, 3]\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "final measurement_index = 50\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.02190115313572887218) D0\n",
      "error(0.01110794330592123833) D0 D2 D6 D40\n",
      "error(0.006252091880126776566) D0 D2 D40\n",
      "error(0.01110794330592123833) D0 D3 D5 D6 D40\n",
      "error(0.002831414999999999887) D0 D3 D5 D13 D21 D40\n",
      "error(0.002831414999999999887) D0 D3 D5 D21 D40\n",
      "error(0.001010783130056933663) D0 D3 D6 D13 D21 D40\n",
      "error(0.001010783130056933663) D0 D3 D6 D21 D40\n",
      "error(0.008979938338230254377) D0 D3 D40\n",
      "error(0.01110794330592123833) D0 D4\n",
      "error(0.01276920199645859705) D0 D4 D5\n",
      "error(0.006330146405388720893) D0 D4 D12 D20\n",
      "error(0.001015965840252101588) D0 D4 D13 D21\n",
      "error(0.006330146405388720893) D0 D4 D20\n",
      "error(0.001015965840252101588) D0 D4 D21\n",
      "error(0.002665439999999999823) D0 D5 D13 D21\n",
      "error(0.002665439999999999823) D0 D5 D21\n",
      "error(0.002831414999999999887) D0 D6 D8\n",
      "error(0.001018345769905341881) D0 D6 D8 D12 D20\n",
      "error(0.002665439999999999823) D0 D6 D8 D13 D21\n",
      "error(0.002831414999999999887) D0 D6 D8 D16\n",
      "error(0.001018345769905341881) D0 D6 D8 D16 D20\n",
      "error(0.002665439999999999823) D0 D6 D8 D16 D21\n",
      "error(0.001015965840252101588) D0 D6 D11 D13 D21 D40\n",
      "error(0.001015965840252101588) D0 D6 D11 D19 D21 D40\n",
      "error(0.0432087996420145587) D0 D8\n",
      "error(0.002838065267102216072) D0 D8 D12 D13 D20 D21\n",
      "error(0.002665439999999999823) D0 D8 D12 D20\n",
      "error(0.0432087996420145587) D0 D8 D16\n",
      "error(0.002665439999999999823) D0 D8 D16 D20\n",
      "error(0.002838065267102216072) D0 D8 D16 D20 D21\n",
      "error(2.879825239673086635e-05) D0 D11 D19 D40\n",
      "error(2.879825239673086635e-05) D0 D11 D40\n",
      "error(0.001015965840252101588) D0 D12 D13 D20 D21\n",
      "error(0.001010783130056933663) D0 D12 D20\n",
      "error(0.001010783130056933663) D0 D20\n",
      "error(0.001015965840252101588) D0 D20 D21\n",
      "error(0.008830112259019891677) D1\n",
      "error(0.01110794330592123833) D1 D3 D5 D40\n",
      "error(0.006252091880126776566) D1 D3 D40\n",
      "error(0.01276920199645859705) D1 D5\n",
      "error(0.006317584575443702458) D1 D5 D9\n",
      "error(0.006317584575443702458) D1 D5 D9 D17\n",
      "error(0.04234524506783991782) D1 D9\n",
      "error(0.04234524506783991782) D1 D9 D17\n",
      "error(0.009634435037852471378) D2\n",
      "error(0.01110794330592123833) D2 D6\n",
      "error(0.002665439999999999823) D2 D6 D8 D14 D22 D40\n",
      "error(0.002665439999999999823) D2 D6 D8 D16 D22 D40\n",
      "error(0.001010783130056933663) D2 D6 D8 D16 D40\n",
      "error(0.001010783130056933663) D2 D6 D8 D40\n",
      "error(0.002831414999999999887) D2 D6 D14 D22\n",
      "error(0.002831414999999999887) D2 D6 D22\n",
      "error(0.001869636747823257353) D2 D8 D14 D22 D40\n",
      "error(0.001869636747823257353) D2 D8 D16 D22 D40\n",
      "error(0.002792729717509890783) D2 D8 D16 D40\n",
      "error(0.002792729717509890783) D2 D8 D40\n",
      "error(0.04390978330455011514) D2 D10\n",
      "error(0.006325066785842492489) D2 D10 D14 D22\n",
      "error(0.04390978330455011514) D2 D10 D18\n",
      "error(0.006325066785842492489) D2 D10 D18 D22\n",
      "error(0.001864462904302397611) D2 D14 D22\n",
      "error(0.001864462904302397611) D2 D22\n",
      "error(0.01561830075635057061) D3\n",
      "error(0.002665439999999999823) D3 D5 D9 D13 D21 D40\n",
      "error(0.002665439999999999823) D3 D5 D9 D17 D21 D40\n",
      "error(0.001864462904302397611) D3 D5 D9 D17 D40\n",
      "error(0.001864462904302397611) D3 D5 D9 D40\n",
      "error(0.001018345769905341881) D3 D5 D13 D21 D40\n",
      "error(0.001018345769905341881) D3 D5 D21 D40\n",
      "error(0.01110794330592123833) D3 D6 D7\n",
      "error(0.002831414999999999887) D3 D6 D7 D11\n",
      "error(0.002831414999999999887) D3 D6 D7 D11 D19\n",
      "error(0.002665439999999999823) D3 D6 D11 D13 D21\n",
      "error(0.002665439999999999823) D3 D6 D11 D19 D21\n",
      "error(0.01443490243866349387) D3 D7\n",
      "error(0.002665439999999999823) D3 D7 D11\n",
      "error(0.001018345769905341881) D3 D7 D11 D13 D21\n",
      "error(0.002665439999999999823) D3 D7 D11 D19\n",
      "error(0.001018345769905341881) D3 D7 D11 D19 D21\n",
      "error(0.001015965840252101588) D3 D9 D13 D21 D40\n",
      "error(0.001015965840252101588) D3 D9 D17 D21 D40\n",
      "error(0.002792729717509890349) D3 D9 D17 D40\n",
      "error(0.002792729717509890349) D3 D9 D40\n",
      "error(0.0432087996420145587) D3 D11\n",
      "error(0.002838065267102216072) D3 D11 D13 D21\n",
      "error(0.0432087996420145587) D3 D11 D19\n",
      "error(0.002838065267102216072) D3 D11 D19 D21\n",
      "error(0.0001074957233508252151) D3 D40\n",
      "error(0.006252091880126776566) D4\n",
      "error(0.008830112259019891677) D4 D5\n",
      "error(0.04311536755819837807) D4 D12 D20\n",
      "error(2.879825239673086635e-05) D4 D13 D21\n",
      "error(0.04311536755819837807) D4 D20\n",
      "error(2.879825239673086635e-05) D4 D21\n",
      "error(0.02176068892243085764) D5\n",
      "error(0.006252091880126776566) D5 D6\n",
      "error(0.001869636747823257353) D5 D9\n",
      "error(0.002838065267102216072) D5 D9 D13 D21\n",
      "error(0.001869636747823257353) D5 D9 D17\n",
      "error(0.002838065267102216072) D5 D9 D17 D21\n",
      "error(0.0432087996420145587) D5 D13 D21\n",
      "error(0.0432087996420145587) D5 D21\n",
      "error(0.01511974341922005076) D6\n",
      "error(0.008979938338230252642) D6 D7\n",
      "error(0.001010783130056933663) D6 D7 D11\n",
      "error(0.001010783130056933663) D6 D7 D11 D19\n",
      "error(0.001015965840252101588) D6 D8 D11 D13 D21 D40\n",
      "error(0.002838065267102216072) D6 D8 D11 D14 D22 D40\n",
      "error(0.001015965840252101588) D6 D8 D11 D16 D19 D21 D40\n",
      "error(0.002838065267102216072) D6 D8 D11 D16 D19 D22 D40\n",
      "error(0.001018345769905341881) D6 D8 D14 D22 D40\n",
      "error(0.001018345769905341881) D6 D8 D16 D22 D40\n",
      "error(0.002665439999999999823) D6 D11 D14 D22\n",
      "error(0.001015965840252101588) D6 D11 D15 D23\n",
      "error(0.002665439999999999823) D6 D11 D19 D22\n",
      "error(0.001015965840252101588) D6 D11 D19 D23\n",
      "error(5.375075081862617642e-05) D6 D12 D20\n",
      "error(0.002849896465810894831) D6 D13 D21\n",
      "error(0.0432087996420145587) D6 D14 D22\n",
      "error(2.879825239673086635e-05) D6 D15 D23\n",
      "error(5.375075081862617642e-05) D6 D20\n",
      "error(0.002849896465810894831) D6 D21\n",
      "error(0.0432087996420145587) D6 D22\n",
      "error(2.879825239673086635e-05) D6 D23\n",
      "error(0.01234693478767508006) D7\n",
      "error(0.001015965840252101588) D7 D11\n",
      "error(0.006337628425401439433) D7 D11 D15 D23\n",
      "error(0.001015965840252101588) D7 D11 D19\n",
      "error(0.006337628425401439433) D7 D11 D19 D23\n",
      "error(5.375075081862617642e-05) D7 D13 D21\n",
      "error(0.04310844294704657687) D7 D15 D23\n",
      "error(5.375075081862617642e-05) D7 D21\n",
      "error(0.04310844294704657687) D7 D23\n",
      "error(0.01767043043371865213) D8\n",
      "error(0.002876688512641980156) D8 D10 D14 D22 D40\n",
      "error(0.002024695128044953513) D8 D10 D14 D40\n",
      "error(0.002035039432888804435) D8 D10 D16 D18 D22 D40\n",
      "error(5.865671620409242679e-05) D8 D10 D16 D18 D40\n",
      "error(0.007953768324862837968) D8 D10 D22 D40\n",
      "error(0.004254882737577601187) D8 D10 D40\n",
      "error(0.002035039432888804435) D8 D11 D13 D14 D21 D22 D40\n",
      "error(0.001181603590391430226) D8 D11 D13 D14 D40\n",
      "error(0.002831414999999999887) D8 D11 D13 D40\n",
      "error(0.001010783130056933663) D8 D11 D14 D40\n",
      "error(0.002876688512641980156) D8 D11 D16 D19 D21 D22 D40\n",
      "error(0.001535392182246036628) D8 D11 D16 D19 D40\n",
      "error(0.007953768324862837968) D8 D11 D21 D22 D40\n",
      "error(0.007044809191149375809) D8 D11 D40\n",
      "error(0.007484258404601240242) D8 D12\n",
      "error(0.002871476899058759708) D8 D12 D13\n",
      "error(0.002876688512641980156) D8 D12 D13 D20 D21\n",
      "error(0.003737436856077045854) D8 D12 D20\n",
      "error(0.003675989848273618615) D8 D13\n",
      "error(0.001018345769905341881) D8 D13 D25 D33\n",
      "error(0.005481761066404799987) D8 D14 D24 D32\n",
      "error(0.001824296242217414085) D8 D16\n",
      "error(0.004576208582325332064) D8 D16 D20\n",
      "error(0.002035039432888804435) D8 D16 D20 D21\n",
      "error(5.375075081862617642e-05) D8 D16 D40\n",
      "error(0.007953768324862837968) D8 D20\n",
      "error(0.007953768324862837968) D8 D20 D21\n",
      "error(0.049158419805032251) D8 D24 D32\n",
      "error(5.375075081862617642e-05) D8 D25 D33\n",
      "error(5.375075081862617642e-05) D8 D40\n",
      "error(0.007626782989063276945) D9\n",
      "error(0.002876688512641980156) D9 D11 D13 D21 D40\n",
      "error(0.002024695128044953513) D9 D11 D13 D40\n",
      "error(0.002035039432888804435) D9 D11 D17 D19 D21 D40\n",
      "error(5.865671620409242679e-05) D9 D11 D17 D19 D40\n",
      "error(0.007953768324862837968) D9 D11 D21 D40\n",
      "error(0.004254882737577601187) D9 D11 D40\n",
      "error(0.002881755385102814822) D9 D13\n",
      "error(0.002035039432888804435) D9 D13 D21\n",
      "error(0.006330146405388720893) D9 D13 D25 D33\n",
      "error(0.001867712848782757075) D9 D17\n",
      "error(0.002876688512641980156) D9 D17 D21\n",
      "error(0.007953768324862837968) D9 D21\n",
      "error(0.04311536755819837807) D9 D25 D33\n",
      "error(0.007941192370062495967) D10\n",
      "error(0.004006327370131653257) D10 D14\n",
      "error(0.00288696689093221508) D10 D14 D22\n",
      "error(0.004519963676295111164) D10 D14 D24 D32 D40\n",
      "error(0.001018345769905341881) D10 D14 D27 D35\n",
      "error(0.001433458058695054327) D10 D18\n",
      "error(0.003727176062222229119) D10 D18 D22\n",
      "error(0.007953768324862837968) D10 D22\n",
      "error(0.003803463737702784692) D10 D24 D32 D40\n",
      "error(0.04891386968098601629) D10 D26 D34\n",
      "error(5.375075081862617642e-05) D10 D27 D35\n",
      "error(0.01459562353802248275) D11\n",
      "error(0.003670834766484575885) D11 D13 D25 D33 D40\n",
      "error(0.002024695128044953513) D11 D14 D15\n",
      "error(0.003727176062222229119) D11 D14 D15 D22 D23\n",
      "error(0.002831414999999999887) D11 D14 D15 D27 D35\n",
      "error(0.001015965840252101588) D11 D14 D24 D32 D40\n",
      "error(0.003678357090807468904) D11 D14 D27 D35\n",
      "error(0.002029818995841314432) D11 D15\n",
      "error(0.002035039432888804435) D11 D15 D23\n",
      "error(0.002665439999999999823) D11 D15 D27 D35\n",
      "error(0.005091480207622430323) D11 D19\n",
      "error(0.00288696689093221508) D11 D19 D22 D23\n",
      "error(0.002876688512641980156) D11 D19 D23\n",
      "error(0.007953768324862837968) D11 D22 D23\n",
      "error(0.007953768324862837968) D11 D23\n",
      "error(2.879825239673086635e-05) D11 D24 D32 D40\n",
      "error(0.004652365743471347306) D11 D25 D33 D40\n",
      "error(0.04580936623556411402) D11 D27 D35\n",
      "error(0.04238874677572322669) D12\n",
      "error(0.001368504195195012051) D12 D13\n",
      "error(0.001535392182246036628) D12 D13 D20 D21\n",
      "error(0.00315388573601166778) D12 D20\n",
      "error(0.04774183183085162208) D13\n",
      "error(4.752677363723468355e-05) D13 D14\n",
      "error(5.865671620409242679e-05) D13 D14 D21 D22\n",
      "error(0.001593868776323137306) D13 D21\n",
      "error(0.003848264352626754731) D13 D25 D33\n",
      "error(0.04751821157447768534) D14\n",
      "error(0.001444561076875621776) D14 D15\n",
      "error(0.001433458058695054327) D14 D15 D22 D23\n",
      "error(0.001010783130056933663) D14 D15 D27 D35\n",
      "error(0.005018784120695379131) D14 D22\n",
      "error(0.003848264352626754731) D14 D24 D27 D32 D35 D40\n",
      "error(0.002665439999999999823) D14 D27 D35\n",
      "error(0.04680271058570958237) D15\n",
      "error(5.865671620409242679e-05) D15 D23\n",
      "error(0.009170415199135256365) D15 D27 D35\n",
      "error(0.007823344399498959392) D16\n",
      "error(4.752677363723468355e-05) D16 D18\n",
      "error(0.001181603590391430226) D16 D18 D22\n",
      "error(0.001444561076875621776) D16 D19\n",
      "error(0.002831414999999999887) D16 D19 D21\n",
      "error(0.002024695128044953513) D16 D19 D21 D22\n",
      "error(0.001010783130056933663) D16 D19 D22\n",
      "error(0.008316697338066831105) D16 D20\n",
      "error(0.002029818995841314432) D16 D20 D21\n",
      "error(0.003675989848273618615) D16 D21\n",
      "error(0.001018345769905341881) D16 D21 D25 D29 D33 D37\n",
      "error(0.005481761066404799987) D16 D22 D24 D28 D32 D36\n",
      "error(0.049158419805032251) D16 D24 D28 D32 D36\n",
      "error(5.375075081862617642e-05) D16 D25 D29 D33 D37\n",
      "error(0.001700936124048502921) D17\n",
      "error(4.752677363723468355e-05) D17 D19\n",
      "error(0.001181603590391430226) D17 D19 D21\n",
      "error(0.003721973364761755471) D17 D21\n",
      "error(0.006330146405388720893) D17 D21 D25 D29 D33 D37\n",
      "error(0.04311536755819837807) D17 D25 D29 D33 D37\n",
      "error(0.002452874174621053581) D18\n",
      "error(0.004844644623733006597) D18 D22\n",
      "error(0.004519963676295111164) D18 D22 D24 D28 D32 D36\n",
      "error(0.001018345769905341881) D18 D22 D27 D31 D35 D39\n",
      "error(0.003803463737702784692) D18 D24 D28 D32 D36\n",
      "error(0.04891386968098601629) D18 D26 D30 D34 D38\n",
      "error(5.375075081862617642e-05) D18 D27 D31 D35 D39\n",
      "error(0.001415900887654034145) D19\n",
      "error(0.003670834766484575885) D19 D21 D25 D29 D33 D37\n",
      "error(0.001181603590391430226) D19 D22 D23\n",
      "error(0.002831414999999999887) D19 D22 D23 D27 D31 D35 D39\n",
      "error(0.001015965840252101588) D19 D22 D24 D28 D32 D36\n",
      "error(0.003678357090807468904) D19 D22 D27 D31 D35 D39\n",
      "error(0.002871476899058759708) D19 D23\n",
      "error(0.002665439999999999823) D19 D23 D27 D31 D35 D39\n",
      "error(2.879825239673086635e-05) D19 D24 D28 D32 D36\n",
      "error(0.004652365743471347306) D19 D25 D29 D33 D37\n",
      "error(0.04580936623556411402) D19 D27 D31 D35 D39\n",
      "error(0.04904909287488143366) D20\n",
      "error(0.006969606652586811564) D20 D21\n",
      "error(0.05658525658481455139) D21\n",
      "error(0.004254882737577601187) D21 D22\n",
      "error(0.003848264352626754731) D21 D25 D29 D33 D37\n",
      "error(0.05941454464120803081) D22\n",
      "error(0.006944001722500811775) D22 D23\n",
      "error(0.001010783130056933663) D22 D23 D27 D31 D35 D39\n",
      "error(0.003848264352626754731) D22 D24 D27 D28 D31 D32 D35 D36 D39\n",
      "error(0.002665439999999999823) D22 D27 D31 D35 D39\n",
      "error(0.05061659774613072593) D23\n",
      "error(0.009170415199135256365) D23 D27 D31 D35 D39\n",
      "error(0.002093469798726521267) D24 D26 D28 D30 D32 D34 D36 D38\n",
      "error(0.01922651150468780712) D24 D26 D32 D34 D40\n",
      "error(0.004403695449867173033) D24 D27 D28 D31 D32 D35 D36 D39\n",
      "error(0.01980840640617578113) D24 D27 D32 D35 D40\n",
      "error(0.007221868154226087841) D24 D28 D32 D36\n",
      "error(0.03896848978193721835) D24 D32\n",
      "error(0.002093469798726521267) D25 D27 D29 D31 D33 D35 D37 D39\n",
      "error(0.01922651150468780712) D25 D27 D33 D35 D40\n",
      "error(0.004403695449867173033) D25 D29 D33 D37\n",
      "error(0.01980840640617578113) D25 D33\n",
      "error(0.006325905782176100521) D26 D30 D34 D38\n",
      "error(0.02167086832168945223) D26 D34\n",
      "error(0.01076529151742893799) D27 D31 D35 D39\n",
      "error(0.04228363247782022938) D27 D35\n",
      "error(0.003593262660715611841) D28 D30 D36 D38 D40\n",
      "error(0.003593262660715611841) D28 D31 D36 D39 D40\n",
      "error(0.007160702248333440309) D28 D36\n",
      "error(0.003593262660715611841) D29 D31 D37 D39 D40\n",
      "error(0.003593262660715611841) D29 D37\n",
      "error(0.003593262660715611841) D30 D38\n",
      "error(0.007160702248333440309) D31 D39\n",
      "final measurement_index = 50\n",
      "0 observables_errors_interactions_lists.shape = 10 and shape of first element: 1\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-24\n",
      "0 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "MLE decoder took 0.330678s.\n",
      "fidelity 0.5\n",
      "all_fidelities [0.5, 0.5, 0.5]\n",
      "distance = 5\n",
      "num_CX_per_layer_list = [3, 3, 3]\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "final measurement_index = 146\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.02190115313572887218) D0\n",
      "error(0.006252091880126776566) D0 D3\n",
      "error(0.01110794330592123833) D0 D3 D16\n",
      "error(0.008979938338230254377) D0 D4\n",
      "error(0.01110794330592123833) D0 D4 D14 D16\n",
      "error(0.002831414999999999887) D0 D4 D14 D38 D62\n",
      "error(0.002831414999999999887) D0 D4 D14 D62\n",
      "error(0.001010783130056933663) D0 D4 D16 D38 D62\n",
      "error(0.001010783130056933663) D0 D4 D16 D62\n",
      "error(0.01110794330592123833) D0 D12\n",
      "error(0.01276920199645859705) D0 D12 D14\n",
      "error(0.006330146405388720893) D0 D12 D36 D60\n",
      "error(0.001015965840252101588) D0 D12 D38 D62\n",
      "error(0.006330146405388720893) D0 D12 D60\n",
      "error(0.001015965840252101588) D0 D12 D62\n",
      "error(0.002665439999999999823) D0 D14 D38 D62\n",
      "error(0.002665439999999999823) D0 D14 D62\n",
      "error(0.002831414999999999887) D0 D16 D24\n",
      "error(0.001018345769905341881) D0 D16 D24 D36 D60\n",
      "error(0.002665439999999999823) D0 D16 D24 D38 D62\n",
      "error(0.002831414999999999887) D0 D16 D24 D48\n",
      "error(0.001018345769905341881) D0 D16 D24 D48 D60\n",
      "error(0.002665439999999999823) D0 D16 D24 D48 D62\n",
      "error(0.001015965840252101588) D0 D16 D28 D38 D62\n",
      "error(0.001015965840252101588) D0 D16 D28 D52 D62\n",
      "error(0.0432087996420145587) D0 D24\n",
      "error(0.002838065267102216072) D0 D24 D36 D38 D60 D62\n",
      "error(0.002665439999999999823) D0 D24 D36 D60\n",
      "error(0.0432087996420145587) D0 D24 D48\n",
      "error(0.002665439999999999823) D0 D24 D48 D60\n",
      "error(0.002838065267102216072) D0 D24 D48 D60 D62\n",
      "error(2.879825239673086635e-05) D0 D28\n",
      "error(2.879825239673086635e-05) D0 D28 D52\n",
      "error(0.001015965840252101588) D0 D36 D38 D60 D62\n",
      "error(0.001010783130056933663) D0 D36 D60\n",
      "error(0.001010783130056933663) D0 D60\n",
      "error(0.001015965840252101588) D0 D60 D62\n",
      "error(0.02190115313572887218) D1\n",
      "error(0.006252091880126776566) D1 D4\n",
      "error(0.01110794330592123833) D1 D4 D14 D17\n",
      "error(0.008979938338230254377) D1 D5\n",
      "error(0.01110794330592123833) D1 D5 D15 D17\n",
      "error(0.002831414999999999887) D1 D5 D15 D39 D63\n",
      "error(0.002831414999999999887) D1 D5 D15 D63\n",
      "error(0.001010783130056933663) D1 D5 D17 D39 D63\n",
      "error(0.001010783130056933663) D1 D5 D17 D63\n",
      "error(0.01110794330592123833) D1 D13 D14\n",
      "error(0.01276920199645859705) D1 D13 D15\n",
      "error(0.006330146405388720893) D1 D13 D37 D61\n",
      "error(0.001015965840252101588) D1 D13 D39 D63\n",
      "error(0.006330146405388720893) D1 D13 D61\n",
      "error(0.001015965840252101588) D1 D13 D63\n",
      "error(0.002831414999999999887) D1 D14 D17 D25\n",
      "error(0.002831414999999999887) D1 D14 D17 D25 D49\n",
      "error(0.002665439999999999823) D1 D14 D25 D37 D61\n",
      "error(0.002665439999999999823) D1 D14 D25 D49 D61\n",
      "error(0.001010783130056933663) D1 D14 D37 D61\n",
      "error(0.001010783130056933663) D1 D14 D61\n",
      "error(0.002665439999999999823) D1 D15 D39 D63\n",
      "error(0.002665439999999999823) D1 D15 D63\n",
      "error(0.001018345769905341881) D1 D17 D25 D37 D61\n",
      "error(0.002665439999999999823) D1 D17 D25 D39 D63\n",
      "error(0.001018345769905341881) D1 D17 D25 D49 D61\n",
      "error(0.002665439999999999823) D1 D17 D25 D49 D63\n",
      "error(0.001015965840252101588) D1 D17 D29 D39 D63\n",
      "error(0.001015965840252101588) D1 D17 D29 D53 D63\n",
      "error(0.0432087996420145587) D1 D25\n",
      "error(0.002838065267102216072) D1 D25 D37 D39 D61 D63\n",
      "error(0.0432087996420145587) D1 D25 D49\n",
      "error(0.002838065267102216072) D1 D25 D49 D61 D63\n",
      "error(2.879825239673086635e-05) D1 D29\n",
      "error(2.879825239673086635e-05) D1 D29 D53\n",
      "error(0.001015965840252101588) D1 D37 D39 D61 D63\n",
      "error(0.001015965840252101588) D1 D61 D63\n",
      "error(0.008830112259019891677) D2\n",
      "error(0.006252091880126776566) D2 D5\n",
      "error(0.01110794330592123833) D2 D5 D15\n",
      "error(0.01276920199645859705) D2 D15\n",
      "error(0.006317584575443702458) D2 D15 D26\n",
      "error(0.006317584575443702458) D2 D15 D26 D50\n",
      "error(0.04234524506783991782) D2 D26\n",
      "error(0.04234524506783991782) D2 D26 D50\n",
      "error(0.002831414999999999887) D3 D6 D16 D40 D64 D120\n",
      "error(0.002831414999999999887) D3 D6 D16 D64 D120\n",
      "error(0.01110794330592123833) D3 D6 D16 D120\n",
      "error(0.001010783130056933663) D3 D6 D40 D64 D120\n",
      "error(0.001010783130056933663) D3 D6 D64 D120\n",
      "error(0.008979938338230254377) D3 D6 D120\n",
      "error(0.001010783130056933663) D3 D16 D24\n",
      "error(0.002665439999999999823) D3 D16 D24 D40 D64\n",
      "error(0.001010783130056933663) D3 D16 D24 D48\n",
      "error(0.002665439999999999823) D3 D16 D24 D48 D64\n",
      "error(0.002792729717509890783) D3 D24\n",
      "error(0.001869636747823257353) D3 D24 D40 D64\n",
      "error(0.002792729717509890783) D3 D24 D48\n",
      "error(0.001869636747823257353) D3 D24 D48 D64\n",
      "error(0.04390978330455011514) D3 D27\n",
      "error(0.006325066785842492489) D3 D27 D40 D64\n",
      "error(0.04390978330455011514) D3 D27 D51\n",
      "error(0.006325066785842492489) D3 D27 D51 D64\n",
      "error(0.001015965840252101588) D3 D30 D40 D64 D120\n",
      "error(0.001015965840252101588) D3 D30 D54 D64 D120\n",
      "error(2.879825239673086635e-05) D3 D30 D54 D120\n",
      "error(2.879825239673086635e-05) D3 D30 D120\n",
      "error(0.0001074957233508252151) D4\n",
      "error(0.01110794330592123833) D4 D6 D16 D18 D120\n",
      "error(0.006252091880126776566) D4 D6 D120\n",
      "error(0.01110794330592123833) D4 D7 D17 D18 D120\n",
      "error(0.002831414999999999887) D4 D7 D17 D41 D65 D120\n",
      "error(0.002831414999999999887) D4 D7 D17 D65 D120\n",
      "error(0.001010783130056933663) D4 D7 D18 D41 D65 D120\n",
      "error(0.001010783130056933663) D4 D7 D18 D65 D120\n",
      "error(0.008979938338230254377) D4 D7 D120\n",
      "error(0.001010783130056933663) D4 D14 D17 D25\n",
      "error(0.001010783130056933663) D4 D14 D17 D25 D49\n",
      "error(0.002665439999999999823) D4 D14 D25 D38 D62\n",
      "error(0.001015965840252101588) D4 D14 D25 D41 D65\n",
      "error(0.002665439999999999823) D4 D14 D25 D49 D62\n",
      "error(0.001015965840252101588) D4 D14 D25 D49 D65\n",
      "error(0.001018345769905341881) D4 D14 D38 D62\n",
      "error(0.001018345769905341881) D4 D14 D62\n",
      "error(0.002831414999999999887) D4 D16 D18 D28\n",
      "error(0.002831414999999999887) D4 D16 D18 D28 D52\n",
      "error(0.002665439999999999823) D4 D16 D28 D38 D62\n",
      "error(0.002665439999999999823) D4 D16 D28 D52 D62\n",
      "error(0.002665439999999999823) D4 D17 D25 D41 D65\n",
      "error(0.002665439999999999823) D4 D17 D25 D49 D65\n",
      "error(0.001018345769905341881) D4 D18 D28 D38 D62\n",
      "error(0.002665439999999999823) D4 D18 D28 D41 D65\n",
      "error(0.001018345769905341881) D4 D18 D28 D52 D62\n",
      "error(0.002665439999999999823) D4 D18 D28 D52 D65\n",
      "error(0.001015965840252101588) D4 D18 D31 D41 D65 D120\n",
      "error(0.001015965840252101588) D4 D18 D31 D55 D65 D120\n",
      "error(0.002849896465810894831) D4 D25\n",
      "error(0.001015965840252101588) D4 D25 D38 D41 D62 D65\n",
      "error(0.002849896465810894831) D4 D25 D49\n",
      "error(0.001015965840252101588) D4 D25 D49 D62 D65\n",
      "error(0.0432087996420145587) D4 D28\n",
      "error(0.002838065267102216072) D4 D28 D38 D41 D62 D65\n",
      "error(0.0432087996420145587) D4 D28 D52\n",
      "error(0.002838065267102216072) D4 D28 D52 D62 D65\n",
      "error(2.879825239673086635e-05) D4 D31 D55 D120\n",
      "error(2.879825239673086635e-05) D4 D31 D120\n",
      "error(0.0001074957233508252151) D5\n",
      "error(0.01110794330592123833) D5 D7 D17 D19 D120\n",
      "error(0.006252091880126776566) D5 D7 D120\n",
      "error(0.01276920199645859705) D5 D8 D19 D120\n",
      "error(0.008830112259019891677) D5 D8 D120\n",
      "error(0.001864462904302397611) D5 D15 D26\n",
      "error(0.002665439999999999823) D5 D15 D26 D39 D63\n",
      "error(0.001864462904302397611) D5 D15 D26 D50\n",
      "error(0.002665439999999999823) D5 D15 D26 D50 D63\n",
      "error(0.001018345769905341881) D5 D15 D39 D63\n",
      "error(0.001018345769905341881) D5 D15 D63\n",
      "error(0.002831414999999999887) D5 D17 D19 D29\n",
      "error(0.002831414999999999887) D5 D17 D19 D29 D53\n",
      "error(0.002665439999999999823) D5 D17 D29 D39 D63\n",
      "error(0.002665439999999999823) D5 D17 D29 D53 D63\n",
      "error(0.002665439999999999823) D5 D19 D29\n",
      "error(0.001018345769905341881) D5 D19 D29 D39 D63\n",
      "error(0.002665439999999999823) D5 D19 D29 D53\n",
      "error(0.001018345769905341881) D5 D19 D29 D53 D63\n",
      "error(0.001015965840252101588) D5 D19 D32 D56 D120\n",
      "error(0.001015965840252101588) D5 D19 D32 D120\n",
      "error(0.002792729717509890349) D5 D26\n",
      "error(0.001015965840252101588) D5 D26 D39 D63\n",
      "error(0.002792729717509890349) D5 D26 D50\n",
      "error(0.001015965840252101588) D5 D26 D50 D63\n",
      "error(0.0432087996420145587) D5 D29\n",
      "error(0.002838065267102216072) D5 D29 D39 D63\n",
      "error(0.0432087996420145587) D5 D29 D53\n",
      "error(0.002838065267102216072) D5 D29 D53 D63\n",
      "error(2.879825239673086635e-05) D5 D32 D56 D120\n",
      "error(2.879825239673086635e-05) D5 D32 D120\n",
      "error(0.006252091880126776566) D6 D9\n",
      "error(0.01110794330592123833) D6 D9 D20\n",
      "error(0.008979938338230254377) D6 D10\n",
      "error(0.01110794330592123833) D6 D10 D18 D20\n",
      "error(0.002831414999999999887) D6 D10 D18 D42 D66\n",
      "error(0.002831414999999999887) D6 D10 D18 D66\n",
      "error(0.001010783130056933663) D6 D10 D20 D42 D66\n",
      "error(0.001010783130056933663) D6 D10 D20 D66\n",
      "error(0.001010783130056933663) D6 D16 D18 D28 D52 D120\n",
      "error(0.001010783130056933663) D6 D16 D18 D28 D120\n",
      "error(0.001018345769905341881) D6 D16 D24 D40 D64 D120\n",
      "error(0.001018345769905341881) D6 D16 D24 D48 D64 D120\n",
      "error(0.002665439999999999823) D6 D16 D28 D40 D64 D120\n",
      "error(0.001015965840252101588) D6 D16 D28 D42 D66 D120\n",
      "error(0.002665439999999999823) D6 D16 D28 D52 D64 D120\n",
      "error(0.001015965840252101588) D6 D16 D28 D52 D66 D120\n",
      "error(0.002665439999999999823) D6 D18 D28 D42 D66 D120\n",
      "error(0.002665439999999999823) D6 D18 D28 D52 D66 D120\n",
      "error(0.002831414999999999887) D6 D20 D30\n",
      "error(0.001018345769905341881) D6 D20 D30 D40 D64\n",
      "error(0.002665439999999999823) D6 D20 D30 D42 D66\n",
      "error(0.002831414999999999887) D6 D20 D30 D54\n",
      "error(0.001018345769905341881) D6 D20 D30 D54 D64\n",
      "error(0.002665439999999999823) D6 D20 D30 D54 D66\n",
      "error(0.001015965840252101588) D6 D20 D34 D42 D66\n",
      "error(0.001015965840252101588) D6 D20 D34 D58 D66\n",
      "error(5.375075081862617642e-05) D6 D24 D48 D120\n",
      "error(5.375075081862617642e-05) D6 D24 D120\n",
      "error(0.001015965840252101588) D6 D28 D40 D42 D64 D66 D120\n",
      "error(0.001015965840252101588) D6 D28 D52 D64 D66 D120\n",
      "error(0.002849896465810894831) D6 D28 D52 D120\n",
      "error(0.002849896465810894831) D6 D28 D120\n",
      "error(0.0432087996420145587) D6 D30\n",
      "error(0.002838065267102216072) D6 D30 D40 D42 D64 D66\n",
      "error(0.002665439999999999823) D6 D30 D40 D64\n",
      "error(0.0432087996420145587) D6 D30 D54\n",
      "error(0.002665439999999999823) D6 D30 D54 D64\n",
      "error(0.002838065267102216072) D6 D30 D54 D64 D66\n",
      "error(2.879825239673086635e-05) D6 D34\n",
      "error(2.879825239673086635e-05) D6 D34 D58\n",
      "error(0.006252091880126776566) D7 D10\n",
      "error(0.01110794330592123833) D7 D10 D18 D21\n",
      "error(0.008979938338230254377) D7 D11\n",
      "error(0.01110794330592123833) D7 D11 D19 D21\n",
      "error(0.002831414999999999887) D7 D11 D19 D43 D67\n",
      "error(0.002831414999999999887) D7 D11 D19 D67\n",
      "error(0.001010783130056933663) D7 D11 D21 D43 D67\n",
      "error(0.001010783130056933663) D7 D11 D21 D67\n",
      "error(0.001010783130056933663) D7 D17 D19 D29 D53 D120\n",
      "error(0.001010783130056933663) D7 D17 D19 D29 D120\n",
      "error(0.001018345769905341881) D7 D17 D25 D41 D65 D120\n",
      "error(0.001018345769905341881) D7 D17 D25 D49 D65 D120\n",
      "error(0.002665439999999999823) D7 D17 D29 D41 D65 D120\n",
      "error(0.001015965840252101588) D7 D17 D29 D43 D67 D120\n",
      "error(0.002665439999999999823) D7 D17 D29 D53 D65 D120\n",
      "error(0.001015965840252101588) D7 D17 D29 D53 D67 D120\n",
      "error(0.002831414999999999887) D7 D18 D21 D31\n",
      "error(0.002831414999999999887) D7 D18 D21 D31 D55\n",
      "error(0.002665439999999999823) D7 D18 D31 D41 D65\n",
      "error(0.002665439999999999823) D7 D18 D31 D55 D65\n",
      "error(0.002665439999999999823) D7 D19 D29 D43 D67 D120\n",
      "error(0.002665439999999999823) D7 D19 D29 D53 D67 D120\n",
      "error(0.001018345769905341881) D7 D21 D31 D41 D65\n",
      "error(0.002665439999999999823) D7 D21 D31 D43 D67\n",
      "error(0.001018345769905341881) D7 D21 D31 D55 D65\n",
      "error(0.002665439999999999823) D7 D21 D31 D55 D67\n",
      "error(0.001015965840252101588) D7 D21 D35 D43 D67\n",
      "error(0.001015965840252101588) D7 D21 D35 D59 D67\n",
      "error(5.375075081862617642e-05) D7 D25 D49 D120\n",
      "error(5.375075081862617642e-05) D7 D25 D120\n",
      "error(0.001015965840252101588) D7 D29 D41 D43 D65 D67 D120\n",
      "error(0.001015965840252101588) D7 D29 D53 D65 D67 D120\n",
      "error(0.002849896465810894831) D7 D29 D53 D120\n",
      "error(0.002849896465810894831) D7 D29 D120\n",
      "error(0.0432087996420145587) D7 D31\n",
      "error(0.002838065267102216072) D7 D31 D41 D43 D65 D67\n",
      "error(0.0432087996420145587) D7 D31 D55\n",
      "error(0.002838065267102216072) D7 D31 D55 D65 D67\n",
      "error(2.879825239673086635e-05) D7 D35\n",
      "error(2.879825239673086635e-05) D7 D35 D59\n",
      "error(0.006252091880126776566) D8 D11\n",
      "error(0.01110794330592123833) D8 D11 D19\n",
      "error(0.006317584575443702458) D8 D19 D32\n",
      "error(0.006317584575443702458) D8 D19 D32 D56\n",
      "error(0.04234524506783991782) D8 D32\n",
      "error(0.04234524506783991782) D8 D32 D56\n",
      "error(0.009634435037852471378) D9\n",
      "error(0.01110794330592123833) D9 D20\n",
      "error(0.001010783130056933663) D9 D20 D30\n",
      "error(0.002665439999999999823) D9 D20 D30 D44 D68\n",
      "error(0.001010783130056933663) D9 D20 D30 D54\n",
      "error(0.002665439999999999823) D9 D20 D30 D54 D68\n",
      "error(0.002831414999999999887) D9 D20 D44 D68\n",
      "error(0.002831414999999999887) D9 D20 D68\n",
      "error(0.002792729717509890783) D9 D30\n",
      "error(0.001869636747823257353) D9 D30 D44 D68\n",
      "error(0.002792729717509890783) D9 D30 D54\n",
      "error(0.001869636747823257353) D9 D30 D54 D68\n",
      "error(0.04390978330455011514) D9 D33\n",
      "error(0.006325066785842492489) D9 D33 D44 D68\n",
      "error(0.04390978330455011514) D9 D33 D57\n",
      "error(0.006325066785842492489) D9 D33 D57 D68\n",
      "error(0.001864462904302397611) D9 D44 D68\n",
      "error(0.001864462904302397611) D9 D68\n",
      "error(0.01576605617183972352) D10\n",
      "error(0.001010783130056933663) D10 D18 D21 D31\n",
      "error(0.001010783130056933663) D10 D18 D21 D31 D55\n",
      "error(0.001018345769905341881) D10 D18 D28 D42 D66 D120\n",
      "error(0.001018345769905341881) D10 D18 D28 D52 D66 D120\n",
      "error(0.002665439999999999823) D10 D18 D31 D42 D66\n",
      "error(0.001015965840252101588) D10 D18 D31 D45 D69\n",
      "error(0.002665439999999999823) D10 D18 D31 D55 D66\n",
      "error(0.001015965840252101588) D10 D18 D31 D55 D69\n",
      "error(0.01110794330592123833) D10 D20 D22\n",
      "error(0.002831414999999999887) D10 D20 D22 D34\n",
      "error(0.002831414999999999887) D10 D20 D22 D34 D58\n",
      "error(0.002665439999999999823) D10 D20 D34 D42 D66\n",
      "error(0.002665439999999999823) D10 D20 D34 D58 D66\n",
      "error(0.01110794330592123833) D10 D21 D22\n",
      "error(0.002665439999999999823) D10 D21 D31 D45 D69\n",
      "error(0.002665439999999999823) D10 D21 D31 D55 D69\n",
      "error(0.002831414999999999887) D10 D21 D45 D69\n",
      "error(0.002831414999999999887) D10 D21 D69\n",
      "error(0.001018345769905341881) D10 D22 D34 D42 D66\n",
      "error(0.002665439999999999823) D10 D22 D34 D45 D69\n",
      "error(0.001018345769905341881) D10 D22 D34 D58 D66\n",
      "error(0.002665439999999999823) D10 D22 D34 D58 D69\n",
      "error(0.001864462904302397611) D10 D22 D45 D69\n",
      "error(0.001864462904302397611) D10 D22 D69\n",
      "error(5.375075081862617642e-05) D10 D28 D52 D120\n",
      "error(5.375075081862617642e-05) D10 D28 D120\n",
      "error(0.002849896465810894831) D10 D31\n",
      "error(0.001015965840252101588) D10 D31 D42 D45 D66 D69\n",
      "error(0.002849896465810894831) D10 D31 D55\n",
      "error(0.001015965840252101588) D10 D31 D55 D66 D69\n",
      "error(0.0432087996420145587) D10 D34\n",
      "error(0.002838065267102216072) D10 D34 D42 D45 D66 D69\n",
      "error(0.0432087996420145587) D10 D34 D58\n",
      "error(0.002838065267102216072) D10 D34 D58 D66 D69\n",
      "error(0.01561830075635057061) D11\n",
      "error(0.001018345769905341881) D11 D19 D29 D43 D67 D120\n",
      "error(0.001018345769905341881) D11 D19 D29 D53 D67 D120\n",
      "error(0.001864462904302397611) D11 D19 D32\n",
      "error(0.002665439999999999823) D11 D19 D32 D43 D67\n",
      "error(0.001864462904302397611) D11 D19 D32 D56\n",
      "error(0.002665439999999999823) D11 D19 D32 D56 D67\n",
      "error(0.01110794330592123833) D11 D21 D23\n",
      "error(0.002831414999999999887) D11 D21 D23 D35\n",
      "error(0.002831414999999999887) D11 D21 D23 D35 D59\n",
      "error(0.002665439999999999823) D11 D21 D35 D43 D67\n",
      "error(0.002665439999999999823) D11 D21 D35 D59 D67\n",
      "error(0.01443490243866349387) D11 D23\n",
      "error(0.002665439999999999823) D11 D23 D35\n",
      "error(0.001018345769905341881) D11 D23 D35 D43 D67\n",
      "error(0.002665439999999999823) D11 D23 D35 D59\n",
      "error(0.001018345769905341881) D11 D23 D35 D59 D67\n",
      "error(5.375075081862617642e-05) D11 D29 D53 D120\n",
      "error(5.375075081862617642e-05) D11 D29 D120\n",
      "error(0.002792729717509890349) D11 D32\n",
      "error(0.001015965840252101588) D11 D32 D43 D67\n",
      "error(0.002792729717509890349) D11 D32 D56\n",
      "error(0.001015965840252101588) D11 D32 D56 D67\n",
      "error(0.0432087996420145587) D11 D35\n",
      "error(0.002838065267102216072) D11 D35 D43 D67\n",
      "error(0.0432087996420145587) D11 D35 D59\n",
      "error(0.002838065267102216072) D11 D35 D59 D67\n",
      "error(0.006252091880126776566) D12\n",
      "error(0.008830112259019891677) D12 D14\n",
      "error(0.04311536755819837807) D12 D36 D60\n",
      "error(2.879825239673086635e-05) D12 D38 D62\n",
      "error(0.04311536755819837807) D12 D60\n",
      "error(2.879825239673086635e-05) D12 D62\n",
      "error(0.006252091880126776566) D13 D14\n",
      "error(0.008830112259019891677) D13 D15\n",
      "error(0.04311536755819837807) D13 D37 D61\n",
      "error(2.879825239673086635e-05) D13 D39 D63\n",
      "error(0.04311536755819837807) D13 D61\n",
      "error(2.879825239673086635e-05) D13 D63\n",
      "error(0.006252091880126776566) D14 D16\n",
      "error(0.008979938338230252642) D14 D17\n",
      "error(0.001869636747823257353) D14 D25 D37 D61\n",
      "error(0.002838065267102216072) D14 D25 D38 D62\n",
      "error(0.001869636747823257353) D14 D25 D49 D61\n",
      "error(0.002838065267102216072) D14 D25 D49 D62\n",
      "error(0.002792729717509890783) D14 D37 D61\n",
      "error(0.0432087996420145587) D14 D38 D62\n",
      "error(2.879825239673086635e-05) D14 D41 D65\n",
      "error(0.002792729717509890783) D14 D61\n",
      "error(0.0432087996420145587) D14 D62\n",
      "error(2.879825239673086635e-05) D14 D65\n",
      "error(0.02176068892243085764) D15\n",
      "error(0.006252091880126776566) D15 D17\n",
      "error(0.001869636747823257353) D15 D26\n",
      "error(0.002838065267102216072) D15 D26 D39 D63\n",
      "error(0.001869636747823257353) D15 D26 D50\n",
      "error(0.002838065267102216072) D15 D26 D50 D63\n",
      "error(0.0432087996420145587) D15 D39 D63\n",
      "error(0.0432087996420145587) D15 D63\n",
      "error(0.01511974341922005076) D16\n",
      "error(0.008979938338230252642) D16 D18\n",
      "error(0.001015965840252101588) D16 D24 D28 D38 D62\n",
      "error(0.002838065267102216072) D16 D24 D28 D40 D64\n",
      "error(0.001015965840252101588) D16 D24 D28 D48 D52 D62\n",
      "error(0.002838065267102216072) D16 D24 D28 D48 D52 D64\n",
      "error(5.375075081862617642e-05) D16 D36 D60\n",
      "error(0.002849896465810894831) D16 D38 D62\n",
      "error(0.0432087996420145587) D16 D40 D64\n",
      "error(2.879825239673086635e-05) D16 D42 D66\n",
      "error(5.375075081862617642e-05) D16 D60\n",
      "error(0.002849896465810894831) D16 D62\n",
      "error(0.0432087996420145587) D16 D64\n",
      "error(2.879825239673086635e-05) D16 D66\n",
      "error(0.006252091880126776566) D17 D18\n",
      "error(0.008979938338230252642) D17 D19\n",
      "error(0.001015965840252101588) D17 D25 D29 D39 D63\n",
      "error(0.002838065267102216072) D17 D25 D29 D41 D65\n",
      "error(0.001015965840252101588) D17 D25 D29 D49 D53 D63\n",
      "error(0.002838065267102216072) D17 D25 D29 D49 D53 D65\n",
      "error(5.375075081862617642e-05) D17 D37 D61\n",
      "error(0.002849896465810894831) D17 D39 D63\n",
      "error(0.0432087996420145587) D17 D41 D65\n",
      "error(2.879825239673086635e-05) D17 D43 D67\n",
      "error(5.375075081862617642e-05) D17 D61\n",
      "error(0.002849896465810894831) D17 D63\n",
      "error(0.0432087996420145587) D17 D65\n",
      "error(2.879825239673086635e-05) D17 D67\n",
      "error(0.006252091880126776566) D18 D20\n",
      "error(0.008979938338230252642) D18 D21\n",
      "error(0.001015965840252101588) D18 D28 D31 D41 D65 D120\n",
      "error(0.002838065267102216072) D18 D28 D31 D42 D66 D120\n",
      "error(0.001015965840252101588) D18 D28 D31 D52 D55 D65 D120\n",
      "error(0.002838065267102216072) D18 D28 D31 D52 D55 D66 D120\n",
      "error(5.375075081862617642e-05) D18 D38 D62\n",
      "error(0.002849896465810894831) D18 D41 D65\n",
      "error(0.0432087996420145587) D18 D42 D66\n",
      "error(2.879825239673086635e-05) D18 D45 D69\n",
      "error(5.375075081862617642e-05) D18 D62\n",
      "error(0.002849896465810894831) D18 D65\n",
      "error(0.0432087996420145587) D18 D66\n",
      "error(2.879825239673086635e-05) D18 D69\n",
      "error(0.02187065438864821063) D19\n",
      "error(0.006252091880126776566) D19 D21\n",
      "error(0.002838065267102216072) D19 D29 D32 D43 D67 D120\n",
      "error(0.002838065267102216072) D19 D29 D32 D53 D56 D67 D120\n",
      "error(0.001015965840252101588) D19 D29 D32 D53 D56 D120\n",
      "error(0.001015965840252101588) D19 D29 D32 D120\n",
      "error(5.375075081862617642e-05) D19 D39 D63\n",
      "error(0.0432087996420145587) D19 D43 D67\n",
      "error(5.375075081862617642e-05) D19 D63\n",
      "error(0.0432087996420145587) D19 D67\n",
      "error(0.01511974341922005076) D20\n",
      "error(0.008979938338230252642) D20 D22\n",
      "error(0.001010783130056933663) D20 D22 D34\n",
      "error(0.001010783130056933663) D20 D22 D34 D58\n",
      "error(0.001015965840252101588) D20 D30 D34 D42 D66\n",
      "error(0.002838065267102216072) D20 D30 D34 D44 D68\n",
      "error(0.001015965840252101588) D20 D30 D34 D54 D58 D66\n",
      "error(0.002838065267102216072) D20 D30 D34 D54 D58 D68\n",
      "error(0.001018345769905341881) D20 D30 D44 D68\n",
      "error(0.001018345769905341881) D20 D30 D54 D68\n",
      "error(0.002665439999999999823) D20 D34 D44 D68\n",
      "error(0.001015965840252101588) D20 D34 D46 D70\n",
      "error(0.002665439999999999823) D20 D34 D58 D68\n",
      "error(0.001015965840252101588) D20 D34 D58 D70\n",
      "error(5.375075081862617642e-05) D20 D40 D64\n",
      "error(0.002849896465810894831) D20 D42 D66\n",
      "error(0.0432087996420145587) D20 D44 D68\n",
      "error(2.879825239673086635e-05) D20 D46 D70\n",
      "error(5.375075081862617642e-05) D20 D64\n",
      "error(0.002849896465810894831) D20 D66\n",
      "error(0.0432087996420145587) D20 D68\n",
      "error(2.879825239673086635e-05) D20 D70\n",
      "error(0.006252091880126776566) D21 D22\n",
      "error(0.008979938338230252642) D21 D23\n",
      "error(0.001010783130056933663) D21 D23 D35\n",
      "error(0.001010783130056933663) D21 D23 D35 D59\n",
      "error(0.001015965840252101588) D21 D31 D35 D43 D67\n",
      "error(0.002838065267102216072) D21 D31 D35 D45 D69\n",
      "error(0.001015965840252101588) D21 D31 D35 D55 D59 D67\n",
      "error(0.002838065267102216072) D21 D31 D35 D55 D59 D69\n",
      "error(0.001018345769905341881) D21 D31 D45 D69\n",
      "error(0.001018345769905341881) D21 D31 D55 D69\n",
      "error(0.002665439999999999823) D21 D35 D45 D69\n",
      "error(0.001015965840252101588) D21 D35 D47 D71\n",
      "error(0.002665439999999999823) D21 D35 D59 D69\n",
      "error(0.001015965840252101588) D21 D35 D59 D71\n",
      "error(5.375075081862617642e-05) D21 D41 D65\n",
      "error(0.002849896465810894831) D21 D43 D67\n",
      "error(0.0432087996420145587) D21 D45 D69\n",
      "error(2.879825239673086635e-05) D21 D47 D71\n",
      "error(5.375075081862617642e-05) D21 D65\n",
      "error(0.002849896465810894831) D21 D67\n",
      "error(0.0432087996420145587) D21 D69\n",
      "error(2.879825239673086635e-05) D21 D71\n",
      "error(0.001015965840252101588) D22 D34 D45 D69\n",
      "error(0.006337628425401439433) D22 D34 D46 D70\n",
      "error(0.001015965840252101588) D22 D34 D58 D69\n",
      "error(0.006337628425401439433) D22 D34 D58 D70\n",
      "error(5.375075081862617642e-05) D22 D42 D66\n",
      "error(0.002792729717509890349) D22 D45 D69\n",
      "error(0.04310844294704657687) D22 D46 D70\n",
      "error(5.375075081862617642e-05) D22 D66\n",
      "error(0.002792729717509890349) D22 D69\n",
      "error(0.04310844294704657687) D22 D70\n",
      "error(0.01234693478767508006) D23\n",
      "error(0.001015965840252101588) D23 D35\n",
      "error(0.006337628425401439433) D23 D35 D47 D71\n",
      "error(0.001015965840252101588) D23 D35 D59\n",
      "error(0.006337628425401439433) D23 D35 D59 D71\n",
      "error(5.375075081862617642e-05) D23 D43 D67\n",
      "error(0.04310844294704657687) D23 D47 D71\n",
      "error(5.375075081862617642e-05) D23 D67\n",
      "error(0.04310844294704657687) D23 D71\n",
      "error(0.01767043043371865213) D24\n",
      "error(0.004254882737577601187) D24 D27\n",
      "error(0.002024695128044953513) D24 D27 D40\n",
      "error(0.002876688512641980156) D24 D27 D40 D64\n",
      "error(5.865671620409242679e-05) D24 D27 D48 D51\n",
      "error(0.002035039432888804435) D24 D27 D48 D51 D64\n",
      "error(0.007953768324862837968) D24 D27 D64\n",
      "error(0.007044809191149375809) D24 D28\n",
      "error(0.002831414999999999887) D24 D28 D38\n",
      "error(0.001181603590391430226) D24 D28 D38 D40\n",
      "error(0.002035039432888804435) D24 D28 D38 D40 D62 D64\n",
      "error(0.001010783130056933663) D24 D28 D40\n",
      "error(0.001535392182246036628) D24 D28 D48 D52\n",
      "error(0.002876688512641980156) D24 D28 D48 D52 D62 D64\n",
      "error(0.007953768324862837968) D24 D28 D62 D64\n",
      "error(0.007484258404601240242) D24 D36\n",
      "error(0.002871476899058759708) D24 D36 D38\n",
      "error(0.002876688512641980156) D24 D36 D38 D60 D62\n",
      "error(0.003737436856077045854) D24 D36 D60\n",
      "error(0.003675989848273618615) D24 D38\n",
      "error(0.001018345769905341881) D24 D38 D73 D97\n",
      "error(0.005481761066404799987) D24 D40 D72 D96\n",
      "error(0.001824296242217414085) D24 D48\n",
      "error(0.004576208582325332064) D24 D48 D60\n",
      "error(0.002035039432888804435) D24 D48 D60 D62\n",
      "error(0.007953768324862837968) D24 D60\n",
      "error(0.007953768324862837968) D24 D60 D62\n",
      "error(0.049158419805032251) D24 D72 D96\n",
      "error(5.375075081862617642e-05) D24 D73 D97\n",
      "error(0.01596367290077850207) D25\n",
      "error(0.004254882737577601187) D25 D28\n",
      "error(0.002024695128044953513) D25 D28 D38 D41\n",
      "error(0.002876688512641980156) D25 D28 D38 D41 D62 D65\n",
      "error(5.865671620409242679e-05) D25 D28 D49 D52\n",
      "error(0.002035039432888804435) D25 D28 D49 D52 D62 D65\n",
      "error(0.007953768324862837968) D25 D28 D62 D65\n",
      "error(0.007044809191149375809) D25 D29\n",
      "error(0.002831414999999999887) D25 D29 D39\n",
      "error(0.001181603590391430226) D25 D29 D39 D41\n",
      "error(0.002035039432888804435) D25 D29 D39 D41 D63 D65\n",
      "error(0.001010783130056933663) D25 D29 D41\n",
      "error(0.001535392182246036628) D25 D29 D49 D53\n",
      "error(0.002876688512641980156) D25 D29 D49 D53 D63 D65\n",
      "error(0.007953768324862837968) D25 D29 D63 D65\n",
      "error(0.006317584575443702458) D25 D37\n",
      "error(0.001181603590391430226) D25 D37 D38\n",
      "error(0.002035039432888804435) D25 D37 D38 D61 D62\n",
      "error(0.002871476899058759708) D25 D37 D39\n",
      "error(0.002876688512641980156) D25 D37 D39 D61 D63\n",
      "error(0.001864462904302397611) D25 D38\n",
      "error(0.002831414999999999887) D25 D38 D41 D73 D97\n",
      "error(0.003678357090807468904) D25 D38 D73 D97\n",
      "error(0.003675989848273618615) D25 D39\n",
      "error(0.001018345769905341881) D25 D39 D74 D98\n",
      "error(0.002665439999999999823) D25 D41 D73 D97\n",
      "error(0.001926150457181806039) D25 D49\n",
      "error(0.002876688512641980156) D25 D49 D61 D62\n",
      "error(0.002035039432888804435) D25 D49 D61 D63\n",
      "error(0.007953768324862837968) D25 D61 D62\n",
      "error(0.007953768324862837968) D25 D61 D63\n",
      "error(0.04580936623556411402) D25 D73 D97\n",
      "error(5.375075081862617642e-05) D25 D74 D98\n",
      "error(0.007626782989063276945) D26\n",
      "error(0.004254882737577601187) D26 D29\n",
      "error(0.002024695128044953513) D26 D29 D39\n",
      "error(0.002876688512641980156) D26 D29 D39 D63\n",
      "error(5.865671620409242679e-05) D26 D29 D50 D53\n",
      "error(0.002035039432888804435) D26 D29 D50 D53 D63\n",
      "error(0.007953768324862837968) D26 D29 D63\n",
      "error(0.002881755385102814822) D26 D39\n",
      "error(0.002035039432888804435) D26 D39 D63\n",
      "error(0.006330146405388720893) D26 D39 D74 D98\n",
      "error(0.001867712848782757075) D26 D50\n",
      "error(0.002876688512641980156) D26 D50 D63\n",
      "error(0.007953768324862837968) D26 D63\n",
      "error(0.04311536755819837807) D26 D74 D98\n",
      "error(0.00288696689093221508) D27 D30 D40 D64 D120\n",
      "error(0.004006327370131653257) D27 D30 D40 D120\n",
      "error(0.003727176062222229119) D27 D30 D51 D54 D64 D120\n",
      "error(0.001433458058695054327) D27 D30 D51 D54 D120\n",
      "error(0.007953768324862837968) D27 D30 D64 D120\n",
      "error(0.007941192370062495967) D27 D30 D120\n",
      "error(0.004519963676295111164) D27 D40 D72 D96\n",
      "error(0.001018345769905341881) D27 D40 D76 D100\n",
      "error(0.003803463737702784692) D27 D72 D96\n",
      "error(0.04891386968098601629) D27 D75 D99\n",
      "error(5.375075081862617642e-05) D27 D76 D100\n",
      "error(0.002876688512641980156) D28 D30 D40 D42 D64 D66 D120\n",
      "error(0.002024695128044953513) D28 D30 D40 D42 D120\n",
      "error(0.002035039432888804435) D28 D30 D52 D54 D64 D66 D120\n",
      "error(5.865671620409242679e-05) D28 D30 D52 D54 D120\n",
      "error(0.007953768324862837968) D28 D30 D64 D66 D120\n",
      "error(0.004254882737577601187) D28 D30 D120\n",
      "error(0.002035039432888804435) D28 D31 D41 D42 D65 D66 D120\n",
      "error(0.001181603590391430226) D28 D31 D41 D42 D120\n",
      "error(0.002831414999999999887) D28 D31 D41 D120\n",
      "error(0.001010783130056933663) D28 D31 D42 D120\n",
      "error(0.002876688512641980156) D28 D31 D52 D55 D65 D66 D120\n",
      "error(0.001535392182246036628) D28 D31 D52 D55 D120\n",
      "error(0.007953768324862837968) D28 D31 D65 D66 D120\n",
      "error(0.007044809191149375809) D28 D31 D120\n",
      "error(0.001010783130056933663) D28 D38 D41 D73 D97\n",
      "error(0.002665439999999999823) D28 D38 D73 D97\n",
      "error(0.002831414999999999887) D28 D40 D42 D76 D100\n",
      "error(0.001015965840252101588) D28 D40 D72 D96\n",
      "error(0.003678357090807468904) D28 D40 D76 D100\n",
      "error(0.003675989848273618615) D28 D41 D73 D97\n",
      "error(0.001018345769905341881) D28 D41 D77 D101\n",
      "error(0.002665439999999999823) D28 D42 D76 D100\n",
      "error(2.879825239673086635e-05) D28 D72 D96\n",
      "error(0.003860514276163778263) D28 D73 D97\n",
      "error(0.04580936623556411402) D28 D76 D100\n",
      "error(5.375075081862617642e-05) D28 D77 D101\n",
      "error(0.002876688512641980156) D29 D31 D41 D43 D65 D67 D120\n",
      "error(0.002024695128044953513) D29 D31 D41 D43 D120\n",
      "error(0.002035039432888804435) D29 D31 D53 D55 D65 D67 D120\n",
      "error(5.865671620409242679e-05) D29 D31 D53 D55 D120\n",
      "error(0.007953768324862837968) D29 D31 D65 D67 D120\n",
      "error(0.004254882737577601187) D29 D31 D120\n",
      "error(0.002035039432888804435) D29 D32 D43 D67 D120\n",
      "error(0.002029818995841314432) D29 D32 D43 D120\n",
      "error(0.002876688512641980156) D29 D32 D53 D56 D67 D120\n",
      "error(0.001535392182246036628) D29 D32 D53 D56 D120\n",
      "error(0.007953768324862837968) D29 D32 D67 D120\n",
      "error(0.006969606652586811564) D29 D32 D120\n",
      "error(0.003670834766484575885) D29 D39 D74 D98\n",
      "error(0.002831414999999999887) D29 D41 D43 D77 D101\n",
      "error(0.001015965840252101588) D29 D41 D73 D97\n",
      "error(0.003678357090807468904) D29 D41 D77 D101\n",
      "error(0.002665439999999999823) D29 D43 D77 D101\n",
      "error(2.879825239673086635e-05) D29 D73 D97\n",
      "error(0.004652365743471347306) D29 D74 D98\n",
      "error(0.04580936623556411402) D29 D77 D101\n",
      "error(5.375075081862617642e-05) D30\n",
      "error(0.004254882737577601187) D30 D33\n",
      "error(0.002024695128044953513) D30 D33 D44\n",
      "error(0.002876688512641980156) D30 D33 D44 D68\n",
      "error(5.865671620409242679e-05) D30 D33 D54 D57\n",
      "error(0.002035039432888804435) D30 D33 D54 D57 D68\n",
      "error(0.007953768324862837968) D30 D33 D68\n",
      "error(0.007044809191149375809) D30 D34\n",
      "error(0.002831414999999999887) D30 D34 D42\n",
      "error(0.001181603590391430226) D30 D34 D42 D44\n",
      "error(0.002035039432888804435) D30 D34 D42 D44 D66 D68\n",
      "error(0.001010783130056933663) D30 D34 D44\n",
      "error(0.001535392182246036628) D30 D34 D54 D58\n",
      "error(0.002876688512641980156) D30 D34 D54 D58 D66 D68\n",
      "error(0.007953768324862837968) D30 D34 D66 D68\n",
      "error(0.001010783130056933663) D30 D40 D42 D76 D100 D120\n",
      "error(0.002665439999999999823) D30 D40 D76 D100 D120\n",
      "error(0.003675989848273618615) D30 D42 D76 D100 D120\n",
      "error(0.001018345769905341881) D30 D42 D79 D103\n",
      "error(0.005481761066404799987) D30 D44 D78 D102\n",
      "error(5.375075081862617642e-05) D30 D54\n",
      "error(0.001044711783160383149) D30 D75 D99 D120\n",
      "error(0.003860514276163778263) D30 D76 D100 D120\n",
      "error(0.049158419805032251) D30 D78 D102\n",
      "error(5.375075081862617642e-05) D30 D79 D103\n",
      "error(5.375075081862617642e-05) D31\n",
      "error(0.004254882737577601187) D31 D34\n",
      "error(0.002024695128044953513) D31 D34 D42 D45\n",
      "error(0.002876688512641980156) D31 D34 D42 D45 D66 D69\n",
      "error(5.865671620409242679e-05) D31 D34 D55 D58\n",
      "error(0.002035039432888804435) D31 D34 D55 D58 D66 D69\n",
      "error(0.007953768324862837968) D31 D34 D66 D69\n",
      "error(0.007044809191149375809) D31 D35\n",
      "error(0.002831414999999999887) D31 D35 D43\n",
      "error(0.001181603590391430226) D31 D35 D43 D45\n",
      "error(0.002035039432888804435) D31 D35 D43 D45 D67 D69\n",
      "error(0.001010783130056933663) D31 D35 D45\n",
      "error(0.001535392182246036628) D31 D35 D55 D59\n",
      "error(0.002876688512641980156) D31 D35 D55 D59 D67 D69\n",
      "error(0.007953768324862837968) D31 D35 D67 D69\n",
      "error(0.001010783130056933663) D31 D41 D43 D77 D101 D120\n",
      "error(0.002665439999999999823) D31 D41 D77 D101 D120\n",
      "error(0.002831414999999999887) D31 D42 D45 D79 D103\n",
      "error(0.001015965840252101588) D31 D42 D76 D100 D120\n",
      "error(0.003678357090807468904) D31 D42 D79 D103\n",
      "error(0.003675989848273618615) D31 D43 D77 D101 D120\n",
      "error(0.001018345769905341881) D31 D43 D80 D104\n",
      "error(0.002665439999999999823) D31 D45 D79 D103\n",
      "error(5.375075081862617642e-05) D31 D55\n",
      "error(2.879825239673086635e-05) D31 D76 D100 D120\n",
      "error(0.003860514276163778263) D31 D77 D101 D120\n",
      "error(0.04580936623556411402) D31 D79 D103\n",
      "error(5.375075081862617642e-05) D31 D80 D104\n",
      "error(0.004254882737577601187) D32 D35\n",
      "error(0.002024695128044953513) D32 D35 D43\n",
      "error(0.002876688512641980156) D32 D35 D43 D67\n",
      "error(5.865671620409242679e-05) D32 D35 D56 D59\n",
      "error(0.002035039432888804435) D32 D35 D56 D59 D67\n",
      "error(0.007953768324862837968) D32 D35 D67\n",
      "error(0.001015965840252101588) D32 D43 D77 D101 D120\n",
      "error(0.006330146405388720893) D32 D43 D80 D104\n",
      "error(2.879825239673086635e-05) D32 D77 D101 D120\n",
      "error(0.04311536755819837807) D32 D80 D104\n",
      "error(0.007941192370062495967) D33\n",
      "error(0.004006327370131653257) D33 D44\n",
      "error(0.00288696689093221508) D33 D44 D68\n",
      "error(0.004519963676295111164) D33 D44 D78 D102\n",
      "error(0.001018345769905341881) D33 D44 D82 D106\n",
      "error(0.001433458058695054327) D33 D57\n",
      "error(0.003727176062222229119) D33 D57 D68\n",
      "error(0.007953768324862837968) D33 D68\n",
      "error(0.003803463737702784692) D33 D78 D102\n",
      "error(0.04891386968098601629) D33 D81 D105\n",
      "error(5.375075081862617642e-05) D33 D82 D106\n",
      "error(0.01466966287075303389) D34\n",
      "error(0.001010783130056933663) D34 D42 D45 D79 D103\n",
      "error(0.002665439999999999823) D34 D42 D79 D103\n",
      "error(0.002024695128044953513) D34 D44 D46\n",
      "error(0.003727176062222229119) D34 D44 D46 D68 D70\n",
      "error(0.002831414999999999887) D34 D44 D46 D82 D106\n",
      "error(0.001015965840252101588) D34 D44 D78 D102\n",
      "error(0.003678357090807468904) D34 D44 D82 D106\n",
      "error(0.002831414999999999887) D34 D45\n",
      "error(0.001181603590391430226) D34 D45 D46\n",
      "error(0.002035039432888804435) D34 D45 D46 D69 D70\n",
      "error(0.003675989848273618615) D34 D45 D79 D103\n",
      "error(0.001018345769905341881) D34 D45 D83 D107\n",
      "error(0.001010783130056933663) D34 D46\n",
      "error(0.002665439999999999823) D34 D46 D82 D106\n",
      "error(0.005091480207622429456) D34 D58\n",
      "error(0.00288696689093221508) D34 D58 D68 D70\n",
      "error(0.002876688512641980156) D34 D58 D69 D70\n",
      "error(0.007953768324862837968) D34 D68 D70\n",
      "error(0.007953768324862837968) D34 D69 D70\n",
      "error(2.879825239673086635e-05) D34 D78 D102\n",
      "error(0.003860514276163778263) D34 D79 D103\n",
      "error(0.04580936623556411402) D34 D82 D106\n",
      "error(5.375075081862617642e-05) D34 D83 D107\n",
      "error(0.01459562353802248275) D35\n",
      "error(0.003670834766484575885) D35 D43 D80 D104\n",
      "error(0.002024695128044953513) D35 D45 D47\n",
      "error(0.003727176062222229119) D35 D45 D47 D69 D71\n",
      "error(0.002831414999999999887) D35 D45 D47 D83 D107\n",
      "error(0.001015965840252101588) D35 D45 D79 D103\n",
      "error(0.003678357090807468904) D35 D45 D83 D107\n",
      "error(0.002029818995841314432) D35 D47\n",
      "error(0.002035039432888804435) D35 D47 D71\n",
      "error(0.002665439999999999823) D35 D47 D83 D107\n",
      "error(0.005091480207622429456) D35 D59\n",
      "error(0.00288696689093221508) D35 D59 D69 D71\n",
      "error(0.002876688512641980156) D35 D59 D71\n",
      "error(0.007953768324862837968) D35 D69 D71\n",
      "error(0.007953768324862837968) D35 D71\n",
      "error(2.879825239673086635e-05) D35 D79 D103\n",
      "error(0.004652365743471347306) D35 D80 D104\n",
      "error(0.04580936623556411402) D35 D83 D107\n",
      "error(0.04238874677572322669) D36\n",
      "error(0.001368504195195012051) D36 D38\n",
      "error(0.001535392182246036628) D36 D38 D60 D62\n",
      "error(0.00315388573601166778) D36 D60\n",
      "error(0.04234524506783991782) D37\n",
      "error(4.752677363723468355e-05) D37 D38\n",
      "error(5.865671620409242679e-05) D37 D38 D61 D62\n",
      "error(0.001368504195195012051) D37 D39\n",
      "error(0.001535392182246036628) D37 D39 D61 D63\n",
      "error(0.0458351796367094666) D38\n",
      "error(4.752677363723468355e-05) D38 D40\n",
      "error(5.865671620409242679e-05) D38 D40 D62 D64\n",
      "error(0.001444561076875621776) D38 D41\n",
      "error(0.001535392182246036628) D38 D41 D62 D65\n",
      "error(0.003848264352626754731) D38 D73 D97\n",
      "error(0.04774183183085162208) D39\n",
      "error(4.752677363723468355e-05) D39 D41\n",
      "error(5.865671620409242679e-05) D39 D41 D63 D65\n",
      "error(0.001593868776323137306) D39 D63\n",
      "error(0.003848264352626754731) D39 D74 D98\n",
      "error(0.04751821157447768534) D40\n",
      "error(0.001444561076875621776) D40 D42\n",
      "error(0.001535392182246036628) D40 D42 D64 D66\n",
      "error(0.005075694926858413322) D40 D64\n",
      "error(0.003848264352626754731) D40 D72 D76 D96 D100\n",
      "error(0.04588739754968995666) D41\n",
      "error(4.752677363723468355e-05) D41 D42\n",
      "error(5.865671620409242679e-05) D41 D42 D65 D66\n",
      "error(0.001444561076875621776) D41 D43\n",
      "error(0.001535392182246036628) D41 D43 D65 D67\n",
      "error(0.003848264352626754731) D41 D73 D77 D97 D101\n",
      "error(0.04588739754968995666) D42\n",
      "error(4.752677363723468355e-05) D42 D44\n",
      "error(5.865671620409242679e-05) D42 D44 D66 D68\n",
      "error(0.001444561076875621776) D42 D45\n",
      "error(0.001535392182246036628) D42 D45 D66 D69\n",
      "error(0.003848264352626754731) D42 D76 D79 D100 D103 D120\n",
      "error(0.04779383052518309388) D43\n",
      "error(4.752677363723468355e-05) D43 D45\n",
      "error(5.865671620409242679e-05) D43 D45 D67 D69\n",
      "error(0.001593868776323137306) D43 D67\n",
      "error(0.003848264352626754731) D43 D77 D80 D101 D104 D120\n",
      "error(0.04751821157447768534) D44\n",
      "error(0.001444561076875621776) D44 D46\n",
      "error(0.001433458058695054327) D44 D46 D68 D70\n",
      "error(0.001010783130056933663) D44 D46 D82 D106\n",
      "error(0.005018784120695379131) D44 D68\n",
      "error(0.003848264352626754731) D44 D78 D82 D102 D106\n",
      "error(0.002665439999999999823) D44 D82 D106\n",
      "error(0.04588739754968995666) D45\n",
      "error(4.752677363723468355e-05) D45 D46\n",
      "error(5.865671620409242679e-05) D45 D46 D69 D70\n",
      "error(0.001444561076875621776) D45 D47\n",
      "error(0.001433458058695054327) D45 D47 D69 D71\n",
      "error(0.001010783130056933663) D45 D47 D83 D107\n",
      "error(0.003848264352626754731) D45 D79 D83 D103 D107\n",
      "error(0.002665439999999999823) D45 D83 D107\n",
      "error(0.04648337918539993674) D46\n",
      "error(0.009170415199135256365) D46 D82 D106\n",
      "error(0.04680271058570958237) D47\n",
      "error(5.865671620409242679e-05) D47 D71\n",
      "error(0.009170415199135256365) D47 D83 D107\n",
      "error(0.007823344399498959392) D48\n",
      "error(4.752677363723468355e-05) D48 D51\n",
      "error(0.001181603590391430226) D48 D51 D64\n",
      "error(0.001444561076875621776) D48 D52\n",
      "error(0.002831414999999999887) D48 D52 D62\n",
      "error(0.002024695128044953513) D48 D52 D62 D64\n",
      "error(0.001010783130056933663) D48 D52 D64\n",
      "error(0.008316697338066831105) D48 D60\n",
      "error(0.002029818995841314432) D48 D60 D62\n",
      "error(0.003675989848273618615) D48 D62\n",
      "error(0.001018345769905341881) D48 D62 D73 D85 D97 D109\n",
      "error(0.005481761066404799987) D48 D64 D72 D84 D96 D108\n",
      "error(0.049158419805032251) D48 D72 D84 D96 D108\n",
      "error(5.375075081862617642e-05) D48 D73 D85 D97 D109\n",
      "error(0.005980737839138529355) D49\n",
      "error(4.752677363723468355e-05) D49 D52\n",
      "error(0.001181603590391430226) D49 D52 D62 D65\n",
      "error(0.001444561076875621776) D49 D53\n",
      "error(0.002831414999999999887) D49 D53 D63\n",
      "error(0.002024695128044953513) D49 D53 D63 D65\n",
      "error(0.001010783130056933663) D49 D53 D65\n",
      "error(0.006317584575443702458) D49 D61\n",
      "error(0.002024695128044953513) D49 D61 D62\n",
      "error(0.002029818995841314432) D49 D61 D63\n",
      "error(0.001864462904302397611) D49 D62\n",
      "error(0.002831414999999999887) D49 D62 D65 D73 D85 D97 D109\n",
      "error(0.003678357090807468904) D49 D62 D73 D85 D97 D109\n",
      "error(0.003675989848273618615) D49 D63\n",
      "error(0.001018345769905341881) D49 D63 D74 D86 D98 D110\n",
      "error(0.002665439999999999823) D49 D65 D73 D85 D97 D109\n",
      "error(0.04580936623556411402) D49 D73 D85 D97 D109\n",
      "error(5.375075081862617642e-05) D49 D74 D86 D98 D110\n",
      "error(0.001700936124048502921) D50\n",
      "error(4.752677363723468355e-05) D50 D53\n",
      "error(0.001181603590391430226) D50 D53 D63\n",
      "error(0.003721973364761755471) D50 D63\n",
      "error(0.006330146405388720893) D50 D63 D74 D86 D98 D110\n",
      "error(0.04311536755819837807) D50 D74 D86 D98 D110\n",
      "error(0.002452874174621053581) D51 D54\n",
      "error(0.004844644623733006597) D51 D54 D64\n",
      "error(0.004519963676295111164) D51 D64 D72 D84 D96 D108\n",
      "error(0.001018345769905341881) D51 D64 D76 D88 D100 D112\n",
      "error(0.003803463737702784692) D51 D72 D84 D96 D108\n",
      "error(0.04891386968098601629) D51 D75 D87 D99 D111\n",
      "error(5.375075081862617642e-05) D51 D76 D88 D100 D112\n",
      "error(4.752677363723468355e-05) D52 D54\n",
      "error(0.001181603590391430226) D52 D54 D64 D66\n",
      "error(0.001444561076875621776) D52 D55\n",
      "error(0.002831414999999999887) D52 D55 D65\n",
      "error(0.002024695128044953513) D52 D55 D65 D66\n",
      "error(0.001010783130056933663) D52 D55 D66\n",
      "error(0.001010783130056933663) D52 D62 D65 D73 D85 D97 D109\n",
      "error(0.002665439999999999823) D52 D62 D73 D85 D97 D109\n",
      "error(0.002831414999999999887) D52 D64 D66 D76 D88 D100 D112\n",
      "error(0.001015965840252101588) D52 D64 D72 D84 D96 D108\n",
      "error(0.003678357090807468904) D52 D64 D76 D88 D100 D112\n",
      "error(0.003675989848273618615) D52 D65 D73 D85 D97 D109\n",
      "error(0.001018345769905341881) D52 D65 D77 D89 D101 D113\n",
      "error(0.002665439999999999823) D52 D66 D76 D88 D100 D112\n",
      "error(2.879825239673086635e-05) D52 D72 D84 D96 D108\n",
      "error(0.003860514276163778263) D52 D73 D85 D97 D109\n",
      "error(0.04580936623556411402) D52 D76 D88 D100 D112\n",
      "error(5.375075081862617642e-05) D52 D77 D89 D101 D113\n",
      "error(4.752677363723468355e-05) D53 D55\n",
      "error(0.001181603590391430226) D53 D55 D65 D67\n",
      "error(0.001368504195195012051) D53 D56\n",
      "error(0.002871476899058759708) D53 D56 D67\n",
      "error(0.003670834766484575885) D53 D63 D74 D86 D98 D110\n",
      "error(0.002831414999999999887) D53 D65 D67 D77 D89 D101 D113\n",
      "error(0.001015965840252101588) D53 D65 D73 D85 D97 D109\n",
      "error(0.003678357090807468904) D53 D65 D77 D89 D101 D113\n",
      "error(0.002665439999999999823) D53 D67 D77 D89 D101 D113\n",
      "error(2.879825239673086635e-05) D53 D73 D85 D97 D109\n",
      "error(0.004652365743471347306) D53 D74 D86 D98 D110\n",
      "error(0.04580936623556411402) D53 D77 D89 D101 D113\n",
      "error(4.752677363723468355e-05) D54 D57\n",
      "error(0.001181603590391430226) D54 D57 D68\n",
      "error(0.001444561076875621776) D54 D58\n",
      "error(0.002831414999999999887) D54 D58 D66\n",
      "error(0.002024695128044953513) D54 D58 D66 D68\n",
      "error(0.001010783130056933663) D54 D58 D68\n",
      "error(0.001010783130056933663) D54 D64 D66 D76 D88 D100 D112\n",
      "error(0.002665439999999999823) D54 D64 D76 D88 D100 D112\n",
      "error(0.003675989848273618615) D54 D66 D76 D88 D100 D112\n",
      "error(0.001018345769905341881) D54 D66 D79 D91 D103 D115\n",
      "error(0.005481761066404799987) D54 D68 D78 D90 D102 D114\n",
      "error(0.001044711783160383149) D54 D75 D87 D99 D111\n",
      "error(0.003860514276163778263) D54 D76 D88 D100 D112\n",
      "error(0.049158419805032251) D54 D78 D90 D102 D114\n",
      "error(5.375075081862617642e-05) D54 D79 D91 D103 D115\n",
      "error(4.752677363723468355e-05) D55 D58\n",
      "error(0.001181603590391430226) D55 D58 D66 D69\n",
      "error(0.001444561076875621776) D55 D59\n",
      "error(0.002831414999999999887) D55 D59 D67\n",
      "error(0.002024695128044953513) D55 D59 D67 D69\n",
      "error(0.001010783130056933663) D55 D59 D69\n",
      "error(0.001010783130056933663) D55 D65 D67 D77 D89 D101 D113\n",
      "error(0.002665439999999999823) D55 D65 D77 D89 D101 D113\n",
      "error(0.002831414999999999887) D55 D66 D69 D79 D91 D103 D115\n",
      "error(0.001015965840252101588) D55 D66 D76 D88 D100 D112\n",
      "error(0.003678357090807468904) D55 D66 D79 D91 D103 D115\n",
      "error(0.003675989848273618615) D55 D67 D77 D89 D101 D113\n",
      "error(0.001018345769905341881) D55 D67 D80 D92 D104 D116\n",
      "error(0.002665439999999999823) D55 D69 D79 D91 D103 D115\n",
      "error(2.879825239673086635e-05) D55 D76 D88 D100 D112\n",
      "error(0.003860514276163778263) D55 D77 D89 D101 D113\n",
      "error(0.04580936623556411402) D55 D79 D91 D103 D115\n",
      "error(5.375075081862617642e-05) D55 D80 D92 D104 D116\n",
      "error(4.752677363723468355e-05) D56 D59\n",
      "error(0.001181603590391430226) D56 D59 D67\n",
      "error(0.001015965840252101588) D56 D67 D77 D89 D101 D113\n",
      "error(0.006330146405388720893) D56 D67 D80 D92 D104 D116\n",
      "error(2.879825239673086635e-05) D56 D77 D89 D101 D113\n",
      "error(0.04311536755819837807) D56 D80 D92 D104 D116\n",
      "error(0.002452874174621053581) D57\n",
      "error(0.004844644623733006597) D57 D68\n",
      "error(0.004519963676295111164) D57 D68 D78 D90 D102 D114\n",
      "error(0.001018345769905341881) D57 D68 D82 D94 D106 D118\n",
      "error(0.003803463737702784692) D57 D78 D90 D102 D114\n",
      "error(0.04891386968098601629) D57 D81 D93 D105 D117\n",
      "error(5.375075081862617642e-05) D57 D82 D94 D106 D118\n",
      "error(0.001491950539858244397) D58\n",
      "error(0.001010783130056933663) D58 D66 D69 D79 D91 D103 D115\n",
      "error(0.002665439999999999823) D58 D66 D79 D91 D103 D115\n",
      "error(0.001181603590391430226) D58 D68 D70\n",
      "error(0.002831414999999999887) D58 D68 D70 D82 D94 D106 D118\n",
      "error(0.001015965840252101588) D58 D68 D78 D90 D102 D114\n",
      "error(0.003678357090807468904) D58 D68 D82 D94 D106 D118\n",
      "error(0.002831414999999999887) D58 D69\n",
      "error(0.002024695128044953513) D58 D69 D70\n",
      "error(0.003675989848273618615) D58 D69 D79 D91 D103 D115\n",
      "error(0.001018345769905341881) D58 D69 D83 D95 D107 D119\n",
      "error(0.001010783130056933663) D58 D70\n",
      "error(0.002665439999999999823) D58 D70 D82 D94 D106 D118\n",
      "error(2.879825239673086635e-05) D58 D78 D90 D102 D114\n",
      "error(0.003860514276163778263) D58 D79 D91 D103 D115\n",
      "error(0.04580936623556411402) D58 D82 D94 D106 D118\n",
      "error(5.375075081862617642e-05) D58 D83 D95 D107 D119\n",
      "error(0.001415900887654034145) D59\n",
      "error(0.003670834766484575885) D59 D67 D80 D92 D104 D116\n",
      "error(0.001181603590391430226) D59 D69 D71\n",
      "error(0.002831414999999999887) D59 D69 D71 D83 D95 D107 D119\n",
      "error(0.001015965840252101588) D59 D69 D79 D91 D103 D115\n",
      "error(0.003678357090807468904) D59 D69 D83 D95 D107 D119\n",
      "error(0.002871476899058759708) D59 D71\n",
      "error(0.002665439999999999823) D59 D71 D83 D95 D107 D119\n",
      "error(2.879825239673086635e-05) D59 D79 D91 D103 D115\n",
      "error(0.004652365743471347306) D59 D80 D92 D104 D116\n",
      "error(0.04580936623556411402) D59 D83 D95 D107 D119\n",
      "error(0.04904909287488143366) D60\n",
      "error(0.006969606652586811564) D60 D62\n",
      "error(0.04234524506783991782) D61\n",
      "error(0.004254882737577601187) D61 D62\n",
      "error(0.006969606652586811564) D61 D63\n",
      "error(0.0458351796367094666) D62\n",
      "error(0.004254882737577601187) D62 D64\n",
      "error(0.007044809191149375809) D62 D65\n",
      "error(0.003848264352626754731) D62 D73 D85 D97 D109\n",
      "error(0.05658525658481455139) D63\n",
      "error(0.004254882737577601187) D63 D65\n",
      "error(0.003848264352626754731) D63 D74 D86 D98 D110\n",
      "error(0.05946520125734573031) D64\n",
      "error(0.007044809191149375809) D64 D66\n",
      "error(0.003848264352626754731) D64 D72 D76 D84 D88 D96 D100 D108 D112\n",
      "error(0.04588739754968995666) D65\n",
      "error(0.004254882737577601187) D65 D66\n",
      "error(0.007044809191149375809) D65 D67\n",
      "error(0.003848264352626754731) D65 D73 D77 D85 D89 D97 D101 D109 D113\n",
      "error(0.04588739754968995666) D66\n",
      "error(0.004254882737577601187) D66 D68\n",
      "error(0.007044809191149375809) D66 D69\n",
      "error(0.003848264352626754731) D66 D76 D79 D88 D91 D100 D103 D112 D115\n",
      "error(0.05663623850029493589) D67\n",
      "error(0.004254882737577601187) D67 D69\n",
      "error(0.003848264352626754731) D67 D77 D80 D89 D92 D101 D104 D113 D116\n",
      "error(0.05941454464120803081) D68\n",
      "error(0.006944001722500811775) D68 D70\n",
      "error(0.001010783130056933663) D68 D70 D82 D94 D106 D118\n",
      "error(0.003848264352626754731) D68 D78 D82 D90 D94 D102 D106 D114 D118\n",
      "error(0.002665439999999999823) D68 D82 D94 D106 D118\n",
      "error(0.04588739754968995666) D69\n",
      "error(0.004254882737577601187) D69 D70\n",
      "error(0.006944001722500811775) D69 D71\n",
      "error(0.001010783130056933663) D69 D71 D83 D95 D107 D119\n",
      "error(0.003848264352626754731) D69 D79 D83 D91 D95 D103 D107 D115 D119\n",
      "error(0.002665439999999999823) D69 D83 D95 D107 D119\n",
      "error(0.04648337918539993674) D70\n",
      "error(0.009170415199135256365) D70 D82 D94 D106 D118\n",
      "error(0.05061659774613071205) D71\n",
      "error(0.009170415199135256365) D71 D83 D95 D107 D119\n",
      "error(0.002093469798726521267) D72 D75 D84 D87 D96 D99 D108 D111\n",
      "error(0.01922651150468780712) D72 D75 D96 D99\n",
      "error(0.004403695449867173033) D72 D76 D84 D88 D96 D100 D108 D112\n",
      "error(0.01980840640617578113) D72 D76 D96 D100\n",
      "error(0.007221868154226087841) D72 D84 D96 D108\n",
      "error(0.03896848978193721835) D72 D96\n",
      "error(0.002093469798726521267) D73 D76 D85 D88 D97 D100 D109 D112\n",
      "error(0.01922651150468780712) D73 D76 D97 D100\n",
      "error(0.004403695449867173033) D73 D77 D85 D89 D97 D101 D109 D113\n",
      "error(0.01980840640617578113) D73 D77 D97 D101\n",
      "error(0.006478727241739520859) D73 D85 D97 D109\n",
      "error(0.03827322480354783396) D73 D97\n",
      "error(0.002093469798726521267) D74 D77 D86 D89 D98 D101 D110 D113\n",
      "error(0.01922651150468780712) D74 D77 D98 D101\n",
      "error(0.004403695449867173033) D74 D86 D98 D110\n",
      "error(0.01980840640617578113) D74 D98\n",
      "error(0.005149960930846266688) D75 D78 D87 D90 D99 D102 D111 D114\n",
      "error(0.02053147558014934218) D75 D78 D99 D102 D120\n",
      "error(0.002093469798726521267) D76 D78 D88 D90 D100 D102 D112 D114\n",
      "error(0.01922651150468780712) D76 D78 D100 D102 D120\n",
      "error(0.004403695449867173033) D76 D79 D88 D91 D100 D103 D112 D115\n",
      "error(0.01980840640617578113) D76 D79 D100 D103 D120\n",
      "error(0.002093469798726521267) D77 D79 D89 D91 D101 D103 D113 D115\n",
      "error(0.01922651150468780712) D77 D79 D101 D103 D120\n",
      "error(0.004403695449867173033) D77 D80 D89 D92 D101 D104 D113 D116\n",
      "error(0.01980840640617578113) D77 D80 D101 D104 D120\n",
      "error(0.002093469798726521267) D78 D81 D90 D93 D102 D105 D114 D117\n",
      "error(0.01922651150468780712) D78 D81 D102 D105\n",
      "error(0.004403695449867173033) D78 D82 D90 D94 D102 D106 D114 D118\n",
      "error(0.01980840640617578113) D78 D82 D102 D106\n",
      "error(0.002093469798726521267) D79 D82 D91 D94 D103 D106 D115 D118\n",
      "error(0.01922651150468780712) D79 D82 D103 D106\n",
      "error(0.004403695449867173033) D79 D83 D91 D95 D103 D107 D115 D119\n",
      "error(0.01980840640617578113) D79 D83 D103 D107\n",
      "error(0.002093469798726521267) D80 D83 D92 D95 D104 D107 D116 D119\n",
      "error(0.01922651150468780712) D80 D83 D104 D107\n",
      "error(0.006325905782176100521) D81 D93 D105 D117\n",
      "error(0.02167086832168945223) D81 D105\n",
      "error(0.01076529151742893278) D82 D94 D106 D118\n",
      "error(0.04228363247782022938) D82 D106\n",
      "error(0.01076529151742893278) D83 D95 D107 D119\n",
      "error(0.04228363247782022938) D83 D107\n",
      "error(0.003593262660715611841) D84 D87 D108 D111\n",
      "error(0.003593262660715611841) D84 D88 D108 D112\n",
      "error(0.007160702248333440309) D84 D108\n",
      "error(0.003593262660715611841) D85 D88 D109 D112\n",
      "error(0.003593262660715611841) D85 D89 D109 D113\n",
      "error(0.007160702248333440309) D85 D109\n",
      "error(0.003593262660715611841) D86 D89 D110 D113\n",
      "error(0.003593262660715611841) D86 D110\n",
      "error(0.003593262660715611841) D87 D90 D111 D114 D120\n",
      "error(0.003593262660715611841) D88 D90 D112 D114 D120\n",
      "error(0.003593262660715611841) D88 D91 D112 D115 D120\n",
      "error(0.003593262660715611841) D89 D91 D113 D115 D120\n",
      "error(0.003593262660715611841) D89 D92 D113 D116 D120\n",
      "error(0.003593262660715611841) D90 D93 D114 D117\n",
      "error(0.003593262660715611841) D90 D94 D114 D118\n",
      "error(0.003593262660715611841) D91 D94 D115 D118\n",
      "error(0.003593262660715611841) D91 D95 D115 D119\n",
      "error(0.003593262660715611841) D92 D95 D116 D119\n",
      "error(0.003593262660715611841) D93 D117\n",
      "error(0.007160702248333440309) D94 D118\n",
      "error(0.007160702248333440309) D95 D119\n",
      "final measurement_index = 146\n",
      "Preprocessing is done! it took 111.78s\n",
      "0 observables_errors_interactions_lists.shape = 10 and shape of first element: 1\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-24\n",
      "0 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "MLE decoder took 1.712902s.\n",
      "fidelity 0.5\n",
      "all_fidelities [0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "num_rounds = 3\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "num_cxs_per_rounds = [1, 3]\n",
    "num_shots = 10\n",
    "\n",
    "logical_error_rates = []\n",
    "for num_cxs_per_round in num_cxs_per_rounds:\n",
    "    num_CX_per_layer_list = [num_cxs_per_round,num_cxs_per_round,num_cxs_per_round]\n",
    "    for distance in [3,5]:\n",
    "        print(f\"distance = {distance}\")\n",
    "        print(f\"num_CX_per_layer_list = {num_CX_per_layer_list}\")\n",
    "        noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                        'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "                    'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "        Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                    'bias_preserving_gates': 'False',\n",
    "                    'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                    'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "                    'ordering': gate_ordering,\n",
    "                    'decoder': 'MLE',\n",
    "                    'circuit_type': f'logical_CX',\n",
    "                    'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                    'loss_decoder': 'independent',\n",
    "                    'obs_pos': 'd-1', 'n_r': '0', 'num_CX_per_layer_list':num_CX_per_layer_list}\n",
    "\n",
    "\n",
    "        # Load the experimental measurements\n",
    "        exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "        exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                        exp_measurements[:, 1, :distance**2-1],\n",
    "                                        exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                        exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                        exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                        exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "        measurement_events, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)\n",
    "        detection_events_signs = None\n",
    "\n",
    "        # Now let's decode!\n",
    "        use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "        use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "        use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "        output_dir = '.'\n",
    "        # DO IT\n",
    "        predictions, log_probabilities, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        measurement_events,\n",
    "                                                                        detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        logical_gaps=True, \n",
    "                                                                        noise_params=noise_params, num_shots=num_shots)\n",
    "\n",
    "\n",
    "        logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "\n",
    "        print('fidelity', 1-logical_probability)\n",
    "        logical_error_rates.append(1-logical_probability)\n",
    "\n",
    "        print('all_fidelities', logical_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]\n",
      " [15]\n",
      " [17]\n",
      " [19]\n",
      " [21]\n",
      " [23]\n",
      " [25]\n",
      " [27]\n",
      " [29]\n",
      " [31]\n",
      " [33]\n",
      " [35]\n",
      " [37]\n",
      " [39]]\n",
      "[3]\n",
      "logical_CX__Nlayers1__NCX3\n",
      "final measurement_index = 50\n",
      "logical_CX__Nlayers1__NCX3\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.04791151666368750894) D0\n",
      "error(0.02455889779263274383) D0 D3\n",
      "error(0.02455889779263274383) D0 D4\n",
      "error(0.04791151666368750894) D1\n",
      "error(0.02455889779263274383) D1 D4\n",
      "error(0.02455889779263274383) D1 D5\n",
      "error(0.02455889779263274383) D2\n",
      "error(0.02455889779263274383) D2 D5\n",
      "error(0.02455889779263274383) D3 D6 D12\n",
      "error(0.02455889779263274383) D4 D6 D12\n",
      "error(0.02455889779263274383) D4 D7 D12\n",
      "error(0.02455889779263274383) D5 D7 D12\n",
      "error(0.02455889779263274383) D5 D8 D12\n",
      "error(0.02455889779263274383) D6 D9\n",
      "error(0.02455889779263274383) D6 D10\n",
      "error(0.02455889779263274383) D7 D10\n",
      "error(0.02455889779263274383) D7 D11\n",
      "error(0.02455889779263274383) D8 D11\n",
      "error(0.02455889779263274383) D9\n",
      "error(0.04791151666368750894) D10\n",
      "error(0.04791151666368750894) D11\n",
      "final measurement_index = 50\n",
      "0 fidelity 0.96\n",
      "all_fidelities [0.96]\n",
      "[5]\n",
      "logical_CX__Nlayers1__NCX5\n",
      "final measurement_index = 50\n",
      "logical_CX__Nlayers1__NCX5\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.06466309401878500562) D0\n",
      "error(0.03345048173788937179) D0 D3\n",
      "error(0.03345048173788937179) D0 D4\n",
      "error(0.06466309401878500562) D1\n",
      "error(0.03345048173788937179) D1 D4\n",
      "error(0.03345048173788937179) D1 D5\n",
      "error(0.03345048173788937179) D2\n",
      "error(0.03345048173788937179) D2 D5\n",
      "error(0.03345048173788937179) D3 D6 D12\n",
      "error(0.03345048173788937179) D4 D6 D12\n",
      "error(0.03345048173788937179) D4 D7 D12\n",
      "error(0.03345048173788937179) D5 D7 D12\n",
      "error(0.03345048173788937179) D5 D8 D12\n",
      "error(0.03345048173788937179) D6 D9\n",
      "error(0.03345048173788937179) D6 D10\n",
      "error(0.03345048173788937179) D7 D10\n",
      "error(0.03345048173788937179) D7 D11\n",
      "error(0.03345048173788937179) D8 D11\n",
      "error(0.03345048173788937179) D9\n",
      "error(0.06466309401878500562) D10\n",
      "error(0.06466309401878500562) D11\n",
      "final measurement_index = 50\n",
      "0 fidelity 0.95\n",
      "all_fidelities [0.96, 0.95]\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "num_rounds = 1\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "num_cxs_per_rounds = [1, 3, 5, 7, 9, 11, 13, 15, 17]\n",
    "#[0.96, 0.9, 0.848, 0.798, 0.742, 0.677, 0.638]\n",
    "num_CX_per_layer_lists = [[i, i+1] for i in range(1, 20)]\n",
    "num_CX_per_layer_lists = np.array([np.arange(3, 21, 2)]).T\n",
    "\n",
    "num_CX_per_layer_lists = np.array([np.arange(3, 41, 2)]).T\n",
    "#num_CX_per_layer_lists = [[i, i+1] for i in range(1, 20)]\n",
    "#num_CX_per_layer_lists = [[i, i, i] for i in range(1, 17, 2)]\n",
    "print(num_CX_per_layer_lists)\n",
    "num_shots = 100\n",
    "#raise Exception\n",
    "logical_error_rates = []\n",
    "num_CX_per_layer_lists = num_CX_per_layer_lists[:2]\n",
    "for (index, num_CX_per_layer_list) in enumerate(num_CX_per_layer_lists):\n",
    "    noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                    'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "                'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "    print(num_CX_per_layer_list)\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                'bias_preserving_gates': 'False',\n",
    "                'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "                'ordering': gate_ordering,\n",
    "                'decoder': 'MLE',\n",
    "                'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "                   'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                'loss_decoder': 'independent',\n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "    # Load the experimental measurements\n",
    "    # exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "    # exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "    #                                 exp_measurements[:, 1, :distance**2-1],\n",
    "    #                                 exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "    #                                 exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "    #                                 exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "    #                                 exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "    simulated_measurement_events, simulated_detector_events, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params = noise_params)\n",
    "\n",
    "    # Now let's decode!\n",
    "    use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "    use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "    use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "    output_dir = '.'\n",
    "    #print(circuit)\n",
    "    #print(circuit.detector_error_model(approximate_disjoint_errors=True))\n",
    "    #circuit.logical_qubits[1].visualize_code()\n",
    "    #raise Exception\n",
    "    #raise Exception\n",
    "    # DO IT\n",
    "    predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        simulated_measurement_events,\n",
    "                                                                        None, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots=num_shots)\n",
    "\n",
    "    \"\"\"np.save('predictions_{}_{}'.format(3, index), predictions)\n",
    "    np.save('log_probabilities_{}_{}'.format(3, index), log_probabilities)\n",
    "    np.save('observable_flips_{}_{}'.format(3, index), observable_flips)\"\"\"\n",
    "    logical_probability = np.mean(np.logical_xor(observable_flips.flatten(), predictions.flatten()))\n",
    "\n",
    "    print('fidelity', 1-logical_probability)\n",
    "    logical_error_rates.append(1-logical_probability)\n",
    "\n",
    "    print('all_fidelities', logical_error_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]\n",
      " [15]\n",
      " [17]\n",
      " [19]]\n",
      "[5]\n",
      "logical_CX__Nlayers1__NCX5\n",
      "error(0.05979961699394466951) D0\n",
      "error(0.0308516316739152717) D0 D3\n",
      "error(0.0308516316739152717) D0 D4\n",
      "error(0.05979961699394466951) D1\n",
      "error(0.0308516316739152717) D1 D4\n",
      "error(0.0308516316739152717) D1 D5\n",
      "error(0.0308516316739152717) D2\n",
      "error(0.0308516316739152717) D2 D5\n",
      "error(0.0308516316739152717) D3 D6 L0\n",
      "error(0.0308516316739152717) D4 D6 L0\n",
      "error(0.0308516316739152717) D4 D7 L0\n",
      "error(0.0308516316739152717) D5 D7 L0\n",
      "error(0.0308516316739152717) D5 D8 L0\n",
      "error(0.0308516316739152717) D6 D9\n",
      "error(0.0308516316739152717) D6 D10\n",
      "error(0.0308516316739152717) D7 D10\n",
      "error(0.0308516316739152717) D7 D11\n",
      "error(0.0308516316739152717) D8 D11\n",
      "error(0.0308516316739152717) D9\n",
      "error(0.05979961699394466951) D10\n",
      "error(0.05979961699394466951) D11\n",
      "logical_CX__Nlayers1__NCX5\n",
      "final measurement_index = 50\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.05979962731993435782) D0\n",
      "error(0.03085163717643346973) D0 D3\n",
      "error(0.03085163717643346973) D0 D4\n",
      "error(0.05979962731993435782) D1\n",
      "error(0.03085163717643346973) D1 D4\n",
      "error(0.03085163717643346973) D1 D5\n",
      "error(0.03085163717643346973) D2\n",
      "error(0.03085163717643346973) D2 D5\n",
      "error(0.03085163717643346973) D3 D6 D12\n",
      "error(0.03085163717643346973) D4 D6 D12\n",
      "error(0.03085163717643346973) D4 D7 D12\n",
      "error(0.03085163717643346973) D5 D7 D12\n",
      "error(0.03085163717643346973) D5 D8 D12\n",
      "error(0.03085163717643346973) D6 D9\n",
      "error(0.03085163717643346973) D6 D10\n",
      "error(0.03085163717643346973) D7 D10\n",
      "error(0.03085163717643346973) D7 D11\n",
      "error(0.03085163717643346973) D8 D11\n",
      "error(0.03085163717643346973) D9\n",
      "error(0.05979962731993435782) D10\n",
      "error(0.05979962731993435782) D11\n",
      "final measurement_index = 50\n",
      "0 "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 0 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_53173/1016509139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#raise Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# DO IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     57\u001b[0m                                                                         \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                                                         \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     \u001b[0mreturn_matrix_with_observables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLE'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                     \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_errors_interactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dem_loss_mle_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasurement_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final_dem_hyperedges_matrix doesn't contain observables, only detectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m                     \u001b[0;31m# print(f'Total loss decoder time per shot is {time.time() - start_time:.4f}s.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_dem_loss_mle_experiment\u001b[0;34m(self, measurement_event, return_matrix_with_observables)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m11\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0;34m'independent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Independent decoder:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mstart_time_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_hyperedges_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# print(f'Summing over all relevant DEMs to generate the final DEM took {time.time() - start_time_ind:.5f}s')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0;34m(self, use_pre_processed_data, return_hyperedges_matrix, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mDEM_specific_loss_event_lil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_DEMs_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEMs_specific_loss_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_detectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProbs_specific_loss_event\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0mDEM_specific_loss_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEM_specific_loss_event_lil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mcombine_DEMs_sum\u001b[0;34m(self, DEMs_list, num_detectors, Probs_list)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern_to_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_detectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m             \u001b[0mnew_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m             \u001b[0mfinal_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mfinal_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 13 is out of bounds for axis 0 with size 13"
     ]
    }
   ],
   "source": [
    "# from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# num_rounds = 1\n",
    "# distance = 5\n",
    "# decoder_basis = 'XX'\n",
    "# gate_ordering = ['N', 'Z']\n",
    "# num_cxs_per_rounds = [1, 3, 5, 7, 9, 11, 13, 15, 17]\n",
    "# #[0.96, 0.9, 0.848, 0.798, 0.742, 0.677, 0.638]\n",
    "# num_CX_per_layer_lists = [[i, i+1] for i in range(1, 20)]\n",
    "# num_CX_per_layer_lists = np.array([np.arange(3, 21, 2)]).T\n",
    "# print(num_CX_per_layer_lists)\n",
    "# num_CX_per_layer_lists = [[5]]\n",
    "# #raise Exception\n",
    "# logical_error_rates = []\n",
    "# for num_CX_per_layer_list in num_CX_per_layer_lists:\n",
    "#     noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "#                     'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "#                 'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "#     print(num_CX_per_layer_list)\n",
    "#     Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "#                 'bias_preserving_gates': 'False',\n",
    "#                 'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "#                 'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "#                 'ordering': gate_ordering,\n",
    "#                 'decoder': 'MLE',\n",
    "#                 'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "#                 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "#                 'loss_decoder': 'independent',\n",
    "#                 'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "#     # Load the experimental measurements\n",
    "#     exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "#     exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "#                                     exp_measurements[:, 1, :distance**2-1],\n",
    "#                                     exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "#                                     exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "#                                     exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "#                                     exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "#     # Now let's decode!\n",
    "#     use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "#     use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "#     use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "#     output_dir = '.'\n",
    "#     simulate_data = True\n",
    "#     circuit = get_lossless_circuit(Meta_params, distance, distance, noise_params)\n",
    "#     print(circuit.detector_error_model(approximate_disjoint_errors=True))\n",
    "#     #raise Exception\n",
    "#     #raise Exception\n",
    "#     # DO IT\n",
    "#     predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "#                                                                         None,\n",
    "#                                                                         None, use_loss_decoding,\n",
    "#                                                                         use_independent_decoder,\n",
    "#                                                                         use_independent_and_first_comb_decoder,\n",
    "#                                                                         simulate_data=simulate_data, logical_gaps=False,\n",
    "#                                                                         noise_params=noise_params, num_shots=10)\n",
    "\n",
    "\n",
    "#     logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "\n",
    "#     print('fidelity', 1-logical_probability)\n",
    "#     logical_error_rates.append(1-logical_probability)\n",
    "\n",
    "#     print('all_fidelities', logical_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.000131129) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "X_ERROR(0.000131129) 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.00322009) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "DETECTOR rec[-50] rec[-49] rec[-25] rec[-24]\n",
      "DETECTOR rec[-48] rec[-47] rec[-23] rec[-22]\n",
      "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-25] rec[-24] rec[-20] rec[-19]\n",
      "DETECTOR rec[-49] rec[-48] rec[-44] rec[-43] rec[-24] rec[-23] rec[-19] rec[-18]\n",
      "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-23] rec[-22] rec[-18] rec[-17]\n",
      "DETECTOR rec[-47] rec[-46] rec[-42] rec[-41] rec[-22] rec[-21] rec[-17] rec[-16]\n",
      "DETECTOR rec[-46] rec[-41] rec[-21] rec[-16]\n",
      "DETECTOR rec[-45] rec[-40] rec[-20] rec[-15]\n",
      "DETECTOR rec[-45] rec[-44] rec[-40] rec[-39] rec[-20] rec[-19] rec[-15] rec[-14]\n",
      "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-19] rec[-18] rec[-14] rec[-13]\n",
      "DETECTOR rec[-43] rec[-42] rec[-38] rec[-37] rec[-18] rec[-17] rec[-13] rec[-12]\n",
      "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-17] rec[-16] rec[-12] rec[-11]\n",
      "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-15] rec[-14] rec[-10] rec[-9]\n",
      "DETECTOR rec[-39] rec[-38] rec[-34] rec[-33] rec[-14] rec[-13] rec[-9] rec[-8]\n",
      "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-13] rec[-12] rec[-8] rec[-7]\n",
      "DETECTOR rec[-37] rec[-36] rec[-32] rec[-31] rec[-12] rec[-11] rec[-7] rec[-6]\n",
      "DETECTOR rec[-36] rec[-31] rec[-11] rec[-6]\n",
      "DETECTOR rec[-35] rec[-30] rec[-10] rec[-5]\n",
      "DETECTOR rec[-35] rec[-34] rec[-30] rec[-29] rec[-10] rec[-9] rec[-5] rec[-4]\n",
      "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-9] rec[-8] rec[-4] rec[-3]\n",
      "DETECTOR rec[-33] rec[-32] rec[-28] rec[-27] rec[-8] rec[-7] rec[-3] rec[-2]\n",
      "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-7] rec[-6] rec[-2] rec[-1]\n",
      "DETECTOR rec[-29] rec[-28] rec[-4] rec[-3]\n",
      "DETECTOR rec[-27] rec[-26] rec[-2] rec[-1]\n",
      "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n"
     ]
    }
   ],
   "source": [
    "print(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 2],\n",
       "       [0, 1, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 2, 0, 1],\n",
       "       [1, 1, 0, ..., 0, 1, 1],\n",
       "       [1, 1, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theory measu events out:\n",
    "observable_flips.shape\n",
    "predictions.shape\n",
    "# 1 - logical error 0.085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## all theory:\n",
    "observable_flips.shape\n",
    "predictions.shape\n",
    "# 1 - logical error 0.105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### experiment:\n",
    "observable_flips.shape\n",
    "predictions.shape\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips.astype(int), predictions.astype(int)))\n",
    "logical_probability\n",
    "# observable_flips.astype(int)\n",
    "# predictions\n",
    "# 1 - logical error 0.815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93,  77,  80,  74,  71,  65,  87,  79,  87,  86,  71,  73,  67,\n",
       "        76,  68,  82,  72,  70,  86,  61,  76,  80,  91,  88,  77,  80,\n",
       "        87,  68,  75,  71,  78,  84,  72,  80,  81,  74,  87,  72,  68,\n",
       "        70,  81,  75,  90,  83,  85,  66,  80,  77,  75,  70,  68,  80,\n",
       "        78,  73,  77,  83,  74,  72,  86,  78,  66,  75,  83,  69,  81,\n",
       "        80,  66,  76,  73,  72,  76,  76,  80,  70,  65,  81,  77,  80,\n",
       "        79,  82,  74,  86,  74,  71,  73,  78,  71,  74,  87,  77,  69,\n",
       "        83,  79,  87,  68,  82,  75,  66,  78,  80,  70,  72,  78,  69,\n",
       "        74,  83,  66,  79,  78,  60,  73,  74,  82,  79,  75,  85,  84,\n",
       "        77,  79,  67,  73,  85,  80,  80,  74,  79,  82,  79,  79,  72,\n",
       "        89,  73,  76,  82,  93,  74,  69,  77,  84,  81,  73,  80,  83,\n",
       "        82,  92,  77,  90,  64,  98,  79,  88,  80,  88,  64,  77,  73,\n",
       "        85,  81,  87,  67,  63,  86,  83,  72,  76,  74,  85,  74,  76,\n",
       "        78,  81,  72,  90,  76,  71,  85,  72,  66,  74,  86,  83,  74,\n",
       "        71,  79,  83,  85,  69,  89,  69,  74,  76,  84,  75,  72,  72,\n",
       "        79,  74,  74,  84,  77,  79,  66,  71,  80,  82,  88,  87,  77,\n",
       "        67,  66,  77,  68,  74,  82,  83,  78,  68,  75,  77,  78,  68,\n",
       "        77,  78,  64,  74,  72,  67,  71,  80,  78,  78,  79,  80,  82,\n",
       "        69,  68,  83,  75,  79,  88,  74,  91,  85,  86,  80,  79,  75,\n",
       "        82,  76,  70,  79,  87,  82,  69,  67,  73,  75,  81,  70,  72,\n",
       "        66,  84,  84,  80,  74,  86,  81,  75,  62,  77,  74,  74,  77,\n",
       "        86,  82,  75,  75,  82,  73,  86,  78,  72,  82,  78,  63,  72,\n",
       "        89,  73,  81,  79,  68,  92,  67,  69,  77,  64,  76,  73,  87,\n",
       "        86,  71,  85,  68,  64,  59,  75,  80,  75,  82,  81,  74,  83,\n",
       "        90,  85,  91,  62,  72,  73,  83,  85,  76,  88,  75,  86,  80,\n",
       "        80,  81,  76,  79,  72,  86,  73,  80,  83,  57,  68,  92,  89,\n",
       "        72,  75,  74,  80,  85,  82,  75,  71,  80,  71,  77,  73,  88,\n",
       "        73,  70,  83,  86,  86,  79,  93,  77,  77,  79,  74,  75,  84,\n",
       "        85,  73,  71,  71,  76,  82,  73,  88,  88,  73,  71,  79,  86,\n",
       "        85,  72,  80,  72,  73,  78,  66,  70,  79,  71,  86,  65,  72,\n",
       "        82,  78,  86,  83,  70,  80,  69,  69,  83,  63,  88,  71,  91,\n",
       "        77,  72,  81,  85,  66,  91,  77,  74,  63,  82,  88,  79,  78,\n",
       "        78,  67,  84,  83,  80,  89,  82,  89,  76,  75,  69,  75,  71,\n",
       "        69,  78,  74,  80,  60,  79,  95,  81,  83,  74,  81,  71,  87,\n",
       "        86,  79,  81,  71,  83,  76,  76,  75,  87,  83,  83,  75,  70,\n",
       "        74,  80,  86,  75,  85,  82,  84,  72,  88,  79,  77,  87,  72,\n",
       "        68,  78,  80,  85,  67,  82,  82,  71,  84,  81,  72,  77,  73,\n",
       "        78,  76,  85,  82,  88,  88,  69,  75,  68,  69,  79,  78,  80,\n",
       "        75,  68,  77,  68,  80,  68,  81,  75,  81,  61,  76,  72,  78,\n",
       "        66,  72,  80,  88,  86,  76,  73,  73,  80,  77,  74,  85,  83,\n",
       "        81,  75,  87,  83,  91,  79,  74,  76,  78,  78,  80,  79,  87,\n",
       "        65,  85,  77,  74,  87,  79,  63,  68,  86,  88,  74,  79,  69,\n",
       "        73,  73,  79,  84,  90,  80,  81,  74,  77,  73,  68,  66,  70,\n",
       "        60,  85,  81,  80,  88,  87,  69,  79,  78,  78,  82,  79,  73,\n",
       "        81,  71,  75,  78,  82,  89,  83,  86,  74,  75,  83,  77,  77,\n",
       "        73,  72,  79,  84,  80,  79,  87,  74,  79,  88,  67,  86,  61,\n",
       "        65,  73,  74,  81,  77,  69,  77,  77,  83,  76,  83,  74,  70,\n",
       "        71,  80,  68,  85,  69,  84,  82,  72,  68,  77,  81,  70,  84,\n",
       "        61,  78,  81,  74,  77,  76,  74,  85,  81,  73,  67,  85,  81,\n",
       "        79,  84,  93,  66,  76,  77,  89,  77,  62,  81,  72,  75,  74,\n",
       "        75,  81,  58,  77,  90,  79,  85,  82,  82,  77,  71,  89,  78,\n",
       "        73,  76,  79,  69,  75,  89,  71,  83,  79,  72,  77,  86,  81,\n",
       "        82,  82,  86,  79,  71,  89,  83,  79,  77,  70,  80,  85,  84,\n",
       "        71,  85,  84,  86,  65,  67,  90,  86,  71,  80,  85,  71,  78,\n",
       "        86,  72,  78,  85,  92,  61,  74,  73,  73,  71,  82,  97,  80,\n",
       "        71,  69,  81,  70,  91,  82,  75,  65,  79,  71,  63,  77,  86,\n",
       "        85,  72,  74,  72,  92,  64,  65,  74,  70,  81,  86,  62,  62,\n",
       "        80,  61,  70,  70,  75,  76,  75,  84,  70,  77,  74,  98,  89,\n",
       "        83,  80,  70,  66,  87,  65,  78,  87,  77,  80,  83,  56,  78,\n",
       "        75,  86,  68,  84,  93,  88,  77,  73,  77,  86,  78,  83,  71,\n",
       "        84,  77,  82,  78,  90,  83,  82,  75,  90,  87,  66,  62,  76,\n",
       "        77,  77,  73,  71,  72,  79,  85,  73,  78,  78,  84,  85,  88,\n",
       "        76,  79,  67,  82,  85,  81,  75,  68,  86,  73,  85,  66,  90,\n",
       "        81,  75,  75,  65,  77,  80,  75,  64,  79,  77,  73,  60,  76,\n",
       "        85,  60,  77,  74,  79,  66,  85,  62,  83,  68,  71,  81,  77,\n",
       "        82,  78,  77,  71,  75,  76,  72,  75,  76,  70,  68,  68,  69,\n",
       "        81,  71,  75,  84,  81,  87,  77,  70,  71,  77,  75,  78,  81,\n",
       "        79,  78,  79,  89,  65,  84,  79,  70,  79,  73,  84,  74,  77,\n",
       "        83,  77,  76,  80,  80,  83,  78,  74,  94,  77,  81,  62,  89,\n",
       "        85,  75,  79,  72,  68,  74,  77,  62,  74,  71,  73,  77,  81,\n",
       "        74,  75,  74,  67,  64,  74,  90,  79,  81,  87,  71,  83,  78,\n",
       "        67,  74,  77,  84,  61,  67,  80,  81,  89,  76,  73,  79,  74,\n",
       "        71,  73,  70,  83,  81,  72,  75,  77,  67,  78,  80,  82,  64,\n",
       "        82,  70,  88,  76,  81,  74,  78,  91,  83, 101,  79,  58,  79,\n",
       "        86,  60,  85,  70,  78,  74,  77,  84,  77,  66,  84,  78,  69,\n",
       "        84,  83,  66,  84,  83,  69,  77,  89,  80,  72,  83,  78,  85,\n",
       "        93,  80,  79,  88,  73,  75,  68,  71,  74,  73,  82,  68])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theory:\n",
    "np.sum(measurement_events,axis=1)\n",
    "# 1 - logical error 0.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72, 66, 75, 84, 78, 84, 65, 87, 79, 90, 76, 80, 77, 89, 73, 72, 76,\n",
       "       73, 88, 71, 71, 77, 93, 68, 76, 74, 75, 75, 72, 67, 75, 90, 82, 77,\n",
       "       88, 83, 80, 75, 76, 77, 89, 80, 72, 86, 84, 84, 83, 85, 88, 80, 84,\n",
       "       70, 70, 83, 70, 72, 75, 85, 85, 79, 95, 80, 74, 82, 72, 76, 83, 79,\n",
       "       78, 77, 81, 61, 91, 71, 77, 76, 77, 64, 68, 85, 87, 73, 86, 71, 84,\n",
       "       77, 74, 77, 80, 77, 89, 64, 74, 72, 73, 74, 78, 74, 70, 76, 62, 70,\n",
       "       85, 82, 78, 93, 84, 75, 80, 78, 79, 79, 79, 70, 84, 70, 70, 69, 88,\n",
       "       83, 81, 67, 77, 73, 76, 83, 81, 76, 66, 82, 79, 73, 74, 79, 80, 74,\n",
       "       77, 69, 79, 81, 79, 79, 91, 75, 82, 87, 75, 74, 80, 85, 91, 83, 70,\n",
       "       90, 89, 70, 90, 83, 87, 75, 75, 87, 73, 85, 74, 85, 83, 84, 82, 66,\n",
       "       74, 72, 71, 72, 95, 65, 76, 77, 84, 77, 67, 69, 78, 71, 66, 81, 69,\n",
       "       82, 69, 80, 88, 93, 86, 75, 77, 74, 86, 73, 80, 87, 79, 76, 82, 82,\n",
       "       65, 69, 74, 74, 77, 74, 71, 84, 81, 79, 77, 69, 79, 85, 73, 69, 87,\n",
       "       79, 82, 89, 86, 69, 83, 69, 81, 80, 80, 81, 67, 72, 74, 74, 84, 79,\n",
       "       71, 84, 83, 74, 82, 77, 90, 84, 72, 82, 88, 83, 90, 79, 85, 65, 89,\n",
       "       79, 79, 76, 85, 78, 87, 76, 76, 76, 87, 87, 74, 86, 84, 86, 83, 82,\n",
       "       85, 74, 82, 80, 85, 80, 70, 77, 84, 73, 90, 74, 64, 86, 68, 92, 83,\n",
       "       75, 79, 75, 83, 79, 73, 74, 78, 80, 72, 83, 75, 83, 67, 70, 82, 73,\n",
       "       69, 71, 80, 91, 62, 68, 80, 60, 75, 76, 91, 75, 79, 74, 91, 84, 63,\n",
       "       84, 72, 89, 77, 72, 74, 73, 66, 85, 67, 84, 65, 88, 76, 93, 65, 85,\n",
       "       79, 80, 83, 78, 71, 77, 87, 97, 67, 68, 78, 83, 84, 73, 78, 92, 85,\n",
       "       85, 84, 71, 88, 77, 88, 71, 79, 72, 90, 83, 64, 75, 78, 67, 77, 76,\n",
       "       73, 82, 80, 78, 86, 80, 71, 68, 90, 79, 70, 76, 71, 91, 70, 86, 84,\n",
       "       76, 85, 79, 75, 67, 83, 81, 78, 85, 86, 70, 63, 80, 72, 83, 81, 75,\n",
       "       71, 80, 81, 75, 87, 77, 71, 73, 84, 68, 83, 70, 81, 70, 71, 77, 85,\n",
       "       84, 73, 87, 77, 78, 78, 81, 76, 64, 85, 76, 87, 77, 66, 87, 74, 93,\n",
       "       70, 68, 81, 88, 76, 92, 81, 79, 80, 81, 79, 82, 77, 84, 77, 70, 85,\n",
       "       83, 70, 72, 77, 82, 88, 77, 76, 68, 81, 67, 82, 77, 81, 65, 62, 81,\n",
       "       84, 86, 69, 79, 66, 80, 75, 79, 80, 86, 82, 85, 78, 79, 88, 73, 79,\n",
       "       80, 74, 68, 73, 76, 76, 65, 73, 81, 76, 78, 75, 75, 83, 77, 91, 80,\n",
       "       69, 80, 84, 80, 74, 80, 80, 89, 80, 77, 87, 81, 78, 83, 97, 71, 82,\n",
       "       88, 96, 75, 85, 67, 87, 80, 73, 65, 71, 86, 81, 76, 72, 58, 77, 76,\n",
       "       79, 83, 85, 81, 68, 82, 79, 73, 83, 77, 75, 85, 78, 81, 83, 75, 76,\n",
       "       73, 83, 67, 83, 89, 79, 66, 79, 72, 67, 81, 89, 63, 74, 84, 85, 66,\n",
       "       86, 80, 83, 83, 68, 81, 81, 81, 70, 85, 69, 62, 79, 67, 87, 71, 90,\n",
       "       71, 72, 82, 75, 73, 83, 74, 90, 78, 72, 82, 86, 74, 74, 85, 63, 73,\n",
       "       86, 59, 79, 76, 76, 78, 61, 87, 69, 69, 86, 86, 74, 67, 80, 80, 61,\n",
       "       71, 74, 69, 78, 89, 90, 71, 74, 80, 72, 76, 63, 79, 83, 82, 79, 87,\n",
       "       78, 79, 68, 76, 85, 73, 76, 87, 83, 90, 88, 80, 74, 87, 66, 71, 67,\n",
       "       90, 69, 74, 65, 93, 80, 78, 72, 74, 89, 74, 79, 69, 67, 81, 78, 86,\n",
       "       86, 73, 70, 79, 84, 82, 78, 89, 86, 81, 67, 68, 82, 76, 89, 77, 84,\n",
       "       82, 82, 73, 78, 77, 79, 64, 88, 70, 80, 86, 62, 77, 78, 70, 86, 88,\n",
       "       67, 78, 74, 81, 75, 85, 80, 78, 75, 67, 85, 72, 79, 73, 77, 86, 80,\n",
       "       84, 83, 85, 83, 68, 82, 81, 86, 80, 76, 81, 82, 73, 73, 77, 80, 81,\n",
       "       79, 73, 80, 73, 68, 67, 76, 74, 86, 77, 84, 71, 65, 72, 90, 79, 72,\n",
       "       78, 75, 67, 75, 79, 70, 83, 69, 75, 77, 80, 79, 77, 91, 85, 72, 89,\n",
       "       89, 75, 82, 79, 66, 72, 85, 77, 74, 83, 76, 78, 81, 73, 80, 70, 76,\n",
       "       76, 77, 75, 84, 89, 78, 71, 88, 74, 79, 82, 82, 74, 79, 79, 83, 90,\n",
       "       83, 75, 77, 87, 82, 73, 87, 76, 92, 80, 79, 78, 75, 85, 78, 84, 75,\n",
       "       75, 69, 84, 79, 93, 77, 81, 73, 79, 71, 72, 79, 85, 86, 88, 76, 68,\n",
       "       81, 86, 67, 77, 71, 88, 90, 81, 88, 82, 75, 80, 80, 75, 91, 79, 90,\n",
       "       73, 76, 88, 72, 81, 88, 71, 91, 81, 74, 82, 73, 84, 64, 66, 77, 81,\n",
       "       82, 74, 72, 79, 67, 76, 74, 69, 78, 84, 84, 79, 75, 74, 81, 86, 76,\n",
       "       79, 81, 67, 76, 85, 81, 80, 81, 80, 67, 91, 90, 78, 79, 82, 86, 70,\n",
       "       74, 68, 93, 78, 80, 83, 76, 74, 85, 81, 72, 71, 78, 83, 79, 77, 83,\n",
       "       70, 82, 92, 84, 80, 75, 78, 86, 74, 80, 79, 68, 90, 72, 67, 84, 77,\n",
       "       67, 74, 82, 76, 83, 77, 77, 75, 81, 80, 82, 68, 72, 77, 84, 80, 81,\n",
       "       72, 76, 87, 85, 70, 71, 79, 78, 73, 87, 77, 82, 72, 83, 76, 88, 74,\n",
       "       81, 65, 79, 78, 84, 77, 66, 87, 76, 90, 81, 82, 88, 78])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment:\n",
    "np.sum(measurement_events,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 2, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 146)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  8,  3,  6,  5,  4,  6,  5,  6,  8,  8,  2,  8,  6, 10,  6,  4,\n",
       "        5,  3,  4,  2,  6,  7,  5,  5,  3,  4,  5,  6,  3,  6,  7,  8,  6,\n",
       "        8,  2,  7,  7, 11,  6,  7,  5,  4,  6,  2,  5,  5,  8,  4,  5,  8,\n",
       "        6,  8,  4,  1,  1,  3,  3,  5,  9,  3,  5,  2,  5,  3,  4,  2,  1,\n",
       "        8,  7,  6,  7,  3,  2,  7,  4,  3,  5,  6,  5,  4,  7,  3,  7,  7,\n",
       "        3,  6,  3,  2,  5,  5,  5,  3,  4,  8,  8,  4,  6,  7,  7,  5,  4,\n",
       "        3,  5,  4,  7,  5,  8,  4,  5,  4,  6,  2,  5,  4,  6,  7,  7,  6,\n",
       "        5,  8,  7,  7,  4,  5,  5,  2,  6,  6,  5,  8,  6,  8,  4,  4,  6,\n",
       "        3,  8,  6,  5, 11,  9,  7,  6,  8,  7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exp_measurements[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510911424903723"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n 1 - logical error 0.14890885750962768\n"
     ]
    }
   ],
   "source": [
    "print('/n 1 - logical error',1- logical_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "hi\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "x = 4\n",
    "num_CX_per_layer = 2*x + 1\n",
    "for cx_ix in range(num_CX_per_layer):\n",
    "    print(cx_ix)\n",
    "    if cx_ix == num_CX_per_layer // 2 : # new GB - add Y pulse on all qubits:\n",
    "        print('hi')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "dict_data = {1: [1, 2], 3: [3, 4]}\n",
    "qubits_to_exclude = [q for sublist in dict_data.values() for q in sublist]\n",
    "print(qubits_to_exclude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_layers = 20\n",
    "num_cxs_per_round = 0\n",
    "circuit_type = f'logical_CX_NL{num_layers}_NCX{num_cxs_per_round}'\n",
    "num_layers, num_cxs_per_round = map(int, re.findall(r'\\d+', circuit_type))\n",
    "print(num_layers)\n",
    "print(num_cxs_per_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9553333333333334"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_16894/3841985880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# DO IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     66\u001b[0m                                                                     \u001b[0mexp_measurements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                                                                     \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mreturn_matrix_with_observables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLE'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_errors_interactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dem_loss_mle_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasurement_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final_dem_hyperedges_matrix doesn't contain observables, only detectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0;31m# print(f'Total loss decoder time per shot is {time.time() - start_time:.4f}s.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_dem_loss_mle_experiment\u001b[0;34m(self, measurement_event, return_matrix_with_observables)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m11\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0;34m'independent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Independent decoder:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mstart_time_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_hyperedges_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# print(f'Summing over all relevant DEMs to generate the final DEM took {time.time() - start_time_ind:.5f}s')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0;34m(self, use_pre_processed_data, return_hyperedges_matrix, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;31m# sum over all loss DEMs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0mfinal_hyperedges_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_DEMs_high_order_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEMs_loss_pauli_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_detectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProbs_loss_pauli_events\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# GB: new Probs_loss_pauli_events. TODO: change this function to also get Probs_loss_pauli_events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m         \u001b[0;31m# print(f'New method: Time to sum over all DEMS (independent, combination, Pauli) with high order equation: {time.time() - start_time:.4f}s.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mcombine_DEMs_high_order_csr\u001b[0;34m(self, DEMs_list, num_detectors, Probs_list)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0mfinal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0mprob_i_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0;31m# Consider terms where 3 specific events happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0mfinal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0mprob_i_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0;31m# Consider terms where 3 specific events happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3086\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m     \"\"\"\n\u001b[0;32m-> 3088\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3089\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     71\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     71\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0madditional_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mpydev_step_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_step_cmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0mis_stepping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydev_step_cmd\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydb_disposed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_rounds = 3\n",
    "num_cx = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                    'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                    'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                    'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                    'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                    'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                    'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': f'logical_CX_NL{num_rounds}_NCX{num_cx}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "simulate_data = True\n",
    "\n",
    "if simulate_data:\n",
    "    detection_events_signs = None\n",
    "    exp_measurements = None\n",
    "    num_shots = 1000\n",
    "\n",
    "else:\n",
    "    # Load the theory circuit\n",
    "    _, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "    # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "    detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "    # Find detection event signs\n",
    "    detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "    exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '.'\n",
    "# DO IT\n",
    "predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                    exp_measurements,\n",
    "                                                                    detection_events_signs, use_loss_decoding,\n",
    "                                                                    use_independent_decoder,\n",
    "                                                                    use_independent_and_first_comb_decoder,\n",
    "                                                                    simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                    noise_params=noise_params, num_shots=num_shots)\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "print('/n logical error', logical_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299999999999999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta_params['printing'] = 'False'\n",
    "\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "print(circuit.num_detectors)\n",
    "print(\"HI\")\n",
    "print(circuit.detector_error_model(approximate_disjoint_errors=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a plot of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtDklEQVR4nO3deViUVfsH8O+wI8iuLIIs7vuCG+4rqL0uaWVlqZmVPy1FssWsNHvLtHo1K61MLVvUUiozTXHNXUFxRdxASSFUFFxBhvP74zQjw8zADMwGfD/X9Vwz88yZ57mHbW7OOc+5FUIIASIiIqJqxM7aARARERFZGhMgIiIiqnaYABEREVG1wwSIiIiIqh0mQERERFTtMAEiIiKiaocJEBEREVU7DtYOwBYVFRXh8uXLqFmzJhQKhbXDISIiIgMIIXDz5k0EBQXBzq70Ph4mQDpcvnwZISEh1g6DiIiIyiEjIwPBwcGltmECpEPNmjUByC+gh4eHlaMhIiIiQ+Tl5SEkJET9OV4aJkA6qIa9PDw8mAARERFVMoZMX+EkaCIiIqp2mAARERFRtcMEiIiIiKodzgEiIqoGioqKUFBQYO0wiCrMycmpzEvcDcEEiIioiisoKEBaWhqKioqsHQpRhdnZ2SE8PBxOTk4VOg4TICKiKkwIgczMTNjb2yMkJMQk/zkTWYtqoeLMzEzUrVu3QosVMwEiIqrCCgsLcefOHQQFBaFGjRrWDoeowmrVqoXLly+jsLAQjo6O5T4O/xUgIqrClEolAFR4uIDIVqh+llU/2+XFBIiIqBpgXUOqKkz1s8whMAtSKoGdO4HMTCAwEOjWDbC3t3ZURERE1Q8TIAuJjwcmTwb+/vvBvuBg4JNPgGHDrBcXERFRdcQhMAuIjwceeUQz+QGAS5fk/vh468RFRGQopRLYvh1YsULeVnD6RZmEEHj++efh4+MDhUKB5ORk856wAk6dOoVOnTrBxcUFrVu3tnY4OoWFhWH+/PnWDsOmWD0BWrhwIcLDw+Hi4oLIyEjs3Lmz1PY7duxAZGQkXFxcEBERgS+++EKrzY0bNzBx4kQEBgbCxcUFTZo0wfr16831FkqlVMqeHyG0n1Pti401/x8TIqLyio8HwsKAXr2AJ5+Ut2Fh5v3n7c8//8Q333yDdevWITMzE82bNzffySpoxowZcHNzQ2pqKrZs2WLtcMhAVk2AVq1ahdjYWEyfPh2HDx9Gt27dMGDAAFy8eFFn+7S0NAwcOBDdunXD4cOH8cYbb2DSpElYs2aNuk1BQQH69euH9PR0rF69GqmpqVi8eDHq1KljqbelYedO7Z6f4oQAMjJkOyIiW2OtHuxz584hMDAQnTt3RkBAABwcbHfGxrlz59C1a1eEhobC19e3XMfgKt1WIKyoQ4cOYvz48Rr7GjduLF5//XWd7V999VXRuHFjjX0vvPCC6NSpk/rxokWLREREhCgoKCh3XLm5uQKAyM3NLfcxVH78UQiZ5pS+/fhjhU9FRKTl7t274uTJk+Lu3btCCCGKioS4dcuwLTdXiDp19P/dUiiECA6W7Qw5XlGRYTGPHj1aAFBvoaGhQgghNmzYILp06SI8PT2Fj4+PeOihh8TZs2fVr0tLSxMAxJo1a0TPnj2Fq6uraNmypdizZ4/G8Xft2iW6d+8uXF1dhZeXl4iOjhY5OTni22+/FT4+PuLevXsa7YcNGyaefvppnbEWjxOAmDFjhhBCiKNHj4pevXoJFxcX4ePjI5577jlx8+ZNjfc4ZMgQ8f7774vAwEARGhqqjn/VqlWia9euwsXFRbRr106kpqaKAwcOiMjISOHm5iZiYmJEdna2+lg9evQQkydP1ohryJAhYvTo0erHoaGhYt68eerHH3/8sWjevLmoUaOGCA4OFv/3f/+nEZ8tK/kzXZwxn99W6wEqKChAUlISoqOjNfZHR0djz549Ol+zd+9erfYxMTFITEzE/fv3AQBr165FVFQUJk6cCH9/fzRv3hzvv/9+qesF5OfnIy8vT2MzlcBA07YjIqqIO3cAd3fDNk9P2dOjjxCyZ8jT07Dj3bljWIyffPIJZs2aheDgYGRmZuLgwYMAgNu3byMuLg4HDx7Eli1bYGdnh4cfflirxMf06dMxdepUJCcno2HDhnjiiSdQWFgIAEhOTkafPn3QrFkz7N27F7t27cKgQYOgVCrx6KOPQqlUYu3atepjXb16FevWrcMzzzyjM9bMzEw0a9YML7/8MjIzMzF16lTcuXMH/fv3h7e3Nw4ePIiff/4Zmzdvxosvvqjx2i1btiAlJQUJCQlYt26dev+MGTPw5ptv4tChQ3BwcMATTzyBV199FZ988gl27tyJc+fO4e233zbsi6mHnZ0dFixYgOPHj+Pbb7/F1q1b8eqrr1bomJWOObIzQ1y6dEkAELt379bY/95774mGDRvqfE2DBg3Ee++9p7Fv9+7dAoC4fPmyEEKIRo0aCWdnZzF27FiRmJgoVqxYIXx8fMQ777yjN5YZM2ZoZfEwUQ9QYaH8D0mh0P8fVEiIbEdEZGol/1u+dcuwXmlzbLduGR73vHnz1D0/+mRnZwsA4tixY0KIBz1AX3/9tbrNiRMnBACRkpIihBDiiSeeEF26dNF7zP/7v/8TAwYMUD+eP3++iIiIEEWldF+1atVK3fMjhBBfffWV8Pb2FreKveE//vhD2NnZiaysLCGE7AHy9/cX+fn56ja64l+xYoUAILZs2aLeN3v2bNGoUSP14/L0AJX0008/CV9fX73P25JK3wOkUnJBIyFEqYsc6WpffH9RURFq166Nr776CpGRkXj88ccxffp0LFq0SO8xp02bhtzcXPWWkZFR3rejxd5eXuouYyz5XuTt/PlcD4iILKNGDeDWLcM2Q68dWb/esONVtBLHuXPn8OSTTyIiIgIeHh4IDw8HAK15oy1btlTfD/y3ez07OxvAgx4gfZ577jls2rQJl/7t+lq2bBnGjBlj1OJ7KSkpaNWqFdzc3NT7unTpgqKiIqSmpqr3tWjRQucK3cXj9/f3V7ctvk/1fspr27Zt6NevH+rUqYOaNWti1KhRuHbtGm7fvl2h41YmVptV5ufnB3t7e2RlZWnsz87OVn/DSwoICNDZ3sHBQT3xLDAwEI6OjrAvllE0adIEWVlZKCgo0PnD5uzsDGdn54q+Jb2GDQNWr9a9DtD8+VwHiIgsR6EAin0ulyo6Wv6dunRJ95WsCoV8PjraMv/EDRo0CCEhIVi8eDGCgoJQVFSE5s2ba00gLl4fqvg/xwDg6upa6jnatGmDVq1aYfny5YiJicGxY8fw+++/GxVnaf/IF9/vpucboSv+kvuKD/vZ2dmpOwNUVNNCdLlw4QIGDhyI8ePH491334WPjw927dqFZ599ttTXVTVW6wFycnJCZGQkEhISNPYnJCSgc+fOOl8TFRWl1X7Tpk1o166d+oejS5cuOHv2rMYPx+nTpxEYGGjVWjjDhgHp6cCGDYCqGPOOHUx+iMh22VIP9rVr15CSkoI333wTffr0QZMmTXD9+nWjj9OyZcsyL1UfN24cli1bhqVLl6Jv374ICQkx6hxNmzZFcnKyRm/K7t27YWdnh4YNGxodc1lq1aqFzMxM9WOlUonjx4/rbZ+YmIjCwkJ8/PHH6NSpExo2bIjLly+bPC5bZ9UhsLi4OHz99ddYunQpUlJSMGXKFFy8eBHjx48HIIemRo0apW4/fvx4XLhwAXFxcUhJScHSpUuxZMkSTJ06Vd3m//7v/3Dt2jVMnjwZp0+fxh9//IH3338fEydOtPj7K8neHujfH2jTRj4+cMC68RARlUXVg11yJZHgYLnfUv/EeXt7w9fXF1999RXOnj2LrVu3Ii4uzujjTJs2DQcPHsSECRNw9OhRnDp1CosWLcLVq1fVbUaOHIlLly5h8eLFGDt2rNHnGDlyJFxcXDB69GgcP34c27Ztw0svvYSnn35a7whHRfTu3Rt//PEH/vjjD5w6dQoTJkzAjRs39LavV68eCgsL8emnn+L8+fP47rvvdK6pV9VZNQEaMWIE5s+fj1mzZqF169b466+/sH79eoSGhgKQs+uLj+2Gh4dj/fr12L59O1q3bo13330XCxYswPDhw9VtQkJCsGnTJhw8eBAtW7bEpEmTMHnyZLz++usWf3/6dOokb/fts24cRESGUPVgb9sG/PijvE1Ls2wPtp2dHVauXImkpCQ0b94cU6ZMwYcffmj0cRo2bIhNmzbhyJEj6NChA6KiovDbb79prDPk4eGB4cOHw93dHUOHDjX6HDVq1MDGjRuRk5OD9u3b45FHHkGfPn3w2WefGX0sQ4wdOxajR4/GqFGj0KNHD4SHh6NXr15627du3Rr/+9//MGfOHDRv3hw//PADZs+ebZbYbJlClBw4JOTl5cHT0xO5ubnw8PAw+fF/+AF46imZCO3da/LDExGp3bt3D2lpaeoV98kw/fr1Q5MmTbBgwQJrh0IllPYzbcznt+0urVmFqXqADh0C8vMBM86/JiIiI+Tk5GDTpk3YunWr2XpsyDYwAbKCiAigVi3gyhXg8OEHCREREVlX27Ztcf36dcyZMweNGjWydjhkRkyArEChkEnP77/LITAmQEREtiE9Pd3aIZCFWH0hxOqKE6GJiIishwmQlURFyVsmQERERJbHBMhK2reXCyJevAhUw/WniIiIrIoJkJW4uwOq0i7sBSIiIrIsJkBWpJoHxLWAiIiILIsJkBVxIjQRkeF69uyJ2NhY9eOwsDDMnz+/3K/XxdhjlpSeng6FQoHk5ORyH6O6UCgU+PXXX612fl4Gb0WqidCJicD9+0CxYr9ERLZFqQR27gQyM4HAQKBbN8tUQS3FwYMH9VZU1yU+Pl6jqnplVVRUBC8vLyQmJqJhw4Zo0KABlixZgu7du1s7tEqFPUBW1KAB4O0N3LsHHDli7WiIiPSIjwfCwoBevYAnn5S3YWFyvxXVqlULNWrUMLi9j48PatasacaILOP48eNwdnZGw4YNkZ2djYsXL6J9+/ZGHeP+/ftmiq7yYAJkRXZ2HAYjIhsXHw888gjw99+a+y9dkvvNlATdvn0bo0aNgru7OwIDA/Hxxx9rtSk+XPXEE0/g8ccf13j+/v378PPzw7JlywBoD4FlZ2dj0KBBcHV1RXh4OH744Qetc+Tm5uL5559H7dq14eHhgd69e+OIAf+xnjp1Cp07d4aLiwuaNWuG7du3AwCEEKhfvz4++ugjjfbHjx+HnZ0dzp07V+ax9+zZgy5dugAAdu7ciTZt2sDV1bXU18ycOROtW7fG0qVLERERAWdnZwghcPHiRQwZMgTu7u7w8PDAY489hn/++Uf9ujFjxmgVhI2NjUXPnj3Vj3v27IlJkybh1VdfhY+PDwICAjBz5kyN15w5cwbdu3eHi4sLmjZtioSEBI3nCwoK8OKLLyIwMBAuLi4ICwsze4FWDoFZWadOwIYNciL0iy9aOxoiqvKEAO7cMaytUglMmiRfo+s4CgUweTLQt69hw2E1asjXGOCVV17Btm3b8MsvvyAgIABvvPEGkpKS0Lp1a53tR44cicceewy3bt2Cu7s7AGDjxo24ffs2hg8frvM1Y8aMQUZGBrZu3QonJydMmjQJ2dnZxd6iwEMPPQQfHx+sX78enp6e+PLLL9GnTx+cPn0aPj4+pcY/f/58NG3aFP/73/8wePBgpKWlwdfXF2PHjsWyZcswdepUdfulS5eiW7duqFevnt5jenl5AZDFQIUQ8PLyQn5+PpRKJby8vNC1a1esW7dO7+vPnj2Ln376CWvWrIH9v9+voUOHws3NDTt27EBhYSEmTJiAESNGqBM2Q3377beIi4vD/v37sXfvXowZMwZdunRBv379UFRUhGHDhsHPzw/79u1DXl6e1lysBQsWYO3atfjpp59Qt25dZGRkICMjw6gYjCZIS25urgAgcnNzzX6ujRuFAISIiDD7qYioGrp79644efKkuHv3rtxx65b8o2ON7dYtg2K+efOmcHJyEitXrlTvu3btmnB1dRWTJ09W7wsNDRXz5s0TQghRUFAg/Pz8xPLly9XPP/HEE+LRRx9VP+7Ro4f69ampqQKA2Ldvn/r5lJQUAUB9zC1btggPDw9x7949jfjq1asnvvzyS52xp6WlCQDigw8+UO+7f/++CA4OFnPmzBFCCHH58mVhb28v9u/fr469Vq1a4ptvvin165KWlibOnz8vvL29xYYNG0RaWppo0KCB+OGHH0RaWprIzMzU+9oZM2YIR0dHkZ2drd63adMmYW9vLy5evKjed+LECQFAHDhwQAghxOjRo8WQIUM0jjV58mTRo0cP9eMePXqIrl27arRp3769eO2114QQQmzcuFHY29uLjIwM9fMbNmwQAMQvv/wihBDipZdeEr179xZFRUWlfg2E0PEzXYwxn98cArOyjh3lP0TnzwPF/vEgIqq2zp07h4KCAkSprhSBnL9TWnFSR0dHPProo+phrNu3b+O3337DyJEjdbZPSUmBg4MD2rVrp97XuHFjdS8LACQlJeHWrVvw9fWFu7u7ektLSytzqKp47KrzpKSkAAACAwPx0EMPYenSpQCAdevW4d69e3j00UdLPWZYWBiuXLmCGjVqoH///nB0dMTly5cxfPhwhIWFISAgoNTXh4aGolatWhpfg5CQEISEhKj3NW3aFF5eXupYDdWyZUuNx4GBgeretJSUFNStWxfBwcHq54t/fQDZG5ecnIxGjRph0qRJ2LRpk1HnLw8OgVmZpyfQpAlw8qScBzR4sLUjIqIqrUYN4NYtw9r+9RcwcGDZ7davBwy5AsnACctC15CbAUaOHIkePXogOzsbCQkJcHFxwYABA0o9h6KUIbmioiIEBgbqHA4qnigZqvi5xo0bh6effhrz5s3DsmXLMGLEiFIndA8YMAA7d+5EYWEhCgsL4e7uDqVSifz8fPj6+gIAbpXxfS15xZwQQuf7L77fzs5O6/uhawJ1yavrFAoFioqK1McrqeR527Zti7S0NGzYsAGbN2/GY489hr59+2L16tWlvqeKYA+QDWBdMCKyGIUCcHMzbIuOBoKD9c/bUSiAkBDZzpDjGTj/p379+nB0dMS+Yn8Ur1+/jtOnT5f6us6dOyMkJASrVq3CDz/8gEcffRROTk462zZp0gSFhYVITExU70tNTcWNGzfUj9u2bYusrCw4ODigfv36Gpufn1+psRSPvbCwEElJSWjcuLF638CBA+Hm5oZFixZhw4YNGDt2bKnH+/rrr5GcnIzIyEjMmTMHycnJiImJwauvvork5ORyrTvUtGlTXLx4UWOuzcmTJ5Gbm4smTZoAkFfaZWZmarzO2HOpznO5WN2nvTpWAPbw8MCIESOwePFirFq1CmvWrEFOTo5R5zIGEyAbwBWhicgm2dsDn3wi75dMXlSP5883+XpA7u7uePbZZ/HKK69gy5YtOH78OMaMGQM7u9I/shQKBZ588kl88cUXSEhIwFNPPaW3baNGjdC/f38899xz2L9/P5KSkjBu3DiNq6n69u2LqKgoDB06FBs3bkR6ejr27NmDN998UyNx0uXzzz/HL7/8glOnTmHixIm4fv26RpJjb2+PMWPGYNq0aahfv77WkFBJderUQVhYGI4ePYphw4ahfv36OHr0KIYMGaJOyozVt29ftGzZEiNHjsShQ4dw4MABjBo1Cj169FAPDfbu3RuJiYlYvnw5zpw5gxkzZuD48eNGn6dRo0YYNWoUjhw5gp07d2L69OkabebNm4eVK1fi1KlTOH36NH7++WcEBASUq6fNUEyAbIAqATp4ECgstG4sREQahg0DVq8G6tTR3B8cLPcPG2aW03744Yfo3r07Bg8ejL59+6Jr166IjIws83UjR47EyZMnUadOHfWl4vosW7YMISEh6NGjB4YNG6a+3F1FoVBg/fr16N69O8aOHYuGDRvi8ccfR3p6Ovz9/Us99gcffIA5c+agVatW2LlzJ3777TetXqNnn30WBQUFZfb+qCQmJsLLywvh4eH4+++/8c8//2jMYTKWaiVmb29vdO/eHX379kVERARWrVqlbhMTE4O33noLr776Ktq3b4+bN29i1KhRRp3Hzs4Ov/zyC/Lz89GhQweMGzcO7733nkYbd3d3zJkzB+3atUP79u2Rnp6O9evXl5n0VoRClHewtQrLy8uDp6cncnNz4eHhYfbzFRXJBRHz8oDkZKBVK7OfkoiqiXv37iEtLQ3h4eFwcXEp/4FscCXoym737t3o2bMn/v777zITKnqgtJ9pYz6/OQnaBtjZAR06AJs3y2EwJkBEZHPs7YFii99R+eXn5yMjIwNvvfUWHnvsMSY/VsIhMBvBFaGJiKqHFStWoFGjRsjNzcXcuXOtHU61xQTIRqjmv3EiNBFR1TZmzBgolUokJSWhTsm5VWQxTIBsRMeO8vb0aeDaNevGQkREVNUxAbIRvr5Aw4by/oED1o2FiKoeXu9CVYWpfpaZANkQrgdERKamKnpZUFBg5UiITEP1s2xfwasQeRWYDenUCVi+nBOhich0HBwcUKNGDVy5cgWOjo5mXVeFyNyKiorU9dAcHCqWwjABsiGqidD798u1gfh3iogqSqFQIDAwEGlpabhw4YK1wyGqMDs7O9StW7fUOm6GYAJkQ5o3l+Vy8vKAlBSgWTNrR0REVYGTkxMaNGjAYTCqEpycnEzSk8kEyIY4OADt2wPbt8thMCZARGQqdnZ2FVsJmqiK4SCLJSmVMrtZsULeKpVaTTgRmoiIyPzYA2Qp8fHA5MnA338/2BccLCstFysmyBWhiYiIzI89QJYQHw888ohm8gMAly7J/fHx6l2qBOjkSSA314IxEhERVSNMgMxNqZQ9P7oWblLti41VD4f5+wPh4fIpLohIRERkHkyAzG3nTu2en+KEADIyZLt/qS6H5zAYERGReTABMrfMTKPbcSI0ERGReTEBMrfAQKPbFZ8IzfI9REREpscEyNy6dZNXe+lbsVKhAEJCZLt/tWoFuLgA168DZ85YKE4iIqJqhAmQudnby0vdAe0kSPV4/nzZ7l9OTkBkpLzPYTAiIiLTYwJkCcOGAatXA3XqaO4PDpb7i60DpMKJ0ERERObDBMhShg0D0tOBjRtlzQtA3teR/ACcCE1ERGROTIAsyd4eiI4GOnaUj0vp3lElQMeOAbduWSA2IiKiaoQJkDV06SJvd+/W26ROHTk3uqgISEy0UFxERETVBBMgazAgAQI4DEZERGQuTICsoXNneXvqFHDtmt5mnAhNRERkHkyArMHPD2jUSN7fs0dvs+I9QFwQkYiIyHSYAFlL167ytpRhsDZtAEdH4MoVIC3NQnERERFVA0yArMWAeUAuLkDbtvI+h8GIiIhMhwmQtagSoIMHgfx8vc04EZqIiMj0mABZS4MGQK1aMvlJStLbjBOhiYiITI8JkLUoFA+uBitlGEzVA5ScDNy9a/6wiIiIqgMmQNZkwDygunWBgACgsLDUjiIiIiIyAhMga1IlQHv26L3OXaHgMBgREZGpWT0BWrhwIcLDw+Hi4oLIyEjs3Lmz1PY7duxAZGQkXFxcEBERgS+++ELj+W+++QYKhUJru3fvnjnfRvlERgLOzvI69zNn9DbjRGgiIiLTsmoCtGrVKsTGxmL69Ok4fPgwunXrhgEDBuDixYs626elpWHgwIHo1q0bDh8+jDfeeAOTJk3CmjVrNNp5eHggMzNTY3NxcbHEWzKOszPQrp28X8owmKoHiAsiEhERmYZVE6D//e9/ePbZZzFu3Dg0adIE8+fPR0hICBYtWqSz/RdffIG6deti/vz5aNKkCcaNG4exY8fio48+0minUCgQEBCgsZUmPz8feXl5GpvFGLAgYmSkLCSfmQn8/beF4iIiIqrCrJYAFRQUICkpCdHR0Rr7o6OjsUdPeYi9e/dqtY+JiUFiYiLu37+v3nfr1i2EhoYiODgY//nPf3D48OFSY5k9ezY8PT3VW0hISDnfVTkYMBG6Rg2gVSt5n8NgREREFWe1BOjq1atQKpXw9/fX2O/v74+srCydr8nKytLZvrCwEFevXgUANG7cGN988w3Wrl2LFStWwMXFBV26dMGZUubYTJs2Dbm5ueotIyOjgu/OCCyMSkREZHFWnwStUCg0HgshtPaV1b74/k6dOuGpp55Cq1at0K1bN/z0009o2LAhPv30U73HdHZ2hoeHh8ZmMb6+QOPG8r6BhVGJiIioYqyWAPn5+cHe3l6rtyc7O1url0clICBAZ3sHBwf4+vrqfI2dnR3at29fag+Q1amGwXbt0ttE1QN06FCplTOIiIjIAFZLgJycnBAZGYmEhASN/QkJCeisGhYqISoqSqv9pk2b0K5dOzg6Oup8jRACycnJCAwMNE3g5mDAPKCICMDPDygokKtCExERUflZdQgsLi4OX3/9NZYuXYqUlBRMmTIFFy9exPjx4wHIuTmjRo1Stx8/fjwuXLiAuLg4pKSkYOnSpViyZAmmTp2qbvPOO+9g48aNOH/+PJKTk/Hss88iOTlZfUybpEqAEhP1du8oFBwGIyIiMhUHa558xIgRuHbtGmbNmoXMzEw0b94c69evR2hoKAAgMzNTY02g8PBwrF+/HlOmTMHnn3+OoKAgLFiwAMOHD1e3uXHjBp5//nlkZWXB09MTbdq0wV9//YUOHTpY/P0ZTFUY9coVWe9Cbw8YsG4dJ0ITERFVlEIILq1XUl5eHjw9PZGbm2u5CdFDhwK//QbMnQu88orOJlu3An36yPpgFy5YJiwiIqLKwpjPb6tfBUb/MmBBxPbtATs74OJF4PJlC8VFRERUBTEBshUGFEatWRNo3lze37/fQnERERFVQUyAbEXbtiyMSkREZCFMgGyFs7Mc4wIMKozKidBERETlxwTIlhiwIKKqBygxEShW/oyIiIiMwATIlhiwIGLDhoCXF3D3LnD0qGXCIiIiqmqYANkS1fo/qanAv8VdS7Kze9ALxGEwIiKi8mECZEtYGJWIiMgimADZGgOGwTgRmoiIqGKYANkaAxZEVFX1OHcOyM62QExERERVDBMgW2NAYVQvL6BJE3mfCyISEREZjwmQralfXxZGzc+XhVH14DAYERFR+TEBsjUKhUHzgDgRmoiIqPyYANkiAxZEVPUAHTgAKJUWiImIiKgKYQJkiwwojNqkiSyOevs2cOKEBWMjIiKqApgA2SJVYdSrV4HTp3U2sbd/cDUYh8GIiIiMwwTIFrEwKhERkVkxAbJVnAhNRERkNkyAbJUBCyKqEqDUVCAnxwIxERERVRFMgGyVAYVRfX2BBg3k/QMHLBQXERFRFcAEyFb5+DxY7pmFUYmIiEyKCZAtY2FUIiIis2ACZMsMWBBR1QO0fz9QVGSBmIiIiKoAJkC2rHhh1Hv3dDZp0QKoUQPIzQVOnbJgbERERJUYEyBbpiqMWlCgtzCqg8ODJYM4DEZERGQYJkC2jIVRiYiIzIIJkK3jRGgiIiKTYwJk61QLIpZSGFXVA3TihJwLRERERKVjAmTr2rYFXFxKLYzq7w+Eh8v86OBBC8dHRERUCTEBsnVOTgYVRlX1AnEYjIiIqGxMgCoDToQmIiIyKSZAlYGRE6H1TBUiIiKifzEBqgyKF0a9ckVnk1at5FShnBzgzBkLxkZERFQJMQGqDAwojOrkBERGyvucB0RERFQ6JkCVhRHzgJgAERERlY4JUGXBidBEREQmwwSoslAtiFhKYVTVROijR4Hbty0UFxERUSXEBKiyqFcPqF271MKodeoAwcFAUREXRCQiIioNE6DKwsDCqKwLRkREVDYmQJUJJ0ITERGZBBOgyqR4AlRGYdS9e7kgIhERkT5MgCoTVWHUa9fkooh6mjg6AtnZQHq6ZcMjIiKqLJgAVSYGFEZ1cQHatJH3OQxGRESkGxOgysaIidBcD4iIiEg3gxOgWbNm4c6dO+aMhQzBidBEREQVphDCsKmy9vb2yMzMRO3atc0dk9Xl5eXB09MTubm58PDwsHY4mnJyAF9feT87G6hVS6tJejoQHg44OAB5eYCrq2VDJCIisgZjPr8N7gEyME8ic/PxAZo2lff1FEYNDQUCAoDCQuDQIQvGRkREVEkYNQdIoVCYKw4yRhnDYAoFh8GIiIhK42BM4z59+sDBofSXHGKXg/l16QIsXlzmROhff+VEaCIiIl2MSoBiYmLg7u5urljIUKoeIFVhVBcXrSbsASIiItLP4EnQdnZ2yMrK4iRoWyCEnOSTnQ3s3PmgUnwxt28Dnp6AUglcvAiEhFghTiIiIgsyyyRozv+xIQYURnVzA1q1kvfZC0RERKTJ6leBLVy4EOHh4XBxcUFkZCR27txZavsdO3YgMjISLi4uiIiIwBdffKG37cqVK6FQKDB06FATR20DuB4QERFRuRmcAKWlpcHPz0/9+OrVq7h27VqFTr5q1SrExsZi+vTpOHz4MLp164YBAwbg4sWLemMYOHAgunXrhsOHD+ONN97ApEmTsGbNGq22Fy5cwNSpU9GtW7cKxWizVAnQnj0GFUYlIiKiBwyeAwQAN27cwPTp07Fq1Spcv34dAODt7Y3HH38c//3vf+Hl5WXUyTt27Ii2bdti0aJF6n1NmjTB0KFDMXv2bK32r732GtauXYuUlBT1vvHjx+PIkSPYW+xTXqlUokePHnjmmWewc+dO3LhxA7/++qveOPLz85Gfn69+nJeXh5CQENudAwQABQVyks+9e0BKCtC4sVaTs2eBBg0AZ2cgN1feEhERVVVmmQOUk5ODjh074ttvv8Xw4cPx8ccf46OPPsKwYcPwzTffICoqSp0UGaKgoABJSUmIjo7W2B8dHY09ehb427t3r1b7mJgYJCYm4v79++p9s2bNQq1atfDss88aFMvs2bPh6emp3kIqw4xhJyegQwd5X88wWL16gJ8fkJ8PJCdbLjQiIiJbZ1QtMCcnJ5w7dw5ffvklYmNjMWXKFHz11Vc4e/YsHB0dMWvWLINPfPXqVSiVSvj7+2vs9/f3R1ZWls7XZGVl6WxfWFiIq1evAgB2796NJUuWYPHixQbHMm3aNOTm5qq3jIwMg19rVVwQkYiIqFwMToB+/fVXfPTRR1oJCAAEBARg7ty5+OWXX4wOoOTVZUKIUq8409Vetf/mzZt46qmnsHjxYo35SmVxdnaGh4eHxlYpcCI0ERFRuRi8EGJmZiaaNWum9/nmzZvr7bnRxc/PD/b29lqvyc7O1plkATLR0tXewcEBvr6+OHHiBNLT0zFo0CD180VFRQAABwcHpKamol69egbHaPOiouTt6dPAlSs6C6NyIjQREZE2g3uA/Pz8kJ6ervf5tLQ0+KqqlBvAyckJkZGRSEhI0NifkJCAzp0763xNVFSUVvtNmzahXbt2cHR0ROPGjXHs2DEkJyert8GDB6NXr15ITk6uHHN7jFG8MKqeXqAOHeRQ2IULQGamBWMjIiKyYQYnQP3798f06dNRUFCg9Vx+fj7eeust9O/f36iTx8XF4euvv8bSpUuRkpKCKVOm4OLFixg/fjwAOTdn1KhR6vbjx4/HhQsXEBcXh5SUFCxduhRLlizB1KlTAQAuLi5o3ry5xubl5YWaNWuiefPmcHJyMiq+SqGMYbCaNYHmzeV9DoMRERFJBg+BvfPOO2jXrh0aNGiAiRMnovG/l12fPHkSCxcuRH5+Pr777jujTj5ixAhcu3YNs2bNQmZmJpo3b47169cjNDQUgBx2K74mUHh4ONavX48pU6bg888/R1BQEBYsWIDhw4cbdd4qxcDCqMeOyQTo4YctGBsREZGNMmodoLS0NEyYMAGbNm3SmHzcr18/fPbZZ6hfv77ZArUkm68FVpxqsR8nJ7nYj47CqMuWAWPHAt27Azt2WCFGIiIiCzDm89uoBEjl+vXrOHPmDACgfv368PHxKV+kNqpSJUAGFEZNSZFThVxdZY7k6GiFOImIiMzMLAshFuft7Y0OHTqgQ4cOVS75qXQUigdJj55hsEaNAC8v4O5dORRGRERU3Rk8B2js2LFltlEoFFiyZEmFAqJy6NIFiI/XmwDZ2QEdOwIbN8p5QG3bWjg+IiIiG2NwAlRamQulUonNmzcjPz+fCZA1lCyMqmMhyagomQDt3QtMmGDh+IiIiGyMwQmQvlWef/vtN7zxxhtwdnbG22+/bbLAyAht2sjJz9euAampOgujckVoIiKiB8o1BwiQNbe6du2KJ598Ev/5z39w/vx5vP7666aMjQxVvDDqrl06m6iePntWLhpNRERUnRmdAJ04cQKDBg1Cz5490ahRI6SmpmLOnDnw9vY2R3xkqDIWRPT2Bpo0kff377dQTERERDbK4AQoIyMDzzzzDFq3bg0HBwccPXoUS5YsQXBwsDnjI0OxMCoREZHBDJ4D1KhRIygUCrz88svo3Lkzzpw5o14LqLjBgwebNEAykKow6pkzck2g2rV1Nlm2jIVRiYiIDE6A7t27BwCYO3eu3jYKhQJKpbLiUZHxVIVRT56UV4MNHarVRNUDdOAAoFQC9vaWDZGIiMhWGDwEVlRUVObG5MfKylgQsWlTWRz11i3gxAkLxkVERGRjyn0VGNmgMuYB2ds/uBqM84CIiKg6MzgBSkpKQq9evZCXl6f1XG5uLnr16oUjR46YNDgykioBSkoC/h2yLIkToYmIiIxIgD7++GP07t1bZ3ExT09P9OvXDx9++KFJgyMjRUQA/v5AQQGQmKiziWquNCdCExFRdWZwArR//34MGTJE7/ODBg3Cnj17TBIUlZNCUeYwWMeO8vbUKaCU6iZERERVmsEJ0KVLl1CzZk29z7u7uyMzM9MkQVEFqBIgPStC+/kB9evL+1wQkYiIqiuDE6BatWohNTVV7/OnTp2Cn5+fSYKiCiheGLWoSGcT1TAY5wEREVF1ZXAC1LdvX7z33ns6nxNC4P3330ffvn1NFhiVk6owak6OLIyqAydCExFRdWdwAvTmm2/i2LFj6NixI3766SccOXIER48exapVq9CxY0ccO3YM06dPN2esZIjihVH1zAMq3gOkp5OIiIioSjM4AapXrx42b96M27dv4/HHH0fbtm3Rpk0bPPHEE7hz5w4SEhJQXzW5hKyrjAURW7QAXF2B3Fy9nURERERVmsGlMACgXbt2OH78OJKTk3HmzBkIIdCwYUO0bt3aTOFRuZRxJZiDA9C+PfDXX/JyeFWVeCIiourCqARIpXXr1kx6bJmBhVH/+ksOg40da+H4iIiIrIylMKoib2+gWTN5X8/aTJwITURE1RkToKqqjGEwVQJ0/Digo7oJERFRlcYEqKoqY0HEgAAgLAwQAjh40HJhERER2QKjEqDCwkK88847yMjIMFc8ZCrFC6PevauziaoXiHXBiIioujEqAXJwcMCHH34IpVJprnjIVFSFUe/fL7MwKucBERFRdWP0EFjfvn2xfft2M4RCJmVAYdTiE6GFsFBcRERENsDoy+AHDBiAadOm4fjx44iMjISbm5vG84MHDzZZcFRBXbsC8fF6E6DWrQFnZ+DaNeDsWaBBA8uGR0REZC0KIYz739/OTn+nkUKhqBLDY3l5efD09ERubi48PDysHU75HTgAdOwI+PgAV64AOr53XbrIK+WXLweeftoKMRIREZmIMZ/fRg+BFRUV6d2qQvJTpbRpI2tesDAqERGRhgpdBn/v3j1TxUHm4OhocGFUXglGRETVidEJkFKpxLvvvos6derA3d0d58+fBwC89dZbWLJkickDpAoycCL00aPA7dsWiomIiMjKjE6A3nvvPXzzzTeYO3cunJyc1PtbtGiBr7/+2qTBkQmUsSBicLDclEq9V8sTERFVOUYnQMuXL8dXX32FkSNHwt7eXr2/ZcuWOHXqlEmDIxNQjXGdPQv884/OJpwHRERE1Y3RCdClS5dQv359rf1FRUW4f/++SYIiE2JhVCIiIi1GJ0DNmjXDzp07tfb//PPPaNOmjUmCIhMrYx5Q8YnQXBCRiIiqA6MXQpwxYwaefvppXLp0CUVFRYiPj0dqaiqWL1+OdevWmSNGqqiuXYGvvtKbALVpIy8Y++cf4MIFWSSViIioKjO6B2jQoEFYtWoV1q9fD4VCgbfffhspKSn4/fff0a9fP3PESBVVRmFUV1e5KjTAy+GJiKh6KNc6QDExMdixYwdu3bqFO3fuYNeuXYiOjjZ1bGQq4eFAQAALoxIREf2r3AshJiYm4rvvvsP333+PpKQkU8ZEpmZkYVQiIqKqzug5QH///TeeeOIJ7N69G15eXgCAGzduoHPnzlixYgVCQkJMHSOZQpcuwJo1ZU6EPnwYuHcPcHGxYGxEREQWZnQP0NixY3H//n2kpKQgJycHOTk5SElJgRACzz77rDliJFMo3gNUVKT1dGgo4O8vR8kOHbJwbERERBZmdAK0c+dOLFq0CI0aNVLva9SoET799FOdl8eTjVAVRr1+HdCxYKVC8WAYjBOhiYioqjM6Aapbt67OBQ8LCwtRp04dkwRFZmBEYVTOAyIioqrO6ARo7ty5eOmll5CYmAjx76p5iYmJmDx5Mj766COTB0gmxInQREREAACFEMat/evt7Y07d+6gsLAQDg5yDrXqvpubm0bbnJwc00VqQXl5efD09ERubi48PDysHY7pbNgADBwI1K8PnDmj9fTt24CnpyyMmpEhi6QSERFVFsZ8fht9Fdj8+fPLGxdZW1SUnOyjKozq76/xtJsb0LKlvBJs3z7gkUesFCcREZGZGZ0AjR492hxxkCV4ecnCqMePy8KoDz+s1aRTJ5kA7d3LBIiIiKquci+ESJWUgYVROQ+IiIiqMiZA1Y2BE6GTkoCCAgvFREREZGFMgKqbMgqj1q8P+PoC+flAcrJlQyMiIrIUqydACxcuRHh4OFxcXBAZGVnmYoo7duxAZGQkXFxcEBERgS+++ELj+fj4eLRr1w5eXl5wc3ND69at8d1335nzLVQuxQujHjyo9XTxBRE5DEZERFWVUQmQ6nL348ePm+Tkq1atQmxsLKZPn47Dhw+jW7duGDBgAC5evKizfVpaGgYOHIhu3brh8OHDeOONNzBp0iSsWbNG3cbHxwfTp0/H3r17cfToUTzzzDN45plnsHHjRpPEXOkZURiVK0ITEVFVZfQ6QPXq1UN8fDxatWpV4ZN37NgRbdu2xaJFi9T7mjRpgqFDh2L27Nla7V977TWsXbsWKSkp6n3jx4/HkSNHsLeUT+u2bdvioYcewrvvvmtQXFV2HSCVefOAuDjgoYeAdeu0nt6yBejbFwgLA9LSLB8eERFReRjz+W30ENibb76JadOmVXiRw4KCAiQlJSE6Olpjf3R0NPbs2aPzNXv37tVqHxMTg8TERJ3lOYQQ2LJlC1JTU9G9e3e9seTn5yMvL09jq9JUPUB79ugsjNq+vewoSk8HsrIsGxoREZElGL0O0IIFC3D27FkEBQUhNDRUa/XnQwaWEr969SqUSiX8SyzG5+/vjyw9n7pZWVk62xcWFuLq1asIDAwEAOTm5qJOnTrIz8+Hvb09Fi5ciH79+umNZfbs2XjnnXcMirtKKFkYtWlTjac9PIDmzYFjx+Q8oKFDrRMmERGRuRidAA018aehQqHQeCyE0NpXVvuS+2vWrInk5GTcunULW7ZsQVxcHCIiItCzZ0+dx5w2bRri4uLUj/Py8hASEmLsW6k8HB2Bjh2B7dvlPKASCRAg5wExASIioqrK6ARoxowZJjmxn58f7O3ttXp7srOztXp5VAICAnS2d3BwgK+vr3qfnZ0d6tevDwBo3bo1UlJSMHv2bL0JkLOzM5ydnSvwbiqhLl0eJEDPPaf1dKdOwOLFvBKMiIiqpnJfBp+UlITvv/8eP/zwAw4fPmz0652cnBAZGYmEhASN/QkJCejcubPO10RFRWm137RpE9q1awdHR0e95xJCID8/3+gYqzQDV4Q+eBAoLLRQTERERBZidA9QdnY2Hn/8cWzfvh1eXl4QQiA3Nxe9evXCypUrUatWLYOPFRcXh6effhrt2rVDVFQUvvrqK1y8eBHjx48HIIemLl26hOXLlwOQV3x99tlniIuLw3PPPYe9e/diyZIlWLFihfqYs2fPRrt27VCvXj0UFBRg/fr1WL58ucaVZoQyC6M2aiRLh924IYfC2rSxSpRERERmYXQP0EsvvYS8vDycOHECOTk5uH79Oo4fP468vDxMmjTJqGONGDEC8+fPx6xZs9C6dWv89ddfWL9+PUJDQwEAmZmZGmsChYeHY/369di+fTtat26Nd999FwsWLMDw4cPVbW7fvo0JEyagWbNm6Ny5M1avXo3vv/8e48aNM/atVm2qwqiAzl4gOzs5TQjgekBERFT1GL0OkKenJzZv3oz27dtr7D9w4ACio6Nx48YNU8ZnFVV+HSCV8eOBL7+UawJ9/LHW0zNnAu+8Azz9NPBvJxwREZHNMus6QEVFRTrn2zg6OqJIx5oyZMMMXBGaE6GJiKiqMToB6t27NyZPnozLly+r9126dAlTpkxBnz59TBocmZkqATp0SGdhVNUQ2JkzwFdfyYvGlErLhUdERGQuRidAn332GW7evImwsDDUq1cP9evXR3h4OG7evIlPP/3UHDGSuYSHA4GBegujbtsGOPw7Tf6FF4BevWR5jPh4y4ZJRERkakZfBRYSEoJDhw4hISEBp06dghACTZs2Rd++fc0RH5mTqjDq6tVyGKxYuZD4eOCRR4CSM8QuXZL7V68Ghg2zcLxEREQmYlQCVFhYCBcXFyQnJ6Nfv36llpegSqJ4AvQvpRKYPFk7+QHkPoUCiI0FhgwB7O0tFyoREZGpGDUE5uDggNDQUCg5EaTq0FEYdedO4O+/9b9ECCAjQ7YjIiKqjKxWDZ5sROvWQI0aDwqjAsjMNOylhrYjIiKyNVarBk82wtER6NBBXuK1axfQtCkCAw17qaHtiIiIbI3Vq8GTDSheGPX559GtGxAcLCc861sms3ZtoFs3i0ZJRERkMkZPggaAsWPHIiQkxCwBkRWUWBDR3h745BN5tZdCoTsJunlTLh9UYkFwIiKiSsHoSdAfffQRJ0FXNarCqOfOycKokJe4r14N1Kmj2TQ4GGjaVK6bGB0NJCdbPlwiIqKKMnoSdJ8+fbB9+3YzhEJW4+UFNG8u7xe7HH7YMCA9XS6I+OOP8jY9XZbGiIqSleL79gWOH7dCzERERBVg9BygAQMGYNq0aTh+/DgiIyO1JkEPHjzYZMGRBXXpAhw7JhOgYisc2tsDPXtqNq1ZE9iwQSY/iYlAnz7Ajh1A48aWDZmIiKi8jK4Gb2env9NIoVBUieGxalMNvrjvv5dl3zt2NLj6aU6OTH6Sk4GgIJkE1a9v3jCJiIj0MXs1eH1bVUh+qq0yCqPq4uMDJCQAzZoBly8DvXvLITIiIiJbZ3QCRFVUWFiphVH18fMDtmwBGjWSq0P37i1viYiIbJnBCdDAgQORm5urfvzee+/hxo0b6sfXrl1D06ZNTRocWZCqMCogF0Q0gr+/TILq1QPS0uSwGFeJJiIiW2ZwArRx40bk5+erH8+ZM0ejHEZhYSFSU1NNGx1ZVon1gIxRpw6wdSsQGgqcOSOToOxsE8dHRERkIgYnQCXnShs5d5oqAx2FUY1Rt65MgoKDgZQUeZXYtWsmjpGIiMgEOAeIHlAVRr1xQ2Yw5RARIZOggAB5VX10tDwcERGRLTE4AVIoFFAoFFr7qApxdJSXwQPlGgZTadBAzgmqVUteVNa/P5CXZ6IYiYiITMDghRCFEBgzZgycnZ0BAPfu3cP48ePVCyEWnx9ElViXLnLJ538Lo5ZX06bA5s1Ar17A/v3AQw/JxRPd3U0YKxERUTkZnACNHj1a4/FTTz2l1WbUqFEVj4isqwIToUtq2VKuE9S7t7ywbPBgYN06OcpGRERkTUavBF0dVMuVoFVycwFvb1kCPitLXuNeQfv3A/36yQry0dHAb78BLi4miJWIiKgYs64ETVWcp6fOwqgV0bEjsH494OYGbNoEPPooUFBgkkMTERGVCxMg0mbCYTCVrl2B33+XPT/r1gFPPCEXnSYiIrIGJkCkrZwrQpelVy85/OXkBMTHA6NGASwfR0RE1sAEiLQVL4x6545JDx0dDaxZI6+4X7kSGDu2XGsuEhERVQgTINKmKoxaWGhUYVRD/ec/wKpVgL09sHw58MILTIKIiMiymACRNoVCTtoBTDoPqLiHHwZ++AGwswO+/hqYNEleeEZERGQJTIBINzNMhC5pxAjgm29kvvX558DUqUyCiIjIMpgAkW4VLIxqqKefBr76St7/3/+A6dOZBBERkfkxASLdWrWqcGFUQ40bB3z2mbw/ezYwa5ZZT0dERMQEiPQwUWFUQ02cKHuAAGDmTOCDD8x+SiIiqsaYAJF+FpgHVNyUKbIHCACmTQPmzbPIaYmIqBpiAkT6qRKghARgxQpg+3azr1z4+uuyBwgA4uKAhQvNejoiIqqmmACRfleuyNvMTODJJ+VSzmFhchlnM3r7bZkIAXJo7OuvzXo6IiKqhpgAkW7x8cDo0dr7L10CHnnErEmQQgG8/74cEgOA558HvvvObKcjIqJqiAkQaVMqgcmTdV+PrtoXG2vW4TCFAvj4Y9kDJAQwZoxcPZqIiMgUmACRtp07gb//1v+8EEBGhmxnRgoFsGCBvEy+qAgYORL45ReznpKIiKoJJkCkLTPTtO0qwM4O+PJLuWCiUilXj163zuynJSKiKo4JEGkLDDRtuwqyswOWLpXJz/37wPDhwKZNFjk1ERFVUUyASFu3bkBwsByD0ic4WLazEAcHORH64YeBggJgyBB5VT4REVF5MAEibfb2wCefyPv6kqDgYLOvCVSSoyOwciXwn/8A9+7JWwut0UhERFUMEyDSbdgwYPVqoE4dzf1+frI7Zt8+2R1z755Fw3JyAn7+GYiOBm7fBgYMAPbvt2gIRERUBTABIv2GDQPS04Ft24Aff5S3WVnAH38Arq7A+vWyG+b2bYuG5eIirwbr1Qu4eROIiQEOHbJoCEREVMkphNC12Ev1lpeXB09PT+Tm5sLDw8Pa4dimv/4CHnoIuHVLlsz44w/A09OiIdy6BfTvL4fBfHzknKAWLSwaAhER2RBjPr/ZA0Tl0707sHkz4OUlM5C+fYGcHIuG4O4uO6E6dpSn7tMHSEmRU5O2b7dY+TIiIqqE2AOkA3uAjJCcDPTrB1y9KrtfNm8Gate2aAg3bsjk59AhmY+5uMiROpXgYDmne9gwi4ZlFKVSriuZmSlXF+jWTc5FJyIiw7EHiCyndWtgxw4gIAA4dkz2DF26ZNEQvLzkukB168pkqHjyA1ikfFmFxMfLGrO9elm05iwRUbXGBIgqrmlTOScoJARITZVJUHq6RUPw8pKLJOpiofJl5RIfL5OzkpVHbD1pIyKq7DgEpgOHwMrpwgU5FnXunBx32rIFaNjQIqfevl32nJTFwwNwc5OX0zs6PtiKPzbkvileY28vL6L75x/dsSoU8suYlsbhMCIiQxjz+e1goZj0WrhwIT788ENkZmaiWbNmmD9/PrqVssLwjh07EBcXhxMnTiAoKAivvvoqxo8fr35+8eLFWL58OY4fPw4AiIyMxPvvv48OHTqY/b1Ue6Ghsieob185G1k1Ubp5c7Of2tCyZHl5cqsMitec7dnT2tEQEVUtVk2AVq1ahdjYWCxcuBBdunTBl19+iQEDBuDkyZOoW7euVvu0tDQMHDgQzz33HL7//nvs3r0bEyZMQK1atTB8+HAAwPbt2/HEE0+gc+fOcHFxwdy5cxEdHY0TJ06gTslF/cj0goJkd0x0NHDkiPzk3rQJaNvWrKc1tCzZ0qVAmzaynMb9+3Iz9n55XqPr9bm5cs5SWZ54Qq440LWrnBwdEVF6lRIiIiqbVYfAOnbsiLZt22LRokXqfU2aNMHQoUMxe/ZsrfavvfYa1q5di5SUFPW+8ePH48iRI9i7d6/OcyiVSnh7e+Ozzz7DqFGjDIqLQ2AmkJMjF+k5eFCuD7RhAxAVZbbTKZVy4vClSw/m/BRni8NJhg7blRQY+CAZ6toVaNnSdt4TEZE1VYqrwAoKCpCUlITo6GiN/dHR0dizZ4/O1+zdu1erfUxMDBITE3FfzwzYO3fu4P79+/Dx8dEbS35+PvLy8jQ2qiAfHzn81a2b7Oro18+s1UtLK1+mejx/vm0lCmXVnFUoZCWSX38FXn0V6NxZzh3KzJTlQCZNkh1r3t4y13zvPXlB3t27Fn0bRESVktUSoKtXr0KpVMLf319jv7+/P7JKXsf8r6ysLJ3tCwsLcfXqVZ2vef3111GnTh307dtXbyyzZ8+Gp6enegsJCTHy3ZBOHh6y56dfvweFu/7802yn01e+LDhY7re1dYAMSdoWLJCV7+fMketN5ubKJOe//5VJT82ashzIxo3Am2/KEUdPT7k492uvAevWAdevW/RtERFVCla/DF5R4i+/EEJrX1ntde0HgLlz52LFihWIj4+Hi4uL3mNOmzYNubm56i0jI8OYt0ClcXMD1q59UMJ98GDZpWEmusqXpaXZXvKjYmzS5uoq55ZPny5zy+vX5QKQCxYAjz4ql2O6fx/YsweYOxcYNEh2xrVoAUyYIL8m/PEmIrLiJGg/Pz/Y29tr9fZkZ2dr9fKoBAQE6Gzv4OAAX19fjf0fffQR3n//fWzevBktW7YsNRZnZ2c4OzuX412QQVxcgDVrgKeekmM3jzwCfP898PjjZjmdvX3lumpq2DDZy1OelaDt7eWk7jZtgJdekvOfzp8Hdu2Sx9u5Ezh9Gjh+XG6q6XZ168pzqOYRNWkC2Fn93yEiIsuxWgLk5OSEyMhIJCQk4OGHH1bvT0hIwJAhQ3S+JioqCr///rvGvk2bNqFdu3ZwdHRU7/vwww/x3//+Fxs3bkS7du3M8wbIOE5OsvvBxQX47ju55PHdu8Azz1g7MptgqqRNoQDq1ZPb6NFyX3a2TIhUSdHhw8DFi8APP8gNkL1EXbo8SIgiI+W3rDQs30FElZqwopUrVwpHR0exZMkScfLkSREbGyvc3NxEenq6EEKI119/XTz99NPq9ufPnxc1atQQU6ZMESdPnhRLliwRjo6OYvXq1eo2c+bMEU5OTmL16tUiMzNTvd28edPguHJzcwUAkZuba7o3S5JSKcQLLwghOyuE+Owza0dU7dy8KURCghAzZgjRu7cQNWo8+HaoNldXIXr2FOLNN4XYuFGIvDzNY6xZI0RwsOZrgoPlfiIiazHm89uqCZAQQnz++eciNDRUODk5ibZt24odO3aonxs9erTo0aOHRvvt27eLNm3aCCcnJxEWFiYWLVqk8XxoaKgAoLXNmDHD4JiYAJlZUZEQU6Y8+OScO9faEVVrBQVC7N8vxEcfCTF0qBB+ftoJkZ2dEG3bCjFpkhBTpwqhUGi3USjkxiTItAoLhdi2TYgff5S3hYXWjojIdhnz+c1SGDpwHSALEAJ46y157TYAzJwJvP02V/izAULIkm47dz4YNktLM+y1trjeUmUWHw9MnqxZKy44WF49aKsT+4nKYs7hc2M+v5kA6cAEyILef19e0gTIxW4++IBJkA26dEkmQytXGnYRX4MGsgJK3bqyQorqNjQU8PPjt9gQqkK5Jf9Cq752tri0A1FZzJ3UMwGqICZAFjZ/PjBlirz/4ovyN4GXJNmkFSvk/PWKcHWVCVHxpKh4ohQcLBd8NIfKMnFbtbJ58Q+J4tjTRpWRJZJ6JkAVxATICr76Chg/Xv5mjB0rH/Mvu80xtHzH++/LdTAvXgQuXHhwm5mpu1RJcQqFLCmnKzlS3Zbn19Law0lCAHfuyLWbbtyQt/q2s2eBffvKPuaWLUDv3mYPnWwYk3pNTIAqiAmQlXz3HTBmDFBUJCuAfvut+boCqFwqWnOtoED+ASyeFBW/f/EikJ9fdhxeXvqTo9BQwN9fsxPRVP95CgHcuqU7aSkrqbl+XS5SaUpubnLZgo4dgU6dgA4dgBJLolEVZu2kXqWoCMjLkyUgc3Lkz7rqvmo7cUKuWF+WbdsqtiQIE6AKYgJkRT//LMdYCguBhx+WYy5cpNKmqJIJQDOhMEU3thBy3SJ9ydGFC/KPaVmcnICQEJkMBQfLeUullfjz9ZW9Vrm5pSc0N27IH82KsLeX9dtK2/75B/joo/Idv0EDmRCpkqKWLcte04kqH3MMJ92//yB50ZXE6Etwrl+XSZAp/Pij/P+3vJgAVRATICtbt07+Zufny4JX8fFy4gjZDF3/eYaEyOlc5v7P89Yt7aSo+P1Ll0z3x1gfJyeZqHh5lZ3MlNzc3MqeBG5IT1udOvL7cPAgsH+/HDI7fVq7rbOzXNhSlRB17Ch7yjgRXVtVGk4KDAT++EMm9YYmMjdvViyuGjXkoqqqzdv7wf0bN4DFi8s+BnuArIwJkA3YvFnWh7hzR046WbsWcHe3dlRUjK1+WBQWysRBlRCtXSs7FsvSurW8cs2QJMbV1fwJRHl62nJygAMHZEKkSop0FcP193+QDHXqBLRrJwvrVme2Mpx0757srczLk8lLyfu5ubKszcqV5ovBy0t/IlNyUz3n7S0X+tenosPnhmICVEFMgGzEzp3AQw/Jf0uiooD16+VvJpERDJ24XdH/PM2hoj1tQjyYUK1KiI4c0R7Gs7MDmjXTHDpr0sQ2ElpLMMVw0v37ZScuhuwrKDDd+/LwkBcUlJXEFH/ey8t833dzDp+rMAGqICZANuTAASAmRvaftm0LbNrEWZ5kFEv952kupu5pu3tX1oMrnhRdvKjdzt1dTqpWJUUdOwIBAdaJ2ZyUSjlX7NIl/W08PIBRo+T/YvqSmLt3TRtXzZryvJ6emrceHvJ8hvRqVsWkvixMgCqICZCNOXIE6NcPuHJFjlEkJBj+l5gIlvnPszLLynqQDO3fL//vuH1bu11oqObQWZs22sMe1hhKEkLGW9bVeLqeu3bNtFfn1aihP3EpbV/x+zVrlr4UGpN6/ZgAVRATIBuUkgL07Qtcvgw0bCgXQAkOtnZUVIlYc+J2ZaNUAidPPkiI9u+XlzGX/LRwdARatXqQFOXmAi+9VL6hJCFkz0Z5kpgbN0y/xEBJQ4bIkfiykhgHB/PGocKkXjcmQBXEBMhGnTsH9OkjZ7aGhckkKCLC2lFRJVKZhmZsTV4ekJioOXSWnW3cMWrWBEaMkIlSyUTmxo2KX73n4FD65HVdV+2dOmXYZdfVcTipMmICVEFMgGzYxYsyCTp7Vl4HvGUL0KiRtaMiqnaEkP+LqJKhTZtkr1FFubiUvcSAvudq1DD+6jwOJ1UtTIAqiAmQjcvMlMNhJ08CtWvLS+ZbtLB2VETVmqF14h55BOjeXX8iU9ql1ObC4aSqw5jPbwuNVhKZUGCgvLY5OhpITpb90hs3ysVMiMgqAgMNazdxou0NJQ0bJpMcXZO3q/NwUlXHHiAd2ANUSVy/DgwYIPvgPTzkOkFdulg7KqJqqbIPJQEcTqoKjPn8LuVCOyIb5+0tL4nv3l3O0IyOBrZulX/Ftm+XffLbt8vHRGRW9vbyUndAex6O6vH8+badUNjby96pJ56Qt7YcK1UcEyCq3GrWBDZskMnPnTty0cSAALn075NPytuwMDnIT0RmpRpKqlNHc39wMOfRkO3hEJgOHAKrhPLzga5d5XW6JXEmI5FFcSiJrIWToKn6cXCQf211EUImQbGxcjUz/iUmMivVUBKRLeMQGFUNO3eWXsxHCCAjQ5ZQZqcnEVG1xwSIqgZ9vT8lPfWULI/82GPAggWyKiQnSRMRVTscAqOqwdBFSBwcZOXHn39+UE7ZwwPo3FlOVOjWDWjf3jqrsRERkcVwErQOnARdCRm6CElKCpCUJIfMdu0Cdu8Gbt7UbOvkJJMgVULUubNcspaIiGwaS2FUEBOgSqo869krlcDRozIhUm3//KPZRqEAWrZ8kBB17SqH0YiIyKYwAaogJkCVWEXLIwshC63u2vUgITp7VrtdRMSDhKhbN6BBA+OrMBIRkUkxAaogJkCVnKkXIcnMlAmRKik6cgQoKtJsU7u27BlSJUStWsn5RtaKmYioGmICVEFMgKhUubnA3r0PeogOHJALMRbn7q45sbpDB8DVVffxdPVaBQfLugJcuJGIyGBMgCqICRAZJT9frkCtSoh275ZJUnGOjrJavSoh6tJF1jJTzVsq+WvI1auJiIzGBKiCmABRhSiVwPHjD64027kTuHxZs41CATRrJktj376t+ziVoXw2EZENYQJUQUyAyKSEkEmMqodo1y4gNdXw12/bxroCREQGMObzmytBE5mbQiGvGhs9Gvj6a+DUKXmpfWysYa/ftg24f9+sIRIRVTdMgIisoXZtWZjVELNmAb6+wMMPA198IXuTiIioQjgEpgOHwMgiylq9GgBq1JBXj127prm/QQMgJkZuPXvKq86IiKo5DoERVQb29vJSd0B7EUWFQm7ffQdkZwMHDwL//a+8gszBAThzBvjsM2DQIMDHB+jdG5gzB0hOZrV7IiIDsAdIB/YAkUUZu3p1Xh6wdSuwcaPcSg6J+fsD0dGyd6hfPzncRkRUDfAqsApiAkQWV96VoFWlO1TJ0LZt2pfVt237YLgsKkoWeyUiqoKYAFUQEyCqtPLzgT17HiREycmaz7u7y+EyVUJUr55VwiQiMgcmQBXEBIiqjKwsICFBJkObNgFXrmg+X6/eg2SoVy+gZk3rxElEZAJMgCqICRBVSUVFskdI1Tu0ezdQWPjgeUdHWb9MlRC1bg3YlXKdBAu4EpGNYQJUQUyAqFq4eVPOGVIlROfOaT5fu7acRB0TIydV+/s/eI4FXInIBjEBqiAmQFQtlZxMfeuW5vOtW8tkyNUVeOcdFnAlIpvDBKiCmABRtVdQoDmZ+vBhw17HAq5EZEVcCJGIKsbJSa4wPXs2cOiQnEz93XdA376lv04IICNDluwo2YNERGRD2AOkA3uAiPRYsQJ48knD2ioUQP36QKtWcmvdWt4GB2uvfE1EZALGfH47WCgmIqoKAgMNa+fjA+TkyJIdZ87IeUHFn1MlRarEqGlTLtBIRBbFHiAd2ANEpEdZBVyLzwHKyQGOHJGX3qtuT53SvPRexcFBJkEle4v8/Mz7foioSuEk6ApiAkRUivh44JFH5P3ifz4MuQosPx84efJBUqRKjG7c0N0+KOhBMqS6rV+//BOsuXYRUZXGBKiCmAARlcHYAq6lUU2cLpkUlVyXSKVGDaBFC83eohYtyl7FmmsXEVV5TIAqiAkQkQHM3Zty8yZw7JhmYnT0KHD3ru72uiZch4TInilVrxXXLiKq0pgAVRATICIbpVTKBRtL9hZdvqy7vbc30LIlkJSk/7J8rl1EVGUwAaogJkBElczVq9oTrlNSdE+41uf994EBA4A6deTka16qT1TpVKqFEBcuXIjw8HC4uLggMjISO3fuLLX9jh07EBkZCRcXF0REROCLL77QeP7EiRMYPnw4wsLCoFAoMH/+fDNGT0Q2wc8P6NMHePllYPlyOVR265ZcwfqFFww7xhtvAG3ayBpoLi5ARIQc1nv8cXncefOAn36SRWTT0+Vq2ZagVALbt8s1mLZvl4+JqMKsug7QqlWrEBsbi4ULF6JLly748ssvMWDAAJw8eRJ169bVap+WloaBAwfiueeew/fff4/du3djwoQJqFWrFoYPHw4AuHPnDiIiIvDoo49iypQpln5LRGQrnJ3lXKDHHwe+/LLs9g0aALm5QHa2TG7S0uRWmtq1ZY9RnTpyGE3XfQ+P8vcmceI2kdlYdQisY8eOaNu2LRYtWqTe16RJEwwdOhSzZ8/Wav/aa69h7dq1SElJUe8bP348jhw5gr1792q1DwsLQ2xsLGJjY42Ki0NgRFWIMWsX2dvL5CczU7b/+295W/L+pUuG9wC5uWkmRCUTpDp1AH9/7flHnLhNZLRKsRJ0QUEBkpKS8Prrr2vsj46Oxp49e3S+Zu/evYiOjtbYFxMTgyVLluD+/ftwdHQsVyz5+fnIz89XP87LyyvXcYjIBtnbyx6TRx6RyYOutYvmz3+QgDg5AaGhctNHCDnvqHhCpCtZunEDuH0bSE2VW2kxBgY+SIiCgmTtNV0JmxAy7thYYMgQTtwmKierJUBXr16FUqmEv7+/xn5/f39kZWXpfE1WVpbO9oWFhbh69SoCDV2mv4TZs2fjnXfeKddriagSGDZM9pjoGk4qz9pFCgVQq5bcWrfW3+72bXmFWsneo+KPMzNlL9Xff2vGVhrV2kkLFsghvoAATtomMpLVa4EpSvzSCiG09pXVXtd+Y0ybNg1xcXHqx3l5eQgJCSn38YjIBg0bJntMLLkStJubnFvUoIH+NoWFwD//aCZHCQnA77+Xffy4OLl5eACNG2tv9eqxxhqRHlZLgPz8/GBvb6/V25Odna3Vy6MSEBCgs72DgwN8fX3LHYuzszOcnZ3L/XoiqiTs7YGePa0dhSYHhwdDXyotWhiWAAUFAVlZQF4ecOCA3Iqzt5dJUMnEqFEjWZSWqBqzWgLk5OSEyMhIJCQk4OGHH1bvT0hIwJAhQ3S+JioqCr+X+KOwadMmtGvXrtzzf4iIbE63bnJ4zpCJ24WFcnHIU6e0t1u3gNOn5bZ2reYxatXS3WsUGlrxXjHWXKNKwKpDYHFxcXj66afRrl07REVF4auvvsLFixcxfvx4AHJo6tKlS1i+fDkAecXXZ599hri4ODz33HPYu3cvlixZghUrVqiPWVBQgJMnT6rvX7p0CcnJyXB3d0f9+vUt/yaJiIxlzMRte3ugWTO5FSeEnH+UmqqdGGVkAFeuyK3k2mvOzkDDhtqJUcOGgLt72bHz0n2qJKy+EvTChQsxd+5cZGZmonnz5pg3bx66d+8OABgzZgzS09Oxfft2dfsdO3ZgypQpOHHiBIKCgvDaa6+pEyYASE9PR3h4uNZ5evTooXGc0vAyeCKyCaYsOlucqmeoZGJ0+jRQ7IpYLSEhunuNAgNZc41sAkthVBATICKyGZYcTlIqgQsXdA+nXbmi/3U1a8oeopQU4M4d3W1Yc40sgAlQBTEBIiIq4do1zeE01f1z54wrz9G/v5zk7eene/PyAuysVKWJc5cqPSZAFcQEiIjIQAUFMglavFjWS6soOzvA11cmQ6rbsraKlBtR4dylKoEJUAUxASIiMtL27UCvXmW3GzdOJixXr2pv5V2F38HBuITJz0+u0aRKmjh3qcpgAlRBTICIiIxkbM01XQoK5FCbKiEqfl/fdvt2+eJ1cnqQNJU1+TswEDh+HPD2tr0Vtzlsp6FS1AIjIqIqxNiaa7o4OckPcWPKGt29+yBRMiRhunJFJjsFBXKZgMuXyz5HZqZMlBwc5AKSvr4Pbg3ZzLUaN4ftKoQ9QDqwB4iIqJzMdem+qQghr1RTJUSrVwMffGDec7q7G54sqbay5jVx2E4nDoFVEBMgIqIKqEzDMobOXfrzT6B5c9nLZOiWk6N7ONAQxXubSm7e3sCHHwLXr+t+ra0vOWDGnw8mQBXEBIiIqJowxdwlfYqKgBs3jEuarl2Tw3qm0Lw5EB4uEyZvb5lQqe7r2meJwrlmHrZjAlRBTICIiKoR1XASoHvukqWHk1TzmvRtiYnaJUxMoUYN3YlSWYmTt7fssSqLBYbtmABVEBMgIqJqxtbnLhVn6LDdzJlAUJAcKsvJkbeqrfjj3NzyD9WpuLuXnjh5egJvvy3Pq4uJhu2YAFUQEyAiomqossxdMvWwnVIp12AqmSTpSpxK7ivv2k36bNsG9OxZ7pfzMngiIiJj2dtX6MPXYkyx5EDJ46l6aoxVWCjnOZWVOB09KofuypKZaXwM5cQEiIiIqLIZNkzOmdE1odiSw3aqVbj9/EpvZ+iwnTFrQFUQh8B04BAYERFVCtV12E4PDoERERFVB9V12M4E7Cx2JiIiIqq+VMN2depo7g8OtsrK1ewBIiIiIssYNgwYMsQmhu2YABEREZHl2MiwHYfAiIiIqNphAkRERETVDhMgIiIiqnaYABEREVG1wwSIiIiIqh0mQERERFTtMAEiIiKiaocJEBEREVU7TICIiIio2uFK0DqIf4u05eXlWTkSIiIiMpTqc1voqjhfAhMgHW7evAkACAkJsXIkREREZKybN2/C09Oz1DYKYUiaVM0UFRXh8uXLqFmzJhQKhUmPnZeXh5CQEGRkZMDDw8OkxzYXxmwZjNkyGLNlVMaYgcoZN2N+QAiBmzdvIigoCHZ2pc/yYQ+QDnZ2dggODjbrOTw8PCrND6oKY7YMxmwZjNkyKmPMQOWMmzFLZfX8qHASNBEREVU7TICIiIio2mECZGHOzs6YMWMGnJ2drR2KwRizZTBmy2DMllEZYwYqZ9yMuXw4CZqIiIiqHfYAERERUbXDBIiIiIiqHSZAREREVO0wASIiIqJqhwmQhfz1118YNGgQgoKCoFAo8Ouvv1o7pDItWrQILVu2VC9UFRUVhQ0bNlg7rFLNnDkTCoVCYwsICLB2WKUKCwvTilmhUGDixInWDq1UN2/eRGxsLEJDQ+Hq6orOnTvj4MGD1g5Lrazfufj4eMTExMDPzw8KhQLJyclWibO4smKeOXMmGjduDDc3N3h7e6Nv377Yv3+/dYL9V1kxjxkzRutnu1OnTtYJ9l9lxazr91GhUODDDz+0TsAoO+Z//vkHY8aMQVBQEGrUqIH+/fvjzJkz1gn2X7Nnz0b79u1Rs2ZN1K5dG0OHDkVqaqpGG2v+HjIBspDbt2+jVatW+Oyzz6wdisGCg4PxwQcfIDExEYmJiejduzeGDBmCEydOWDu0UjVr1gyZmZnq7dixY9YOqVQHDx7UiDchIQEA8Oijj1o5stKNGzcOCQkJ+O6773Ds2DFER0ejb9++uHTpkrVDA1D279zt27fRpUsXfPDBBxaOTL+yYm7YsCE+++wzHDt2DLt27UJYWBiio6Nx5coVC0f6gCF/2/r376/xM75+/XoLRqitrJiLx5qZmYmlS5dCoVBg+PDhFo70gdJiFkJg6NChOH/+PH777TccPnwYoaGh6Nu3L27fvm2FaKUdO3Zg4sSJ2LdvHxISElBYWIjo6GiNmKz6eyjI4gCIX375xdphlIu3t7f4+uuvrR2GXjNmzBCtWrWydhgVMnnyZFGvXj1RVFRk7VD0unPnjrC3txfr1q3T2N+qVSsxffp0K0WlX2m/c2lpaQKAOHz4sEVjKoshfydyc3MFALF582bLBFUGXTGPHj1aDBkyxCrxGMKQr/OQIUNE7969LROQAUrGnJqaKgCI48ePq/cVFhYKHx8fsXjxYitEqFt2drYAIHbs2KH1nDV+D9kDRAZRKpVYuXIlbt++jaioKGuHU6ozZ84gKCgI4eHhePzxx3H+/Hlrh2SwgoICfP/99xg7dqzJC/GaUmFhIZRKJVxcXDT2u7q6YteuXVaKqnopKCjAV199BU9PT7Rq1cra4ZRq+/btqF27Nho2bIjnnnsO2dnZ1g7JYP/88w/++OMPPPvss9YORa/8/HwA0Ph9tLe3h5OTk039Pubm5gIAfHx8rByJxASISnXs2DG4u7vD2dkZ48ePxy+//IKmTZtaOyy9OnbsiOXLl2Pjxo1YvHgxsrKy0LlzZ1y7ds3aoRnk119/xY0bNzBmzBhrh1KqmjVrIioqCu+++y4uX74MpVKJ77//Hvv370dmZqa1w6vS1q1bB3d3d7i4uGDevHlISEiAn5+ftcPSa8CAAfjhhx+wdetWfPzxxzh48CB69+6t/tC2dd9++y1q1qyJYcOGWTsUvRo3bozQ0FBMmzYN169fR0FBAT744ANkZWXZzO+jEAJxcXHo2rUrmjdvbu1wADABojI0atQIycnJ2LdvH/7v//4Po0ePxsmTJ60dll4DBgzA8OHD0aJFC/Tt2xd//PEHAPlHrDJYsmQJBgwYgKCgIGuHUqbvvvsOQgjUqVMHzs7OWLBgAZ588knY29tbO7QqrVevXkhOTsaePXvQv39/PPbYYzbdozJixAg89NBDaN68OQYNGoQNGzbg9OnT6t9NW7d06VKMHDlSq7fTljg6OmLNmjU4ffo0fHx8UKNGDWzfvh0DBgywmd/HF198EUePHsWKFSusHYoaEyAqlZOTE+rXr4927dph9uzZaNWqFT755BNrh2UwNzc3tGjRwupXQxjiwoUL2Lx5M8aNG2ftUAxSr1497NixA7du3UJGRgYOHDiA+/fvIzw83NqhVWlubm6oX78+OnXqhCVLlsDBwQFLliyxdlgGCwwMRGhoaKX4ndy5cydSU1Mrxe9kZGQkkpOTcePGDWRmZuLPP//EtWvXbOL38aWXXsLatWuxbds2BAcHWzscNSZAZBQhRKXpugbk2HhKSgoCAwOtHUqZli1bhtq1a+Ohhx6ydihGcXNzQ2BgIK5fv46NGzdiyJAh1g6pWqlsv5PXrl1DRkZGpfidXLJkCSIjI21+jlVxnp6eqFWrFs6cOYPExESr/j4KIfDiiy8iPj4eW7dutYlkrDgHawdQXdy6dQtnz55VP05LS0NycjJ8fHxQt25dK0am3xtvvIEBAwYgJCQEN2/exMqVK7F9+3b8+eef1g5Nr6lTp2LQoEGoW7cusrOz8d///hd5eXkYPXq0tUMrVVFREZYtW4bRo0fDwaFy/Fpu3LgRQgg0atQIZ8+exSuvvIJGjRrhmWeesXZoAMr+ncvJycHFixdx+fJlAFCvTxIQEGC1taNKi9nX1xfvvfceBg8ejMDAQFy7dg0LFy7E33//bdUlE0qL2cfHBzNnzsTw4cMRGBiI9PR0vPHGG/Dz88PDDz9skzGr/h7n5eXh559/xscff2ytMDWUFfPPP/+MWrVqoW7dujh27BgmT56MoUOHIjo62moxT5w4ET/++CN+++031KxZE1lZWQBkkubq6goA1v09tNj1ZtXctm3bBACtbfTo0dYOTa+xY8eK0NBQ4eTkJGrVqiX69OkjNm3aZO2wSjVixAgRGBgoHB0dRVBQkBg2bJg4ceKEtcMq08aNGwUAkZqaau1QDLZq1SoREREhnJycREBAgJg4caK4ceOGtcNSK+t3btmyZTqfnzFjhk3GfPfuXfHwww+LoKAg4eTkJAIDA8XgwYPFgQMHrBZvWTHfuXNHREdHi1q1aglHR0dRt25dMXr0aHHx4kWbjVnlyy+/FK6urjbzM11WzJ988okIDg5Wf53ffPNNkZ+fb9WYdcULQCxbtkzdxpq/h4p/gyQiIiKqNjgHiIiIiKodJkBERERU7TABIiIiomqHCRARERFVO0yAiIiIqNphAkRERETVDhMgIiIiqnaYABEREVG1wwSIqBpKT0+HQqFAcnKytUNRO3XqFDp16gQXFxe0bt3a2uGQmYSFhWH+/PnWDoOICRCRNYwZMwYKhQIffPCBxv5ff/0VCoXCSlFZ14wZM+Dm5obU1FRs2bJFb7usrCy89NJLiIiIgLOzM0JCQjBo0CCN14SFhUGhUGDfvn0ar42NjUXPnj019uXk5CA2NhZhYWFwcnJCYGAgnnnmGVy8eFHdRqFQlLqNGTPGJF8DIrIcJkBEVuLi4oI5c+bg+vXr1g7FZAoKCsr92nPnzqFr164IDQ2Fr6+vzjbp6emIjIzE1q1bMXfuXBw7dgx//vknevXqhYkTJ2q0dXFxwWuvvVbqOXNyctCpUyds3rwZCxcuxNmzZ7Fq1SqcO3cO7du3x/nz5wEAmZmZ6m3+/Pnw8PDQ2PfJJ5+U+32bwv379w1qp1QqUVRUZOZoiCoHJkBEVtK3b18EBARg9uzZetvMnDlTazho/vz5CAsLUz8eM2YMhg4divfffx/+/v7w8vLCO++8g8LCQrzyyivw8fFBcHAwli5dqnX8U6dOoXPnznBxcUGzZs2wfft2jedPnjyJgQMHwt3dHf7+/nj66adx9epV9fM9e/bEiy++iLi4OPj5+aFfv34630dRURFmzZqF4OBgODs7o3Xr1vjzzz/VzysUCiQlJWHWrFlQKBSYOXOmzuNMmDABCoUCBw4cwCOPPIKGDRuiWbNmiIuL0+rteeGFF7Bv3z6sX79e57EAYPr06bh8+TI2b96MgQMHom7duujevTs2btwIR0dHdVKlqkwdEBAAT09PKBQK9eP8/Hw89dRT8Pb2hpubG5o1a1bqOcPCwvDuu+/iySefhLu7O4KCgvDpp59qtMnNzcXzzz+P2rVrw8PDA71798aRI0fUz6t+LpYuXaruCdNV1vGbb76Bl5cX1q1bh6ZNm8LZ2RkXLlzA9evXMWrUKHh7e6NGjRoYMGAAzpw5o3X84vT93H300UcIDAyEr68vJk6cqJGMZWdnY9CgQXB1dUV4eDh++OEHvV8XIktjAkRkJfb29nj//ffx6aef4u+//67QsbZu3YrLly/jr7/+wv/+9z/MnDkT//nPf+Dt7Y39+/dj/PjxGD9+PDIyMjRe98orr+Dll1/G4cOH0blzZwwePBjXrl0DIHs9evTogdatWyMxMRF//vkn/vnnHzz22GMax/j222/h4OCA3bt348svv9QZ3yeffIKPP/4YH330EY4ePYqYmBgMHjxY/aGbmZmJZs2a4eWXX0ZmZiamTp2qdYycnBz8+eefmDhxItzc3LSe9/Ly0ngcFhaG8ePHY9q0aTp7PYqKirBy5UqMHDkSAQEBGs+5urpiwoQJ2LhxI3JycnS+J5WJEyciPz8ff/31F44dO4Y5c+bA3d291Nd8+OGHaNmyJQ4dOoRp06ZhypQpSEhIAAAIIfDQQw8hKysL69evR1JSEtq2bYs+ffpoxHL27Fn89NNPWLNmTalzue7cuYPZs2fj66+/xokTJ1C7dm2MGTMGiYmJWLt2Lfbu3QshBAYOHGhwT5LKtm3bcO7cOWzbtg3ffvstvvnmG3zzzTfq58eMGYP09HRs3boVq1evxsKFC5GdnW3UOYjMxuz15olIy+jRo8WQIUOEEEJ06tRJjB07VgghxC+//CKK/1rOmDFDtGrVSuO18+bNE6GhoRrHCg0NFUqlUr2vUaNGolu3burHhYWFws3NTaxYsUIIIURaWpoAID744AN1m/v374vg4GAxZ84cIYQQb731loiOjtY4d0ZGhgAgUlNThRBC9OjRQ7Ru3brM9xsUFCTee+89jX3t27cXEyZMUD9u1aqVmDFjht5j7N+/XwAQ8fHxZZ4vNDRUzJs3T2RnZ4uaNWuK5cuXCyGEmDx5sujRo4cQQoisrCwBQMybN0/nMeLj4wUAsX//fo39y5YtE56enurHLVq0EDNnziwzpuKx9e/fX2PfiBEjxIABA4QQQmzZskV4eHiIe/fuabSpV6+e+PLLL4UQ8ufC0dFRZGdnl3quZcuWCQAiOTlZve/06dMCgNi9e7d639WrV4Wrq6v46aef1Mc39OeusLBQve/RRx8VI0aMEEIIkZqaKgCIffv2qZ9PSUkp9WtOZEnsASKysjlz5uDbb7/FyZMny32MZs2awc7uwa+zv78/WrRooX5sb28PX19frf++o6Ki1PcdHBzQrl07pKSkAACSkpKwbds2uLu7q7fGjRsDkPN1VNq1a1dqbHl5ebh8+TK6dOmisb9Lly7qcxlC/DvEY8wk8Vq1amHq1Kl4++23jZ6fZOj5Jk2ahP/+97/o0qULZsyYgaNHj5Z57OJfd9Xj4l/3W7duwdfXV+Nrn5aWpvF1Dw0NRa1atco8l5OTE1q2bKl+nJKSAgcHB3Ts2FG9z9fXF40aNTLq+wHInzt7e3v148DAQPXPmOo8xX8+GjdurNVTR2QtTICIrKx79+6IiYnBG2+8ofWcnZ2d1twOXcMUjo6OGo8VCoXOfYZMgFV94BcVFWHQoEFITk7W2M6cOYPu3bur2+sajirtuCpCCKOSmQYNGkChUBj9IR0XF4e7d+9i4cKFGvtr1aoFLy8vvYnnqVOnoFAoUK9evVKPP27cOJw/fx5PP/00jh07hnbt2mnN6TFE8a97YGCg1tc9NTUVr7zyirq9oV93V1dXja9zyZ+n4vtV7Sryc6f6GStPwkpkSUyAiGzABx98gN9//x179uzR2F+rVi1kZWVpfBiZcu2e4hOHCwsLkZSUpO7ladu2LU6cOIGwsDDUr19fYzP0wxcAPDw8EBQUhF27dmns37NnD5o0aWLwcXx8fBATE4PPP/8ct2/f1nr+xo0bOl/n7u6Ot956C++99x7y8vLU++3s7PDYY4/hxx9/RFZWlsZrVAlTTEwMfHx8yowtJCQE48ePR3x8PF5++WUsXry41PYlJ2zv27dP4+uelZUFBwcHra+7n59fmbGUpWnTpigsLMT+/fvV+65du4bTp0+rvx+m+Llr0qQJCgsLkZiYqN6Xmpqq9/tEZGlMgIhsQIsWLTBy5EitnoOePXviypUrmDt3Ls6dO4fPP/8cGzZsMNl5P//8c/zyyy84deoUJk6ciOvXr2Ps2LEA5OTenJwcPPHEEzhw4ADOnz+PTZs2YezYsVAqlUad55VXXsGcOXOwatUqpKam4vXXX0dycjImT55s1HEWLlwIpVKJDh06YM2aNThz5gxSUlKwYMECrWGl4p5//nl4enpixYoVGvvfe+89BAQEoF+/ftiwYQMyMjLw119/ISYmBvfv38fnn39eZkyxsbHYuHEj0tLScOjQIWzdurXMxG737t2YO3cuTp8+jc8//xw///yz+mvRt29fREVFYejQodi4cSPS09OxZ88evPnmmxrJRHk1aNAAQ4YMwXPPPYddu3bhyJEjeOqpp1CnTh0MGTIEgGl+7ho1aoT+/fvjueeew/79+5GUlIRx48bB1dW1wu+ByBSYABHZiHfffVdr2KFJkyZYuHAhPv/8c7Rq1QoHDhzQeYVUeX3wwQeYM2cOWrVqhZ07d+K3335T9zIEBQVh9+7dUCqViImJQfPmzTF58mR4enpqzDcyxKRJk/Dyyy/j5ZdfRosWLfDnn39i7dq1aNCggVHHCQ8Px6FDh9CrVy+8/PLLaN68Ofr164ctW7Zg0aJFel/n6OiId999F/fu3dPY7+fnh3379qFXr1544YUXEBERgcceewwRERE4ePAgIiIiyoxJqVRi4sSJaNKkCfr3749GjRppDbeV9PLLLyMpKQlt2rTBu+++i48//hgxMTEA5JDR+vXr0b17d4wdOxYNGzbE448/jvT0dPj7+xvwVSrbsmXLEBkZif/85z+IioqCEALr169XD2mZ6udu2bJlCAkJQY8ePTBs2DD1pf1EtkAh9A0IExGRyYWFhSE2NhaxsbHWDoWoWmMPEBEREVU7TICIiIio2uEQGBEREVU77AEiIiKiaocJEBEREVU7TICIiIio2mECRERERNUOEyAiIiKqdpgAERERUbXDBIiIiIiqHSZAREREVO38P6W4WBl+8zTVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_rounds = 3\n",
    "num_cxs_per_round = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
    "logical_errors = np.array([0.16, 0.202, 0.234, 0.292, 0.322, 0.35, 0.384, 0.393, 0.4171, 0.436, 0.4517])\n",
    "errors_per_rounds = .5*(1-(1-logical_errors/.5)**(1/(num_rounds*num_cxs_per_round)))\n",
    "errors_per_rounds_division = logical_errors / (num_rounds*num_cxs_per_round)\n",
    "plt.plot(num_cxs_per_round, errors_per_rounds, marker='o', color='blue', label='fancy formula')\n",
    "plt.plot(num_cxs_per_round, errors_per_rounds_division, marker='o', color='red', label='divide by # rounds')\n",
    "plt.ylabel('Error per CNOT')\n",
    "plt.xlabel('Number of CNOTs per round')\n",
    "plt.xticks(num_cxs_per_round)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 1\n",
      "final measurement_index = 146\n",
      "Preprocessing is done! it took 59.61s\n",
      "0 [0.025]\n",
      "infidelity 0.975\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_cxs = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
    "num_cxs = np.array([1])\n",
    "errors = np.array([0.16, 0.202, 0.234, 0.292, 0.322, 0.35, 0.384, 0.393, 0.4171, 0.429, 0.47])\n",
    "num_rounds = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "\n",
    "\n",
    "errors = []\n",
    "for num_cx in num_cxs:\n",
    "    noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                    'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                    'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                    'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                    'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                    'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                    'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                'bias_preserving_gates': 'False',\n",
    "                'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "                'ordering': gate_ordering,\n",
    "                'decoder': 'MLE',\n",
    "                'circuit_type': f'logical_CX_NL{num_rounds}_NCX{num_cx}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                'loss_decoder': 'independent',\n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "    # Load the experimental measurements\n",
    "    exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                       exp_measurements[:, 1, :distance**2-1],\n",
    "                                       exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                       exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "    # Load the theory circuit\n",
    "    # theory_measurements, theory_detectors, theory_observables, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1000, noise_params)\n",
    "    # print(2 in theory_measurements)\n",
    "    # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "    # exp_detectors, exp_observables = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "    # Find detection event signs\n",
    "    # exp_detection_events_signs = -np.sign(2*np.nanmean(exp_detectors.astype(int), axis=0)-1).astype(int)\n",
    "\n",
    "    # Now let's decode!\n",
    "    use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "    use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "    use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "    output_dir = '.'\n",
    "    simulate_data = True\n",
    "    num_shots = 1000\n",
    "    # DO IT\n",
    "    \"\"\"exp_predictions, exp_observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        exp_measurements,\n",
    "                                                                        exp_detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params)\n",
    "    \n",
    "    exp_logical_probability = np.mean(np.logical_xor(exp_observable_flips, exp_predictions))\"\"\"\n",
    "\n",
    "    #print('infidelity', 1-exp_logical_probability)\n",
    "    theory_predictions, theory_observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        None,\n",
    "                                                                        None, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots = num_shots)\n",
    "\n",
    "    theory_logical_probability = np.mean(np.logical_xor(theory_observable_flips, theory_predictions))\n",
    "    errors.append(theory_logical_probability)\n",
    "    print(errors)\n",
    "    print('infidelity', 1-theory_logical_probability)\n",
    "\n",
    "\n",
    "plt.plot(num_cxs, errors, marker='o', color='blue')\n",
    "plt.ylabel('Error per CNOT')\n",
    "plt.xlabel('Number of CNOTs per round')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 1\n",
      "final measurement_index = 146\n",
      "Preprocessing is done! it took 60.88s\n",
      "0 1000 2000 3000 4000 for num_layers = 3, num_cxs_per_round = 1 we get logical error 0.0222 +- 0.002083610328252382\n",
      "\n",
      "num_layers = 3\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_10161/761206627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0muse_independent_and_first_comb_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/gefenbaranes/Documents/CX_experiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     71\u001b[0m                                                                             \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                                                             \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_loss_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this part can be improved to be a bit faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Decoder initialized, it took {time.time() - start_time:.2f}s for everything'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36minitialize_loss_decoder\u001b[0;34m(self, **kargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_filename_dems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Preprocessing is done! it took {time.time() - start_time:.2f}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mpreprocess_circuit\u001b[0;34m(self, full_filename)\u001b[0m\n\u001b[1;32m    884\u001b[0m                         \u001b[0;31m#     num_potential_losses += len(losses_indices_in_round)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m                         \u001b[0mhyperedges_matrix_dem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dem_loss_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_by_instruction_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_by_instruction_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# GB: change event prob to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m                         \u001b[0;31m# save into the file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_unique_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_by_instruction_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_dem_loss_circuit\u001b[0;34m(self, losses_by_instruction_ix, event_probability, full_filename, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;31m# replace final observables with detectors:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m             \u001b[0mfinal_loss_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservables_to_detectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_circuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0;31m# get the dem (with observables on columns):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mobservables_to_detectors\u001b[0;34m(self, circuit)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "# num_rounds = 5\n",
    "\n",
    "P_dict = {}\n",
    "P_err_dict = {}\n",
    "num_shots_dict = {}\n",
    "num_errors_dict = {}\n",
    "\n",
    "num_layers_vec = [3,2]\n",
    "num_cxs_per_round_vec = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "for num_layers in num_layers_vec:\n",
    "    num_shots_dict[num_layers] = {}\n",
    "    num_errors_dict[num_layers] = {}\n",
    "    P_dict[num_layers] = {}\n",
    "    P_err_dict[num_layers] = {}\n",
    "    for num_cxs_per_round in num_cxs_per_round_vec:\n",
    "        distance = 5\n",
    "        decoder_basis = 'XX'\n",
    "        gate_ordering = ['N', 'Z']\n",
    "        noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                        'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                        'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                        'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                        'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                        'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                        'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "\n",
    "\n",
    "        Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                    'bias_preserving_gates': 'False',\n",
    "                    'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                    'SSR': 'True', 'cycles': str(num_layers - 1),\n",
    "                    'ordering': gate_ordering,\n",
    "                    'decoder': 'MLE',\n",
    "                    'circuit_type': f'logical_CX_NL{num_layers}_NCX{num_cxs_per_round}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                    'loss_decoder': 'independent',\n",
    "                    'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        simulate_data = True\n",
    "\n",
    "        if simulate_data:\n",
    "            detection_events_signs = None\n",
    "            measurement_events = None\n",
    "            num_shots = 5000\n",
    "\n",
    "        else:\n",
    "            # Load the experimental measurements\n",
    "            exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "            exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                            exp_measurements[:, 1, :distance**2-1],\n",
    "                                            exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                            exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                            exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                            exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "            measurement_events = exp_measurements\n",
    "            # Load the theory circuit\n",
    "            _, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "            # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "            detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "            # Find detection event signs\n",
    "            detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "\n",
    "        # Now let's decode!\n",
    "        use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "        use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "        use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "        output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "        predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                            measurement_events,\n",
    "                                                                            detection_events_signs, use_loss_decoding,\n",
    "                                                                            use_independent_decoder,\n",
    "                                                                            use_independent_and_first_comb_decoder,\n",
    "                                                                            simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                            noise_params=noise_params, num_shots=num_shots)\n",
    "        logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "        num_errors = np.sum(np.logical_xor(observable_flips, predictions))\n",
    "        logical_probability_error = (np.sqrt(logical_probability*(1-logical_probability)/num_shots))\n",
    "        print(f'for num_layers = {num_layers}, num_cxs_per_round = {num_cxs_per_round} we get logical error {logical_probability} +- {logical_probability_error}\\n')\n",
    "\n",
    "        \n",
    "        P_dict[num_layers][num_cxs_per_round] = logical_probability\n",
    "        P_err_dict[num_layers][num_cxs_per_round] = logical_probability_error\n",
    "        num_shots_dict[num_layers][num_cxs_per_round] = num_shots\n",
    "        num_errors_dict[num_layers][num_cxs_per_round] = num_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogicalCircuit' object has no attribute 'Pauli_DEM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_68890/1495820122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauli_DEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogicalCircuit' object has no attribute 'Pauli_DEM'"
     ]
    }
   ],
   "source": [
    "print(circuit.Pauli_DEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare theory to exp detection signs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_circuit_txt = \"\"\"\n",
    "    \n",
    "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
    "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 11 31\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 17 19 21 27 29 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 17 37\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 60 80\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 66 68 70 76 78 86 88 90 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 66 86\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 17 19 21 27 29 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-22]\n",
    "DETECTOR rec[-44] rec[-20]\n",
    "DETECTOR rec[-42] rec[-18]\n",
    "DETECTOR rec[-41] rec[-17]\n",
    "DETECTOR rec[-39] rec[-15]\n",
    "DETECTOR rec[-37] rec[-13]\n",
    "DETECTOR rec[-36] rec[-12]\n",
    "DETECTOR rec[-34] rec[-10]\n",
    "DETECTOR rec[-32] rec[-8]\n",
    "DETECTOR rec[-31] rec[-7]\n",
    "DETECTOR rec[-29] rec[-5]\n",
    "DETECTOR rec[-27] rec[-3]\n",
    "DETECTOR rec[-48] rec[-24]\n",
    "DETECTOR rec[-47] rec[-23]\n",
    "DETECTOR rec[-45] rec[-21]\n",
    "DETECTOR rec[-43] rec[-19]\n",
    "DETECTOR rec[-40] rec[-16]\n",
    "DETECTOR rec[-38] rec[-14]\n",
    "DETECTOR rec[-35] rec[-11]\n",
    "DETECTOR rec[-33] rec[-9]\n",
    "DETECTOR rec[-30] rec[-6]\n",
    "DETECTOR rec[-28] rec[-4]\n",
    "DETECTOR rec[-26] rec[-2]\n",
    "DETECTOR rec[-25] rec[-1]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 0 1\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 47 48\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 49 50\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 60 66 68 70 76 78 80 86 88 90 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 96 97\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 8 10 18 20 28 30 38 40 47 48 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-94] rec[-70]\n",
    "DETECTOR rec[-44] rec[-92] rec[-68]\n",
    "DETECTOR rec[-42] rec[-90] rec[-66]\n",
    "DETECTOR rec[-41] rec[-89] rec[-65]\n",
    "DETECTOR rec[-39] rec[-87] rec[-63]\n",
    "DETECTOR rec[-37] rec[-85] rec[-61]\n",
    "DETECTOR rec[-36] rec[-84] rec[-60]\n",
    "DETECTOR rec[-34] rec[-82] rec[-58]\n",
    "DETECTOR rec[-32] rec[-80] rec[-56]\n",
    "DETECTOR rec[-31] rec[-79] rec[-55]\n",
    "DETECTOR rec[-29] rec[-77] rec[-53]\n",
    "DETECTOR rec[-27] rec[-75] rec[-51]\n",
    "DETECTOR rec[-48] rec[-96]\n",
    "DETECTOR rec[-47] rec[-95]\n",
    "DETECTOR rec[-45] rec[-93]\n",
    "DETECTOR rec[-43] rec[-91]\n",
    "DETECTOR rec[-40] rec[-88]\n",
    "DETECTOR rec[-38] rec[-86]\n",
    "DETECTOR rec[-35] rec[-83]\n",
    "DETECTOR rec[-33] rec[-81]\n",
    "DETECTOR rec[-30] rec[-78]\n",
    "DETECTOR rec[-28] rec[-76]\n",
    "DETECTOR rec[-26] rec[-74]\n",
    "DETECTOR rec[-25] rec[-73]\n",
    "DETECTOR rec[-22] rec[-70]\n",
    "DETECTOR rec[-20] rec[-68]\n",
    "DETECTOR rec[-18] rec[-66]\n",
    "DETECTOR rec[-17] rec[-65]\n",
    "DETECTOR rec[-15] rec[-63]\n",
    "DETECTOR rec[-13] rec[-61]\n",
    "DETECTOR rec[-12] rec[-60]\n",
    "DETECTOR rec[-10] rec[-58]\n",
    "DETECTOR rec[-8] rec[-56]\n",
    "DETECTOR rec[-7] rec[-55]\n",
    "DETECTOR rec[-5] rec[-53]\n",
    "DETECTOR rec[-3] rec[-51]\n",
    "DETECTOR rec[-24] rec[-72] rec[-96]\n",
    "DETECTOR rec[-23] rec[-71] rec[-95]\n",
    "DETECTOR rec[-21] rec[-69] rec[-93]\n",
    "DETECTOR rec[-19] rec[-67] rec[-91]\n",
    "DETECTOR rec[-16] rec[-64] rec[-88]\n",
    "DETECTOR rec[-14] rec[-62] rec[-86]\n",
    "DETECTOR rec[-11] rec[-59] rec[-83]\n",
    "DETECTOR rec[-9] rec[-57] rec[-81]\n",
    "DETECTOR rec[-6] rec[-54] rec[-78]\n",
    "DETECTOR rec[-4] rec[-52] rec[-76]\n",
    "DETECTOR rec[-2] rec[-50] rec[-74]\n",
    "DETECTOR rec[-1] rec[-49] rec[-73]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SQRT_Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-96] rec[-72]\n",
    "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-94] rec[-70]\n",
    "DETECTOR rec[-46] rec[-41] rec[-92] rec[-68]\n",
    "DETECTOR rec[-45] rec[-40] rec[-91] rec[-67]\n",
    "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-89] rec[-65]\n",
    "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-87] rec[-63]\n",
    "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-86] rec[-62]\n",
    "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-84] rec[-60]\n",
    "DETECTOR rec[-36] rec[-31] rec[-82] rec[-58]\n",
    "DETECTOR rec[-35] rec[-30] rec[-81] rec[-57]\n",
    "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-79] rec[-55]\n",
    "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-77] rec[-53]\n",
    "DETECTOR rec[-25] rec[-24] rec[-20] rec[-19] rec[-72]\n",
    "DETECTOR rec[-23] rec[-22] rec[-18] rec[-17] rec[-70]\n",
    "DETECTOR rec[-21] rec[-16] rec[-68]\n",
    "DETECTOR rec[-20] rec[-15] rec[-67]\n",
    "DETECTOR rec[-19] rec[-18] rec[-14] rec[-13] rec[-65]\n",
    "DETECTOR rec[-17] rec[-16] rec[-12] rec[-11] rec[-63]\n",
    "DETECTOR rec[-15] rec[-14] rec[-10] rec[-9] rec[-62]\n",
    "DETECTOR rec[-13] rec[-12] rec[-8] rec[-7] rec[-60]\n",
    "DETECTOR rec[-11] rec[-6] rec[-58]\n",
    "DETECTOR rec[-10] rec[-5] rec[-57]\n",
    "DETECTOR rec[-9] rec[-8] rec[-4] rec[-3] rec[-55]\n",
    "DETECTOR rec[-7] rec[-6] rec[-2] rec[-1] rec[-53]\n",
    "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
    "        \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "num_layers = 3\n",
    "num_cxs_per_round = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "        'bias_preserving_gates': 'False',\n",
    "        'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "        'SSR': 'True', 'cycles': str(num_layers - 1),\n",
    "        'ordering': gate_ordering,\n",
    "        'decoder': 'MLE',\n",
    "        'circuit_type': f'logical_CX_NL{num_layers}_NCX{num_cxs_per_round}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "        'loss_decoder': 'independent',\n",
    "        'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "\n",
    "# circuit = stim.Circuit(new_circuit_txt)\n",
    "# test_measurement_events = np.ones((1,146)).astype(bool)\n",
    "\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory) # needs to be all +1\n",
    "\n",
    "# detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "#         1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "#         1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "#         1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "#         1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "#         -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "#         1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "#         -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "# print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "# detection_events_signs_exp - detection_events_signs_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sasha's circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1\n",
      "  1  1  1  1 -1  1 -1 -1  1  1 -1  1  1  1  1  1 -1  1  1  1  1 -1 -1 -1\n",
      " -1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1 -1  1  1  1  1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  0.,  0.,  0.,  0., -2., -2., -2.,  2.,  2., -2., -2.,\n",
       "        0., -2.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0., -2., -2.,  0.,\n",
       "        0.,  0.,  0., -2., -2., -2.,  0.,  0.,  2.,  2.,  2.,  0., -2.,\n",
       "        0.,  2.,  0.,  0.,  0., -2.,  0.,  2., -2., -2.,  0.,  2.,  0.,\n",
       "        0.,  2.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -2., -2., -2.,  0.,  0.,  0.,  0.,  0., -2.,\n",
       "        0.,  0.,  0., -2., -2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_txt = \"\"\"\n",
    "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "SQRT_Y 7 9 11 19 21 27 29 31 39 41 56 58 60 68 70 76 78 80 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97 66 86 17 37\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 11 31\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 17 37\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 60 80\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 66 68 70 76 78 86 88 90 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 66 86\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 19 21 27 29 39 41 56 58 68 70 76 78 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97 66 86 17 37 60 80 11 31\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-22]\n",
    "DETECTOR rec[-44] rec[-20]\n",
    "DETECTOR rec[-42] rec[-18]\n",
    "DETECTOR rec[-41] rec[-17]\n",
    "DETECTOR rec[-39] rec[-15]\n",
    "DETECTOR rec[-37] rec[-13]\n",
    "DETECTOR rec[-36] rec[-12]\n",
    "DETECTOR rec[-34] rec[-10]\n",
    "DETECTOR rec[-32] rec[-8]\n",
    "DETECTOR rec[-31] rec[-7]\n",
    "DETECTOR rec[-29] rec[-5]\n",
    "DETECTOR rec[-27] rec[-3]\n",
    "DETECTOR rec[-48] rec[-24]\n",
    "DETECTOR rec[-47] rec[-23]\n",
    "DETECTOR rec[-45] rec[-21]\n",
    "DETECTOR rec[-43] rec[-19]\n",
    "DETECTOR rec[-40] rec[-16]\n",
    "DETECTOR rec[-38] rec[-14]\n",
    "DETECTOR rec[-35] rec[-11]\n",
    "DETECTOR rec[-33] rec[-9]\n",
    "DETECTOR rec[-30] rec[-6]\n",
    "DETECTOR rec[-28] rec[-4]\n",
    "DETECTOR rec[-26] rec[-2]\n",
    "DETECTOR rec[-25] rec[-1]\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 0 1\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 47 48\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 49 50\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 60 66 68 70 76 78 80 86 88 90 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 96 97\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-94] rec[-70]\n",
    "DETECTOR rec[-44] rec[-92] rec[-68]\n",
    "DETECTOR rec[-42] rec[-90] rec[-66]\n",
    "DETECTOR rec[-41] rec[-89] rec[-65]\n",
    "DETECTOR rec[-39] rec[-87] rec[-63]\n",
    "DETECTOR rec[-37] rec[-85] rec[-61]\n",
    "DETECTOR rec[-36] rec[-84] rec[-60]\n",
    "DETECTOR rec[-34] rec[-82] rec[-58]\n",
    "DETECTOR rec[-32] rec[-80] rec[-56]\n",
    "DETECTOR rec[-31] rec[-79] rec[-55]\n",
    "DETECTOR rec[-29] rec[-77] rec[-53]\n",
    "DETECTOR rec[-27] rec[-75] rec[-51]\n",
    "DETECTOR rec[-48] rec[-96]\n",
    "DETECTOR rec[-47] rec[-95]\n",
    "DETECTOR rec[-45] rec[-93]\n",
    "DETECTOR rec[-43] rec[-91]\n",
    "DETECTOR rec[-40] rec[-88]\n",
    "DETECTOR rec[-38] rec[-86]\n",
    "DETECTOR rec[-35] rec[-83]\n",
    "DETECTOR rec[-33] rec[-81]\n",
    "DETECTOR rec[-30] rec[-78]\n",
    "DETECTOR rec[-28] rec[-76]\n",
    "DETECTOR rec[-26] rec[-74]\n",
    "DETECTOR rec[-25] rec[-73]\n",
    "DETECTOR rec[-22] rec[-70]\n",
    "DETECTOR rec[-20] rec[-68]\n",
    "DETECTOR rec[-18] rec[-66]\n",
    "DETECTOR rec[-17] rec[-65]\n",
    "DETECTOR rec[-15] rec[-63]\n",
    "DETECTOR rec[-13] rec[-61]\n",
    "DETECTOR rec[-12] rec[-60]\n",
    "DETECTOR rec[-10] rec[-58]\n",
    "DETECTOR rec[-8] rec[-56]\n",
    "DETECTOR rec[-7] rec[-55]\n",
    "DETECTOR rec[-5] rec[-53]\n",
    "DETECTOR rec[-3] rec[-51]\n",
    "DETECTOR rec[-24] rec[-72] rec[-96]\n",
    "DETECTOR rec[-23] rec[-71] rec[-95]\n",
    "DETECTOR rec[-21] rec[-69] rec[-93]\n",
    "DETECTOR rec[-19] rec[-67] rec[-91]\n",
    "DETECTOR rec[-16] rec[-64] rec[-88]\n",
    "DETECTOR rec[-14] rec[-62] rec[-86]\n",
    "DETECTOR rec[-11] rec[-59] rec[-83]\n",
    "DETECTOR rec[-9] rec[-57] rec[-81]\n",
    "DETECTOR rec[-6] rec[-54] rec[-78]\n",
    "DETECTOR rec[-4] rec[-52] rec[-76]\n",
    "DETECTOR rec[-2] rec[-50] rec[-74]\n",
    "DETECTOR rec[-1] rec[-49] rec[-73]\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-96] rec[-72]\n",
    "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-94] rec[-70]\n",
    "DETECTOR rec[-46] rec[-41] rec[-92] rec[-68]\n",
    "DETECTOR rec[-45] rec[-40] rec[-91] rec[-67]\n",
    "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-89] rec[-65]\n",
    "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-87] rec[-63]\n",
    "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-86] rec[-62]\n",
    "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-84] rec[-60]\n",
    "DETECTOR rec[-36] rec[-31] rec[-82] rec[-58]\n",
    "DETECTOR rec[-35] rec[-30] rec[-81] rec[-57]\n",
    "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-79] rec[-55]\n",
    "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-77] rec[-53]\n",
    "DETECTOR rec[-25] rec[-24] rec[-20] rec[-19] rec[-72]\n",
    "DETECTOR rec[-23] rec[-22] rec[-18] rec[-17] rec[-70]\n",
    "DETECTOR rec[-21] rec[-16] rec[-68]\n",
    "DETECTOR rec[-20] rec[-15] rec[-67]\n",
    "DETECTOR rec[-19] rec[-18] rec[-14] rec[-13] rec[-65]\n",
    "DETECTOR rec[-17] rec[-16] rec[-12] rec[-11] rec[-63]\n",
    "DETECTOR rec[-15] rec[-14] rec[-10] rec[-9] rec[-62]\n",
    "DETECTOR rec[-13] rec[-12] rec[-8] rec[-7] rec[-60]\n",
    "DETECTOR rec[-11] rec[-6] rec[-58]\n",
    "DETECTOR rec[-10] rec[-5] rec[-57]\n",
    "DETECTOR rec[-9] rec[-8] rec[-4] rec[-3] rec[-55]\n",
    "DETECTOR rec[-7] rec[-6] rec[-2] rec[-1] rec[-53]\n",
    "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "circuit = stim.Circuit(circuit_txt)\n",
    "# detection_events_theory, observable_flips_theory = circuit.compile_m2d_converter().convert(measurements = exp_measurements.astype(bool), separate_observables = True)\n",
    "test_measurement_events = np.ones((1,146)).astype(bool)\n",
    "test_detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=test_measurement_events, separate_observables=True)\n",
    "# print(list(test_detection_events.astype(int)))\n",
    "detection_events_circuit = 1-2*test_detection_events.astype(int).squeeze() # detection --> -1, no detection --> +1\n",
    "\n",
    "print(detection_events_circuit)\n",
    "\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_circuit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_error_model = circuit.detector_error_model(decompose_errors=False, approximate_disjoint_errors=True, ignore_decomposition_failures=True, allow_gauge_detectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1\n",
      "  1  1  1  1 -1  1 -1 -1  1  1 -1  1  1  1  1  1 -1  1  1  1  1 -1 -1 -1\n",
      " -1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1 -1 -1 -1  1  1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  0.,  0.,  0.,  0., -2., -2., -2.,  2.,  2., -2., -2.,\n",
       "        0., -2.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0., -2., -2.,  0.,\n",
       "        0.,  0.,  0., -2., -2., -2.,  0.,  0.,  2.,  2.,  2.,  0., -2.,\n",
       "        0.,  2.,  0.,  0.,  0., -2.,  0.,  2., -2., -2.,  0.,  2.,  0.,\n",
       "        0.,  2.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -2., -2., -2.,  0.,  2.,  2.,  0.,  0., -2.,\n",
       "        0.,  2.,  2., -2., -2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_txt = \"\"\"\n",
    "\n",
    "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
    "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 11 31\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 17 19 21 27 29 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 17 37\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 60 80\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 66 68 70 76 78 86 88 90 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 66 86\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 17 19 21 27 29 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-22]\n",
    "DETECTOR rec[-44] rec[-20]\n",
    "DETECTOR rec[-42] rec[-18]\n",
    "DETECTOR rec[-41] rec[-17]\n",
    "DETECTOR rec[-39] rec[-15]\n",
    "DETECTOR rec[-37] rec[-13]\n",
    "DETECTOR rec[-36] rec[-12]\n",
    "DETECTOR rec[-34] rec[-10]\n",
    "DETECTOR rec[-32] rec[-8]\n",
    "DETECTOR rec[-31] rec[-7]\n",
    "DETECTOR rec[-29] rec[-5]\n",
    "DETECTOR rec[-27] rec[-3]\n",
    "DETECTOR rec[-48] rec[-24]\n",
    "DETECTOR rec[-47] rec[-23]\n",
    "DETECTOR rec[-45] rec[-21]\n",
    "DETECTOR rec[-43] rec[-19]\n",
    "DETECTOR rec[-40] rec[-16]\n",
    "DETECTOR rec[-38] rec[-14]\n",
    "DETECTOR rec[-35] rec[-11]\n",
    "DETECTOR rec[-33] rec[-9]\n",
    "DETECTOR rec[-30] rec[-6]\n",
    "DETECTOR rec[-28] rec[-4]\n",
    "DETECTOR rec[-26] rec[-2]\n",
    "DETECTOR rec[-25] rec[-1]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 0 1\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 47 48\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 49 50\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 60 66 68 70 76 78 80 86 88 90 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 96 97\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 8 10 18 20 28 30 38 40 47 48 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-94] rec[-70]\n",
    "DETECTOR rec[-44] rec[-92] rec[-68]\n",
    "DETECTOR rec[-42] rec[-90] rec[-66]\n",
    "DETECTOR rec[-41] rec[-89] rec[-65]\n",
    "DETECTOR rec[-39] rec[-87] rec[-63]\n",
    "DETECTOR rec[-37] rec[-85] rec[-61]\n",
    "DETECTOR rec[-36] rec[-84] rec[-60]\n",
    "DETECTOR rec[-34] rec[-82] rec[-58]\n",
    "DETECTOR rec[-32] rec[-80] rec[-56]\n",
    "DETECTOR rec[-31] rec[-79] rec[-55]\n",
    "DETECTOR rec[-29] rec[-77] rec[-53]\n",
    "DETECTOR rec[-27] rec[-75] rec[-51]\n",
    "DETECTOR rec[-48] rec[-96]\n",
    "DETECTOR rec[-47] rec[-95]\n",
    "DETECTOR rec[-45] rec[-93]\n",
    "DETECTOR rec[-43] rec[-91]\n",
    "DETECTOR rec[-40] rec[-88]\n",
    "DETECTOR rec[-38] rec[-86]\n",
    "DETECTOR rec[-35] rec[-83]\n",
    "DETECTOR rec[-33] rec[-81]\n",
    "DETECTOR rec[-30] rec[-78]\n",
    "DETECTOR rec[-28] rec[-76]\n",
    "DETECTOR rec[-26] rec[-74]\n",
    "DETECTOR rec[-25] rec[-73]\n",
    "DETECTOR rec[-22] rec[-70]\n",
    "DETECTOR rec[-20] rec[-68]\n",
    "DETECTOR rec[-18] rec[-66]\n",
    "DETECTOR rec[-17] rec[-65]\n",
    "DETECTOR rec[-15] rec[-63]\n",
    "DETECTOR rec[-13] rec[-61]\n",
    "DETECTOR rec[-12] rec[-60]\n",
    "DETECTOR rec[-10] rec[-58]\n",
    "DETECTOR rec[-8] rec[-56]\n",
    "DETECTOR rec[-7] rec[-55]\n",
    "DETECTOR rec[-5] rec[-53]\n",
    "DETECTOR rec[-3] rec[-51]\n",
    "DETECTOR rec[-24] rec[-72] rec[-96]\n",
    "DETECTOR rec[-23] rec[-71] rec[-95]\n",
    "DETECTOR rec[-21] rec[-69] rec[-93]\n",
    "DETECTOR rec[-19] rec[-67] rec[-91]\n",
    "DETECTOR rec[-16] rec[-64] rec[-88]\n",
    "DETECTOR rec[-14] rec[-62] rec[-86]\n",
    "DETECTOR rec[-11] rec[-59] rec[-83]\n",
    "DETECTOR rec[-9] rec[-57] rec[-81]\n",
    "DETECTOR rec[-6] rec[-54] rec[-78]\n",
    "DETECTOR rec[-4] rec[-52] rec[-76]\n",
    "DETECTOR rec[-2] rec[-50] rec[-74]\n",
    "DETECTOR rec[-1] rec[-49] rec[-73]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-96] rec[-72]\n",
    "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-94] rec[-70]\n",
    "DETECTOR rec[-46] rec[-41] rec[-92] rec[-68]\n",
    "DETECTOR rec[-45] rec[-40] rec[-91] rec[-67]\n",
    "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-89] rec[-65]\n",
    "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-87] rec[-63]\n",
    "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-86] rec[-62]\n",
    "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-84] rec[-60]\n",
    "DETECTOR rec[-36] rec[-31] rec[-82] rec[-58]\n",
    "DETECTOR rec[-35] rec[-30] rec[-81] rec[-57]\n",
    "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-79] rec[-55]\n",
    "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-77] rec[-53]\n",
    "DETECTOR rec[-25] rec[-24] rec[-20] rec[-19] rec[-72]\n",
    "DETECTOR rec[-23] rec[-22] rec[-18] rec[-17] rec[-70]\n",
    "DETECTOR rec[-21] rec[-16] rec[-68]\n",
    "DETECTOR rec[-20] rec[-15] rec[-67]\n",
    "DETECTOR rec[-19] rec[-18] rec[-14] rec[-13] rec[-65]\n",
    "DETECTOR rec[-17] rec[-16] rec[-12] rec[-11] rec[-63]\n",
    "DETECTOR rec[-15] rec[-14] rec[-10] rec[-9] rec[-62]\n",
    "DETECTOR rec[-13] rec[-12] rec[-8] rec[-7] rec[-60]\n",
    "DETECTOR rec[-11] rec[-6] rec[-58]\n",
    "DETECTOR rec[-10] rec[-5] rec[-57]\n",
    "DETECTOR rec[-9] rec[-8] rec[-4] rec[-3] rec[-55]\n",
    "DETECTOR rec[-7] rec[-6] rec[-2] rec[-1] rec[-53]\n",
    "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "circuit = stim.Circuit(circuit_txt)\n",
    "# detection_events_theory, observable_flips_theory = circuit.compile_m2d_converter().convert(measurements = exp_measurements.astype(bool), separate_observables = True)\n",
    "test_measurement_events = np.ones((1,146)).astype(bool)\n",
    "test_detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=test_measurement_events, separate_observables=True)\n",
    "# print(list(test_detection_events.astype(int)))\n",
    "detection_events_circuit = 1-2*test_detection_events.astype(int).squeeze() # detection --> -1, no detection --> +1\n",
    "\n",
    "print(detection_events_circuit)\n",
    "\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_signs_theory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with H = Rydagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 1\n",
      "final measurement_index = 146\n",
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  2.,  0.,  0.,  0.,  0., -2., -2.,  2.,  2., -2., -2.,\n",
       "        0., -2.,  0.,  2.,  0.,  0.,  0., -2.,  0.,  2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., -2., -2.,  0., -2.,  0.,  2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2., -2.,\n",
       "        0.,  2.,  2., -2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory)\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_signs_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,\n",
       "       -2.,  2., -2.,  0.,  0.,  0.,  0.,  2.,  2., -2., -2.,  2.,  2.,\n",
       "       -2.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  2.,  2.,  0.,  2.,  0., -2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  2.,  0., -2.,  0.,\n",
       "        0., -2., -2.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_events_signs_exp = np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "# Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "# Find detection event signs\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory)\n",
    "\n",
    "\n",
    "detection_events_signs_theory - detection_events_signs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n"
     ]
    }
   ],
   "source": [
    "num_shots = 100\n",
    "# Change #2: a function that doesn't decode, just gives you the measurements, detection events, observables and the circuit:\n",
    "measurement_events_all_shots, detection_events_all_shots, observable_flips_all_shots, LogicalCircuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "measurement_events = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                            exp_measurements[:, 1, :distance**2-1],\n",
    "                            exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                            exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                            exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                            exp_measurements[:, 1, 2*(distance**2-1):]], axis=1).astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "detection_events, observable_flips = LogicalCircuit.compile_m2d_converter().convert(measurements=measurement_events, separate_observables=True)\n",
    "detection_events_signs = -1*np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False,  True, False],\n",
       "       [False,  True, False, ..., False,  True, False],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True, False],\n",
       "       [ True,  True, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False,  True,  True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "measurement_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_events_all_shots\n",
    "\n",
    "detection_events_signs = np.sign(np.nanmean(detection_events_all_shots,axis = -1))\n",
    "\n",
    "detection_events_signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 5\n",
    "# qubit_states_nans_perlog = np.load('2024_10_15_measurement_events_1CNOT_XX.npy').astype(bool)\n",
    "qubit_states_nans_perlog = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "qubit_states_nans_perlog = qubit_states_nans_perlog.transpose(1,2,0)\n",
    "# exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "#                             exp_measurements[:, 1, :distance**2-1],\n",
    "#                             exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "#                             exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "#                             exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "#                             exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "perfect_reps = np.ones(qubit_states_nans_perlog.shape[-1]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_losses_per_stab_perlog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_62737/3085604329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_logicals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstabilizer_prod_per_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperfect_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ancillas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0merror_prob_Astabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Astabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0merror_prob_Bstabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Bstabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_62737/3085604329.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_logicals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstabilizer_prod_per_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperfect_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ancillas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0merror_prob_Astabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Astabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0merror_prob_Bstabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Bstabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_losses_per_stab_perlog' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_data_blocks = num_logicals = 2\n",
    "\n",
    "num_ancilla_blocks = 2\n",
    "num_rounds = num_ancilla_blocks + 1\n",
    "\n",
    "ancilla_grid_size = 6\n",
    "data_grid_size = d = 5\n",
    "xspc = 3\n",
    "yspc = 2\n",
    "\n",
    "num_datas = 25\n",
    "num_ancillas = 24\n",
    "total_num_ancillas = num_ancillas*num_ancilla_blocks*num_logicals\n",
    "total_num_datas = num_datas*num_data_blocks\n",
    "num_physicals = total_num_ancillas + total_num_datas\n",
    "\n",
    "\n",
    "\n",
    "stabilizer_weights = np.zeros(num_ancillas)\n",
    "stabilizer_masks = np.zeros((num_ancillas, num_datas), dtype = bool)\n",
    "\n",
    "ancilla_Astabs_mask = Zstabs_mask =  np.array([1,1,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,1,1], dtype = bool) \n",
    "ancilla_Bstabs_mask = Xstabs_mask = (1-ancilla_Astabs_mask).astype(bool)\n",
    "\n",
    "deterministic_rounds = np.ones(num_rounds).astype(bool)\n",
    "nondeterministic_rounds = np.array([0] + (num_rounds - 2)*[1] + [0]).astype(bool)\n",
    "\n",
    "\n",
    "### HARDCODE FOR NOW\n",
    "stabilizer_weights = np.array([2., 2., 4., 4., 4., 4., 2., 2., 4., 4., 4., 4., 4., 4., 4., 4., 2.,\n",
    "       2., 4., 4., 4., 4., 2., 2.])\n",
    "stabilizer_masks = np.array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]).astype(bool)\n",
    "\n",
    "\n",
    "stab2A = (ancilla_Astabs_mask & (stabilizer_weights == 2))\n",
    "stab2B = (ancilla_Bstabs_mask & (stabilizer_weights == 2))\n",
    "stab4A = (ancilla_Astabs_mask & (stabilizer_weights == 4))\n",
    "stab4B = (ancilla_Bstabs_mask & (stabilizer_weights == 4))\n",
    "\n",
    "\n",
    "vertical_string_masks = np.zeros((d,num_datas)).astype(bool)\n",
    "horizontal_string_masks = np.zeros((d,num_datas)).astype(bool)\n",
    "\n",
    "for i in range(d):\n",
    "    vertical_string_masks[i,i::d] = True\n",
    "    horizontal_string_masks[i,i*d:d*(i+1)] = True\n",
    "\n",
    "# qubit_states_nans = atoms_present_final.copy()\n",
    "\n",
    "\n",
    "# ## Reshape into per logical\n",
    "# qubit_states_nans_perlog = np.array([qubit_states_nans[logical_qubit_masks[i]] for i in range(num_logicals)])\n",
    "# qubit_states_perlog = np.nan_to_num(qubit_states_nans_perlog, nan = 3) #convert nan to 3 (so it then becomes 2 in the next line)\n",
    "# qubit_states_perlog = ((qubit_states_perlog + 1)/2).astype(int)\n",
    "\n",
    "# data_losses_perlog = np.isnan(qubit_states_nans_perlog[:,-num_datas:])\n",
    "# data_losses_per_stab_perlog = np.array([np.sum(data_losses_perlog[:,stabilizer_masks[i]], axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "# num_data_losses_perlog = np.sum(data_losses_perlog, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stabilizer_prod_per_round = []\n",
    "stabilizer_prod_per_round_withloss = []\n",
    "\n",
    "loss_sign = +1\n",
    "\n",
    "for r in range(-1,num_ancilla_blocks):\n",
    "    if r == -1:\n",
    "        stab_second = qubit_states_nans_perlog[:,num_ancillas*(r+1):num_ancillas*(r+2)]\n",
    "        stab_first = np.ones_like(stab_second)\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second_withloss = np.nan_to_num(stab_second,nan = loss_sign)\n",
    "                                            \n",
    "    elif r == num_ancilla_blocks - 1:\n",
    "        stab_first = qubit_states_nans_perlog[:,num_ancillas*r:num_ancillas*(r+1)]\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second = np.array([np.prod(qubit_states_nans_perlog[:,-num_datas:][:,stabilizer_masks[i]],axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "        stab_second_withloss = np.array([np.prod(np.nan_to_num(qubit_states_nans_perlog[:,-num_datas:][:,stabilizer_masks[i]], nan = loss_sign),axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "    else:\n",
    "        stab_first = qubit_states_nans_perlog[:,num_ancillas*r:num_ancillas*(r+1)]\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second = qubit_states_nans_perlog[:,num_ancillas*(r+1):num_ancillas*(r+2)]\n",
    "        stab_second_withloss = np.nan_to_num(stab_second, nan = loss_sign)\n",
    "\n",
    "    stab_product_per_round = stab_first*stab_second\n",
    "    stab_product_per_round_withloss = stab_first_withloss*stab_second_withloss #convert loss to qubit state |0>\n",
    "\n",
    "    stabilizer_prod_per_round.append(stab_product_per_round)\n",
    "    stabilizer_prod_per_round_withloss.append(stab_product_per_round_withloss)\n",
    "\n",
    "stabilizer_prod_per_round = np.array(stabilizer_prod_per_round)\n",
    "stabilizer_prod_per_round_withloss = np.array(stabilizer_prod_per_round_withloss)\n",
    "\n",
    "# For sublattice A, and sublattice B separately\n",
    "\n",
    "error_prob_Astabs = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Astabs_mask],axis = -1)))/2\n",
    "error_prob_Bstabs = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Bstabs_mask], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_postselected = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Astabs_mask][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Bstabs_mask][:,:,:,perfect_reps], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_fully_postselected = np.zeros_like(error_prob_Astabs_postselected)\n",
    "error_prob_Bstabs_fully_postselected = np.zeros_like(error_prob_Bstabs_postselected)\n",
    "\n",
    "stabilizer_prod_per_round_per_stab_dataloss_postselection = []\n",
    "for log in range(num_logicals):\n",
    "    stabilizer_prod_per_round_per_stab_dataloss_postselection += [[stabilizer_prod_per_round[:,log,i][:,data_losses_per_stab_perlog[log,i] == 0][:,perfect_reps[data_losses_per_stab_perlog[log,i] == 0]] for i in range(num_ancillas)]]\n",
    "    error_prob_Astabs_fully_postselected[:,log] = 1-(1+np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[-1][i],axis = -1) for i in np.where(ancilla_Astabs_mask)[0]]).T)/2\n",
    "    error_prob_Bstabs_fully_postselected[:,log] = 1-(1+np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[-1][i],axis = -1) for i in np.where(ancilla_Bstabs_mask)[0]]).T)/2\n",
    "\n",
    "plt.figure(\"Detected error per round\", figsize = (15,5))\n",
    "plt.clf()\n",
    "for log in range(num_logicals):  \n",
    "    Astab_good_rounds_thislog = deterministic_rounds if prep_basis[log] == 'vertical' else nondeterministic_rounds\n",
    "    Bstab_good_rounds_thislog = nondeterministic_rounds if prep_basis[log] == 'vertical' else deterministic_rounds\n",
    "    \n",
    "    plt.subplot(1,2,log+1)\n",
    "    plt.bar(np.arange(num_rounds)-0.2,np.nanmean(error_prob_Astabs[:,log],axis = -1),width = 0.4,label = \"A\", color = \"b\", alpha = 0.6)\n",
    "    plt.bar(np.arange(num_rounds)+0.2,np.nanmean(error_prob_Bstabs[:,log],axis = -1),width = 0.4,label = \"B\", color = \"orange\", alpha = 0.6)\n",
    "    plt.bar(np.arange(num_rounds)-0.2,np.nanmean(error_prob_Astabs_postselected[:,log],axis = -1),width = 0.4,label = \"A (post)\",color = \"b\")\n",
    "    plt.bar(np.arange(num_rounds)+0.2,np.nanmean(error_prob_Bstabs_postselected[:,log],axis = -1),width = 0.4,label = \"B (post)\", color = \"orange\")\n",
    "    \n",
    "    plt.xticks(np.arange(num_rounds))\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Detected error probability\")\n",
    "    plt.ylim(0,0.6)\n",
    "    plt.legend()\n",
    "    plt.title(f\"\"\"Average error prob (no postselection, exclude loss): {np.nanmean(np.concatenate((error_prob_Astabs[:,log][Astab_good_rounds_thislog],error_prob_Bstabs[:,log][Bstab_good_rounds_thislog]))):.4f}\n",
    "    Average error prob (postselected, exclude loss): {np.nanmean(np.concatenate((error_prob_Astabs_postselected[:,log][Astab_good_rounds_thislog],error_prob_Bstabs_postselected[:,log][Bstab_good_rounds_thislog]))):.4f}\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_prob_Astabs_postselected_weight_2 = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_weight_2  = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "error_prob_Astabs_postselected_weight_4 = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_weight_4  = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_postselected_weight_2_err = np.nanstd(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps],axis = -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Bstabs_postselected_weight_2_err  = np.nanstd(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps], axis= -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Astabs_postselected_weight_4_err = np.nanstd(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps],axis = -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Bstabs_postselected_weight_4_err  = np.nanstd(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps], axis= -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps].shape[-1])\n",
    "\n",
    "stab_mean_prod_stab2A = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab2A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab2B = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab2B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab4A = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab4A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab4B = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab4B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "\n",
    "error_prob_Astabs_fully_postselected_weight_2 = 1-(1+np.abs(stab_mean_prod_stab2A))/2\n",
    "error_prob_Bstabs_fully_postselected_weight_2  = 1-(1+np.abs(stab_mean_prod_stab2B))/2\n",
    "error_prob_Astabs_fully_postselected_weight_4 = 1-(1+np.abs(stab_mean_prod_stab4A))/2\n",
    "error_prob_Bstabs_fully_postselected_weight_4  = 1-(1+np.abs(stab_mean_prod_stab4B))/2\n",
    "\n",
    "error_prob_Astabs_fully_postselected_weight_2_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab2A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Bstabs_fully_postselected_weight_2_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab2B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Astabs_fully_postselected_weight_4_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab4A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Bstabs_fully_postselected_weight_4_err  = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab4B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "\n",
    "\n",
    "error_prob_Astabs_postselected_withloss_weight_2  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab2A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_withloss_weight_2  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab2B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "error_prob_Astabs_postselected_withloss_weight_4  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab4A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_withloss_weight_4  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab4B][:,:,:,perfect_reps], axis= -1)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "for log in range(num_logicals):  \n",
    "    Astab_good_rounds_thislog = deterministic_rounds if prep_basis[log] == 'vertical' else nondeterministic_rounds\n",
    "    Bstab_good_rounds_thislog = nondeterministic_rounds if prep_basis[log] == 'vertical' else deterministic_rounds\n",
    "    \n",
    "    plt.subplot(num_logicals,2,log*num_logicals + 1)\n",
    "\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_postselected_weight_2[Astab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_postselected_weight_2[Bstab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_postselected_weight_4[Astab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_postselected_weight_4[Bstab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_postselected_weight_2,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='steelblue')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_postselected_weight_2,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='steelblue', label='weight 2')\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_postselected_weight_4,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='firebrick')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_postselected_weight_4,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='firebrick', label='weight 4')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.xlabel('QEC cycle')\n",
    "    plt.ylabel(\"Detection probability\")\n",
    "    \n",
    "    all_good_weight2 = np.concatenate((error_prob_Astabs_postselected_weight_2[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_2[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4 =  np.concatenate((error_prob_Astabs_postselected_weight_4[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_4[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    all_good_weight2_err = np.concatenate((error_prob_Astabs_postselected_weight_2_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_2_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4_err = np.concatenate((error_prob_Astabs_postselected_weight_4_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_4_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    plt.title(f\"\"\"Logical {log+1}: Postselected on rearrangement only\n",
    "    Weight 2: {np.mean(all_good_weight2):.4f}({np.mean(all_good_weight2_err)/np.sqrt(all_good_weight2.size):.4f}), Weight 4: {np.mean(all_good_weight4):.4f}({np.mean(all_good_weight4_err)/np.sqrt(all_good_weight4.size):.4f})\n",
    "    Overall {np.mean(np.concatenate((all_good_weight2, all_good_weight4))):.4f}({np.mean(np.concatenate((all_good_weight2_err, all_good_weight4_err)))/np.sqrt(np.concatenate((all_good_weight2, all_good_weight4)).ravel().size):.4f})\"\"\")\n",
    "    \n",
    "    plt.subplot(num_logicals,2,log*num_logicals + 2)\n",
    "\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_fully_postselected_weight_2[Astab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_fully_postselected_weight_2[Bstab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_fully_postselected_weight_4[Astab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_fully_postselected_weight_4[Bstab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_fully_postselected_weight_2,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='steelblue')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_fully_postselected_weight_2,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='steelblue', label='weight 2')\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_fully_postselected_weight_4,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='firebrick')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_fully_postselected_weight_4,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='firebrick', label='weight 4')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.xlabel('QEC cycle')\n",
    "    plt.ylabel(\"Detection probability\")\n",
    "    all_good_weight2 = np.concatenate((error_prob_Astabs_fully_postselected_weight_2[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_2[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4 =  np.concatenate((error_prob_Astabs_fully_postselected_weight_4[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_4[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    all_good_weight2_err = np.concatenate((error_prob_Astabs_fully_postselected_weight_2_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_2_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4_err = np.concatenate((error_prob_Astabs_fully_postselected_weight_4_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_4_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    plt.title(f\"\"\"Logical {log + 1}: Postselected on rearrangement and no data loss\n",
    "    Weight 2: {np.mean(all_good_weight2):.4f}({np.mean(all_good_weight2_err)/np.sqrt(all_good_weight2.size):.4f}), Weight 4: {np.mean(all_good_weight4):.4f}({np.mean(all_good_weight4_err)/np.sqrt(all_good_weight4.size):.4f})\n",
    "    Overall {np.mean(np.concatenate((all_good_weight2, all_good_weight4))):.4f}({np.mean(np.concatenate((all_good_weight2_err, all_good_weight4_err)))/np.sqrt(np.concatenate((all_good_weight2, all_good_weight4)).ravel().size):.4f})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in np.arange(num_logicals):\n",
    "    fig, axs = plt.subplots(ancilla_grid_size,ancilla_grid_size)\n",
    "    # fig.canvas.set_window_title(\"Ancilla stabilizers, excluding loss\")\n",
    "    fig.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "    count = 0\n",
    "    for i in range(ancilla_grid_size**2):\n",
    "        ax = axs[i//ancilla_grid_size,i%ancilla_grid_size]\n",
    "        if ancilla_block_mask[i]:\n",
    "            mean_stab = np.nanmean(stabilizer_prod_per_round[:,log,count,perfect_reps], axis = -1)\n",
    "            # ax.bar(np.arange(num_rounds),mean_stab, color = [\"r\",\"k\"][int(ancilla_Astabs_mask[count])])\n",
    "            ax.bar(np.arange(num_rounds),mean_stab, color = [\"r\",\"k\"][int(ancilla_Astabs_mask[count])])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_ylim(-1,1)\n",
    "            count+=1 \n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    fig.suptitle(\"Logical %i stab. products (perfect rearrangement, exclude loss)\"%(log+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "A = 'logical_CX_NL1_NCX2'\n",
    "\n",
    "print(int(A[13:14]))\n",
    "\n",
    "print(int(A[18:19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
