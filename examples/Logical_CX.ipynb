{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer_list = [3, 3, 3]\n",
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "final measurement_index = 146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_82407/2714425361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msimulate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdetection_events_signs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_simulated_measurement_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeta_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mget_simulated_measurement_events\u001b[0;34m(Meta_params, dx, dy, num_shots, noise_params, printing)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                 \u001b[0mphys_err_vec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_detection_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHeraldedCircuit_SWAP_LD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                 cycles = cycles, output_dir=\"\", save_filename=None, save_data_during_sim=True)\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         measurement_events_all_shots, detection_events_all_shots, observable_flips_all_shots, LogicalCircuit = simulator.sampling_with_loss(num_shots = num_shots,\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36msampling_with_loss\u001b[0;34m(self, num_shots, dx, dy, noise_params, circuit)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0mloss_detection_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_detection_events_all_shots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_shot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mexperimental_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_experimental_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_detection_events\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_detection_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0mmeasurement_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperimental_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_experimental_circuit\u001b[0;34m(self, loss_detection_events)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;31m# Step 1 - generate the circuit that is really running in the experiment, for the given loss pattern (without gates after losing qubits):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mexperimental_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_loss_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_by_instruction_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_losses_by_instruction_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoving_Pauli_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# no losses in this shot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_loss_circuit\u001b[0;34m(self, losses_by_instruction_ix, removing_Pauli_errors, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;31m#                                                             circuit_offset = first_loss_instruction_index,loss_qubits_remove_gates_range=loss_qubits_remove_gates_range,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;31m#                                                             removing_Pauli_errors=removing_Pauli_errors, remove_gates_due_to_loss=remove_gates_due_to_loss) # after removing the following gates with the lost qubits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         heralded_circuit_after_ix = self.generate_circuit_without_lost_qubit_faster(lost_qubits = lost_qubits, circuit = circuit_after_ix, \n\u001b[0m\u001b[1;32m    767\u001b[0m                                                                     \u001b[0mcircuit_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_loss_instruction_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_qubits_remove_gates_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_qubits_remove_gates_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                                                     removing_Pauli_errors=removing_Pauli_errors, remove_gates_due_to_loss=remove_gates_due_to_loss) # after removing the following gates with the lost qubits.\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_circuit_without_lost_qubit_faster\u001b[0;34m(self, lost_qubits, circuit, circuit_offset, loss_qubits_remove_gates_range, removing_Pauli_errors, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1350\u001b[0m                     \u001b[0mnew_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                 \u001b[0mnew_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_circuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "# num_rounds = 5\n",
    "num_layers = 2\n",
    "distance = 5\n",
    "n=5\n",
    "first_layer = int((n-1)/2)\n",
    "second_layer = int((n+1)/2)\n",
    "num_CX_per_layer_list = [first_layer, second_layer]\n",
    "# num_CX_per_layer_list = [1,1,3]\n",
    "num_CX_per_layer_list = [3,3,3]\n",
    "num_layers = len(num_CX_per_layer_list)\n",
    "assert len(num_CX_per_layer_list) ==  num_layers\n",
    "\n",
    "print(f\"num_CX_per_layer_list = {num_CX_per_layer_list}\")\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': '0',\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX', 'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0', 'num_CX_per_layer_list':num_CX_per_layer_list}\n",
    "\n",
    "noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "            'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "\n",
    "simulate_data = True\n",
    "num_shots = 1000\n",
    "if simulate_data:\n",
    "    detection_events_signs = None\n",
    "    measurement_events, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)\n",
    "\n",
    "\n",
    "else:\n",
    "    # measurement_events, detection_events, observable_flips, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "    # detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)    \n",
    "    # detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int) # Find detection event signs (not needed anymore)\n",
    "    detection_events_signs = None\n",
    "    exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "    measurement_events = exp_measurements[:num_shots]\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "logical_gap = True\n",
    "# circuit = get_lossless_circuit(Meta_params, distance, distance, noise_params)\n",
    "\n",
    "# DO IT\n",
    "if not logical_gap:\n",
    "    predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        measurement_events,\n",
    "                                                                        detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots=num_shots)\n",
    "\n",
    "else:\n",
    "    predictions, log_probabilities, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        measurement_events,\n",
    "                                                                        detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        logical_gaps=True, \n",
    "                                                                        noise_params=noise_params, num_shots=num_shots)\n",
    "\n",
    "\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "print('logical error',logical_probability)\n",
    "\n",
    "\n",
    "# error bar: (np.sqrt(P*(1-P)/num_shots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(measurement_events,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 1, 0, 2],\n",
       "       [1, 1, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical_CX__Nlayers3__NCX3_3_3\n",
      "final measurement_index = 146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9f444c36a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAADXz0lEQVR4nOx9d3wdxb392d3bVCzLVW5yBXdsXCi2MRCK6QmBAC8ECAQTeCQhtORBeC8BAiGVOL/kQSC0QEgeSYCE5oBDMTbGFBds3Ltc5CIXSVa5ZXd/f8zO7szszL1Xsoolzfl8/LlXe3d39l5Zd86ec77fMVzXdaGhoaGhoaGh0U4w2/sCNDQ0NDQ0NLo2NBnR0NDQ0NDQaFdoMqKhoaGhoaHRrtBkRENDQ0NDQ6NdocmIhoaGhoaGRrtCkxENDQ0NDQ2NdoUmIxoaGhoaGhrtCk1GNDQ0NDQ0NNoVkfa+gHzgOA527dqFbt26wTCM9r4cDQ0NDQ0NjTzgui5qa2sxYMAAmKZa/+gQZGTXrl0oLy9v78vQ0NDQ0NDQaAa2b9+OQYMGKV/vEGSkW7duAMibKSkpaeer0dDQ0NDQ0MgHNTU1KC8v9+dxFToEGaHWTElJiSYjGhoaGhoaHQy5IhY6wKqhoaGhoaHRrtBkRENDQ0NDQ6NdocmIhoaGhoaGRruiQ2RGNDQ0NDSOXriui0wmA9u22/tSNNoYlmUhEokccdsNTUY0NDQ0NJqNVCqFyspK1NfXt/elaLQTCgsL0b9/f8RisWafQ5MRDQ0NDY1mwXEcbNmyBZZlYcCAAYjFYroxZReC67pIpVLYt28ftmzZgmOPPTZrY7Ns0GREQ0NDQ6NZSKVScBwH5eXlKCwsbO/L0WgHFBQUIBqNYtu2bUilUkgkEs06jw6wamhoaGgcEZp7N6zROdASv3/9P0hDQ0NDQ0OjXdEsMvLII49g2LBhSCQSmDJlChYsWJB1/+effx4TJ070Qy7XXXcd9u/f36wL1tDQ0NDQ6KzYunUrDMPA8uXL2/tS2hRNJiMvvPACbr31Vtxzzz1YtmwZZs6cifPOOw8VFRXS/RcuXIhrrrkG119/PVatWoW//e1v+OSTTzB79uwjvngNDQ0NDY3OhPLyclRWVmL8+PHtfSm49957cfzxx7fJWE0mIw8//DCuv/56zJ49G2PGjMGcOXNQXl6ORx99VLr/4sWLMXToUNxyyy0YNmwYTjnlFNx444349NNPj/jiNTQ0NDQ0OgtSqRQsy0K/fv0QiXSt+pImkZFUKoUlS5Zg1qxZ3PZZs2Zh0aJF0mOmT5+OHTt24I033oDrutizZw/+/ve/44ILLlCOk0wmUVNTw/3T0NBoJ9RVAQt/DdTubu8r0dBoMbiui5///OcYPnw4CgoKMHHiRPz973+H67o466yzcO6558J1XQDAoUOHMHjwYNxzzz0AgPfeew+GYeD111/HxIkTkUgkcNJJJ2HlypXcGIsWLcKpp56KgoIClJeX45ZbbkFdXZ3/+tChQ/HAAw/g2muvRffu3XHDDTeEbBo61ptvvolJkyahoKAAZ5xxBvbu3Yu5c+dizJgxKCkpwVe/+lWu14vq/VHQ87799tuYOnUqCgsLMX36dKxbtw4A8Mwzz+C+++7DZ599BsMwYBgGnnnmmdb4VfgXnDd27tzpAnA/+OADbvuDDz7ojhw5Unnc3/72N7e4uNiNRCIuAPeLX/yim0qllPv/6Ec/cgGE/lVXVzflcjU0OhfsTPuM+/4vXfdHJa477972GV/jqEVDQ4O7evVqt6Ghwd/mOI5bl0y3+T/HcZp07T/4wQ/c0aNHu//617/cTZs2uU8//bQbj8fd9957z92xY4fbo0cPd86cOa7ruu4VV1zhTp061Z+33n33XReAO2bMGPett95yV6xY4V544YXu0KFD/X1WrFjhFhcXu7/+9a/d9evXux988IE7adIk99prr/WvYciQIW5JSYn7i1/8wt2wYYO7YcMGd8uWLS4Ad9myZdxYJ598srtw4UJ36dKl7jHHHOOedtpp7qxZs9ylS5e677//vturVy/3pz/9aV7vjz3vSSed5L733nvuqlWr3JkzZ7rTp093Xdd16+vr3TvuuMMdN26cW1lZ6VZWVrr19fV5/z+gqK6uzmv+bpYOJDa1cV1X2ehm9erVuOWWW/DDH/4Q55xzDiorK/G9730PN910E5588knpMXfffTduv/12/+eamhqUl5c351I1NDoHlj0PzP0+8NX/A4bNbNuxk7XksbG6bcfV6JBoSNsY+8M323zc1fefg8JYflNaXV0dHn74YbzzzjuYNm0aAGD48OFYuHAhHnvsMfz5z3/GY489hquvvhp79uzBq6++imXLliEajXLn+dGPfoSzzz4bAPDHP/4RgwYNwssvv4zLL78cv/jFL3DllVfi1ltvBQAce+yx+H//7//htNNOw6OPPur34zjjjDNw5513+ufcunWr9JofeOABzJgxAwBw/fXX4+6778amTZswfPhwAMBXvvIVvPvuu/iv//qvnO/vtNNO88/74IMP+j/fdddduOCCC9DY2IiCggIUFxcjEomgX79+eX2uR4ImkZHevXvDsizs3s3LtXv37kVZWZn0mIceeggzZszA9773PQDAhAkTUFRUhJkzZ+KBBx5A//79Q8fE43HE4/GmXJqGRufGtg+A1GFg++K2JyOOt96Ik27bcTU0WgmrV69GY2OjTyQoUqkUJk2aBAC47LLL8PLLL+Ohhx7Co48+ipEjR4bOQyd6AOjZsydGjRqFNWvWAACWLFmCjRs34vnnn/f3cV3X71o7ZswYAMDUqVPzuuYJEyb4z8vKylBYWOgTEbrt448/zvv9yc5L5+O9e/di8ODBeV1XS6FJZCQWi2HKlCmYN28evvzlL/vb582bhy996UvSY+rr60NBHMuyAMD34zQ0NHKAEgI70/Zju443tiYjGrlRELWw+v5z2mXcfOE45P/066+/joEDB3Kv0Rvh+vp6LFmyBJZlYcOGDXmfm7oEjuPgxhtvxC233BLah53oi4qK8jovq8oYhhFSaQzD8N9XPu9PdV72+LZEk22a22+/HVdffTWmTp2KadOm4fHHH0dFRQVuuukmAMRi2blzJ5599lkAwEUXXYQbbrgBjz76qG/T3HrrrTjxxBMxYMCAln03GhqdFZQQtIc6ocmIRhNgGEbedkl7YezYsYjH46ioqOAsCxZ33HEHTNPE3Llzcf755+OCCy7AGWecwe2zePFin1gcPHgQ69evx+jRowEAkydPxqpVq3DMMce07puRIJ/3lw9isVibrcTc5P8xV1xxBfbv34/777/fr4V+4403MGTIEABAZWUl13Pk2muvRW1tLX73u9/hjjvuQGlpKc444wz87Gc/a7l3oaHR2eFSZSTV9mNrm0ajk6Fbt2648847cdttt8FxHJxyyimoqanBokWLUFxcjN69e+Opp57Chx9+iMmTJ+Ouu+7C17/+daxYsQI9evTwz3P//fejV69eKCsrwz333IPevXvj4osvBgD813/9F04++WR861vfwg033ICioiKsWbMG8+bNw29/+9t2fX9f//rX8zrP0KFDsWXLFixfvhyDBg1Ct27dWi1C0Sz6evPNN+Pmm2+WviYr/fnOd76D73znO80ZSkNDA2DUifa0adph7C4Gx3FhmnrV27bAj3/8Y/Tt2xcPPfQQNm/ejNLSUkyePBl33303rrjiCtx7772YPHkyABJUfeutt3DTTTfhhRde8M/x05/+FN/97nexYcMGTJw4Ea+88gpisRgAksWYP38+7rnnHsycOROu62LEiBG44oor2vX9/eAHP8j7HJdeeileeuklfOELX8ChQ4fw9NNP49prr22V6zXcDhDcqKmpQffu3VFdXY2SkpL2vhwNjbbHC1cDa14BTpgNXPCrth37tduAT58Cjp0FfO1vbTt2F0LF/np88X8X4rIpg3DPBWPb+3LyQmNjI7Zs2eIvD9JV8N577+ELX/gCDh48iNLS0va+nHZHtv8H+c7feqE8DY2OgPbMbejMSJtg2faDOFSfxh8WbMGiTVXtfTkaGm0KTUY0NDoC2pMQ+JkRbdO0JtJ2IFL/98ufI5lpm+CghsbRAE1GNDQ6AnQ1TadH2g7KKTdX1eH3721ux6vRyIbTTz8drutqi6YFocmIhkZHgN9npD3JSDtU8nQhZDwyUlpI+j7873sbsaWqLtshGhqdBpqMaGh0BPjKSDtYJbq0t02Q8myamcf2wcxjeyOVcfDQG2va+ao0NNoGmoxoaHQEtGefEV3a2yagNk3UMvCtL5BGWWt26xXLNboGNBnR0OgIaFebRisjbQFq08QsE0VeB9OMfdR3XtDQaBFoMqKh0RFA2wG1h02jA6xtAmrTRC0T0QhpfJbWZESji0CTEQ2NjgC3HZURXdrbJqDKSMQyEDHJVzNbYaOh0ZmhyYiGRkdAe1a0UFVGKyOtijRj00QtooxkNBlpM7z33nswDAOHDh1q70vpktBkREOjI6A9K1p0ZqRNQC2ZiGUgannKiKNtmtbC6aefjltvvbW9L0PDgyYjGhodAe1Z0dKe4dkuhKCaxkREKyNdBum0/rsCNBnR0OgYOCpKe/WXZmuCJSNRLzPiuICt1ZEWx7XXXov58+fjN7/5DQzDgGEY2Lp1KwBgyZIlmDp1KgoLCzF9+nSsW7eOO/bVV1/FlClTkEgkMHz4cNx3333IZIKbhIqKCnzpS19CcXExSkpKcPnll2PPnj3+6/feey+OP/54PPXUUxg+fDji8Tj++Mc/olevXkgmk9xYl156Ka655prW+yCOImgyoqHREdCu7eC1TdMWyPjVNAaikeCrucOFWF0XSNW1/b8mLED/m9/8BtOmTcMNN9yAyspKVFZWory8HABwzz334Fe/+hU+/fRTRCIRfOMb3/CPe/PNN3HVVVfhlltuwerVq/HYY4/hmWeewYMPPui9dRcXX3wxDhw4gPnz52PevHnYtGkTrrjiCm78jRs34q9//StefPFFLF++HJdffjls28Yrr7zi71NVVYXXXnsN11133ZH8NjoMIu19ARoaGnnAaUebhhIh1yHXYep7mNZAirVpTMPfnuloyki6HvjJgLYf9we7gFhRXrt2794dsVgMhYWF6NevHwBg7dq1AIAHH3wQp512GgDgrrvuwgUXXIDGxkYkEgk8+OCDuOuuu/D1r38dADB8+HD8+Mc/xve//3386Ec/wr///W+sWLECW7Zs8cnNc889h3HjxuGTTz7BCSecAABIpVJ47rnn0KdPH/+arrzySjz99NO47LLLAADPP/88Bg0ahNNPP/3IP5sOAE1GNDQ6AtpTGXGYO3MnDZjxtr+GLoCMH2A1/QArAKQzDqA/8jbDhAkT/Of9+/cHAOzduxeDBw/GkiVL8Mknn/hKCADYto3GxkbU19djzZo1KC8v94kIAIwdOxalpaVYs2aNT0aGDBnCEREAuOGGG3DCCSdg586dGDhwIJ5++mlce+21MAwDXQGajGhodAQcDZkRgORGInpmbA0Epb0GLNOAYRDnIe10MJsmWkhUivYYtyVOE436zykRcLzfgeM4uO+++3DJJZeEjkskEnBdV0oexO1FRWEFZ9KkSZg4cSKeffZZnHPOOVi5ciVeffXVI34/HQWajGhodAS0ZzUNJUKAzo20IqhNQxueRS0TqYzT8VrCG0bedkl7IhaLwbbt3DsymDx5MtatW4djjjlG+vrYsWNRUVGB7du3++rI6tWrUV1djTFjxuQ8/+zZs/HrX/8aO3fuxFlnncUpLJ0dmoxoaHQEtGefEYf5wtaL5bUa/ACrF16NmgZS6IAB1g6CoUOH4qOPPsLWrVtRXFzsqx/Z8MMf/hAXXnghysvLcdlll8E0TaxYsQIrV67EAw88gLPOOgsTJkzA1772NcyZMweZTAY333wzTjvtNEydOjXn+b/2ta/hzjvvxB/+8Ac8++yzLfE2Owx0Ek1DoyOAbQffhKqBnKj8DFj2p+zn5GyadrCJughYmwYg2RGyvYMpIx0Ed955JyzLwtixY9GnTx9UVFTkPOacc87Ba6+9hnnz5uGEE07AySefjIcffhhDhgwBQGydf/zjH+jRowdOPfVUnHXWWRg+fDheeOGFvK6ppKQEl156KYqLi3HxxRcfydvrcNDKiIZGR4BPFlyiVFgt9Kf7yncIIek3Aeg/Qb6PtmnaBLTbKmvTAECmo2VGOghGjhyJDz/8kNt27bXXcj8ff/zxcAWifs455+Ccc85Rnnfw4MH45z//qXz93nvvxb333qt8vbKyEl/72tcQj3etbJYmIxoaHQGOQAhaiow0HPQeD6j34ZQRbdO0FtIZr7SX2jR+F1atjHQFHDhwAG+99Rbeeecd/O53v2vvy2lzaDKiodERIFa0RAta5ry0q2omi/0ilvZqtAqoAhI1qU1DHlM6M9IlMHnyZBw8eBA/+9nPMGrUqPa+nDaHJiMaGh0BnFXSguoEzYDYSfU+IhHSaBWkxQArtWm0MtIlQNvRd1XoAKuGRkdAa4VIKbnIds7OmBmp3gl88gSQqm/vK/GRytDSXqKI0PVp9GJ5Gl0BWhnR0OgI4MprW5AQUBKS1abphKW9838GLP0jEEkAk65q76sBwNg0niKibRqNrgStjGhodASwif6WVCd8myabMtIJMyP1+/nHowDUpolFKBnpODaNWHGi0bXQEr9/TUY0NDoC3FZQRhyb6eyap03Dju04wNJngX3rwse0BY7kCzCT5B+PAqRt3qah/UaO5tJe2jq9vv7osbs02h7098+20m8qtE2jodER0BohUvY82SZldtJnj6lYRPqUDDsN+Por4eNaE8nDwOOnAcNPBy74VdOPt/MgI3YGWP48MPQUoNeIZl1mU5C2BZvGy4ykjmJlxLIslJaWYu/evQCAwsLCLrOwmwZRROrr67F3716UlpbCsqxmn0uTEQ2NjgCxz0hLgFVDsikjqrHrqshjfZYeJa2FfWuB/RuBVF3zyEgmjyqiLfOBV28BjjkbuOrvzbvOplwSraYRMiNHe4C1X79+AOATEo2uh9LSUv//QXOhyYiGRkdAazQeY1WOfDMj3DG0EqcdrI5Mozd2MyuL8lFGaJ4kW0O4FoLjuMg4lIxQm6ZjZEYMw0D//v3Rt29fpNOdJFOkkTei0egRKSIUmoxoaHQEcLmNFirtzVcZUfU4yWdCby1QMpKtCijr8Xlcu79PM8eo2gBULAaOvxIws39Zp5lcSERQRtJHcWaEhWVZLTIpaXRN6ACrhkZHQGtUtDh5ZkZUZcX0mNZcPC/dAHz6NOkLwiKTRxVQNuRFRqj60kyyNff7wCvfBrYuzH05jPoRs/hqGtomXkOjM0OTEQ2Nox3inXF72jSOxKZpTWVk1T+A124F3vsJv521aZpTVZNP59l8yp6zgWZq8rB50kwuhNo0tC08tW80NDozNBnR0DjawdokQNOVEccBnr4AeP5yoTImX5tGlRlpA2WkXhGS9cd0m9cePx8L5khtmnwaynlIM8qIRTuwUmXkKM+MaGi0BHRmREPjaIcrKiNNnBwbDwHbFgbHRuLh82SbMDllhJn46TGtqYz4hKBR2M78bKcAq4n9DWzFeWVjH6kVlIfNQ5WRmGX6pbG+TXOUV9NoaLQEtDKioXG0wxGUkab2GeFCp6wakqdN4yjCs/S5kw5bSS0FW0F4MnmqOirkkzk5UuWnCY3VaGaEhlaBwK452kt7NTRaApqMaGgc7RCVkabaEjI1AxCIRTNW7WWPaa3y3nyUkebYKHkpI0eYGfHJTG7ymBIanrHP0zozotEF0Cwy8sgjj2DYsGFIJBKYMmUKFixYoNz32muvhWEYoX/jxo1r9kVraHQpiJmRpk6OSmWDrYxpRmkve0xrWTUqZYQjQk38POxMQLDyqabJJJsXks2nsZoHsfsqwJT26moajS6AJpORF154AbfeeivuueceLFu2DDNnzsR5552HiooK6f6/+c1vUFlZ6f/bvn07evbsicsuu+yIL15Do0sglBnJfafdmLZx7pz38YOXV8p7g4jnaVaA9QitknygsjoyR0JG8jzW36+ZIVk7/wBs0H2VsWm8dvC6mkajK6DJZOThhx/G9ddfj9mzZ2PMmDGYM2cOysvL8eijj0r37969O/r16+f/+/TTT3Hw4EFcd911R3zxGhpdAmIeg50Y964FHh5LenEw2Lj3MNbursWbn+/mlRGlTaOYMF03S2kvM6m3mjLSCmSEPTYfm0Ycw7GBJ84G/nat+ljXbVJpcFabRmdGNLoAmkRGUqkUlixZglmzZnHbZ82ahUWLFuV1jieffBJnnXUWhgwZ0pShNTS6LrIpI9sWAjU7gXVzuV2SGUJAbNdVd2/Ni4xkGftIQ6T5wK/YETMjeZKR3SuBz1/it+VbRcTlUpjxanYBOz4GVr2stm/yzePQ09MVexllJFibRisjGp0fTSrtraqqgm3bKCsr47aXlZVh9+7dOY+vrKzE3Llz8ec//znrfslkEslk8AdcU1PTlMvU0OhQuOOvn2HD3lq8+J/TuTtjH9kyI4qAZzJNJjfbdvOzaVTKRrbwrOw6WhoqZUT1PkS8fBOw53OgbDzQZ6R3LpZkZFFGlPkaQRGKJsLHNjFgS3uJxDhlxMuMaGVEowugWQFWcYlo13XzWjb6mWeeQWlpKS6++OKs+z300EPo3r27/6+8vLw5l6mh0SHwxspKrNhRjYoD9fIdshECNmTJIOmFHm1XJCPMpOrkkRnJVlbcxLv/ZiEfZSQbEarbxz+y5wSyqyqc+qJ4nmlQHNu0zyYtU0ZMXU2j0XXQJDLSu3dvWJYVUkH27t0bUktEuK6Lp556CldffTVisVjWfe+++25UV1f7/7Zv396Uy9TQ6FCglkpKVTWRjRAoJmt6zozjCpkRhb2Rt02jUEOa26U0F/zyWKGiJV+bxidrbJO0PImM6v2x29MKZSVf5YaeRpYZidBVe7UyotH50SQyEovFMGXKFMybN4/bPm/ePEyfPj3rsfPnz8fGjRtx/fXX5xwnHo+jpKSE+6eh0RmRsR3QG18lGQkpIywZkUy2CJQRRyQjtmRtGUBNJkKt6FUN1FpZGRHHy+Q52ctsLPac2Rq2qapuMvkoI00L96b9ahqGjJjaptHoOmiyTXP77bfjiSeewFNPPYU1a9bgtttuQ0VFBW666SYARNW45pprQsc9+eSTOOmkkzB+/Pgjv2oNjQ6Ieav34POd1dy2FDPRpFSTTigzIskvKDIjGceFq6qAOdIAa75B0CMBp2Io1A0VEXLd3MpItuNVVks+ykpTA6wOVUbYAKtem0aj66DJa9NcccUV2L9/P+6//35UVlZi/PjxeOONN/zqmMrKylDPkerqarz44ov4zW9+0zJXraHRwbDrUANuePZTDOlViPnf+4K/nZIGIJtNk40QyAOe1KYBAMe2Yfn7N7EDq2gROYogZ2t3YM32XEWksoVOuTEagWiBZGyWwChUpHQeyoio3Gz4N/Dqd4GLHwGGnwYg+N1HJQHWTGu12tfQOIrQrIXybr75Ztx8883S15555pnQtu7du6O+XhHO09DoAjhQRyaw/Yf5iZNTRppl03iTnjApJplzOXYmICPc3X4+No1IhNq6moYdQ1Fqq7p2dn/28xHJi+p4lQKiUmu4c2YhPxveAmp2ABvn+WSENjajoVWA6TOS0cqIRueHXptGQ6MNQH1/VrEAeGUkqSQj+dg08moaAHCUFTB5VNNkI0Jt2YE19FxYtbdJxzbHplEFWBXKSLYur5IKKH/V3ghbTeNlRrQyotEFoMmIhkYbgKoeadsloVK63baZ53kqI7YiwMpUmyTTvE0THKuYJF07bMmQg7OM3dbKSBPzLpySkk0ZUZERBeHJp4NrtvJhSc5HbtPQahqtjGh0fmgyoqHRBmBDiCzpYBWMvEt7pbkNlyMKnDKSUVTQiFkG2aSetenZEbRkzxdtoYzkE0JV2TT5KCMqJYbZntWm0dU0Gl0AmoxoaLQBWAVEZc3knRmRBVgB7u5fadNkC37KJuVs3V9VeY6WhDIzkocykk8ljuxn/5g8utUqVZU8PmfmmujKvJxNozuwanQhaDKiodEGSDEhRDY3kuLIiMQmAfLLjAjPuWoaZZ8RYZLMRxlpa5tGpYaoKl24Y9kAqyL8KvsZIEFdV2Fv5dNnJFu4l14Xc01pqTJCq2m0TaPR+aHJiIZGGyAfa0adGREmI1nTM+E5q744tsJaYS0XQE5GsllErW3TuG6WipY8iJCSyORDRkT1RKHEqDqwZiNLMmUky6q9OjOi0RWgyYiGRhsgnZGTkWZlRpQ9LxgywpzLVVbT5GPTKEp7HUdYI6cVlBGRLCmVkXwCrE20p0KERWUXNWNtGkkFVMYnI+G1aZQkVUOjE0GTEQ2NNgCvjKhsmnz7jEgWyhOeN6YVNk22rIXM7lCV9uZj8RwpQsFPbwzHVi/+pzqeJQ35lPaG3p9CoclnbRqxj4lUGZG0g6c2jSYjGl0AmoxoaLQB0ormZiwxSebdDl5VZspmRlQ2jaLPCCCflFWqjOpuvyWRR38O6bXIrilbt1hZ0zMxkNvU4G5WJSbcoj6lbRqNLg5NRjQ02gCpPKyZI6+mYW0aNnyZZzluXspIRr4vc17HcXH1kx/hW39eGj5fU6DKdmTLc6iOV1XiiK8p91HZNCplJItNY4eVEap+RKxwNY22aTS6AjQZ0dBoAygDrPm0gw+FSBVZjYw8M8IrI1mqafIq7U3L92Um632Hk1iwoQqvr6hUv6d8EFIwVMpIE6tp8intzUZ4FDkdfmzmeNfhCaEkM0JtmphMGdHVNBpdAJqMaGi0AVQKSF4L5WUtr1WQEea8roq82GI1TT4B1pR8X+bnhpQtfd5kKLMWeVpEeSsjeQRYVUqHMsCahfBIbJq0TBnx2sHbDt+1V0OjM0KTEQ2NNkBaFWC15SoJBxUhcGzlKrrsGG6+yohMYRDXRVHZNMwEX88QkPq0QHiagjyqUKTX4u+vqr7Jg8xkIzz5KCNZlZVk6FhpaW8keK7Xp9Ho7NBkREOjDaBSQ5rXDt6b4MUJM63owOrksTaN7HxAYNOY3gLfKpuGVUYYAlLfospIY2gs8nMTO7D6126oj89KJppY2sv+7Lp8NY3XQ0Zq0zAN0HSIVaOzQ5MRDY02gHptGnmZLweqjEQS5FFZ0SLPjCgzJk1Zm4aOrSrtZSbfhpTDPD8CMpK3MtLUahrvWuMl3muyAGueTc+U69oortFOA6D/F4L1hKQ2DfNckxGNzg5NRjQ02gBco7O0os9IrtJeK04eHVWIlLFp0k2waWLF/M8sqKoS8cZ2HWLdZCEE9algvIb0kSgjLRlgbQhvT1AyIivtzcNmEc+b9Xj6OxOIj/ezzKahmRFA2zQanR+ajGhotAHSebSDT+ZURjxCkGNiE8/lqmwaSmpiRd7xWQKslAjR47JYPCwBOSKbJo8F5sSxldtlmY94N/n5pGMfQWkvO76CYGX8pmcBATEMw/9ZL5an0dmhyYiGRhtAWU3TlMyIaNMoMhUZ2+HKQV1Vt1JbICPSPiOCMkL3y9KBla+mOYIAq0oZySd4y+5Pn9M1fighozaNzObJt+mZUhkRj1f0SMmijABBS3ht02h0dmgyoqHRBshHGcmdGRFtGrkyErJ7ZD0uAIlNk0UZiQjKiBgCzbA2TSspI/TnbESBBUfWXOZ477FJNo1KZVH1GVEQJoW1RjNFEYGMaGVEo6tAkxENjTaAsgW8osyXQ4iMZPiqDArvZ7ZahxzO2jSSdvBZMyPUponxx4VCoK1g0ygzI3mQKHZ/8WdfGcnDpqFqVKaJmRFl+DZXZsTgXqZKSVorIxqdHJqMaGi0AVSdVpuljAAeIZBP1qHsiaNam4YSCm9SlykEdGzTAswoM7ZwbGs0Pcs1oVMykc9CeUDQ1yMjECkZCQuNoWp6piJCioX2lMoI+Zxjok2jlRGNLgJNRjQ02gDKnEhT2sHTu3TAs0qEu2xvsm0UK1hykRE/M5Klz4hhAlaUGVtUFxRNz1qizwhVQMTMiIwocMcfgTIihlxV7eAzDUEWhYVqMT5FbxiVTeNnRnQHVo1ODk1GNDTaAKrMCNcOPl+bBiBqgCLAKiojnE1Dj3Hs4LzZAqz0WINVRjLBvv5krWh61hIdWEUrSFQtZIoOkLuiJZ4lMyISlmwL32Xr4Op/Zoq8i6CMiDZNLGJyr2todFZoMqKh0QZQNjpjtqeVNo3QZwTwyIh8YuNW7AXkyghLPGJ0Us8SYDUtwPK6sDqMRcTmTTyFoMXXphEVjIxkbOnx4ufTwO9PA6zSaho6hvDZOI6E5EhyI3T/hGAFqUp7HVraKyoj2qbR6BrQZERDow2QzjAdWFVlvrmUEdMK2rJzFS0evEkxnBkR+oy4Lj+h+sqILDPC2DRsZkS0aZjj61s6MyJWvYhjK8lIjg6u8SwkTDWGbCzZ+jQhKyhHaW9GUdpr6dJeja4BTUY0NNoAKZVNIxATV5Y/cBSEQGEXiNU0PqHwz5cRlJFsZMQJxmYzI/R4ShSY8blqmpbowCq2bRftG9cOr9/D7s/+bGeCz0NSCeRDJEKy1Yrp70KqjNC8i0BmFMoI7bDKdl0FgJhn22R0B1aNTg5NRjQ02gCqhfLE0Kq0hJOzSighyCgn66w2DUCOo5OjYQHRgmC7CIchI/5ieZmwTQP452y5ahqxH4hC2WD3ZSGrpmHJRD7KSEyoNMrkebwqc6Is7fUWyovIlZFURisjGp0bmoxoaLQBOGVEkR8R9/PhyghBKpjYEt3Jo58Z4c9hiKqBnQoap1nRoIdINmWEJUJ2KpicI3FGISDj89U0LdCBVVRGmkpG2ONZ4pBPZiREJrztVgyIFpLnYq8RxwkIoEhYJNaR47iwc2RGtDKi0dmhyYiGRhuAq6ZhrAuROEjLe9mKFp84MNU0lIykaWZEVEYkZITaLFaMWfMmR2aEjs2uTWPFmePDNk2LKiNOml+kL86oMtm6qPpkrZFRhEwgmmVNnlD5sJC1iSSAKG2Ipmj9zh2vtmnYRfAiiqZnOjOi0dmhyYiGRhsg30ZnUjKiym34Ja68jSFmRgxXUCfsFEMmcigjXGmvxKaJxILjM2GbpkU6sNL3B5Bx/bET4dJZ7nhROWKUEZZEZQ2wMmM7meCcVgyIePaWqIyw5CSXTZNu5Kw5sekZLfVVln1raHQSaDKiodEGkPUZcV03P2WEqhOmQAhkky0k1TRigDXDkpEwmeCPleVVGFWGU1aoTcP0GWmJahqWELCEIhJWZYLrdpkQKmNj+cqGcN1icFhmBWWS8rFDORBJpVKWVXszzP8NMcCqq2k0ugo0GdHQaGU4jsvd/VKywG6jc1DKlkzevjJi8CoGnVgLSsmjMsCazaZhlZEcHVhllTxWPKyMsDbNEVXT0IqUQqLMADwhsOJMjkVo2MZlQ0rJY7pBONa7btcJh3zFACrAf+aReBD8FZURW6K+yKpxvOukqodhAJYp2jQ6M6LRNaDJiIZGKyMtTCSULLDSe7dE1HtNlhmhZERUJ0SbphFwXYlNI5KRJK+MRPIIsBom0/SMKQ0WFIa07XAkq0X6jFhxZsG6xuB9R+Jqi4md9DllhFU2mPb6IcXCO1+0gLx3OoZv07DXpDg2Eg8a1WXJjFDVI2qZMAx5ZkS5VICGRieBJiMaGq0MVS6EDbIWxyPSfQEoqmky4QArANipPKppmD4hZjSYMGU2DVfaK2l6ZsWY45MhJaQhbcNp7roqGYmlwlktcfW1S0twG+X2EiDpqkoJT4J7f9w1+QFWlTISC8hjRsiMxANrzW8FL6gigF6bRqPrQJMRDY1Whtg7JOk1N0sx65HEI1nugNnMCFdeK2RGACDTGLJpQgHWTFJh0zQhM8KpFtSmSUqVkEbRNsoXMruDU0YS/OfBgt2HrXphlRE2g6OqiOHUF/F9U5tG3pYfkUQ40yISSJaMRMJfx75NowOsGp0cmoxoaLQyZAQjZTu+nRKzTL/ZVc4+I2x5LRey9O6q041hZSRk06SaYNNIVu1lMycRRhmxAzJSGLP8UzQ7xCpVRlK8uqEiUhmJHSMqIwCvesjG5j4fIcCqVEaY6xavzyeQQQWUv2KvKSMjdKE8rYxodG5oMqKh0cqgd75sODGVcXziEY9aARnJ1WdEWl6b4CbcxrSojOQgI1agbGQfm1m1l7VpIkGAlRKPongEiSh5T83OjeTMjCTURIrbxyMcaUEZAfI7nrNpJCQnpIwwuRKxUknS+4T+/4hZEpvG0gvlaXQNaDKiodHKoEpFEaMWJDOOTzxilun3l2hanxFZmWnSH49aP6HMSMimocqGUJGSbWyOzDDKSJpYQoUxC4UxQpyar4zI319W5cE/lsmVUDuF6zPiHceSHBbcGIoqItWxMkXHt2moMlLqvx9fGbHUyojOjGh0dmgyoqHRyvDvfCOBApLMOH62IxbJZdPQzIjJN/liq0qiwYRL7Z8iLxQbVkbSTDt4drLNUtpriqW97GTPZkbI2AVRCwVRQr6a3RKes5IUyoiSjLBVL2zehFGT6LkBdQBW7DDLkhzmM+evW132HHSVDbrmppnskAjad0QrIxqdHc0iI4888giGDRuGRCKBKVOmYMGCBVn3TyaTuOeeezBkyBDE43GMGDECTz31VLMuWEOjoyHFKBVsUJVVMFiSEoKstJdtBy804KIkh5IBn4zQtVS40t5ojnbw7NhMaS9n0yT84ynxKIhZfm6k2TaNqsGYLDMSIhOsTaMIsNLX2f0BcCv7RtheJgIBVNo0svBrtswIJSPZMiOajGh0bkSaesALL7yAW2+9FY888ghmzJiBxx57DOeddx5Wr16NwYMHS4+5/PLLsWfPHjz55JM45phjsHfvXmQyR7CAloZGB0JaqJqpBek14ts0kebYNBnh7j+YVJMZMgEWxQkZMH0yUgCk672F8rxtbDWN65CJ2GK+FqSr9ipsGqa0tzBm+SW9zbZppFZQKk9lRBY0TSIUYGXDqf64zHOxfJi9Jl8ZUQVYJR1iJV1z2T4jIoJqGm3TaHRuNJmMPPzww7j++usxe/ZsAMCcOXPw5ptv4tFHH8VDDz0U2v9f//oX5s+fj82bN6Nnz54AgKFDhx7ZVWtodCCwpCNuE4KQTAfKCGfT5GwHL+n1wYY0M0kkM+TPusDLbJicMrKfTKp0G6suAGTSZMmIsrRXYtPYKV8FKYha/kq0ze7CKlNG0vWBxSSMzR+bpzIi61PCBnlZq0WspsmljEgDrNSmKfX3TWWzaXQ1jUYXQZNsmlQqhSVLlmDWrFnc9lmzZmHRokXSY1555RVMnToVP//5zzFw4ECMHDkSd955JxoaGqT7a2h0NqQYGT7OZENSEpsmd2kvVSdSQjfRoDU5tWloYNaAdzy9kw+V9mZp/sW1g2eUkYxcGaEqSEEs4gdYm2XTOA6Ta2Em/saaYJ+sHVhZssSQhpAyIrFpKJmg1pRPeJiut1zJsLhQHrOIoGiBhWyaBl/1yBZg1TaNRmdHk5SRqqoq2LaNsrIybntZWRl2794tPWbz5s1YuHAhEokEXn75ZVRVVeHmm2/GgQMHlLmRZDKJZDK4O6mpqZHup6HREcAqI1Qt4JURK3vTM7a81u8zkhEmRkYZ8QKshb4y4lmiPhlhFoazogHJAMLZC9nYXFUJ36fEt2mirE3TDEuWJRcRJpfSWB1st7KQESlpyLO0V6mesFkbxv4RlREuwCo0ZQuV9iaZ0t4sNo1em0ajk6NZAVZx/QTXdUPbKBzHgWEYeP7553HiiSfi/PPPx8MPP4xnnnlGqY489NBD6N69u/+vvLy8OZepoXFUIM1kAuJ+UNVuXmmvqQqwspkRSkbEzEhRcKzNVNMYRngNFdnYKpuGzYz4yoiFAm/8+ubYNLZglVBikKQ3Jkb27rHKpmd5lPaGGqOxAVaJGpWttFdsqibJjKQ9JUteTaNtGo2ugSaRkd69e8OyrJAKsnfv3pBaQtG/f38MHDgQ3bsHLavHjBkD13WxY8cO6TF33303qqur/X/bt29vymVqaBxVoHe+pJrGy4xkHKS8SSgebUJpr7Syg2957ts0cVpNI9g07B0+JTeqihqutNdTUNhVaoUOpfUMGTmiahpWoWErdqhNE4nzqxhnq6bh2sEzJIqeWzyePZbdN7Rqr6pHiaIsmJ4DCMiI6yCTIcRQZtNEdDt4jS6CJpGRWCyGKVOmYN68edz2efPmYfr06dJjZsyYgV27duHw4cP+tvXr18M0TQwaNEh6TDweR0lJCfdPQ6OjgqodUYsPqvqlvVauAKt3V2yIhIBaLTGpMlIQ9WwaMNU0gKCMRPlHsQurPzYTYE0Ff8t8ZiQVND2LMspIc8gInbzNKCFClPAkGTJCxwfyVEaYACq9ZpEssOeiY7JjcBVMQU5HOTZbiu26YWUEgOsdL7NpYjrAqtFF0GSb5vbbb8cTTzyBp556CmvWrMFtt92GiooK3HTTTQCIqnHNNdf4+1955ZXo1asXrrvuOqxevRrvv/8+vve97+Eb3/gGCgoKWu6daGgcpZAtiMfaNPGoiZgVKCYhyHIbLCHgqmnYpmfknFbWPiPCGi3ipO6wAVZKRuqYsfm7f04ZiR5BB9aMmO0QMiM+mchFRth28A1hosH2LxGPtSTqiXTVXlX3Vt7CgpMJbK94cIPleJmTiG4Hr9GF0eTS3iuuuAL79+/H/fffj8rKSowfPx5vvPEGhgwZAgCorKxERUWFv39xcTHmzZuH73znO5g6dSp69eqFyy+/HA888EDLvQsNjaMYKSaoapnkeZJZmyaWUxmR5DaStcHrzN2/mw5sGhpglVbT0IX1ZLkI2dhsaS8lI4blbQ8maxpgLYhZvqjScCQBVksgDb5NI3RQVXZgjQUKhpMmpcHc8bLSXpVNk5SvBxRSRiTdX12bJ3HRAvK6nYTrkRFZnxGaGdHt4DU6O5pMRgDg5ptvxs033yx97ZlnngltGz16dMja0dDoKmCbnllG2KbJvx08s1AeVUZoANWbGJ10I+i8pVRGMilyLiAgGLkyI6xFlKoPxmaPzTRyTc98MtKcAGsuZSSSg0TJlBEgIDOSa/eR1aaRdJ7NGmBlerhw9pZHIO2kX40jC7DGIloZ0egaaBYZ0dDQyB9sPxFaockulBePsKv2SiZuThmh2QlvYvPv3smjnQru0v3SXpoZiVGbJgW4lIwIE24oMyJpRZ/yVBnJZF3PND2jZKR5mRGFMpIUlRGJsgHIS3u548XMiKTpmdSmYTu7MtU0rktIISBfmwYIiBDNwUQTQLIabqYBgJlVGdGZEY3ODk1GNDRaGdzaIx4HSKZtThmJZyvtZXMbYohUmFQdpudFQdSCAQcmDbqyNo0rKCMqu4Mbm+ZVPLtBDIFypb3BV0vzqmkUygirCGW7bl/dSJDGZWaEZDbEzIlYessdKwnJylbtpcezbecBcCv+AoG1Jto/mSSAAjkZ0dU0Gl0EetVeDY1WRpLNhngTTtJuyqq9TG6DWiVUGbH4yZqSkVjERMQyYIE5X5RRRsRqmqaU9oo2jR9+5demSURboJpGVCco/Ak9j6Zn7P5+5kS0aZJZjlW0g48yAXy2CytLhNgeLiFVhrd5ZAHWmO7AqtFFoMmIhkYrI53xmp5FTMSjHhlJK9rB5xtg9a0Sb2Lz7spdz6aJR0xETJGMSPqMiAFW0e5gy4rpPmlPGfEn9MDG8FftjVpBO/hmZUbEqpcE/7osz8Edn281jqS0V2yMxlpB7HnNCPlcAL4Lq8rmUVlE3v6y0l69No1GV4G2aTQ0Whkp21NALBOWSe5+k2KANS+bhsltJEWbxiMj3l12PGLBDJERqoykwfUoAfIo7WUW6aMQrQ6b78BK0bx28GI/EJGM5FlNI2RqfAVDJDNSm0YyBkviDINU6qTreGWEtWnoYwp8wzbAr/IxvPdK8yHc2zR1O3iNrgFNRjQ0WhlUGYlFAjKSYgKsbGmvtM8I1w7e+5Ol9olIRtKUjBBlJAJGlWDXpqEIZUYUAVbTWzSOhWjxMKW9hRwZaQllJM6/HsqMpIXjRWVEPF60SmQ2jaD8iF1vAaJIpet4ZSRkMVGbRp4ZMbxzRiNhm4bmSDJaGdHo5NBkREOjlcH2E6G5AL7pmZV/aa8lqBOhO/+kd04TlmHA4sgIXZtG0mckopjUudJecWx+onftpG8nFEQDMtKsAGtTlRGxCogt7QX4fIfk2nmbhlkMjx3DZpue8eqGdG0bsfyYkhFhXRzTVts0tNxX+v9CQ6MTQZMRDY1WBtuBNcasTeMHWJvS9CxklYgLvtHMiAXLNGCBuaNmFAyfjNDzyapKuLElRChLRUpBzIIBajG4SGUc/z3mBd8OEdQX/73kmRkRS4P9a88SYLUFIsMSHls4r6wLa4hIKcqSqTLi2zRaGdHoutBkREOjlcF2YGVJR4pZQC9r1YSsvJZCMbHF/WoaqqpE+IoZGrwU16YRbRp/bCM8tk8U+MXmLNNAzDJhxILJtSFtN42MhBQIkYyI1TSiTaPIjIjHy0hYKPOhWCgPgHR9moyYORFtGho6JsdSZSQq+Xz80l6dGdHo5NDVNBoarYx0rrVpIqa/PedCeWJuQ8iMGJmAjJgGkxkxI3y3UlVTsZBNIykrFse2WKvDJf1NDIOUF3t3+022alTqAkXIQlHZNCqbR6wEklXTiNUw7HpAYkWMRBkRx1AoI5btZUYkAdYoU03julod0ei80GREQ6OVkWKbmzFBVWk7eCkZYdvBK3IbUZo/8AKsUQsR04RpsDYLc4fv0D4j+XZgNSU2DT/ZGnARgc1V0gQr9zaxoiZnaS8lCsyquNzxOZQRMYtiy2wakYww6wFZvLrBKyON/D70+FCPEzK25ZD3Kg2wMgRFr0+j0ZmhyYiGRisjrVgQL5X32jRZCIFw528xNo1pAhFa2mtG+LbmYtMzVVVK1tJeoSwYQAwZrpKmoLmNz3IpIyFVRtWBlSdr4eN5i4k8V5GRmmCfUFYnW4BVpYxQMpKltJdphKZzIxqdGZqMaGi0MnhlhA2wMmvTMHK8I94By/qMUAiSv+ndZSc8ZSTIjFjgOomGmp41o7RXkueIIc1V0lBi0uTGZ6HcRi4yIdo0ig6sFFnJhCL8ylbDUOLQpACrkBnxCaSnjEiraYJtuqJGozNDkxENjVZGyrujjVpMB1YmM8IqI2R/YdLJWk3DBykjDsltxL2eJn7TM9MSmneJ7eBVNk2W0l56PtMiRAlEGeFtGkJgmq6MiOW1qj4hEkXHccKNy1TKiqwNfqjpmfe+6WfBXosfYPXIiJ0Jfl8qm0ewiCIObeEvq6ZhlRFNRjQ6LzQZ0dBoZaSYNWjiEpsmnpOMZOszElYn4kj7ZERq07gOkKbrywilvaoAq7S0l6mu8caPGWnOpvGVkSZnRgSrxBTIUGgRO0nmg92PkgYAgBGEcX1lhVVGBFVFJEIR5n37ykiDeuxQZkQIsLqE/MhsGsMw/EZ5OjOi0ZmhyYiGRisjzSojHuloSNlBMzSmtBeQhFh9QmCoK1oYG4KQEctbm4atpmEmUccjB7lsGra0NxSeZc7nHR9X2DTNV0ZYwsNYLeJE72SIIgLwxEKmjETi5P2wr9upoGopI1YaiSXN7Lm846kywipLoVWNG/ifvWOjjtqmAYL+I9Jws4ZGJ4EmIxoarQy+hJdMznXM5ByLmKQUVrU+jcOqE2KfEbaqhExacaRJB1bWpjHMsFUB5NGBlbV5FBYRcx1xpH1rBjiCAKuojISeCw3JgKBCiJIJtn0+S2S462aOpwRI1fQs23VkBDLClmGrcj6eqhJxKRkJ2zRA0JlVKyManRmajGhotDKCPiOBMmIzEwvdpizvzacdvGH4ZaZxI8VkRhhlRFRVgHA1TVNKe9lJ2ZvgY8igUKKMNDY1wJpLGREVHfba2dJaqoCw1TQRxTlFQuFXwyjyJkC4tFcMr0qP58OzMTeHMkIbn+nMiEYnhiYjGhqtDFVQlYLe+SrLe/NpBw9w6gRtBx/x+oy4ZsTroqpacE6yRguQo7SXzXCQ88SQbpkAa3OUEarqSI9NyJ9zZCbFH2+xqhPkx4gL7YllveJ1sMd426M0M6JQRiJMpZWGRmeFJiMaGq2MFNeB1eJei1nEoqHPAZlNw5b2ipmR8CSboAFWw4DJVtMAYcvBFKpplAFWMzgHheTuP2bw1TTNz4xIFIaIxF4xGSuGqiliwzPxWPYzYNvc0+NEm0ZFJoBAGREDrJZiPPZ8NDPikRHZQnnsdulSARoanQSajGhotCJc1+WDqoIyEmd+jjHdWfmTsFZJ7vxCHCmSGbGCdvCuV3rL3bEbVtAvQ2nTMBaRGGKV3P2LfUbo86ZX0+RQGGTqBiUCUmWEqaZRkQtbUEbEpmXZrsMPsKbC+4TW9OGDrXnbNHp9Go1ODE1GNDRaEbbj+kUaMcsrt2VWZ41JyEjWzIiqHTwQkBGDraZhSnsBfmKUPc9W2gvwloWstFfswNqiyojCXhFbwovKBnN9oWPZnzMCmaFjM31UQscLqyWHWskD4Wocodw4hhw2jff/Rds0Gp0ZmoxoaLQi2PwHJRsyNQRgbJpQZoQulGeErRLJhBtHyl8oj5IR1xAUENXzUGaEKSsGeDIksSLEzIhv0zS5A2suZUQSEA3ZNGw/kDyUEd+mkagbKlUmKiojwro04nP2eEZNAtQ2TVTbNBpdAJqMaGi0ItKZ4G6WTipxxsaQEZOsmRE24wAobBqSGWH7jLiGTBmRNBHLZtOEjpGEZw1FO/iWVkZkKomobOSrjPh5GZHMsMeo3reQGZGRqNB4/No0cV8ZyU5G9No0Gp0ZmoxoaLQikjaZhA0jkNvZO+D8bBomMwKo1YkoDbCmEI9aXAfWIDOimJRz2jRUWVHYNL4yIto0tJqmuZkRlRrCEgLh2qUBVgUxAYLPMJPk27lz70+hdPgdWD0CJCVRCvLDVD8B6j4j1L7RyohGZ4YmIxoarQi2+yqtmqHr0wA8GfFbxduCihBSJ5iKGkVmJOE1UgtKe2VkgjlPzg6s3tgqIsQGWJmmZ7TnSEO6iROpP6krCIE0wCoGUFX7K/qGZJJCO3cFgZEpI+lsyojCpqF9YXwyolBGTF3aq9H5ocmIxtGDnUuBA1va+ypaFH73VStMOsjzQEVQlvZmU0akmZG0bwXFKBnxbRqVupBrbRpKZlgiFJ5wY8gobJojXJsm9FwWYM1m0yianrHntZO8TaW0aSSZEbEsOKsywlfTRAwHEWTUZCSiq2k0Oj80GdE4OnB4L/Dk2cAzFwaBzU4Av/tqjtAquz1rZgSQWxSAf5dOMyMAEDXJuZxc1TB0e67MiKmqpgkCrC1TTZNrbRqJ0iE2PVNla7IpI347d4sPCytJHA2wUmVEQqKUpb3Beygw0v6CeCIiWhnR6ALQZETj6MDeNWSxs5odwMHOo4743VctuRrCWjb0zjjcZ4RW08jUibAykvCqaQAgapBj/Woa1d0+24GVJYP5lvYqm56Ra21ygDWXMiLLu4jt4GXNyYCwUmFJbBr2WEAe9mX3C7WSz4P8MNsLLfXnE9Xt4DW6ADQZ6Qyo2QXsXtneV3FkOLQteL5zaftdRwvD774aCe5647mUkVBpL1UncgRY2T4jnlUSMcixjrSaRlFZ4zCWSqi0V5VXYUp7JU3PmqSMOHbwnmU5EXbNGfbas7aDV+RH2NfspDzzke14vwNrIyFxedk03vGmCdfbr5ultrF0aa9GV4AmIx0drgs8+yXg8S8A+ze199U0HwcZMrJrWftdRwtDpozIKmjY5+rMiKy8Npj0XG5tGm+9G18ZkVg8KhuDtWrYVXvFsZnjbTPmjy2zaRrSNpx8V53lchsSSyTUJ0TVZySP9WjY4zNJeZ8Q8WeVdZRRkJksHVwd77yFppDVYXfXa9NodAFoMtLRsW8tULWeLJ++6Z2WO6+dAf5xM/DeT1vunNnQSZURdsVeiiYHWP3MiKQihpkMbZNvegbAr6Zx6J86OzGyKgc72dJJHQgUihxN09IGuSZV0zMAaMzkqY6wFS0yhSFUmitUAtmyhmn5lvZKSooBtU3D2j+ZhjxX7WUIpPdaUTZlxNQBVo3OD01GOjo2/jt4XvFhy5234kNg+fPA/J8Fd3utCVYZqfwsmIA7OPxqGhUBkZX2ZmsHDwQ2jWFy+ZGMSTMjaX+MqF9NI1mbhiMmFgDP+mDJSKi0V27TpEGuKW5kOBWItWzytmrY/28y4qVaeThbnxF2xeIQOWAyJzKLR/xZtLfi3cnzg1vD69qIz4XxqTJSZKrJSNBnRCsjGp0Xmox0dGyYFzzf9mHLVaJQlcV1gEMVLXPObGCVkXQdsG9d64/ZBpApIzICwm4PZ0YUjceE7EPapIQg5YcefWUkV2bEMHi7ItfYwvEpj4wUmrbfTwUATNNA9wLy2r5aoVJHBVZdYLMhQkls6DqydVAFgjJcVYYj05DFplGU9gLA4JPJ49YPGGVFYQuZEY5A2t44BVnIiM6MaHQFaDLSkZE8zKghBlC7i5/UjwSb3w2eH9jcMudUId0AHN5DnpeNJ4+7OodVQytjVAREFmbllBHXDWdGqDIiTLZpg+YPMj4hCNs0imoaQN6FNc/S3pRLJtiEZFId0acIALBx7+HQa1LIuq8C6syIWJYs6zPC/iwSjdLB5HHl34GGg4oxFGFYABh6CnnculCxNo26AZpjUmVEnRnR7eA1ugI0GenI2LqQ3ImVDgEGTSXbtrWAVVN/ANi1PPi5tUttqfISLwFGfIE8P1pyI3VVQOWKZh/OdmClUNk00gArq3SJ6oQlkhEy6RUYwcQW9ZWRHKW57M9sZiNrWXEwfsrLjCSMMBk5tm83AMCGfMmIrPsqO54ywJqlmoY7XjjvlGuB7oOB6u3ElpQdq1KUgICMVCwKFszLZ4E/ALZ3roSRJcBqtlw7eMdx8fGWA2hs6sKFGhqtDE1GOjJoXuSYs4DB08jzikVHft4t8wEwk2C2rqj1B4CdS45svINbyWPpEGDAZPI8H2Vk9T+Bp88Hqnfw2/dvAv54EVCx+MiuCwD+/g3g8dOaXTqdkigjuZqeJdlJx2UmDbGluzCxpRAmIxHv9+jkWpuGfU2aGZGUFTP5ETYzIuLYsmIAwMa9taHXpFCRiV7HksfeI/ntqnbwoWxIgXx7rAg4/xfkedV6/pz+sYowLAD0mwDEugGN1cH/W1WAVTiWho4Ls9k0kZarpvnH8p24/LEP8cs3O4cNqtF5oMlIa2D+L4DHTycT2Xs/Aza+nX+W4/A+0oX0s//LvS8lI8eeDQyZQZ5vawEyssmzaBKl5DGbMvKX/wD+cAaw/ZPmj0fDqz2GAAMmkee7Pw93AxXx4SPAtg+Az1/it3/6FLDlfWDBr5p1OZXVDdiwp5bcaVd8SGySZhIbejcbU1XTSNap4ZUR5rlICISJLVAnGDJC+4zIqmlYlQNg7A62mkZR2ivkOWhmhK6zwuKYvoSMbNiTrzIi6b4KAP3GA7etAr70v/LrzlbaC6iVFQAYdS4w5iJmX7HpWZa+IVYEGOLdDOzfGN5HVYmDIHRckEUZaclqmiXbiA317zV7jvhc+SBjO1i0sarpTe80uhw0GWkOXJcEPP/8H8C/fsATjQNbgHcfJL0yPn8ReO8nwJ8uAf51F+oa01iy7SDcbMRkzSvA1gXAh7/Lfg37NxGSYEaBoTOBwScBMMiX4eG9R/beaF7k+K9570mRGan8DNj+EXl+JGXFNOdSOgToMRQo6ElKlfd8nv06q7y7u31r+df2riaPFR81uSonYzv4yqMf4sLfLsT+is+DCW7vmiadh0KmjHAExAo/58gIe/2+1eKRCGFSTLlBrw8KatPYufqMAHwXVopQaa9KlSHXFJMqI8Sm2VJVl5/VoFJGAKD7IEnWRewzojg+RkgRooXycc/9WbBPiHAoGs1RUKtGtk8Wmybj9WdJSEicf0gL9hnZUlUHANi6vx67qxuP+Hy58H+fbMeVT3yEOW+vb/WxNDo2NBlpKja9AzxxJvDcl4H1c4HF/8tPxB89BsAFBp0InHUfMP4r3vbfY+0T1+Mrjy7EP5fvUp+fTqT7NwXdL2WgqsiQaUC8GCjoAfQdS7YdSYnvgc0kw2FGgUlXkW0Ht8mvZelzwfMdn+BwMoOlFQebPia1aXoMIXfbVB3JlhupqwrChvQzo6DEIVkdfk3cr3ont2nRpv3YeagByYyDfRuW8Ps2A34HVmZ5eN6aCedHciojlEQId+9JCSGw/ABrPmREsDsA9aq9AiFIuUGfEREDuidQFLOQcVxs218fej0ElTKigrKaRlA3Zt5B/k8PP11+nu4DgbPvJ8/7jOZfy0IoAABDBDKissNEMmLQappsZKTlMiOUjADAR1v2H/H5cuGTrQcAAJ/vrG71sTQ6NppFRh555BEMGzYMiUQCU6ZMwYIFC5T7vvfeezAMI/Rv7dq1ymOOWuzfBDx/OclIRAqIVwwA7zxA7tQbq4Fl3gR9+n8Bp9wKfOVJT1Y2MKXqn/hl9DHMXbFDNQKwZxV5TNcDtZXq/di8CAWVio8kxEpVkfKTiDdvRsidcq1AoNINwMq/Bj/v+AQ/ee1zXPLIIvxz+U5i2zxzYX6TOKuMAMBAkhs5vPlj9TFVzJ3W3rXBpFl/gP/cVJ9FzS7gsdOAJ84KQocAXv0seJ92JZMT2buqWWXTvk3DKSPM2jSyPiPKzIhYTSOQEa+ihSUEEXjKCP1TV9kH7GsymyZHeJYSoSjCyohhGL5Vk1duJJsyIoNoLykal/3j8BhcXXUNDtlZSM4J1wO3rgRO+y9hDDWhAAD0nxioKuI+hqH8nWVMtb1FEfOraY6MjDSkbFQyasjiza1PRlbvqgEAbK3Kg4RqdGk0mYy88MILuPXWW3HPPfdg2bJlmDlzJs477zxUVGTvRbFu3TpUVlb6/4499thmX3SLYf8m4JMnw300Dm0Hnr04yE5QbPuA2Af9JpAvrKteJJLvrqXAujeApc8CqcPkrmrEmcFxk64CLn0CGZi41FqAizf/CKmkJA/husAe5k5+/wb5dR/eRzIRgEBGppPHIwmx0vc84nRiB1CCIFo1a14l5Kt7OSFmjYewfSOZvP/66XZg/k+J3fTB/8s95kHv8+8xFACQKjseALB77SJUNyi+pKuYAF6mIVBXRPKj+iwqFgckyyNVyYyNf63a7e9SsJ85V2M1R3I+2rwfV/5hMdbtzj65UpVD1YE1dzWNTBmR9AxBkNuIutmqaZqgjLgu/CBziAjxxyapMuLKf1/H0IqafHIjsi6m2aBsB88f/9zibViwoQofbsoxCZcO5lfsBbKW55JtkSBELtnH9T4vV/jMaTl2VpuGVtPk205fga3767ifF28+cETny4XGtI1N+8jve1d1A5L5duDNA//6vBL/8fiHqKxuaLFzarQvmkxGHn74YVx//fWYPXs2xowZgzlz5qC8vByPPvpo1uP69u2Lfv36+f8sy8q6f5vgtduA128H1r/Jb//4caIQLHyY3175GXkcfjpQ3Aco7gucdCPZ9s6DnkUD4OSb+WZNADJjL8F30rcg5Vo4z/gQtc9dGQ5oVu8g1gJFlYKMfDCHfOEOmBRYMwAwmJARp3IlDh7I8oW7bx2pQnnlFmDDv8kdpZ0BqjYCWzyVa/gZ5LHnMPIoVtQsfZY8TrrKt1X61ZAS2OWbdsKl59n8rlJRqGlM47Zn3g3es9fvYZ1FiOpwdyc+WKnwmvcJ2ykJ8WyZGtPrirltkXz8yuXB8w8fAVwX89ftQ21jcGffq877/GnVCGP5/GHBFizatB/3v+YpJts/DpaRZyBVRpR9RsjfBJ8ZYckIef2g99/mUJr/86VkhFVGTFEZydpnRAiCZiVC/GTb6FJlRNKt99B2nFBMckx5lfcqFqtzXRdLKw6iul6YuEMBVrmyQstZQ03l8oFkUcAQhs5Q7tNgk89nXwP/vUDLsePZSntpZkTszNtEUItmRJ8iGAb5eU9N6+VG1u2uBeVPrgtsP9By6sjTH2zF4s0H8PqKLOqxRodCk8hIKpXCkiVLMGvWLG77rFmzsGhR9rvxSZMmoX///jjzzDPx7rvvZt03mUyipqaG+9cqGHYqedwyn9++7QPyuHMZHyCkZKT/xGDb9FtIf4y9q0ifgsLewITLQ0PtqU1irn0ibkzfjqQbRa8d/wb+70p+AhPzDTSZ72FLVR327NwMfPwHsuGM/+ZIz5q6Imxz+8KEg30vfEs6OQIgAdttHwBL/wg8fynw82HAT/oDv5tCiEGiFBhwPNm3h0dG2IqaA5uJ6gGDhFzLTwAATDLI5D3NWAWD3t3WViq7qf7xg61Yv47YUm5RXyBGgoXLD8ax1imHabioWvJP+XugygidFH0yQh7/nppGyk0P75EHcNk+KvvWAJvewaveF9uIPkXohWp0tw+Q9zjiDO7cruti+fZDAIAPNu7HrlfvB548m1QVCWPJFsrLqYzYCmXEK+3dcoBMuttr+DtNatNEOGVErKZhS3MFMkJ/pqv2cuFZoZJHuMNvdMOqjI9nzscVn1yOM80l+ZERhTKyfPshXPLIIvzXi0Lfl1CAVZ4Zob+LULv9fKBaHI/F0Jnha/JAbax6h69g8smIjMR58G2aI1RGKBmZWF6KcQNKALSuVbNqF/+93ZJWDSU2m6vqcuyp0VHQJDJSVVUF27ZRVlbGbS8rK8Pu3bulx/Tv3x+PP/44XnzxRbz00ksYNWoUzjzzTLz//vvKcR566CF0797d/1deXt6Uy8wfw04jj1sWBHegjTVw6USVqg2yCY5Nyk0BnowU9gSmfTv4+YTZ/OJZHnYdIsTgXWcSvpG+E42IkdzHot8GO9HqEfqFz5CRQ/UpXPTbhVj01N3ky3rwNM4KchwXP3h5JX6VvhwZ18TIPXOBp84N9+CoqQTWvEaeT7gCKOpLrCU7FeRgzn0okKl7DieP7CS77E/kccQZQGk5MIiQkcnmRlimgTNMIXi6OUw+kxkbzy7ehsEGuWNOFg/yX1u5sxpz7RMBAIN3z5PLu1Q1Osb7DPZ6WRuPMHzmDMcK17t2MdDruoEy4gUP7UW/w79Xk3LHm08/BmNMYh25PYcDA6dy5955qAFVh8mEWYx6lC73FLG9q8nqyRvf9odKeRUQsWY3PROqWQCkvTAq7StCkXS99WgYZcRyqTKSR58RX2HwjueIkFDaG7JpwkSInMMFDlXAcB38LvpbFO1bBjvXpEqVEUG52en9DdHH0PvIoYzQbrjNUkay2VsUbG4kxlfsZDwyQsmHf01+SbSajLRUgHXzPjJxD+9dhJOH9QLQulbN6ko+tCraRM1FMmOj0lN0NuXbSK+NUZfM4IZnP8VfPm6DpTQ6CZoVYDUEC8J13dA2ilGjRuGGG27A5MmTMW3aNDzyyCO44IIL8Mtf/lJ5/rvvvhvV1dX+v+3btzfnMnNjwCSvWdEhYI8XVtz+EQw2NLjjU/JYtYFkE2LFQM8R/HlO/k+g2wCiKJxwvXQoSkZGlXXDIvc43Je+mryw9vVgJ5oXoWl/xqZZt7sWpalduCDjrUVzxv9wqshfPqnAsopDeDsyE1/P3IP9bjcy4T52Gp+jWPpHMsENngZc8jhwx1rgpoXAdz8DfrALuGkBcPyVwf6iTeM4wPK/kOeTvfcwiBCHkcYOXDWxFGdYywEAjeXenaKYvalYjLmfbsC+2iTKPTKyN9LPf3nlzhrMdcg5p2EFPlq7lT8+eZioUAAw9mLyuHcNmfg8dWm9W46P7FHkNTHEenALyYBYMeCiOQAMWJvfwaDMNgzpVYgLJvTHGIOEalO9xgB9x3hjkHNTVaRfSQJXRf6NQqcOye4eaWk8BDz/FeCzF8jxNDOitGkkq/ayk45YzQIg4xELOpH5Hwu1Sty0b03RapqMtJpGVEa8u3aHkhGZMiK3aRpYMsLaYkxr+QIjhcesn6Nyc5aSbSBQRsTyYe+zDE3KbIA1kwwUQYUy0iy7I1eAlV7HeT8Dpn4jWNaAju39rtLC74wSyuxkpGXWptlSRSbuYb2LcdJwQkZas6KGhlcH9SA3Z3lVUuWBnQcb/P9iR6sy8u81ezBv9R7c/+pq1DSqLbj2xB8XbcXNzy85arrxNomM9O7dG5ZlhVSQvXv3htSSbDj55JOxYYMiDwEgHo+jpKSE+9cqsCJB6JMGQrcu5Hap3uhNZNSiKRsfdMKkSJQA//kB8O1PSI5EAno3N25gCSYMKsW/ba/TaOVyEkgFAptm3MXk8VCFX+mxdX8dvmu9hJhhY2+f6Zw/va82iZ/NJdVJd8wahdgxp+KLyQewt2gkUF8FvDjbWx49DSx5hhx0wmzyaFpAv+NIeFR8XwBj02wlk0zFIhL6jHcHRp1PXutWhj1mGUzDxVcj76CfcRB1bhxz+8wOPlN6t7v8z8BT5+DYedfCgINjouTLcFOafDk2pm2s31OL9e4gVEbKETcyqPz4H/w10WBvYe/gc9i/kVTlNB5CxjWx2e2Pjx2PjIghVqp8lY0Deh8LjLkQAPANay4umjAAiaiFSXFS8ru/20iyH+BX7SyvOAQAOG90KW6Ok7zR3wqvAK57g9hWrgO8fT/g2NKmZzkXypMFWBllZF+MKIW7I4GaBAS5DQA+CaDVNPKmZyplRGbTCGRGIDINnv1gwglsHiCwTABssoahl1GLnv+4kqtgCkHRQVVps7AB1k3vEhLVbQBQ3I/bjSpszerXwVUhZQnWTroKuPDXoQAsJSO0MZ2/3VOzIlBPCDFPGTnStWmoTTOsdxFOHNoThkHUkr2tkBuxHRdrvXD3Bcf1B9ByykgFkz3ZV5tUh9zbEWsqyXtvSNt4aUmW6sl2QnVDGg++sQZvrNyNd9YeQV+qFkSTyEgsFsOUKVMwb948bvu8efMwffr0vM+zbNky9O/fvylDtx783AhPRt6ypwAADm/2mnrt9nxqxqLZtO9wIBkX9lQSESBQRgaWFuD0kX2wDz2wPX4MACCz4d9Yunk3XGoJDTvNW5bc9e2RvbsqcIlFQqGv9foGd+6H5q5BTWMG4weW4OvTh+KiiQOwE31wM+6BW9iL2D/vPUQqfmorgaI+fLfJbOjhVdMka0jZ7Ocvkp/HXORPAmnbwccZohYdu+EJAMBC5zg8uaUHGStdB+z4mEwy7/4EADDOXoNrYu/hlD7kC+qzWhI4XVNZA9tx0asojtQoQhL6bn8TDivt0/Bqn1FAyUDyWTkZUuEDYKvbD0nEsNQZCQcG+QxrGQJNLZoBk1CXzOApm5CqS6yF+PII8sU/1rNptkeHE6IWSfhVO1QZ+ZLzb5TYB7Hd6YP7t47B1kMZ4IKHiUJWswPY/K5CGZHbNPGIiVLU4pgMkxUSF6oDsLTHeTg9+Su82e0S7leV5MgImdAtb5KTKyMCGfEzIxKbxiNDhzxOuV/IXjewWQg2mM30LHl62C9xyC1C4eGK4O9JBr80V7A0vM8yKZIR1qZZ7WWMxn4xRK5TR2TTeATEjMpJew6orLWUb62pyUjEG+9IqmkO1adw0Av+Du1diO6FUYzt7+VGtrS8VbNtfx3qUzYSUROnj+rrbWsZZUQMwm7ed/RZNWsqg7zMc4u3ZW90yex303NL2oRczV1Z6f89fLq1Gb2hWgFN/qu6/fbb8cQTT+Cpp57CmjVrcNttt6GiogI33XQTAGKxXHPNNf7+c+bMwT/+8Q9s2LABq1atwt13340XX3wR3/72t1VDtBk27KnFW41Uyl9EmmjtWgYA+H2GTNb9GjZh594qJrxKeoscrCMZjnPnvI8dB3P/ke06RO4+BpQW4LRRfQAAbyaJlLtg7l/wgz+8DMPJoM4owuOfJZGhVpCXGynZ8R4sw8VyZzjerA7uiBvTNl77jAQv7//SeFimgbPHliEeMfHp/ii2z3iI7PjBb4B/30eeT74m/x4O0QIy4QMkP0O/7I+71N9l077D+NQmFTBWI/mPPd+dhM8rD6N2gNcMatO7pAKners/Md4VfQFl9ZsAAJ9Wl+BwMuM3RzpuUHf0n3YFAGCasxQrtzDNyShp630ssaqojbLy7wCAde4gFMcjqEER1roemWLb5Hu/4/XmCMz69fu4f0UJPnZGIW6kMWLdY0AmhUE2sYHWOEMIEehD/p9kdq/Gyp3ViCKDcVufAQC82/urSLkRPLd4G1mmfgK5bix9jlFGAkuN7cAqKiO/i/4/vGjdHVh0EmUk4wJb3f5ICnMqF470lBGLKiP0+Gx9RvLIjKytIq9trea/XBscRglgm6ZRZcSMot+AIdjnlnrbs7T695ueKZQRlU2TqgPWebbnmC+GTptsiQBrvn834thewJd2qqVI56GMRHxlpPk2DVVF+pUkUBgj13CSnxtpeatmtTcZj+pX4q/avONgffM+ewEVAhnZtO/os2pYMrJpXx0+zPEZZ2wHP5+7Fv9atRu/n7+ptS8PLy0Nvk+XbGvdEu980WQycsUVV2DOnDm4//77cfzxx+P999/HG2+8gSFDyJd+ZWUl13MklUrhzjvvxIQJEzBz5kwsXLgQr7/+Oi655BLVEG2GB99YgxvfakRjtJSEOBc/Crg2trt9sNQdiSqjJyzDxZtvzQ1WbvWUkU+3HUR9ykZtYwZ3/u0z/s5dAqqMDCgtwMRBpSgtjOKt5HEAgInJJTg+Sj6zVfYg/GTuOnxcS74oqCUx7BCZTOc7x2PVrhp/vE+3HkTKdtC/ewKTyksBAN0SUZwxmtyN/LlmIjDxq2RiObCJTGpTrm3aB0WtmiXPAPX7PXvkVP/l1btqsNTh+8bUDyEVKL/aOAAAYK+di/S7PwcA3J++CiucYSiwa2HVEcVim9sHK7YfwoodHhkZ2B2xgcdjX3QAEkYaWxYzVTW0kqa3RyQpGfEUj/VOOU4c1hP9uyeY3IhHRlzXJ5a3LzSw81ADBvUoRGLWD733+Edg4zxE3Axq3EJ8XudZhF4J9f7Ny5HMOPhqYhGih3cBxWXoM5PkhD7YWEX2nRzkgeIp8oeea3E8un2QQc5hH/KkXRqsZjMjtjw7kXIMZFzvfN5k72dG6Pa8MiOezSJRRrb0PBX/sKfjX0UXc4cmHcOfWFlrJgiTJnBM326BQuNkufujZEjs8moryAQlLfs3kCxQUV9g8Mn8KR3Xr0ZpVvaCkrh8u8IKoNU04ZwP+VwjkmZxFNEWyIywFg3F9BHkO+adNXtzfn81FbSSZmz/EvTpFkdB1ILjIq8bt1zYfoB8l9K/naNNGdl/OIm9tUkYBnDJZHIj96fF27Ie89mOQ6hNkv8Dz3ywFftqA7L+9po9uPyxD/HMB1uU+Y5t++tw3dMf4/H3N+VUYbYfqMfHWwMCsmpXzVGxdlCzAqw333wztm7dimQyiSVLluDUU4OJ6ZlnnsF7773n//z9738fGzduRENDAw4cOIAFCxbg/PPPP+ILbwmMG1ACFyY2FB5PNnz4CABgsT0G3RIRGINIFUV8/T9JyasV89tEL2Pani/efABPfZBlMTkEmZGBpQlYpoGZx/bBUvdY1LgF6Gkcxv1DCNlJDCTKy7I6j4xUbYSTSWNiajkAYL49AYeTGWzx/NdFm8jkNW1ELy5EfNFEQgJe/WwX3HN/SpqTAcDIc/1+Hnmj51DyuPJv5HHcxdwia6t31WCtOzioFOg/ETdeeAoG9SjA3AZCFKx9qxBt2IvtTh/8xT4T/xp2lz/BOTBR6fbC0oqDWOkpI+MHdgcMA4eGngcAKN70Bu59ZRWufvIj7NzgqVR9RpJHttcKgHVuOYb2KsK0Eb3wgeMFCVf+FWg45IdXU4hgnTMIFxzXH2/ddiomnHIhCQ47aeDVWwEAa9zBqDjo2XAe4WnY+TnKcADfN58n26d/ByccSyzHtbtrcbAuRTI4AyYBThon1ZJOuVzTM9XaNBHT7zeRSXtfRr4yEvxu6aQqTsrpjONnE6hNE/FsHpsSBa7PSI5qGj8zYvjj10Z74tb0t7Eywn/mqYwT3PWzqodPRmI4tqzYtyucTNPJiFLZEN/HmAvDmQ3mGPH4z3dW4+onP8L89fvU16RowZ8vaKUTLYEWt2dTRqJ+B9bmEwafjPQJyMgpx/ZGt3gEu2sa/bbtLQUaXh03oASGYWBIL1Jd1BJWDVVGThrWEwD8xmpthaUVB/H1pz7GVkV4lmZlhvQsxI2nEoX7zVV7svZ0WbChyn/ekLbxyHtEEV+/pxbf/vMyfLzlAO59dTVO+dk7+P38TTicDMjrxr2HcfljH+LddfvwkzfW4sHX12QlJC8vI6rIjGN6oV9JAhknaFXQnmgWGeksGNuf5BQWZrwv1hT5T7TYGYvhfYrRcyTJwXzJ8Bp49R3rf0HSNVhOHEr+IH7+5jqs3yPvxlnTmPabafXvTpLlt589EhdNGoLGQaTiJLadZFXGTDwZlmlgVdLLn+zfgAMbPkR3ow6H3CI4A0jwldoZi7xuktNH9ObGPGN0XxTFLOw81ICle13giueIdH3WfU3+nNLdPWXEm9huXz0CNzz7KepT5D2trqxBGhEc6kGUHow8F2P6l+DdO0/H9y/7Araaga3077Jr8bPLp+DWqy8HTvwmAKAu0Q8ZRPDh5v1+H4rjBpLfjW/V2J/gr4vW4sMNu9EnTf6Y0j09NYYqIx7WueUY1rsQM0b0xjvOJFRYg8kd84e/88Orq53BKOvRDT/7ygRftsYZ/0Me60iga40zGBX0y9MjPImDa/Hz6OModmqB/scDJ92E3sVxv925f8cxiagjX6h/E4AbKu39UeSPuCfyJ641fCxi+g3LMinaeCycGaGlsSlhckrbLCEgx5tUGRHbuYvPAXVmhBmbEiExt5HiiBBj09iBMjKkZ6Ff4nqgVj2B2N7xtmBp0ACq0qahGPul0DlZAiIqDP9cvhMLNlRh9h8/wb8+l7coQI+hRJ3qNUL+eg4kPQstKZIRh/xeLFetjPilvZL1ofbVJvNqsU+rToYzykgiauGc8STk++qKXdLj8sWBuhQWb97vKyzUphnr9TMZ2ouMe6QhVtd1/czIF7wsSlvbNE8u2IL56/fhyYXyG1Bq0YzuV4JR/brhxKE9YTsu/vyRusx3oUdGLphAbmyeX1yBDXtqcdNzS9CQtnHcwO4Y1KMAVYdT+OnctZjx03cw59/r8fGWA/iPxz/Enpok+ncnRPmJhVvww3+ukqpdruv6ZOSSSYMwZUgPAGjemmItjK5NRrw/lH9WH8Nt/8gdg+G9i3xlpNggjNb1LJqM7eCz7YQM/Pji8Th9VB+kMg5ue2G5tIdCpZcXKS2MoihOvpSG9S7Cr684Hn0nX8DtGx1wHEb0KcJmlygb2L8RDav/BQBYGpmECYOJYrJyRzVqGtNYseMQgEBypUhELcwa533RfLaL3Klf8VygJuSJ+lQGj64I7tp2uT3x8v5yzFu9B7/59wa4rut/8dROvwuY8B/ASSQ/FLVMXDplEAafQIKoTs9jcN1Nd+GSyYOIxHrGfwNTrkXVyT8AQBqI2Y6L3sUx/w+reNiJqCkoR5GRxHPlr+GXZ3VHzLBR58bxsw+8L2FGGUkhim1uGYb2JsqIAxMPNXqW4OJHsfNTEnL93B2GX102EcVxZsIbNBUYeZ7/4xp3CHbXNBJp1BujX3IrTrNWwLbipDTamwhPHk5Iqe+/H/cVIFKAwfY2TDI2cgHWbqjDdZE3cUPkDRQgUBEipuGvUZKh1UeyzIhCGUnZYWXE8pURmhnJpox4n4WfGQn3OKF358l0mIz4FoTMprFiiFgmTM/uqD6svkPeVHkIALB0Jz/J0vdrOy7/d8a+p4Ke4UXrAK5XjUjiGtPU9nLxrT8vJWsriSgZQMrfr3wh9NLDb63D9//+WdZ255sc8re4yxrIvyeHKiNZbBoaYM2Ev1uue+ZjnDtnAT7LcWe7ZV/YpgECBfWNlbu5TMqmfYfzarW+p6YRD7y2GjN++g7+4/HF+OZzn2JLVR32eTbF6H5kGYAhvVtGGTlUn/btDJq927Y/z9WgFdh+oB6LNlVhT01jXkFTqsSoyqLp9+EYLyB81TQSYXj+owqpHVLbmMay7YdQilr8zwlE8UnZDr78yCJsrqrDgO4JPHPdCXj3ztPxy8smYnifIlQ3pDHn3xtw+WMfoupwCuMGlOD1W2biZ5ceB8MgYdgHXg+vC7Zs+yFsqapDQdTCueP7+WTk0xZWxpqDLk1GhvQsRGHMwtpMGTJFpDT5QLQfdrh9yB3EgOPhIpDHKwvJRL52dy0a0ja6JSI4tm8xfn7pBJQkIli1qwbzvMZZLPy8SPdwMzRubRkA6DsGY/uXYIvrlSU2HETpRpKX2Fx6sq8YrNhZjY83H4Djki+YAaXhc180kbDs11dW5m40JUFtYxrXPvUJ3qoMGji5476M+79EFJAnFm7Bu+v24lB9GhHTwMDjzwQueYxUFjEwp38HGHsxzEse5+wdxLsBF/0GA0/5GpedGD+we2A5GQZKLvsdAGDKvpdwcaP3Wbj98cQH20g76KJeQDH5/W1wB8KBiaG9yGcyrHcR5tonoKrbGCB1GAO3vgQA6DHiRL/XAocv/MB/ui1CFKEdB+uBkgFw40GJeeOp/+OHWgHg5OFCE6lEd79E+3LrPcQZZSTqBATEsoPnhsGQkbRHRmR9RlSZkYwbUkZoNY3dpGoaobTXkCkj/JdqynaQcvmxyfNAGQEAx4h4Q6htmsYkITMHG/n/syp1o5EJzx4edi7/f8xDMotNQ3/uWRSD7bi49YXleGdt+O8YpeVAjJ/MHcfFb9/diL9+ugM/fm11+BgQ8vTT9BX4QvJXWJY4kX+v3rVnU0aiES/AKigjjWkbn++sQcZx8cu35F2OAXI3LMuMAMCMEb3QsyiGA3UpX2Vdsu0gzvn1+7js9x9mnZxf+KQCM3/2Lp5YuAUNXpbh32v24uL//cAfi6qOzVZGPvh/wMs3+aXg1KIpK4ljWK8iJKIm0rbb7FbzjWkbF/1uIa78w0c46SdvY8J9b+E//7QEtYreILbj+irT+j2H/eaHLGhZ75j+hIidO66fp2ok8dziraH9F28+ANtx8OfCX6Lfn8/Ef59Ift+HkxlELQP/+7XJ6FUcR9Qy8ZUpgzDvttPwuysn+URvYnkp/jz7ZPQsiuGKEwbjV5eRm+bnFm/l7BwAeGkpyaKdO74fiuIRTB1KyMiSbQdbPDfUVHRpMmKahsdeDVT2PAkA8JlFekoM71MMxLvBYCyAhbXkrobmRY4vL4VpGuhbksBVJxP2++TCcOvxnUx4NYTug4A+3hjdBwOJEowb0B1JxLA/QmTIbg3kP9ChAafiuEGEjKzeVYOFG4O8iAynHNMH3Qui2FebbHJzo7Tt4NqnP8HHWw/gQDy4mxs44ypcPW0ozh3XD7bj4rv/txwAcEzfYq5kNfQeL/8jMGiK9OVYxPRJFgDuOQCS5fDUFnz6FADA8IjA9//+GbFSvN/TWmcQYpbpf9bkszFw536+lPmsM8+RX2v/CcB5PwemfRs1nu1UcaAeMAzUlBAyusQ8DkUzv8UddqLnX6/dXYND9d5k7NkFx5ubOGWEa9PP5isc22/fbmdRRmxFEDNtO4EN4JEcujZNWtpnRN7zwhWraThlRF5eS5QR79zSACt5LeOTEXWTL8MjQylHXporjn8wFdww/L/KsdIv1WQWm4baPt88dTi+OHEAXBf4x7L8bItkxvEbcP1pcYX/ZS9etw0LW9z+IYuJBliz2jRUGREUHXZiX7ChCh8pKjb21CTRkLZhmQbKe/KdYSOWifOPIzc+r3y2C/WpDO7463JkHBc7DjZgx0G5OmI7Ln46dy1StoOpQ3rguavH4a0rStCvJOGXptLSYYAhI01pUpZJkX49n/0FWE4yWpSMDO5ZCNM0MLw3sUc3N9Oq2XGwHofq02RhZQOobcxg7ue78Z9/Wiqt/Nl5sIHb/rFQFp3KOL5tRpWRWMTEd88klvKj720KEZ0FG/ZhnLENY50NgOvguMwqnD2W3Fz98KJxmDS4B7e/ZRq4cMIAzP3uTMz97kz87cZp6F4Y/C1fMnkQhvQqRNp2sWhjkEVJ2w5e85a8oMHaMf1LUBC1UNOYwcZ2DgJ3aTICwF+j4fUeV8Eddwl+3UhKAofToNdAMoFmXBN/30kmyWVe06vJzH+Sr08fiqhl4JOtB0OS6S4mvCoFbWnuNdei9tFmJ+jFssoZgj79h+CYPsVIRE0cTmZ870+0aChikeCL5tXPmuYJz1+3D0u2HUS3eASPzT4TmPUAcPrd/qJ4P/riWBTFLD8LQ6+5uZg8uNR/Pl4kIwBw5o+AXkHFzpjjpmLqkB6oS9n4yycV/voxC+wJKO9ZAMtb6fT88eQzXIjjsT5GrBbXiiPef5z6Yk66ETjnQQz2vkCptPxuv+vwkn0KXhr6w1Cvib7dEhjRpwiuy3xBJch7iiPFZUb4gKdk4gZLRsKZEWWA1XaQFkKkvjLiehM2S0aEtWn+vY5MZnurvS/2LJkRmbrgqzKM2sNmRoBAGXFttTJClZmkw5NblbqRjJZin1uCCqcPnq4cLA2TZ8uMUIKQiJg4ybPb8u1KKSpEP3h5JVfWKe4jkrikTd6j6arHiyrawW8RJuBfvbVeqmRQVaS8RwEXpKa4aAKxat78fDfue2U1tjJWyqpd1aH9AWD59oM4WJ9GSSKC//vmyZi56WGM/OeFePOcgzjBu9tmc2xDPZtmx8GG/C2VqnVBfumDOYCdwXavGoeSqhFeVqu5IVZKbkb3K8GaH5+LP11/EgpjFhZurMJdL64IfZ6bqvhxRAK4ueow0raLbvGI33kWAL48aSCG9y7Cwfo0nlq4lTtm4YYqv4cUAGDP5/jtVyfh7TtOw9XeTa4MhkFupllVmeK0kcTCYkPZizfvx6H6NHoXx/zfTdQycbxXhdne/Ua6PBmh7P2Dg6U4cN7vsaKR/BJ9OdNbd2WjOxCf7CRrktCwzyRmAi0rSfh/1GKwaVc2ZQQgi+0ddxlw2vcABIx6VSroajvfmYihvYsQsUz/mukdyMkyu8EDvaa5n+9uUo0/JTqXn1BO1Jjp3wFOv8uvqujfvQB3zApsCvYuqDlg2f+EQRIyEiskFpBnGVh9R+PaGUMBkAY+7snfwj9OeQX/cGZwUvQpx/bG23echk//+2yM/NqvADMCY/hp6pVXGdAKgIoD9XAcF8/sHobb0zdj2LBjpPuHrJoomYDjRpqfBBQEhN1up6k64X0ZstU0tlwZ4QmBZ9O4tLQ3t01zwLNFGhu965BV8tDMSGhSZfIqMpvGG8vxyofdPJQRqhqw789/zto0iGJW8uf4YuoBpBGRhslZQiD73AAgFrF80hhqrAaieh2o46+b7meZBk4b2QeNaQc3/WmJUsURx27w3qOZRRnpliCfa33K9kPjQBBKnTa8F2IREx9vPcBVZVCoLBqKE4b2RL+SBGqTGbzwKemvQy2Az3fWSI95ew0JeZ82qi9pV7+RVI113/QK/nLDyXjz1lPxHycEa4qVdUsgHjGRcVz/+zAndq8Mnh+qAD7/u2/HlPcgf5vDexchigxS2z7O3tVXAVomPLhnAeIRC6cc2xv/+7XJsEwDLy3biV+8ydtfdC2cohj5exLX9vHDq/27cdWNEcvErWcTZfWJBZt99XTnoQZsq6rBl6wPmPf9ORJRCyP6FDf5/VCcPiogI5RQvbGShLNnjevn36wB8K2aT9u534gmI94d/apdNf4f98DSAiRolcNxlwGTrsJfSr4B1wVeXrrTv3OYVM7LZ984hWQM3lhZyf3BsQ3PpOhWBlz6hK/C9CwiAc7NbqCMzLcnYph3p87aGKP7dUPvYnUjppOG90KfbnEcqk8HfTByoLohjXlriGf+5UkDlft9ffpQTBpcCsMIV/M0FScN64mSRASj+3VDvxKFgjRwCvDl35O+KcfOwhdG9UU8YmLr/nqs2VOPFQ19ABi+JEwxok8xSgtjpPX/d5YCX3kqr2uid18V++vxtyXbsXz7IRTGLD/xHnoP4nofnhoQR5q/e1EpI0wViq+MSHMbCquEIwTUpqEdWOnaMiazvoxY2UG+oFyxtFc6tpAZyRVg9UKmrq+MqCdfw5UrIywBEUt1D6IEhd374IzRfZHKOLj9r8u5u1oVOWBfi0VMv7pJJO47DtbjvN8swA3PfsptpwpKImJizhXHo1sigm376zl1hA37iudttHPbND2LYuhdTMjc+j3BnTm1PKaN6OXfQf/yrXXc+z6czODvSwjBGNZbPrmZpoELmf/T104fiq+dRMr/VcoIbSF+5ui+ZPHNGi/0u/EdRNwMRvXrBpOZ8EwzKO/dmm+IlZKRhPd9t+BhbN9P3v9gRhn5VuQf+M7mm4DfTETl3F9i9hPzcwcy928Cavdwtg/FF0b1xUOXEIv2kfc2+UUCQFC588Xjyffiuj21HEEN8iLhm7MLj+uP0f26oTaZwe/e2QjXdbFwwz7MNFegt1ET3BzsWRX0F2omTh7eCzHLxI6DDdi0rw624+KtVYSMULWYgoZYl2zTyki7YmRZN1imgQN1KXzoBbiGM7X4iBUCX/pfdJ9Aql4e9brjHdO3mPPpAGIvnDy8JzKOiz9+uNXfnjUzosDY/iV+RU2tW4AV5kgM8Gwe1sbIRQIs0/DXhnglT6vmDa9V8Kiybr6NpTr3X244Ge/ecfoR2zS9iuOYd/tpeOGb05SLLgIAJlxOCEk0gaJ4xJcj//V5pe+hD1XcAQIg7e3j3fK6JvrluaayBg95a//cdtZIvzxbxMlebmR1ZQ2q69P+BJwI2TS5lRE/4CmxSrJlRvwQqUdsaGYkw6oMPUcA0aLQ8gUNNm1IJjQ9k1TykKwEO9nbobG59+QRM9uzhlzWyhFgeuM3Ovz/A5W6QclFPGrhp5ceB8s08PnOGuxm+jpkzYwwZES6WCHIDYXrhluRs2P3KIqhbzfyO29Is9YMU8kTIiPkPRpZyAgAjPKUinW7A5KzpaoOvVCN8fG9+M/TR6AwZmHFjmpc98wn2HGwHtUNaVz95EdYWnEIxfEIrmCUChFfmToIEdPAsX2L8V/njsbYAeQ75vNdYWVk56EGrN1dC9Pw7ICdS4IXU7XhtaA8DPFtzzzzHZSMnP4DsuRD1ToM3vceAGCw97c5ok8RTje9vkOHd6P/Rz/Gz7dfiSVvPqs+b00l8PtTgD9ehArvWnwysui3wKu34vLJA3DWGKJMf7AxsGJog7UTh/XAyLJiHGvsgP3sJf6CqmuEShoWpmngdqqOLNyCGT99B4++twmXUotm8tdJH6B0HXBoa36fkQKFsYifY5u/fh8+3nIA++tSKC2M+lYkxaTBPWAYxI5mm621Nbo8GSFyGPkjec2rtR8umczO8P5jUhbMZhxYzD5lOADgzx9V4HAyA9tx/S/FgU0gI+MGlOBDZyxetM7D/6SvQ/+eJf7qnccNYsmI2qKhoOV7b63anZcX/rLXKvjLkwdmJwYgn1/Wyb8JKCtJhAheLpzvEa03Pt/t3ymq5Oimgn5B7apuxKH6NMb0L8F1njUkQ9+SBIbT3MjWA0CE/L7Dykij4nnwReBmK6/1yYjYZ8QNKSO0tJcjI9e/SRZ1FEhZIw2MimOzmRFvknZdfvyUzSojkrVpvLu+fJQR0yXjh5QRRWaEPo9HTPTtlkChp26wZZR8ZkSo0mFa9sdlixUyP4t/P1T1oMdRRZUnI2oiRD9z08lORkb3I5MbbagFEDLybOynOP3dL6N3ahfu++I4xCIm3lu3D7N+/T6+/MgHWFZxCN0Lonh+9kk+oVGd/+07TsNLN09HQczCmP7dYBqkj4m4kB5VRSYP7oEeRTFgJ68WYf1b8jG6Z/D76K8R3TRP+joH1w3WLxo6AziJ9CT6auNfAbj+3+bw0qi/wvafCq/BVqcMPY3DmF15H7Dir/Jzb18MpOuBqnVIVRFLvbxnIVkNfN6PgCVPA9s/8sv12XbpVBkZ0acYJw3rhfsiz6DPngVkuQ1kV0YA4OyxZbhh5jAUxizsqm7E/v1VONv0yNykrwF9SVNN7GZWtk43Ats/4VfDzgNsbmTu5yS4OmtsWSg31L0gipF9u4Xea1ujy5MRABjn3QVQCXS4xKubMLC7L5UCfHiVxRmj+2J47yLUNmbwx0Vbsbe2EbbjImIa6NMt/3Utxg4ogQ0Ld9RdjX84p/gWDQAc06cYg3oUoFdRLMRyZZg8uBQDSwtQl7Jx/m8W4LzfLMAXf7cQb68Jly/SVsGGAVx8vNqiOVpwxpi+iFoGNu497NtsLUWOBpQGQVjDAH7y5fE+IVSBXe/D8bqdRo2gSgZAFmVEQkakpb3kS0nst8E1PfNIgOHZNGmWjBT0ALqHf7cNnmVgOLnHBsJ3/FIyIpT2utQiyhJgNXxlJL9qGnodlPBRq6UxLd9fRTRiEdM/h2hD0Z9Fi6fR205JSIH3mMxTGfE/czf74miUSKz1Jrvq+jQidbsxztwG004Cm97GZVPLMfe7M3Hi0J6oT9nYvK8OPYti+MsNJ2OiF1LMhiG9ivx8SmEs4mcWVgnqyDve98YZYzxlzVMF/DYF6/8lPf/MxvdwrvUJpm55LHcZ6aEK0qjQjJJlH076TziRAhxnbsH0yAb08azpggOrETcy2O92w38fOAcXuA/j/zKnw4ID96VvkvWwRNBVuwH0qSbqS3nPQqLwUAJesZizL1zXRXV92i/lHd6nGOd2r8B0yyvn3rkE+2qTqDpM+quMLJNbYoZh4J4LxmLp/5yNP1wzFf8zfD0SRhpu71GkiWKZ1zF6D0NG3r4fePIs4O2mNaykfVgWb97v50XOO05uMc88tjdOHt6Ta8LY1tBkBOHwpezO2jQNf/VJAKFyK3a/W7wyrsfmb/K/PPp1T3ChodzXxIc42Qk2Ypl45dunYO6tM/0vj2wwDAOXTSVdUDdX1WFNZQ1W7KjGbS8sDzU28lsFj+iNft2b1/q6LVGSiGLmsX38n+MRE/1VmZMmImqZfiL+yhMHK3/nLKhSNX/9Pm65+BgkoU4gD2VEbZUA/J22rAuq3/Qsjz91ahnkY9MA4QlebLjGvacIDbB6Cglr5Qig+Qmap1CNJz4P1Any2Mg1OssjwGpZPhlRERbRnlIpIxwRYjMjYoDVzk8ZGeMrIzWkb8j+Okw11wc7eKuNj+hTjP/75sn4yZePw3nj++GFb57cbAuVWrS02zNA1Cbaj+TM0WWEsHoLT+LU7xHycGATULUxdL7xEVL2XJ7Zir9/kn35DN+i6Tua/N8p6oWqQWcDAC4oXB3kUTwi9JkzAoCBn102Gb+KfwvPZs6GARd45TvAZ0KjOnq9AMY562AYnmq9/aNgn+0fYdyA7ohHTBysT2PTvjq/kqZfSQLF8Qimbn862L9mJ177YCkAYFgvr7/KnlVkCQoJElELZ48tw+VRElw1Jv4HueOhZIQqI44DfE4WAMXCOcC2D4OTOA5RTFJy2+vYvsUY0D2BVMZB1eEkuiUimKGw9f/7wrH4v29O87vatgc0GUG4LJXLjDA401t8rlucNDtT4aKJAzCyrBg1jRk8NJd0wWtKXgQABvUoQDemO6h4t9+zKIa+3fKfdL/9hWPwt5um4bnrT8Rz15+IiYO6o6Yxg+//fYV/l+K6rt8ngdahdwSc57W0BkjOw2wC6cuFO2eNwmVTBuG/zhud1/6njuyDiEmUmvX7g7vdKHvnm0dmJGyVsH1GFHf8tuMvyOYHWL3jU27uP/WQMuLnVVgyolYbgqZn6tLefJQRWlnSYPO/R1U1TZJRNoCAECTzJAT+ysoRU2nTJHOoMiIRUtk04nnr/c88Oxk5tqwYpgEcrE9jX20SW6oOY6rJVHps/cCX8U3TwJUnDcajV03BsWX55aNkoNm0z5kQ66JNVUhmHAwsLSB3/1XrySKj0SJSeTiELKGBDW+Gzld4iJCnhJHG//3rXeyXNAzzQclIvwn+ps0lpLLxZKwI9vMsouXOMZh9yjBcOGEARg/ojh9mrsW6IV/zLvq3wf7MQpkAMNncgH4lCfJ/pmJxsN/2jxAzgYmDSgEAS7cd9HuZjOhbBOxeifjmt+DAwF5vJeoP3yfveerQHoQkPToDeP4ytb2yeT6w7QOiPE643Hu/gjKycwlwmCrYLvDyjUCyFmisAV64iigmb/4gdGqA3IRSdQQAzh5TxtvFy/7kNZTLs7qplaHJCHhlJBE15Z1SAZw5pgxXnzwEP/riuKwTnsUElaj105S8CMA2ZCMY1uvIrIeIZeKEoT0x89g+mHlsHzx8xfFIRE0s2FCFP320DXtrG/GtPy/F1v31KIhaOGdcv9wnPUpw9tgyRLzfh1hJc6S4aOIA/OKyiSjJQ4ECiP9Km9C9/vkeJL0JOubI7RhpTw6wyggt7Q23ZAf4u3wSYOXVCUMWYJXAdlzfFjGyKCNs3oK1IpSZEaG01xW7vErgkxEnP2XED5F6TffkyoiaECQlNo1IWNhj2NwIVUCovB0oIwqbJqSMeN8jWZQiel56Q7J2dy22VNVjCquM1O0FqjZkPUdTQe1r1qZ528uLnDG6L8mTUYtmwCSSLRp5LvlZtGpcF9gbtCcvT27Eg2+E25WnbQf/84/PsXa5F4Ltd5z/2pLI8QCAYan1QL2XbfDCs5dffDHuuYA0PhzrNbJ8ufirZJ89K4E6L4R6cCvQeAjwOmuPNbZheA+LKDw7PgkupOEgsH8jpjBlr7SXyfDexcDCXwMAPi89A2/bpPfStPhW3HXeaNz3xfHA6n8CcIEdHxPCIcKxAxJxwvWkMSQQKCOHthHCsfY18vOxs0hTzEPbgH9+C3jiLGDd6+S1HUJmhwHNjQASi+adB0lDudWvKI9vS2gyAqBHUQwDPEtiaK8iJdGIRUz8+OLx+MqUQdLXWZwzrh/GDwzIxABVw7MsYBUb2jSopTCiTzHuPo/88f7kjTU461fz8cbK3bBMA3efP9pfQ6cjoLQw5hOAYQpVqy1Buye+vqLS70pqOpIKk9BzlphkK69VkBFJO3hTFmCVIJmxkfFaxhtZ2sHbEpvGcVw+PCu1afJXRqi11CDYNCpC4ZMJL8+TiEhyG2metMnOG7NMZZ8RVeOysDKSPcDKXrfruqjPeJkkuMwqyXLQ3h9rd9dg5959GOsFN9HTW7xv20L5gXaG3PXnOL8I+v2z42ADDtWnUNOYxpveQoJneCqxH16l3ZVHep2Nty0ikylFzU4gGfw8ztyGl5bu9FcdB8jncdeLK/Hc4m0oPuRlMRhlZPXhYqx3BpIKsS3vE0JyYDMZftwMP2xPb+I+rbKAvl5zw61exQq1aPpPRF2sN6KGjWmJ7YQoJWuAWDFQfjLZZ/tiTKVrt2w76PcYOb6wClj1MgCg73l3w/EaQV4zuAo3nTYCBTEL2Ph28N4//N/wh7v8eaJ+JLqTZpIUhT2Bbt66ZHtWAeveIM8nXAF8+VEABiE6VetI9gsA9m8MlwJXbQDqqjD9mN7oWRRDv5IEZh7LWDSZJFDrVVdKVKz2gCYjHugf3pE0mmFhGAbXFKypNg17TTHLVJaTHgmuPnkITjmmNxrTDmoaMxg/sASvfHsGrpk2tMXHam3cfd4YnH9cv6wdC9sKtCRwx8EGee+NdG6bxhWtEkk7eCBsXYiEIF+bpjEddG/1G3BJlZEwCaCTuUiEuPcU4ZUR3wqSgGZGGjJqm0bMygBAPKrObaQ4BUm+5g0fYFXbNI0SokFVmYIcmRHHZUuzXX8VYwBZCRoAjCoLKmrie5YhYjhoLOgXSPxbJWTEdYGXZgNPnQO899Os5xfRvSDqV62s3lWDX725DvvrUhjWuwgzjvEmth1eJchAsqgoeo0gnZKdDLCJmZD38irIGaXEevjms0vwp8Xb4DguHp63Hi8u3YHuOIxBhkdSqG0B0vJ9oeMpJZvfDUqKe47g1sMa3Z+Stlq4w2aSjVvmk8fK5eRxwCRsTpCbsYlYTypsALJYJrWaKj7yQ6yb99VhmddZe+bOP5C/jZHnot+oE/C1Sy4FAFiVywnhq9kF7F0Fqr5g3VzS14QiWQu8/WPy/NTvh9by8t/zqpeJDWZGgWPPBoaeAsy4hbxWfhLwn4uI4phpBKq3B8dX7wAenQ78fiZKnFr867sz8ep3Tgl6ZwHAIWb/jf/O+X+vLaDJiAfaPXOSomS3OTh9ZB8/0Ei9x6bgxKE9YZkGJpZ3b1L4NV+YpoGHL5+IiyYOwH9fMAb/uHmGL812NIwdUIJHvjYFg3q0rILUHAwoLfAb0/lkJK1SQxTEhN7FStvByyfldIZtB+9V0+SpjDSmWWVEXdrLKSPepEwn+qQrWZuG2g+eMuI3WsumjIBmRkSbRl6V4lfTUGWE2jScMqKuaEkxygolFSkxqMqRkTAxSUT5sVXVNOx4Kbb6CQhanyvgT7KVteh/iOQe0gNPBIbMIDswuREfix/x7+Lx4e+Aw3uD16p3AH++Alj5d+WYVN3988cVeHYxUWIevHg8IW2pOm/Shd+wEQCxFABg0zvBtj3efp6KM9zegimDS3E4mcF//+NznPub9/Hbd0jo9aK+hIhURfr7Dc/21jZiTWUNFlAysundwJ7wVlenGNGnGDGLLJlR1cdTOba8Tx5pJc2A4/EZiJU+IrkaqPDCq+UnA4MDZaS0MIZjvHzgvtokZpor0Hfba4SgU0Wj7xiSmUnVEvLgdaPFwCnAsecAcIHFjwYXuHAOsdV6DgdO/Gb4Q6dWzdI/ksdhM4PGb2fdB9y8GLj2DbKSNFXFWItu+0fk7652F/D6HehbkghXch7aFjxvrObDu+0ETUY8XDdjGF6/5RRcN2NYi53TMAw8de0JePuO0+TrreTA0N5FmHfbqXjy2hNa7JpE9C1J4LdfnYTZM4fnLFvVyB/UqmmUTdB5lPYi62J1iooWO7w+DFVG0k0hI5SE+GPLS3t9RSQjKCOypmdemTNdDydbky9q0zQ6JresPUdAsigjcVluw5arJOzPrDICCH1U8lRGctk07LnSGcf/zAHkvDulNs2a3TU4ziXh1cSI6SQ4asWBw7v5O/Bti4C3/oc8L+hBemt4WQc4DvDSjSTb8ep3gVrJKsUIciOvraiE65KOzNOpKlL5Gfk/0q0/Xyo+/HTySAkAECgj4y8BDAtmw3789coh+NFFY1ESc3HjgV/gvyPP4bYvDMaNo0ljuc8y5X64/r21ZI2Vuv4nkf9Dh7YBq14i5xzIk5GoZfoEYoU1jvzt7N9IyBdVRvofjw8aSU+oPoc+C5SRwSf5S4Bg/0agrsq3auJI4YGoV0Fz4jeBAceT56blr9mFHZ8GZOSYs4BpN5Pny58HqncCb94DLHyYbDv7x/JlKagyQv92Rl8QvGYYhPzQlal7e+t1VTH5IUr8APIZycgmS0YAYH37WzV69vFgmQbGDWh5BeJI1xgY3qc47/CkxtGDWeMIGQlsGsVKvQpikrXXB5cZEfqM0ACroIzkJiMO0i5dtE3MjDATNFtNk+bJSMakxIt9f1QZoWSEfIkaWQKbQQt7yycKGdsB25pCnhnxCIFHDBoz4WsFyOdEVQ+2VwtbTQPIK3ZCz9M8EZIHWOXkJ2U7fMl1joqa8h6FKIxZgOtgsknuhKNDppE1kKg6QHMjtbuBv11L1K3jLgMufZJs/+RJMiku/t9g39Rh4N0HpWOOG1CCAajCIGMvuhdE/ZAogECZYFURABgyjfx/PbgVOOhNenu9DMiASYC34ra153NcN2MY3r4ohUutBZgdmYtbKr6LgftJ+epn6cFY7XU0pY3Wpo8ZApSfSM5FJ2DJauA0N7JyPwKisPQ5ogJYMaR6jcZ7tQORdi1EG/aRviaGSYhNYU+gj1c9tz2war4V+QeGGHsI+frCPfyA9Bq2LwY2vUeeH3MWMOw0onSk64HfTiHqlOuQbqssyWBRNp7/edT58v2AgIzsZ5QRWhZMFxZ9/XZiHbE4VEEeu3mhVk1GNDQ6J0aVdUN5zwJFhUkepb2hipaAJMsyI3SyTqqUEScHGcnYsL27dFMcmysrDqsy9BpsI4sKRMmIdyeYrZQ14pGhDKyA8GSpbglnRsI2DXu867JdbIPtbDt4QG3tcNU0tOlZSBlhCYtg03CKkoEUXcQwhzJimgZGlnXDSGMHSox6NBqJYOIaegp53LoQ2LceeOYCUhLaZwxw0W/IqtZDZpD/F698hzTSAsikCADLnuO7fnoY3xN4Pf4DzIt9Hz+b7vLrYFUwOQsW8W4BQdm6gJDafV4Zct8xQYWMV77bZ/PL/qHGziUwvazJancIPty0H8mMjQUbiDJyxui+wPAvBGNZcaAsqLihGONZWmsqa4Bhp5KNHz9OHsvGYVetjQY3hrVgMmZ9xwEJr2ig/CT/PU4d2hMjjJ24yXqVbDvvZ8F+FPT9fv4SkKwmStTAyeTv9mRPHck0ACWDgCv/Cnzx/3F/0xx6jghszQGTiR2jQm9iNXE2DS0LvvDXhIg1VgOv3MIfR0nipKsJcaxa54eB2wuajGhotAIMw8Cssf3ysGnkC+UZok2TIzNCFRKxHXygjARffPtqk6H1QRrTNtIeGbGyBljDHVjp5OrQhb5Y1cMWlZE8bBraNRaRII+SVpORcGYke4iUvA/vvMx5YpYJ0zT8MnFeGWHLecNVOpQIFeSjjAjBX9trkZ8rMwIQq4Y2O9tVPD6Q62luZMNbwB/OIBZDyUDgP54HYkVk4jvjv8k+m94mv5djzyFEZezF5Hf95g9CmZPe6/+CHsZhFBgpnLPqe6TkFSCdTWlp6dBTwxc6/DTyuHk+cGALIUGRAqB0KENGVpDz0TLgK54H+o71T7HaGYJFm6rw8ZYDqEvZ6NMtjvEDugMjGDLSf4LU6qDKyNrdtQEZaTjgHXO8v0DepngwHgafxDynuZGPMHTPPLwQfxAxw8aWHqcAY74Yfr/UKkp7axeNOCP4mz3uMuCE2cCMW4FvLQ4qjlSwIsHnMDqLKgKEbZr6A8Gihf0nAl/2CNjGeUF5MxAoI/2OCwK7ijb+bQVNRjQ0WglfnDggjwBrvspIjtyGX9HCdGB1HFIyCl4ZufyxD3HOnPdR0xhMfsmM41d2hG2a8No09BggmFwdMwvx8jIjRoRcn5ll4o14AdaMq1ZGslfTZFdGAFIGzR4LAFGLkBBZ47NcrehD3V/zISNU1aK5EdV6Pa5LsgZ//wbOwweYYZI739q+jD0x6ARSWdFYTYKUQ2YA35xPqlsohkwHRpxJnhf0BL74W0JSzr6PHLtlPiEzFHYa+Ogx8jySgHFom5czeRN49VayfeadUpvEJwBb3g9Crn1HE5WNluvuXknCtXaKKDxjLgSunwec+E1UTbgRu9AbH285gLdWee3nR/UlbRcGTAoCnaJF5IGSkW3763G4bKpPggEAAyb5ZGRPyYRgOy3pBQJlZPtHMP72dfTGIWx0BuDgGT+VKxrdBwaWBxC0xgcIWbrgV+RzznORTpxxDyExU6/Pvh+1Yg7vIb97qoqUDiHqTZ+RQI+hZNteJktCMyM9hgTkqJ1LfDUZ0dBoJUwsL8XUY7wvqHwICJsZccXMCPlTdV2Xy4z4YUhKRtiVc11mMnaD47ftr0Nj2uEWQEuyygjEAKvCpknz67X4yghX2kuVEc+eMfMhI1QZsQL1RZG7YMenyggNk3K9QVRWCRNepX0qZC3h2fFkRCORZ9MzgPld+WQkhzJSvYNkDT5/EaetvAvnWx8DAEz2Tj5WGARHT/wmcM0/geI+4XOd/wuiiFz2DNCN5JrQYyhw8n+S52/cGagfq/9J7rKL+gBff41YBxveJBU4rg1MvDJQW0QMOjEI1a7+J9lG7/apMnJwC8mwAKSPBgDEi4Hzf4GeF/8MPQqjqEvZeOFTUobqr4VjWsDYL5HntHJHQM+iGMpKCAFetz8T5EwAYMDx/urLDWUMmWE/z57DgSI6XgSZGXfA/M8FmHxc2BLywRKjEWeo98sHx5wFXPpEuOxXRKIEKPYaVFZtDMKrTLM4v9cKfS1VD9QR2wulg72KHxCLLxksxNjW0GREQ6MV0a3YuxPKKzPCBlipMsKX14rriwU2jahOpLhAZMqh+7v+ORpS7AQbVHYENk24tDctaQdPJ1WXVszYkvdKPXBKSlQ2jWPD9NScDCx/DJW6wD4PqxO5K2hSApEBIO01wto8jZL8CB07V58R9ryBTZMjM0I/QzMKu+cxAICDbjF6jDyF3+/SJ0nvifN/EZRQi+g1AvjaXwMbhWLmneRu+lAFUT8cJ2jWdcJsoPwEcncPAHDJZJst9xBNBJO7SEYKe5LsBEDu5A2TqAAMTNPwGxmmMg5ilolTaBUPAJz3c+BbHwPHnCkfH4E6srqylgRJAaIA9RnjKyMl/UeQEt3Tf0AmZgrDAM76ETD6QuCb8xE5+4cY3l++rosPmp3pdxzQrQ07WLNWDc39sCHYMoGMUIsmXgIkSsnxPYaRG5jN77XFFUvRcdpsamh0RNCsRF7VNMHzUIjUUydUi7z5IVIqR9tJjoxQ1YNtkV6fCl5vTNvIuLkzI7akrJhOqj4ZkbW7914zvYyDcmE4ZkLOIMKslsurC7LqFrG8VpbtoEgLnxtb0isjI5wSk6W0N55jbRp2THoNdi5lhH6eBT1gfedTPP3KPBzKxHBrP2FRs0QJkBgnP0cuJEqAK54DnpxF1I+/fR3YtZT83qhVMOkqoprsWwec+5Ca8FAMO5XYNPR33ZepxOl3HFBD1sHC8NOBkvBqstNG9PZXmz1peE++K3S0wK/KUWF0vxK8t24fnvtwK5whY3G1EUF68KmIR2LYfpCQkcE9C4Gxd8lPMOkq8i9fTLqG9DGZcm3+x7QEeo8kQeGq9aT1PRAQEAAo80ggrWiiZKR0SEAmR51P2uFb4fxNW0GTEQ2N1gRVBNgJOq0iJqxNIy+vtQVpJKSMWDHA9c7FtP9OOeRLh52U67k1Vmy/YZpv00hLeyUBVqqMRCRkRCjtNbwvO0upjAQTcpqtpslDGfEXyvNtGrUyIn5urDLCNj4T36t43sCmyRZglds0STbA6kKtjPiELgYYBq77ktyaOGL0n0jUj39+C1jjrVcy4XLe7pn+nfzPN+x0AA8EPzPhVPQ7Dlg/lzyf+FXp4bRhJBAsUtoUnDSsJ34/fxPW7zmMH+0x8ZTxc9RuKMWF//wc26o8MtKrBZskFvUCLv9jy50vX9CKmr1rgL1ryfN+rDIyPnjdcYK8CKsEnfOgWuVqI2gyoqHRmvDJSD4r9QbbVcpIRiAjKVpF4wUyXTMG2PACrMEkSAOs7CTZkGJLVBmbBg750pJV8nAKAU8UDFk1jVDaa3g2jakgI04m7XvHrE2TPTPCWyVxaYhUrqyIK/4CATFRrYXTKJA4MraoysgDr+y5/OAvraZRkhFvu6xBVktj0lWkG+fSZ8nP077V/HMNmATEupFAbaKUty5opiFapOy3Mbx3EUaVdUPFgXqc3YyFO08f1Qd/u2kaVuyoxsa9h/HZ9hJsq6zBsx8GDb8G9Wj5ZTbaHL2JdYct88l3SKyYVC1R9BxOvofS9SSnw4ZXKdqZiACajGhotC4oGcmrmoYhI6JV4hECURkRA6yOFSdkJBPYNI5rwOMq3KRcn+InVa4bqJOWd3+V9RmxyXlcGfESSntNr5pGpYyk00nQThYZNsAasqfCPUBiwmJ1jYo+IUA4RCqzaVQVNPIOrFmanollycLYfmYkl01DbbDWxnm/IBU8PYbw1kpTYUVIBc+GN4kqwk54I88hAdhhM0npsQSGYeAv3zwZdclMk1c9p8efMLQnThhKQqCu6+LDzfvxu3c2YtGm/RjepwiFsU4wBVJlhJYVl43jegPBtEgTt8rlxKrxbZrBOJrQCX4TGhpHMaJNUEa4zIi8HXxGYTf4k7XFlPbSdWlg+iSCvWNv4DIjjp8rIcenFaW94UoeXxnxbRp1O3jDuz6VMmKnybGkG6wRKBihPiFhUtQUdcLvyyKxaYLMiKrpWTg/kr3PiNym8Qmkr4zkyNHkymi0FKIJ4Eu/a5lzjf0SISNiYDYS91ahzY6eRTH0LGoZRcgwDEwf0RvTR/TG+j21KC3sJJ2tSwaRHi40l1YmyQ2VjSNkZM+qoOFZafsvKspCkxENjdaE1KZREZNgEqedU0VCELJphDCk65fXMsoITH+ND86mSYvKCLtoW0ahjITtEWoVBTaN955s5hweUbE8qyHiylWATJpsp23Sm9KBNciMeDaNgkywP8uUEVmfEVlvEXZ7UNob2Glp20HUMjkrKJVxJP1ZvElRpYzQzzPSRspIS+L4K0kWhd69HyUYWZZnv4+OANMkVs1uGl4dH96H5nX2rDpqlRFd2quh0ZrISUYUyoiiokUVYPUnazph2UFpbwaWT2LYSZW1aZIZQRlxMooVg9Xt4A1WBXJd/r35Ng0NsPJqgX9+TwWgYVplnxFpNQ1vlSQlygjdJ2TTWNnJSE5lRBib7Gdzj928ahCxA2vOzEhb2zQtCcMgYcq2yLt0ZdDmZwDfY4SCqiXbPw460WoyoqHRhSBW04iTtCIzour1EQ6wUsnf284pI7R0VKGMsGQkbQMwkKEL6tnhzIjtuFy38DAZYSZLO80HWS2BjCC7TUPzK0HQVAigSgKs+WRGuiU8QiBW08gyI/m0gxdLeyOmH42gpCUpjC0SIddXRo4Sm0aj44FVntiqJQpKRg6TUmkU9Aivr9PO0GREQ6M14QdYPT9XXK1WVU0TUkbIDCdmRkS7gWs85gSWhywzwgVYMzRfwoQphdJe1qIBwqqFSZUROj59b4blr6FieQHWSI7MiEhG6BjFgrrA7pO9JTt5XiSqE1mqaWTKCiBvekbHNAwjWDVY6FDbzVt9W1RGXDNXNU0Htmk02ga08VmPYaSLrYjivqSTLsVRpooAmoxoaLQuxN4bLPkAvKCpy+8DRhmhBECRGRHDkAY7YXlj2bB8e4edoPlqGnJ8sE5KOlTJw4ZXATbPQc5jcWMng/cTCUiK5aknSmUkQ20aURkRyUhYnQgpIzST4bi+ckSPF3t9yAKsspbz5H2rlREyPk+G6P4ikQqUkTybnmllREOFkeeQbrFf+IF6H1YxOcrCq4AOsGpotC6iXkkiJSGsLUORSZIKBoao+JN1nqW9dOI0WUKQIqV+GViwPcLTqLAb6HNKRlw7DSNUySOQEVFdiEbIgmROWiAjQV6AlvbS9WdE2F6Il3aDFUt7ixMRoCawpVzXZdrBeyHSSPBZpW2H+8xEMiIPsPJEiB0DCEhOxnZ8chhnjidkKN10myZXn5GOmBnRaBvEu5EVmrOhbDzpRQJoZURDo8vBV0Ya+UemXDZ4LbBw/ICny1slYjt4Oin729mgoGcN2TD9Nu68TcO3gwcCRSKTSUkqebLbNLGIyQd27bAyEqFBVrhcUzYKSkb8ACud0NNym4ZVL2JC0zP6vlhVw8+M5NEOXjYGuRbefgH44Cot721I2xxhoTZNUlCzAmVElRnRNo1GC6CMUUboSr5HETQZ0dBoTYjVNLT5WbwYgJd0lFg4EaqMCIRA2fTMe4xEogHR8Zog2a7JVNPksmnIxJhJp3J2fxXXpolZZkCG7BRjLwQEyYoyZEnMzwBwMorMiC0PoLKKhd+BNcKSEYd7z7TJVdC5Ng8ykhFJGK94iMfHmQAtS2RURAh5KyPaptE4AnA2jVZGNDS6FsQOrH579AKeqLguF2C14JBtOdvBywiBdwedltg0bNOztCTA6tkjdjodquQRVZmkYEPEImZgJSgyI5EoM6FKJl/Hy4wEZIRXX0RlhCMEVhAipYSkMW1zq/rGxNJeL+/CZUZogDUTVkDoOdnXo5YBywy6ixYwi+WxIdiQTSNrVCdDRy7t1Th60Gd00DPoKCQjOjOiodGaEJWRDCO5R+Kka2ImKZ+I7DAhUC+UR7ZHLZMoEel6IFUHgDQ9o8clFQFWOmlyNo1QySOOLbdpZGSEUUZYq0FiS6gCrKHSXNFmsUyYDCFIRMm6NsmMDcO7/ljEJJ8Pcxz93HhlI7syEvQPIdsTTHiVjk33o9cfMQ1/u0ikjLxtGt2rQ+MIECsETr+brE3TZ3R7X00ImoxoaLQm/EZgghUTSQARZptYZQMI68OQCVVUJ6TZB2qLeJmRjEdGXNdV9xkRSnvtdCpUyZPOFWBlyYidZFabDQhIJBqB4xowDVdKwFxfGREyIxlakeKVx9oOXNeVLnQHkIqW6gZCGKhqEY9YiFn85yhreiYulBdWRvhrYjMqZOyg6Rq7iF9MQYQCZSSXTaPJiMYR4rTvt/cVKNEsm+aRRx7BsGHDkEgkMGXKFCxYsCCv4z744ANEIhEcf/zxzRlWQ6PjwVdGGryGZ4IyAvAqAgs7HSIEamWEPEYlNo3tEQzHzWLTCJkRO50KhWdzVfLELIYIZVI88fIQtUw/nCq1aWwxMyLYNIng/iltu5wFw8InBJlAnWBtGpFoZGsHH86M2IQIpcNlvQAfYPXHjlqhsf3yZCtHO3ht02h0ATSZjLzwwgu49dZbcc8992DZsmWYOXMmzjvvPFRUVGQ9rrq6Gtdccw3OPPPMZl+shkaHA2tL2KlgMauokBnxJhzHZO5+JevDqNamoY/RiBEQAs+moeu8ZByHK+3NVk1jS/qMUMJDJ+uM4yJjO+pqGlodxNgLhIx45CgjIyOeTeMqAqzxgIyk7EB5CCkjfuMxhyMs1KZJZ3IHWEXlpygWkLq0HahMojISZ/qMBISFIULC2EZOZcT7HHWAVaMTo8lk5OGHH8b111+P2bNnY8yYMZgzZw7Ky8vx6KPZV2C88cYbceWVV2LatGnNvlgNjQ6HCLP0OUM6VMqIGymA7XrZB0lmROz1kRJKe/kAa1DaCxCRhQ1UNqYdOB6hoCSHqii2tLSX7FMkEAJOnZDZNGyA1TJ81SMjUYNcj8DQ6xDJFjd2xsmijDCEgCEsfmbE5vuXSJueCa3oSwoCMtDIKS7ZlBGJTSMEWGmLfHVmhJI6rYxodF40iYykUiksWbIEs2bN4rbPmjULixYtUh739NNPY9OmTfjRj36U1zjJZBI1NTXcPw2NDgkrCr+EN90oZEZYFYFsd61YsHquE14fhvb6oFnNoDLDC2KyVkmaKCP+5C8oIwCZMNn25rTnBamm4ce2vbELY8Hkm0w7wYTOBVjlpb1RM1BGMmlJaa9NJmRVB9ZE1ETEe/PsCriiMhKU1/KExa+m8dUJryJG0vRMJELdEhFm3Rne/mGRYMZmCUvUJzk2dw05lRHJ56ih0dnQJDJSVVUF27ZRVlbGbS8rK8Pu3bulx2zYsAF33XUXnn/+eUQi+eVlH3roIXTv3t3/V15e3pTL1NA4emAYUtLBKyO8YpJmW7Ir+oz4/TL8MCS1acLKiMMoI2yAFSAVNew22g3UzshKe4Nuo5QQJBl1ImZZTGkv+554ZSTN5lJEeBMyXclWLK+NcXYHSzRyV7TEGHVCrEKKy0p7hVxJPGL5xCOZdkLr0gRjh1WZeJQd2+XOb1CSocqM6ACrRhdAswKstFSOwnXd0DYAsG0bV155Je677z6MHDky9LoKd999N6qrq/1/27dvb85lamgcHYiGsyG8MsJbGsFiderMSEGMz3H4mRFWGaHt4F0mM8LYNACpqKGTaixi+iTAtcOlvRmmfNiflDO2kBmRND1jMiMR0wh6mWQk1TT+xMtX07CkIwiC2lkyIx4hyNjcsVGvmiYpVtPIMiPpMBEKWsXntmnEzIgqGEtb5MPWHVg1ui6aVNrbu3dvWJYVUkH27t0bUksAoLa2Fp9++imWLVuGb3/72wAAxyEleZFIBG+99RbOOOOM0HHxeBzxuP7D0+gkYJURunpvJCEoI1QxifnKiGunYPjqBL8+DLVKRGUkZhmMMuIFWBlVRVRGGtK2X/qaiJhwDCZcavCVPNQiilgG4lELdSnb6+UhC7DKMyOGYSBjqJURn4x4Co2sfDhoSubkZZVETCYz4ts0uclIUHET5D7YkmF2u3xsnrCEe5wIZERZTUMDrFoZ0ei8aJIyEovFMGXKFMybN4/bPm/ePEyfPj20f0lJCVauXInly5f7/2666SaMGjUKy5cvx0knnXRkV6+h0REgbQQmKCMZVhnxJutMJljRV8ht0LvvlFDay3VB9YiP6/2Z28KCbwCpqAnsBsvPjDgZSTt4jwhZpsnZFfLS3mRAsIRJNHh/ajJCcxSBTRN0Sg26qGbvMwJIOrAKNo1s1V6VghGLmBzR8JueReUWUSjAKnZ/pcoI/XxyVtNoMqLRedHkpme33347rr76akydOhXTpk3D448/joqKCtx0000AiMWyc+dOPPvsszBNE+PHj+eO79u3LxKJRGi7hkanBa2oSTcImZGwfWNEEsTGMMhkHVFUtBQIykiK7cAa4ZueUWUkY0uUkZQNx7sxT0QtOLZHRuw0YAmVPN7YUdPIYtMw1TR+aW+gjAABGZGV9iJERvjKEzZ7kb2ahjYes5H0XuPyJnnYNGKn1HjE9EuGaXfXbGNzAdaoqSwZtmiLfL1QnkYXRpPJyBVXXIH9+/fj/vvvR2VlJcaPH4833ngDQ4YMAQBUVlbm7DmiodGloFRG5K3T02wXVKHXRxBg5TMj1HYgmRHvvH47eNofw/UrZwqiFhrSNtcSPhE14Tg0MxIOz1KbxjINbmKVlvayyogwidq+FSRRRrwJ2fCsi1SG2Lpsp1SWLATKCK9O+GvTZBzEs/YZCWdO4krCYsl7iGQLsDKN0WheRSzttdicjQwZ3WdEo/OjWe3gb775Ztx8883S15555pmsx95777249957mzOshkbHRNRTRrhsiLy014wGAVauosXgKzEKop664BKCQic2Qka8SYtW0zDhV6qM9CyKYeehBtSnbRpHITZNmhzrZtJATG7TkABrEORMySwidr2dEBmJAK48M2J4yojJWBIi4WEDrLmUkca07T9n8yYiIYhy1TRBO3c6Ph2DbaZGy6TFtWm4ACujnsQFm4YSyICM5LJptDKi0XnRrGoaDQ2NJkAWVI0Kyog34RhcZiTceMzPjDC9PlIZh++OKrSDpxUybIC1RxEhHQ2pDLfgG82MuFzDNb6SJ2IFNk1DyvHVGq7hms1mRgQyQm0a2do0XojTD3UCoZAsa9Moq2kYQsBV0wgWDFVIWDLjL5QnsXLoa8lMNmVE1mfE9EmOb/9QZSSab9MznRnR6LzQC+VpaLQ2pH1G5MoIInG+C6pYXkttGiY0yXZBzWbTNKZt0G7yPQrJxNaQsn1VIB414XBkRFRGvGoa0/An4NrG4G4+vGqvQhkxI4Att2kMb0I2GUtC7CeitIgYxJl9+A6swkJ5rKpD34dFw8IubMcVqmnkDc1YJBRr00QjQbM21nqyIvm2g9dkRKPzQisjGhqtDUo60op28HaKIyO09NVhu6AK7eDZRlusMhK1jOAO2lM2XI9M1CWDfAglI/VMVUg8YvlNz1zJIn1pqoyYgU1T2xjczYdsGkVmxAFTsSPAoOWtVjTIfaRtn4SxIdTs1TQyZSRslUhX7Y3wny2njDDXlMyn6VmaqaaxAoWJkiAAiERzND3TC+VpdAFoMqKh0dpQKiOsfRNUnvh9QWxJea1vlfBlqn72gSUEHmjvEHZhvNJCatPYfCdRk6nsENvBU2WEsWmoMmIYRDHhmp4p7uhtSngyEluCNv4yI/4YNYL6Iq+mUXVg5S0esddHtmoaQGhuZjHKSJamZ/I+IyZ3XpYYRqKUlOZQRrRNo9GJocmIhkZrQ1o1Iy6UF/TksNnSV0VmJMJUtKRtx88+xNjSXg80M3I4SSb6eMT0Myf1KTsIYkYtQJoZ4Ut7I0xpb42njMQsk3RhVhEvBjZVfhxJ9QitpjEj/voyNQ2M+mKZ3Bov6vJaWZ8RpvGY7RKrRGLTREzDX4OGIzxRyz9vMkvTswLV2jQWS0aC9+STkVyZEW3TaHRiaDKiodHa8Ktp2D4jBdI+I0QZydJ4jAmR+qWijE0Tkygj9FhaxpuIWij0qnHqU0EQMxFlKnGcDEOEwqqMaNP4NgfX9EzeH8NvOS/pM2K63oTM2DSs+hK1DH8dmdCKwQz8qpdQZiSsJvmfG/24DEOeObGYahpGGVE1PUvZjq9Gsf1RyHsi2y3TyJ4ZcZyApGibRqMTQ5MRDY3WBquApGUL5fGt0+lk7cjUCaYLapSdlNkSVUVfD3o3noiafp+SxrTNl6h6ygi4ACsdWx1g9SdzSrBYm0a4HtcfQx1ghRVjyAivvsj7jKibnqkyI7RMmp6bRUzy2cajTDUNs1CeShkBgOqGtL+PaQYEkqpUMbYUW5YZYT8j3WdEoxNDkxENjdZGXtU0QdMzSh7cjKSihbFKZKvXRi0jJOe7PhkJlJHApskwyojlT3iGEy7tpZM3nxnxJlWfjEjKmMXSXoMJyQqgAVbDivjqS41AeOSr9mYJkUqanrHHAhIyEgnKcOnnwykjXKWMvJIHAKobKAEkx9HxKTGMWgZDAGUZmmTwXHdg1ejE0GREQ6O1kauaRiApvjLCZUZouSnTBZVZkj5YKC+sjEAIsCYilq+M1IsBVtamCa2LI6mmSQrKiG/TpJSlvVwvEwGGZ9MYVpRRX4Ksi/8eQfp05K6m4QkLVSYyTMluxDRgmvyq46xNwyojvuLCkBSx6ZnJZGqq61P8tXuPvjISsbIrI2zFkc6MaHRiaDKiodHayKmM8D05KBmBkw4RAn99GCtQRtj+ISQzIgZYyWR5mLFpqJXAV9NYMDyiYDjh8GyaCc/KLBTuvdrq0l6XtYIEmI46M0IJkB/czbhZqmm8z4bJdrBlwUCgTohEhpxPYgVZFqe4UHtLVEbI+OR6DjUI127xZCQeYSqYZJkRatOYUb/XjIZGZ4QmIxoarQ1OAfGUkaiq6VnCbzyWb2aErcyIWmEy4hpBWBUgEyNXTeN3ErX8NWEMSWlvxmbKiukdfsimYQKsisyIY6gnXxpgNa1oOCQr2jS2zYVLWcQZO0VWTQMAh5Py7q3cGBm+iyp7XnbdGRGUtASfOflZ/J0R8piNjOhF8jS6BjQZ0dBobXBr05D1YpQL5VkxnzzwmRF+obwIE4asYxa7kwVYadMz/248aqIwRsZoYO/wIyYMU5YZCY/tqxaiuiBremaJyog6M0KVEYNTRnj1hc19qHIbrE3TyFTTsKTlsKjqMJCtf8O2g2/MUtoL8CFW9vrigk3DZUay2TTaotHo5NBkREOjtUHJQfJwQC4icV4ZYatpWBsjVF4bXjmXV0YkAVbvfEE1TZAZCdk03l26KSntTbNNz6JBwBNgbRq6Lk5DUJIq9BmBxVhBAqgyYkSiQZ8RIcDKWiiyDqoAT04OM5kT0zRIczawuQ0JGaG5FIF0BJmRQFESS3tl20SLiVOUsiojmoxodA1oMqKh0dqIeMpI4yFmm6iMBPkKXxmRqBPByrmGrxCwZaKk8Zgg6XvH1qXk1TTBQnlmYNO4GaUqQ1btFatPRDJSx7xXkRypJ1/Lt2liPiEIBVh91cLh1n5hwYZKRTITskqyKiOqdvDZlZEwGRHGTjFj08/DtYOMEIXuvqrRRaDJiIZGa4NO0I3VwTZLUEaY/iNZF6tzgsxIXFBGqG0TUka8hfLqqTISCfqMsIu5JaKWv1qu4drMujh8aa9lGqGcRFy0abj3LyojjBUkgFdG5L1MYhKbRiQUUcsALZCh102vObC3cgdYxRWDKck4nMz4oeFsmZHgfLwywuVgLGa9UpGgaWVEo4tAkxENjdYGnYwpGbHiZIJnFYzUYX9fTjlweDLCZ0b4kGRUVCcoTIvbLxG1/ExD2nZx2CvPTUQtmCaZ9ExZgFVSTUMRUkZ8MJkIDy67/o0AC15nUqbpWY0ywOoipahoMQwjpE6Ix2e1aaS9TCz/nLSZmWxsQKKMRHkiFRBIRhkBwrkRvUieRheBJiMaGq2NKO0zUk8eKTlhFQNKVBibhpT2KgiBxKbxK0VCgVH12jQAcKiOkhETRtTLjLiZUGlvhrVphAk4lBmhiCTCJammOjNiebaUGYkw1TRpboyAKNhKZYS8H7l6IxICuU3D9BPhMiOUIDFkJJ8Aq0CEaAO6uFiKrVJGtE2j0cmhyYiGRmtDtCnohM1OQpSoWHEm0JhRZkYikgBrQAiEiSvUDt5CzDJheT5GLbPd8sa2XIkyYgfhWdGaCDU989+rZBL19pHbNB4ZYZQRtvQY4Ktp2IZkIhIK9YYqSKGyZHZf6crAQWmvy/R1MST9P1QBVnrttbLSXiCsFmmbRqOLQJMRDY3WRoiMeD+zq9z6r8WDpmBSZUTSZyQl9MsQJX3vfPTYRJRMoIWS0KflkQfTVROhqJXFpjEMfnzx/QFMZiSLTRONKtUXOlZ9yvZJQdzKp6KFD5Fm6zNCx25IZbiGcmIWRCQ8qrHFSiCOQBqGTxhDyghT8q2h0ZmhyYiGRmtDpYyIz719XZOZrAWrRNbrIxRgDVWvyFeVZa0ast2E6R1rcTaNJDwbIgrMudj3JMk6cOXDAiJegNWKxJTqS1yosgHkyohYYeOTmXxsGovPqwBeZkQM7krKegE+wBq1DF+FEtWswFpTtIRXNI7T0Ohs0GREQ6O1IZKRaEL9WiTmt2SHpJqG7fXhV4XkyIwYpnwCLYyFt9NqGlNS2kvzKkQZUdg0gEC2wnf0tLGa6UoyI/Bsmmg0pL6IuYtaJrchz4wE21g7hdo0tJomKlNGImHCw1bTiPuFx7aYfYLn9HcWahanKnfWNo1GF4EmIxoarQ1ZqDPLay5rYyi6oHJNz1ICGQl1YOWrWai1IJtYI1Ey6UXAlPZ6k3iQV8nSZwTIbdNEaGZEoox4Nk0kEstJRtgupuJCd+R9MoSAISsxi296FpcGWHnCEzENLysj2DQKZaSAIyM8KQLA9S4BEJT3ip+J7sCq0UWgyYiGRmtDlRmRvWbF/btkg1soj0yg7Mq5QfMuIftgWr6SQn7myYhMGTEMMmlarE3j9xnhq2lYIuSfk1NGmIlTMoka3sQrU0YifjVNLGyzCGTEz3JIyATAKyPxaJgQZFsoT1zQju5jMqslA9mUEfk+MUtuHQXKSIp7XSsjGl0FmoxoaLQ2rAhPCFSZETMKmKY/WcsyIywhyNpJlFEnRJuGKiN0fRrAW5fGMGB5No0FOzy2zdo0itJeIDvZAvxcijQz4tk0kWhYGREzH/61K3MbwXb2GD/AmqWaJmi4xnd/ZV8Tt7PglBHmeTTCKziBMqKyaegyAZqMaHRuaDKiodEWoC3hAfVkTZ9bkpbsppoQ0F4bfoAV4CevPAKsdFvE6zMSgazpWbBqb9bMCHsXL8uMsOXDLBwbpuGRLVlmJMpXw/hjK5URBSGQtNEXEbSi57u/iudV2TRxhU0jWkKBMpLLptEBVo3ODU1GNDTaAhFFjsIKqyR+wJNdmyZU0WKEJuWoQhkRbZqExKah+QrLu4aIa2ftcRK1DK6XmTrAKlFGLKZ8mIHLWBSRSDykWNCJW0VSRHABViv8PFQSzY7lN1wLqydxxXN+7OyZkdDPSmVE2zQaXQOajGhotAWUaoiEjOSxWF3ENNUTm3jekDJC9ivg7vDJtkjMy4xwAVavkodpB28YhpCFUIwtmURpxY6ojGTSDBmJRiXqC7++i3RsBuzxsswI/SyztYOv9bvWytUQ2bo0gBhgDasyoZ/NXKW9moxodG5oMqKh0RaIqgiIZLtfTWMre32w7eAp+MxIMHkZCmUkq01jOOoeJ54dxE6yTammMdiQLINMOpiII9G4smInFJ5VKCNxhTLC2VkIEwQgUDNSknbzrOIiNkGTbZcRodDPtJrGFm0avTaNRteAJiMaGm2BvJQRsp2zMRSZEWqVsIgq1AnDEkt7wzYNzTjEosFxLp0IJaW9QBb7IUefEUtFRuh4ACKRqGTlW3mAVZkZUSgjIvmQWS3ZCA933ryUkTzISC5lRNs0Gp0cmoxoaLQFVBU0XH7E67/hl75mwr0+mMyIOIlylRqcMiJfQZatpqEVNlaUmfQyjeTRL+0NGq6x5wGamBmhZASiMkJ+zrgmohFLGZKNWCbYtiIqQqCyU7LaW6p9LLnSoc6r5GfT+L9D+vvSC+VpdFFoMqKh0RZgq2mibGVNeOI2pC3Zw5mRsE2jaMku2jTe5CgrP43G2BVkU9zYYWVE3lSMsxQk9kKQGbG57XaaKCMZWFKyFVMoDDIyAeQOsKp+BsJVL2x1TEKRH1GNnS3wmnc7eK2MaHRyaDKiodEWyEcZ8bablqwluwnXdbnMiDgJq5URsekZVUbYCdYrm2XtHaqMSFrRA/naNGEyQm2aKPiJN5MhP2cQ8c4vKDqSXiHidbDgS3vVNk22PiP+PlxmRG7B5DO2kgiZuTIjmoxodG5oMqKh0RZoQjUNt1gdU15LVRGAZkay3OFzmZFwp1VAHmA1LRMZV/haMEVV5sjIiBmlNo0TdJgF4Hg9NTIg44mEQNVsrMnKSD42jSW3trJdBz92fjZNqLRXL5Sn0UWhyYiGRlugCdU08sXqTF8VAfLpM8IoI1a40yogL+0FAjIQnICW9gZNz8i5VNU0bNOz8CQaYfMPTEaClvZmPFsorCLIO6oqMyN5Blhl1TShAKtivOauTRP6WS+Up9HFocmIhkZboEnVNEymgukzwiojUSu8WJ2SjDA2DTt5cgFWZntGWFjPLyum3V89ZYTLbajawUsyI1xIlml0ZvvKiBfgFdaBaXpmhCUv4ZVzsx2ftZqmycqI+lqDzAizUjMLvVCeRheBJiMaGm2BXC3gAX/ipjZNlF1IzjD9ACkgV0ZUVolp8soIhcymAeTKiOO4/sJ0Vk6bJns7eIspH2ZtCcfrM2JDfr0qAqIiBPlaK9lW7fV/VmZG5MqIxRApWSv60LUoS3vp2jTaptHo3NBkREOjLdCEzAhdrC7CBjxN0y+tBQDLCAdYY5YiwGqplJFwgBXgyQAZ2+Isoohkkm1K07Oo9/7IYEFg0/ZUEtuQ2ysqYpKPOiFbKE967YpzqqppVKW97GvZqmnybwcfhYZGZ4YmIxoabYG8qmk8mybCBDwpDNO3aUyDWBj5Nz0LJjJ2IlWtLMuSAXFsMk5YGYlzZcXZbZpIxELa9fZnlRGvmsZmbCKVTZNXNU2emZEj6jOiUEaAgAzlZdP4C+WpbBqtjGh0bmgyoqHRFoiqVu0Ndyu1opK7YMMKBUjFgKdqoTzLYu2YYJ9ChU1jh2way1+XBmiqTSMhI6YRWEFMZoRW07Djq9SXbNUxwXuS7x/Nq5pGvQ+rImVTRgp8MtKEahqxtFcHWDW6CJpFRh555BEMGzYMiUQCU6ZMwYIFC5T7Lly4EDNmzECvXr1QUFCA0aNH49e//nWzL1hDo0OiCcqIJeu2aVqwbb60NvtCecw52GoaZnLnMyOMTSMGWE2Ly6tEJU3P1DZNmIxELRNphPtqyJQR1WJ8vE2TRwdWhWUj+1m2jb2OhMKyCY9P7aws1TR6oTwNDQAQzeHceOGFF3DrrbfikUcewYwZM/DYY4/hvPPOw+rVqzF48ODQ/kVFRfj2t7+NCRMmoKioCAsXLsSNN96IoqIifPOb32yRN6GhcdSDJR05VBIpGTFMZLyJiioT2Ut7mQAra9MoqmnYCT1ERowgr2J4FhEQTLKWafjXxL6P0HO6yTKQ9tQP106BHul4E6+jICOq5yplhLeR2P1zL5RHK3lSXgVRTKGG5KeMKKqOkEdmRC+Up9FF0GRl5OGHH8b111+P2bNnY8yYMZgzZw7Ky8vx6KOPSvefNGkSvvrVr2LcuHEYOnQorrrqKpxzzjlZ1RQNjU6HHKFVAP6EE4nKyIgVajoWVkZYQiBfm4adGC0zCMGyyogjIyOeMkJVEfZcYnZF9p5YRE3Tt2lobxEAcDJEJeGVkaDnCO2PAjQ9wNrUhfLCYygCrIpjAeA/ThyMKUN64KRhvaTnBBhy4jc9E20aj5xom0ajk6NJZCSVSmHJkiWYNWsWt33WrFlYtGhRXudYtmwZFi1ahNNOO025TzKZRE1NDfdPQ6NDI5/SXm8Sj0QkgqVhIm3zmZGImeUOn82MROTVNECQG0lwykg4wOqvS8MQD5YocMhh0xBlhFyTzazU63oTryOppskWKM2vz0ge6oQAVSlxPqW9APDVEwfjxf+cjh5FAZFQjq1sekZLezUZ0ejcaBIZqaqqgm3bKCsr47aXlZVh9+7dWY8dNGgQ4vE4pk6dim9961uYPXu2ct+HHnoI3bt39/+Vl5c35TI1NI4+5Oi6ym6PWBZSrjDJmWZIGTEMQz3JRhQ2jTDxUiuBnWBDyohp+TYNa8dQVSAmTsj52DQuVUaCyZeSEVdi02RbNC9br4+oZIXhfAKsgNjlVW7NJLLYNNJzCsqU/3nK2sG7rrZpNLoMmhVgZeVSAHBdN7RNxIIFC/Dpp5/i97//PebMmYO//OUvyn3vvvtuVFdX+/+2b9/enMvU0Dh6kGOlXnZ71DL8LqQAgg6oEkLAlbtyIdKAgJiMTSMqIwNKyXX16x5ch9Sm8YgQV1Ir6aOR9f3R6zRN//3ZnE3jKSOmxKbJ0m1WRSaAQPFRtZKX/Sw7r4r8ZFNGZGAJCDeubKE8xwZAO83pPiManRtNCrD27t0blmWFVJC9e/eG1BIRw4YNAwAcd9xx2LNnD+6991589atfle4bj8cRj+s7AY1OhLyUEc+msUxk2PsEg1+ojp2I2bxGTBVg5WwafuL97VcnYev+OhzTt9jf5pjCxGdYyNhkwb6IKbFpspERSdbBZEp7aTkvALgOtWmC8QP1JZsyoiYj8aiF2mRGWdFiGoHtFTpWMUYizwCrClHLgO24fNZGpozYgYWlO7BqdHY06S8pFothypQpmDdvHrd93rx5mD59et7ncV0XyWQy944aGp0FlICYUX8VXG478zzK9uEAgoXqvNyGUhnhbJqYf6yVQxmZPqI3t83NYtNEJGNnz4yElREgWP/GZskItWlYZSQqHyOftWkAYEApGb9vt+Ca8lVV8smMZCvtVZ6X9olhj/UzI8HnwT3XAVaNTo4ml/befvvtuPrqqzF16lRMmzYN/7+9uw+Oqrz7Bv49Z3fzQiTBEMgLLyFYWl6CIAlWBNRaSIsoVZ+nopYX79oZaQBJ6SBQ2ltvZjRoK8UWQendKcNYJE/nQUd7U21skZdhLExIKr6M8IxIgIYnwq1JBE1291z3H7vn7Dm7Z8Nucnb35JzvZybT5OzJnnOtze6P3+93XdeOHTvQ2tqKZcuWAQiVWM6fP49du3YBAJ5//nmMHj0a48ePBxBad+RXv/oVVq5caeEwiGxO/VCO/nA2rAcS+j6UGdH9acrGzIg+IIiXJdECAskTlc24+r8/9GWS0HPENs8Ckf6TmOzAVfamASJLzismwYhZmSb6Gtlx+jmiPf/gNJz77EuUD83TjulfJ7Npvap4pRm1z0aSTGYSJSAUhASM9222UZ722kiRMg6RQyX9//CFCxfi0qVL2LhxI9ra2lBZWYl9+/ahvLwcANDW1obW1lbtfEVRsH79epw+fRperxfXXXcdNm3ahEceecS6URDZ3TXFoQxHfqnxuElmxOuR8KVJZuRqPSOmG+XJXsP58ba814vJjEixzbMAcGNFIaaNHoJ7po286piiBaTYMg16aWDta2ZkVOEgjCocZPzdBAOZeOeVFuTgO5OKUZKfc9VeOfPnNZmaLZtM7dVvkteH6xANJH0Kt2tra1FbW2v62M6dOw0/r1y5klkQovxS4KF9wDXDjcdNpsH6ZBkB4YG2Glj4gztgkp2IO5tGTetHBSPZiQQjhp4RCZAkBMKLf+mn9g4ZlIW9tTNjnyCnAPDmhpp245QXgpIPEEAwoO+RMCnTJNQzklypJN6y8tHiLUUvSRJeXFyd1DXNrm/aMxKMfT1YoiE3YO6PKF3KZ8Qek+XQh02wR9fAGt0zEvrQCly1TGOWGZGNmZEEyjSGkkC4RKTtiyMn8PtZecC/7QtlReL8iz4oeQERmUEDQGve1AdDWl9KVMCRaHbDTMI9I/24Rm+yzAIss+XgtWm9DEbI+RiMEGXa4FKg4xyQNwxAKNjw99IzktjUXvPMSCJlGkMwEi4RBZXYzEivRkzr9eGgaZkmEHN9rWckempvgrNpzCQajCSy5HxfqNc3ZrJMpvbqyzREDsdghCjTFv1f4MolIC80q0WSJOPOuWqZxmRGS9ypvdcUA5CAvOHJ94wYgpFwZiQYm5XpDyX81iN0K7CaZUaKw+ufFOcbP5ATWYE1HsNrluBsmmRLQb1JODOilWm4xgg5H4MRokwrGgdgnOFQQDJpYDXrGTFsT68LFApGAA/9FzC4BF5/kiuG6j/8tMxIEmWaBARlHxAEFF0mQAo3bwrdLsPzKkvwn0uqMX1MoeH3+xMoqCvX9gSVXntG+hPw9EZ9XuPy/SY9I1x9lVyEwQiRDQUTnNqrzszweaTYmR1jQs2lnvYu7VBCH9z6Bla1Z8SkgbU/1FVehX4tjXAwIumu7/PImDMxdkHF/pZQfB4JPcHep/YadudNQc+IcWqv2Wya8GvDnhFyAev+wojIMvqdayNTe2N7Rnxm/8qO4pGTzYyYXNskK9Mf6vRdoWtgVTMjiaypoX6ge/X7uyTBtFQSfU54rJJkXXlK/7ymZRrDbJpwMMJN8sgFGIwQ2ZBZMKI2kZr1PPT2oeqRkmxg7bVMY1FmRNuLJZIZkZTEeyTUvWb6Wj5Rg7de1xnRZTD6sp7I1Z7XtExjOpuGZRpyPgYjRDakmPSMRJaDj53O22tmxKOf2nv1YETymJRpTJpn+0Pd/0aY9Iwgem8cE9puvP0MRhJpYO2tr6Rf1/aYZUb0ZRo2sJJ7MBghsiFDZqS3npEEPjC9htk0V/+Tl0wyI2qZpregJxnqjBmh6DIjIhB7/TjUBcn6mhlJ5HWLLEVv3Uwaw7VNl4PXT3Xm1F5yDzawEtmQkmDPSGRmRvyMhawrMSTywWoMRtRpxbHX7g9tyXddj4QcLlFI3qu/LY0vGYwbxxTipuuG9un6pn0b0eekKDPCRc+IYjEYIbIhYzCiLgcf2zPiM9vnJEqyG+WZZ0Ysnk1j0rCplmmkBD58c3we/J9lJivaJsjnvfrrpvWMJNL0m4Qs00XPeivTMBgh52MwQmRDic6mMW2GjDJkkA93TC7BoCxvQg2sxp4R47Wt6hkRJiuOylqZJvVvS4n02mSbBQ0W+M6kErzz8SXM1U9ZVht6DYuesUxD7sFghMiGDKugyvEXHkvkQ1WSJGz7QVXC15b1/xLvZZO+fpHUskSkRyISjKQ+E5BImUbNiFi5xggAzLhuKN6ou8V40HSjvB7jY0QOxgZWIhtKuGckBX0NktekTKNOK7Y4MyLpFvmSw9/L3tR/+GolmF5et2GDQxmJ4fk5Kb8fQ8+ICP13hrpvD6f2kgswM0JkQ731jHhN9qNReyCs4PHGTu2NBEJWzaYJZz90mQBPErNp+iuRqb03VQzFfy6pxuSRBSm/H0P2QwmGZtewTEMuwmCEyIaEyZLsZn0bpmtW9JNslhkxaZ7tF7PMSDgYkdMQjCRSppFlyXQp+pTQl+UUfzgY4Toj5B4s0xDZkHHnXGPPiD47MTxcSlBLClaQTab2RhZcsyYYkcKZEUnXM+JBMHT9NCx/PiwFr1u/6F9zNQjhCqzkIsyMENmQIput9RHbtzFnYjFeWFSF6WOutezahmAgejl4qzIw4Q9f2ZAZCQcjaZhNs3ru1zHza0Nx+/g0ZT6uRt+0q74mWpmGU3vJ+RiMENmRSWZEndHi8RjLNN+tLLH00l6f7sNPTk0DqxqM6Ms0as9IOjIj1+Zl4buVpSm/TsJkDwAJgIhkRrjOCLkIyzRENmTsGUnNZnXxeEx7RmIDof5Qm1RloWtgRfpm09hS9GZ5LNOQizAYIbIjs8yIxTNa4l7abJ2R8LV9Fl1bMs2MhMo0HreWJbRVacN9NGxgJRdhMEJkQ8YG1qieEatmtMThzdKXadQGVmuXg4dXzYxEghFvODPicW1mJGpVWk7tJRdhMEJkR73snGvVjJa4l9ZlJgRSUyKSw7NpZN3y597wbBqPz6UfvtGb5XGjPHIRBiNENiSZrDOSrp4Rry9ybREOhPwWLwcvmWVGwt/rr+8q0UvCs4GVXITBCJENCbPMiMneNKng1WUmFEkKXztUprFsnZFw9sVjKNOwZwSAydRel2aKyFUYjBDZkGHn2qj9YSzr24hDP7VXwJiVsapfRfaY9YyEghGvW4MRrWeEmRFyHwYjRDZkKNOkvWckcm0FoWtpDaxWzaYJBxxqaSYYCECWwuPzufTDlz0j5GIMRojsyJO5nhHIsT0jVl9bDXjUMo3f3x15zK3BSEzPCMs05B4MRohsSPKa7A+Tpp4R/RonClLTwCqHP2DVhc4C/sgeNT63BiPq6671jHCdEXIPBiNENiSbbpQXbiJNcc+I/sNPDUas7leRozIjwYBuiq9bgxG1HMON8siFGIwQ2ZE3duExtWck9WWa2MyI1ddWm1R9CABCwK/LjHhdu+hZVM+IuhKrWxt6yVUYjBDZkGwytTeopKeB1ZgZUaf2WlsikvXZDyWIYCD0wRsQMqRUl6HsSo5egTUcjLCBlVzApX/1RPZmFoxo+8NY1LcR/+ImZRqLl4M37Myr+BH0h7IBgfBUYlfy6PamEUIXjLBMQ87HYITIhiSznXMtXngsrl4zI9aWaQAAwR4EwrNpAvDG+Q0X0E/tDUZ6aFimITdgMEJkQ7LXZGpvunpGJAlBdU+aqJ4Rq7Iyhum7wUAkMyK5OTOiW/Qs2K07zmCEnI/BCJENyfoPoDQvBw9EMhSKMGZGrMrKeL1eBMPPDcWv9YwEmRkJTe0NRBp6GYyQGzAYIbIhj8k6I1owkuqpvQCC4WsGo6b2WrUcvM8jR0oyQb82tZc9IwhnRsLBiOTRMmNETsZghMiGDA2ekrGJNOU9I4hkKKLLNB6LsjJejwS/GngEe6ComRGJmZFQzwhXXyV3YTBCZEOmPSPpWg4ekaAg0sCq7k1jUWZEliNZECWgZUaCrs6M6Kb2Bjitl9ylT8HItm3bUFFRgZycHFRVVeHQoUNxz927dy/mzp2LYcOGIT8/HzNmzMCbb77Z5xsmcgPDKqRSeLM6xdol2XujhIORoEhNA6vPK8GvK9OIIDMjxswIgxFyl6TfWRoaGlBXV4cNGzagubkZs2fPxrx589Da2mp6/sGDBzF37lzs27cPTU1N+Na3voW77roLzc3N/b55IqcyNrCmPzOiBSOQIISwvoFVlrUyjQj2QFEzI24ORgw9IyzTkLskHYxs3rwZDz/8MH70ox9hwoQJ2LJlC0aNGoXt27ebnr9lyxY89thjmD59OsaNG4ennnoK48aNw+uvv97vmydyKsPUV0mGECJ9K7AiEhQEhKxdF7CygVVCQISDrAB7RgAYN8rrbAt9n3VN5u6HKI2SCkZ6enrQ1NSEmpoaw/GamhocOXIkoedQFAVdXV0oLCyMe053dzc6OzsNX0Ru4vUZe0b0AUE6MiNC3Q9HicziAawrEXk9slamCfr9UMJLoCtuDkb0G+Wd/Evo+4pbMnc/RGmU1DvLxYsXEQwGUVxcbDheXFyMCxcuJPQczz77LC5fvoz77rsv7jn19fUoKCjQvkaNGpXMbRINeB59el7ypCQg6I26HH1Xj2K8tmVlmkjPSCDQAyXcIyFcvehZOAANfAV89Ebo+/F3ZO5+iNKoT+9qkmR8QxJCxBwz8/LLL+OJJ55AQ0MDhg8fHve89evXo6OjQ/s6e/ZsX26TaMDyeT2RRcEkOSUBQW/UMlFXt9CmFFt57dA6I6HAQ/F3QwRCmRGWaQCcOQJcuQjkFADlMzN7T0RpktRfflFRETweT0wWpL29PSZbEq2hoQEPP/ww/vSnP2HOnDm9npudnY3sbDZukXt5w4uCeeAHZFlbCh5IT8+IOpunszsIfwqu7ZElLRgJBnq02TRCdnEwomZGLp0K/e+47xj2CSJysqQyI1lZWaiqqkJjY6PheGNjI26++ea4v/fyyy/joYcewu7duzF//vy+3SmRi4TKGOGShSTDr1ifneiNTwtGFMMsnkQyoIkKaD0j3RDhjeFc3TMiRwUe4/leSe6R9F/+6tWrsXjxYlRXV2PGjBnYsWMHWltbsWzZMgChEsv58+exa9cuAKFAZMmSJXjuuedw0003aVmV3NxcFBQUWDgUIufQlzEgeQwzaawMCOLJygplJr8MCHR+FQoUrF6Gvk0aBuAjeD79ACKYC8DlwYg+C+LJAr727czdC1GaJd0zsnDhQmzZsgUbN27E1KlTcfDgQezbtw/l5eUAgLa2NsOaIy+++CICgQCWL1+O0tJS7WvVqlXWjYLIYfTLpQtdz0g6SjRApEyjQEbrpSuhYxZv0HdcmggAyD7/DkR4No2ryzT6sY+9DcgenLFbIUq3Pv3l19bWora21vSxnTt3Gn5+++23+3IJIlfzyTKuqDvnItIzko4SDQCtZKAIGa3/HQ5GLM6MNMuTAQXIvnAcntE3AABEdKnCTfSZEZZoyGW4Nw2RDXn1i4IJSesZSVsw4olslKcFIxZnRi54yvD/xRDISg9KPg+tyOzuzIgajEjA1+dl9FaI0o3BCJEN6cs0QSmyCmo61hgBEMmMQMZZLRixNhDyemW8o4RKNWWdajDi4szIoPBCkKNvAgb3PjuRyGkYjBDZkH5XW0VI2kZ16eoZUUsGCqSUlWl8Hhn/UCaEvldCe7G4OjMy9lvAPS8C97yQ6TshSjsGI0Q2JMtSZOor5LRukgcA+Pp3cTm3DEeUSboyjcWZEVnCO+FgROPmzIjHC0y5H7h2TKbvhCjtGIwQ2VRQMukZsTg7EVflvXj3fx/GCTEW3QH12ta+XXg9Mj4WpejOGaYdc3VmhMjFGIwQ2VQkMyLpMiPp+5MdMSTX8LPVmZHQDsASPh82PXKQK44SuRKDESKbimRG5PT3jAAoLjBuyWB1VkYNbj7Knaodk5gZIXIlBiNENqVuGheEhEC6p/YCyPZ6MGxwJCCxOitTkBvKgvzHiWu1Y66eTUPkYgxGiGzqkPxNnBNF+GLYNG0F1rT1jISVFeRo31sdCP37XZNw//RR+Cx3DD4V+QCA3BxukEnkRgxGiGzq1az5mNX9G1zOG62twOpJY88IAJQWRPpGrA6EKorysOl/XY+jG+aEprUCmHBduaXXIKKBgQVaIpvyhWevBBQRyYyksUwDAGW6JlZfihZc83pkDLv3GeDk7fBNvi8l1yAie2MwQmRTauDhDyoZ6RkBgLIhkTJNSptnB5cAVQ+l7vmJyNZYpiGyKXVdj0BQ6JaDz1xmJJ3TionIXfjuQmRTvnDgEVSEbmpvuntGIpkRX5oDISJyDwYjRDalL9OomRFfmss0+oXP0rnGCRG5C4MRIpvy6hpY1eXg0x0QFF2TrWVEUtXASkTEdxcim1KDgJ6AkrGeEVmWUJwfKtUwM0JEqcJghMim1BLJh22dGesZASJNrOwZIaJUYTBCZFMzv1YEADh46qI2tTfdPSNAZBVWzqYholThuwuRTanByIdtnbjQ0Q0gM6WSscOuARDZS4aIyGpc9IzIpoquycbE0nx80NaJg6c+BZD+nhEAWHrzGBTmZeGOyaVpvzYRuQMzI0Q2NntcKDvy/9q/AJCZzEhBrg+LbipHYV5W2q9NRO7AYITIxmaFgxEV+zaIyIn4zkZkY9PHFCLLG/kzTffeNERE6cBghMjGcnwe3DimUPvZw+m1RORADEaIbE5fqvGxTENEDsR3NiKbm60LRrgKKhE5EYMRIpubUJKPoeGZLOwZISInYjBCZHOyLOHWrw8DAORz4TEiciAuekY0AKydNx7XjyzAvdNGZPpWiIgsx2CEaAAozs/BQzMrMn0bREQpwTINERERZRSDESIiIsooBiNERESUUQxGiIiIKKMYjBAREVFGMRghIiKijGIwQkRERBnFYISIiIgyqk/ByLZt21BRUYGcnBxUVVXh0KFDcc9ta2vDgw8+iG984xuQZRl1dXV9vVciIiJyoKSDkYaGBtTV1WHDhg1obm7G7NmzMW/ePLS2tpqe393djWHDhmHDhg2YMmVKv2+YiIiInEUSQohkfuGb3/wmpk2bhu3bt2vHJkyYgLvvvhv19fW9/u5tt92GqVOnYsuWLUndZGdnJwoKCtDR0YH8/PykfpeIiIgyI9HP76QyIz09PWhqakJNTY3heE1NDY4cOdK3OzXR3d2Nzs5OwxcRERE5U1LByMWLFxEMBlFcXGw4XlxcjAsXLlh2U/X19SgoKNC+Ro0aZdlzExERkb30addeSZIMPwshYo71x/r167F69Wrt546ODowePZoZEiIiogFE/dy+WkdIUsFIUVERPB5PTBakvb09JlvSH9nZ2cjOztZ+VgfDDAkREdHA09XVhYKCgriPJxWMZGVloaqqCo2Njbjnnnu0442Njfje977X97u8irKyMpw9exaDBw+2NAPT2dmJUaNG4ezZs65rjHXr2DlujtsN3DpuwL1jt+u4hRDo6upCWVlZr+clXaZZvXo1Fi9ejOrqasyYMQM7duxAa2srli1bBiBUYjl//jx27dql/U5LSwsA4IsvvsCnn36KlpYWZGVlYeLEiQldU5ZljBw5MtlbTVh+fr6t/uOlk1vHznG7C8ftPm4dux3H3VtGRJV0MLJw4UJcunQJGzduRFtbGyorK7Fv3z6Ul5cDCC1yFr3myA033KB939TUhN27d6O8vByffPJJspcnIiIih+lTA2ttbS1qa2tNH9u5c2fMsSSXMiEiIiIXcfXeNNnZ2Xj88ccNzbJu4daxc9wctxu4ddyAe8c+0Med9AqsRERERFZydWaEiIiIMo/BCBEREWUUgxEiIiLKKAYjRERElFGuDka2bduGiooK5OTkoKqqCocOHcr0LVmqvr4e06dPx+DBgzF8+HDcfffd+OijjwznCCHwxBNPoKysDLm5ubjtttvw/vvvZ+iOU6O+vh6SJKGurk475tRxnz9/HosWLcLQoUMxaNAgTJ06FU1NTdrjThx3IBDAz3/+c1RUVCA3Nxdjx47Fxo0boSiKdo5Txn3w4EHcddddKCsrgyRJePXVVw2PJzLO7u5urFy5EkVFRcjLy8OCBQtw7ty5NI4ieb2N2+/3Y+3atZg8eTLy8vJQVlaGJUuW4F//+pfhOZw27miPPPIIJEnCli1bDMcHyrhdG4w0NDSgrq4OGzZsQHNzM2bPno158+bFLNg2kB04cADLly/HO++8g8bGRgQCAdTU1ODy5cvaOc888ww2b96MrVu34tixYygpKcHcuXPR1dWVwTu3zrFjx7Bjxw5cf/31huNOHPdnn32GmTNnwufz4S9/+Qs++OADPPvssxgyZIh2jhPH/fTTT+OFF17A1q1b8eGHH+KZZ57BL3/5S/z2t7/VznHKuC9fvowpU6Zg69atpo8nMs66ujq88sor2LNnDw4fPowvvvgCd955J4LBYLqGkbTexn3lyhUcP34cv/jFL3D8+HHs3bsXJ0+exIIFCwznOW3ceq+++ir+8Y9/mC65PmDGLVzqxhtvFMuWLTMcGz9+vFi3bl2G7ij12tvbBQBx4MABIYQQiqKIkpISsWnTJu2cr776ShQUFIgXXnghU7dpma6uLjFu3DjR2Ngobr31VrFq1SohhHPHvXbtWjFr1qy4jzt13PPnzxc//OEPDcfuvfdesWjRIiGEc8cNQLzyyivaz4mM8/PPPxc+n0/s2bNHO+f8+fNClmXxxhtvpO3e+yN63GaOHj0qAIgzZ84IIZw97nPnzokRI0aI9957T5SXl4tf//rX2mMDadyuzIz09PSgqakJNTU1huM1NTU4cuRIhu4q9To6OgAAhYWFAIDTp0/jwoULhtchOzsbt956qyNeh+XLl2P+/PmYM2eO4bhTx/3aa6+huroa3//+9zF8+HDccMMN+N3vfqc97tRxz5o1C3/7299w8uRJAMA///lPHD58GHfccQcA5447WiLjbGpqgt/vN5xTVlaGyspKR70WHR0dkCRJywo6ddyKomDx4sVYs2YNJk2aFPP4QBp3n5aDH+guXryIYDCI4uJiw/Hi4mJcuHAhQ3eVWkIIrF69GrNmzUJlZSUAaGM1ex3OnDmT9nu00p49e3D8+HEcO3Ys5jGnjvvjjz/G9u3bsXr1avzsZz/D0aNH8eijjyI7OxtLlixx7LjXrl2Ljo4OjB8/Hh6PB8FgEE8++SQeeOABAM797x0tkXFeuHABWVlZuPbaa2POccp731dffYV169bhwQcf1DaMc+q4n376aXi9Xjz66KOmjw+kcbsyGFFJkmT4WQgRc8wpVqxYgXfffReHDx+Oecxpr8PZs2exatUq/PWvf0VOTk7c85w2bkVRUF1djaeeegpAaIPK999/H9u3b8eSJUu085w27oaGBrz00kvYvXs3Jk2ahJaWFtTV1aGsrAxLly7VznPauOPpyzid8lr4/X7cf//9UBQF27Ztu+r5A3ncTU1NeO6553D8+PGkx2DHcbuyTFNUVASPxxMTGba3t8f8q8IJVq5ciddeew379+/HyJEjteMlJSUA4LjXoampCe3t7aiqqoLX64XX68WBAwfwm9/8Bl6vVxub08ZdWlqKiRMnGo5NmDBBa8p26n/vNWvWYN26dbj//vsxefJkLF68GD/5yU9QX18PwLnjjpbIOEtKStDT04PPPvss7jkDld/vx3333YfTp0+jsbFRy4oAzhz3oUOH0N7ejtGjR2vvc2fOnMFPf/pTjBkzBsDAGrcrg5GsrCxUVVWhsbHRcLyxsRE333xzhu7KekIIrFixAnv37sXf//53VFRUGB6vqKhASUmJ4XXo6enBgQMHBvTr8O1vfxsnTpxAS0uL9lVdXY0f/OAHaGlpwdixYx057pkzZ8ZM3T558iTKy8sBOPe/95UrVyDLxrcyj8ejTe116rijJTLOqqoq+Hw+wzltbW147733BvRroQYip06dwltvvYWhQ4caHnfiuBcvXox3333X8D5XVlaGNWvW4M033wQwwMadocbZjNuzZ4/w+Xzi97//vfjggw9EXV2dyMvLE5988kmmb80yP/7xj0VBQYF4++23RVtbm/Z15coV7ZxNmzaJgoICsXfvXnHixAnxwAMPiNLSUtHZ2ZnBO7eefjaNEM4c99GjR4XX6xVPPvmkOHXqlPjjH/8oBg0aJF566SXtHCeOe+nSpWLEiBHiz3/+szh9+rTYu3evKCoqEo899ph2jlPG3dXVJZqbm0Vzc7MAIDZv3iyam5u1WSOJjHPZsmVi5MiR4q233hLHjx8Xt99+u5gyZYoIBAKZGtZV9TZuv98vFixYIEaOHClaWloM73Xd3d3aczht3GaiZ9MIMXDG7dpgRAghnn/+eVFeXi6ysrLEtGnTtCmvTgHA9OsPf/iDdo6iKOLxxx8XJSUlIjs7W9xyyy3ixIkTmbvpFIkORpw67tdff11UVlaK7OxsMX78eLFjxw7D404cd2dnp1i1apUYPXq0yMnJEWPHjhUbNmwwfBA5Zdz79+83/ZteunSpECKxcX755ZdixYoVorCwUOTm5oo777xTtLa2ZmA0iett3KdPn477Xrd//37tOZw2bjNmwchAGbckhBDpyMAQERERmXFlzwgRERHZB4MRIiIiyigGI0RERJRRDEaIiIgooxiMEBERUUYxGCEiIqKMYjBCREREGcVghIiIiDKKwQgRERFlFIMRIiIiyigGI0RERJRRDEaIiIgoo/4HFUalMA/gW8oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_shots = 1000\n",
    "measurement_events, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)\n",
    "measurement_events[measurement_events == 2] = 0 #change all values in detection_events from 2 to 0\n",
    "\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "exp_measurements = exp_measurements[:num_shots]\n",
    "\n",
    "exp_measurements[exp_measurements == 2] = 0 #change all values in detection_events from 2 to 0\n",
    "\n",
    "plt.plot(np.average(exp_measurements,axis=0), label='experiment')\n",
    "\n",
    "plt.plot(np.average(measurement_events,axis=0), label='theory')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_rounds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_82407/1859235498.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis, 'bias_preserving_gates': 'False', \n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;34m'noise'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'atom_array'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_erasure_biased'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'False'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LD_freq'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1000'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LD_method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SSR'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'True'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cycles'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                \u001b[0;34m'ordering'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0;34m'decoder'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'MLE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'circuit_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'logical_CX_NL3_NCX7'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Steane_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'printing'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'False'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_logicals'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_decoder'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'independent'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_rounds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis, 'bias_preserving_gates': 'False', \n",
    "        'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None', 'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "               'ordering': ['N','Z'],\n",
    "               'decoder': 'MLE',\n",
    "        'circuit_type': 'logical_CX_NL3_NCX7', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2', 'loss_decoder': 'independent', \n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "noise_params = {}\n",
    "\n",
    "qubit_states_nans_perlog = np.load('2024_10_16_measurement_events_7CNOT_XX.npy').transpose(1,2,0).astype(float)\n",
    "qubit_states_nans_perlog[qubit_states_nans_perlog == 2.] = 1. #np.nan\n",
    "qubit_states_nans_perlog[qubit_states_nans_perlog == 0.] = -1\n",
    "qubit_states_nans_perlog.shape\n",
    "\n",
    "exp_measurements = 0.5*(np.concatenate([qubit_states_nans_perlog[0, :d**2-1],\n",
    "                                   qubit_states_nans_perlog[1, :d**2-1],\n",
    "                                   qubit_states_nans_perlog[0, d**2-1:2*(d**2-1)],\n",
    "                                   qubit_states_nans_perlog[1, d**2-1:2*(d**2-1)],\n",
    "                                   qubit_states_nans_perlog[0, 2*(d**2-1):],\n",
    "                                   qubit_states_nans_perlog[1, 2*(d**2-1):]], axis=0)+1).T\n",
    "\n",
    "simulated_measurement_events, simulated_detector_events, _, circuit = get_simulated_measurement_events(Meta_params, d, d, 200, noise_params = noise_params)\n",
    "#detection_events_theory, observable_flips_theory = circuit.compile_m2d_converter().convert(measurements = exp_measurements.astype(bool), separate_observables = True)\n",
    "#detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events_theory.astype(int), axis = 0) -1).astype(int)\n",
    "\n",
    "#detection_events_theory = -1+2*detection_events_theory.T.astype(int)\n",
    "\n",
    "#detector_measurements_nans = detector_measurements_nans*detection_events_signs[:,None]\n",
    "#detection_events_theory = detection_events_theory*detection_events_signs_theory[:,None]\n",
    "\n",
    "plt.plot(np.mean(simulated_measurement_events,axis = 0), label = 'Sim.')\n",
    "plt.plot(np.mean(exp_measurements,axis = 0), label = 'Exp')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_xor(observable_flips, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical_CX__Nlayers1__NCX3\n",
      "final measurement_index = 18\n",
      "Pauli_DEM = error(0.01193448568232855118) D0 D1\n",
      "error(0.01193448568232855118) D0 D1 D2\n",
      "error(0.01193448568232855118) D1 D2 D5 D6 D8\n",
      "error(0.01193448568232855118) D1 D4 D5 D8\n",
      "error(0.01193448568232855118) D2 D3\n",
      "error(0.01193448568232855118) D2 D3 D6 D8\n",
      "error(0.01193448568232855118) D4 D5\n",
      "error(0.01193448568232855118) D5 D6 D7\n",
      "error(0.01193448568232855292) D6 D7\n",
      "final measurement_index = 18\n",
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_49449/126680247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/gefenbaranes/Documents/CX_experiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# DO IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     34\u001b[0m                                                                   \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                                   \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MLE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelated_decoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_gurobi_with_dem_loss_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_shots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservables_errors_interactions_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MLE decoder took {time.time() - start_time:.6f}s.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MLE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelated_decoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_gurobi_with_dem_loss_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdems_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_shots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservables_errors_interactions_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MLE decoder took {time.time() - start_time:.6f}s.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTATE_SUSPEND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# IFDEF CYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_CX_per_layer_list = [3]\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "\n",
    "noise_params = {}\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "               'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "simulate_data = True\n",
    "num_shots = 1000\n",
    "if simulate_data:\n",
    "   detection_events_signs = None\n",
    "   measurement_events = None\n",
    "\n",
    "\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "# DO IT\n",
    "predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                  None,\n",
    "                                                                  None, use_loss_decoding,\n",
    "                                                                  use_independent_decoder,\n",
    "                                                                  use_independent_and_first_comb_decoder,\n",
    "                                                                  simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                  noise_params=noise_params, num_shots=3000)\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "print('logical error',logical_probability)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1]\n",
      "logical_CX__Nlayers1__NCX1\n",
      "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.000131129) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "X_ERROR(0.000131129) 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.00322009) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "DETECTOR rec[-50] rec[-49] rec[-25] rec[-24]\n",
      "DETECTOR rec[-48] rec[-47] rec[-23] rec[-22]\n",
      "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-25] rec[-24] rec[-20] rec[-19]\n",
      "DETECTOR rec[-49] rec[-48] rec[-44] rec[-43] rec[-24] rec[-23] rec[-19] rec[-18]\n",
      "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-23] rec[-22] rec[-18] rec[-17]\n",
      "DETECTOR rec[-47] rec[-46] rec[-42] rec[-41] rec[-22] rec[-21] rec[-17] rec[-16]\n",
      "DETECTOR rec[-46] rec[-41] rec[-21] rec[-16]\n",
      "DETECTOR rec[-45] rec[-40] rec[-20] rec[-15]\n",
      "DETECTOR rec[-45] rec[-44] rec[-40] rec[-39] rec[-20] rec[-19] rec[-15] rec[-14]\n",
      "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-19] rec[-18] rec[-14] rec[-13]\n",
      "DETECTOR rec[-43] rec[-42] rec[-38] rec[-37] rec[-18] rec[-17] rec[-13] rec[-12]\n",
      "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-17] rec[-16] rec[-12] rec[-11]\n",
      "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-15] rec[-14] rec[-10] rec[-9]\n",
      "DETECTOR rec[-39] rec[-38] rec[-34] rec[-33] rec[-14] rec[-13] rec[-9] rec[-8]\n",
      "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-13] rec[-12] rec[-8] rec[-7]\n",
      "DETECTOR rec[-37] rec[-36] rec[-32] rec[-31] rec[-12] rec[-11] rec[-7] rec[-6]\n",
      "DETECTOR rec[-36] rec[-31] rec[-11] rec[-6]\n",
      "DETECTOR rec[-35] rec[-30] rec[-10] rec[-5]\n",
      "DETECTOR rec[-35] rec[-34] rec[-30] rec[-29] rec[-10] rec[-9] rec[-5] rec[-4]\n",
      "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-9] rec[-8] rec[-4] rec[-3]\n",
      "DETECTOR rec[-33] rec[-32] rec[-28] rec[-27] rec[-8] rec[-7] rec[-3] rec[-2]\n",
      "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-7] rec[-6] rec[-2] rec[-1]\n",
      "DETECTOR rec[-29] rec[-28] rec[-4] rec[-3]\n",
      "DETECTOR rec[-27] rec[-26] rec[-2] rec[-1]\n",
      "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
      "DEM from the lossless circuit: error(0.01425905179606385201) D0 D2\n",
      "error(0.01425905179606385201) D0 D2 D3\n",
      "error(0.01425905179606385201) D1 D3 D4\n",
      "error(0.01425905179606385201) D1 D4 D5\n",
      "error(0.01425905179606385201) D2 D3 D8 D9\n",
      "error(0.01425905179606385201) D2 D7 D8\n",
      "error(0.01425905179606385201) D3 D4 D9 D10\n",
      "error(0.01425905179606385201) D4 D5 D10 D11\n",
      "error(0.01425905179606385201) D5 D6\n",
      "error(0.01425905179606385201) D5 D6 D11\n",
      "error(0.01425905179606385201) D7 D8 D12 L0\n",
      "error(0.01425905179606385201) D8 D9 D12 D13 L0\n",
      "error(0.01425905179606385201) D9 D10 D13 D14 L0\n",
      "error(0.01425905179606385201) D10 D11 D14 D15 L0\n",
      "error(0.01425905179606385201) D11 D15 D16 L0\n",
      "error(0.01425905179606385201) D12 D13 D18 D19\n",
      "error(0.01425905179606385201) D12 D17 D18\n",
      "error(0.01425905179606385201) D13 D14 D19 D20\n",
      "error(0.01425905179606385201) D14 D15 D20 D21\n",
      "error(0.01425905179606385201) D15 D16 D21\n",
      "error(0.01425905179606385201) D17 D18\n",
      "error(0.01425905179606385201) D18 D19 D22\n",
      "error(0.01425905179606385201) D19 D20 D22\n",
      "error(0.01425905179606385201) D20 D21 D23\n",
      "error(0.01425905179606385201) D21 D23\n",
      "NOW DECODING\n",
      "logical_CX__Nlayers1__NCX1\n",
      "final measurement_index = 50\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.01425906097371744917) D0 D2\n",
      "error(0.01425906097371744917) D0 D2 D3\n",
      "error(0.01425906097371744917) D1 D3 D4\n",
      "error(0.01425906097371744917) D1 D4 D5\n",
      "error(0.01425906097371744917) D2 D3 D8 D9\n",
      "error(0.01425906097371744917) D2 D7 D8\n",
      "error(0.01425906097371744917) D3 D4 D9 D10\n",
      "error(0.01425906097371744917) D4 D5 D10 D11\n",
      "error(0.01425906097371744917) D5 D6\n",
      "error(0.01425906097371744917) D5 D6 D11\n",
      "error(0.01425906097371744917) D7 D8 D12 D24\n",
      "error(0.01425906097371744917) D8 D9 D12 D13 D24\n",
      "error(0.01425906097371744917) D9 D10 D13 D14 D24\n",
      "error(0.01425906097371744917) D10 D11 D14 D15 D24\n",
      "error(0.01425906097371744917) D11 D15 D16 D24\n",
      "error(0.01425906097371744917) D12 D13 D18 D19\n",
      "error(0.01425906097371744917) D12 D17 D18\n",
      "error(0.01425906097371744917) D13 D14 D19 D20\n",
      "error(0.01425906097371744917) D14 D15 D20 D21\n",
      "error(0.01425906097371744917) D15 D16 D21\n",
      "error(0.01425906097371744917) D17 D18\n",
      "error(0.01425906097371744917) D18 D19 D22\n",
      "error(0.01425906097371744917) D19 D20 D22\n",
      "error(0.01425906097371744917) D20 D21 D23\n",
      "error(0.01425906097371744917) D21 D23\n",
      "final measurement_index = 50\n",
      "0 fidelity 1.0\n",
      "all_fidelities [1.0]\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "num_rounds = 1\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "num_cxs_per_rounds = [1] #[1, 3, 5, 7, 9, 11, 13, 15, 17]\n",
    "#[0.96, 0.9, 0.848, 0.798, 0.742, 0.677, 0.638]\n",
    "num_CX_per_layer_lists = [[i, i+1] for i in range(1, 20)]\n",
    "num_CX_per_layer_lists = np.array([np.arange(3, 21, 2)]).T\n",
    "num_CX_per_layer_lists = [[1]]\n",
    "print(num_CX_per_layer_lists)\n",
    "#raise Exception\n",
    "logical_error_rates = []\n",
    "for num_CX_per_layer_list in num_CX_per_layer_lists:\n",
    "    noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                    'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "                'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "    print(num_CX_per_layer_list)\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                'bias_preserving_gates': 'False',\n",
    "                'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "                'ordering': gate_ordering,\n",
    "                'decoder': 'MLE',\n",
    "                'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "                   'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "                'loss_decoder': 'independent',\n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "    # Load the experimental measurements\n",
    "    exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                       exp_measurements[:, 1, :distance**2-1],\n",
    "                                       exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                       exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "    # Now let's decode!\n",
    "    use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "    use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "    use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "    output_dir = '.'\n",
    "    simulate_data = True\n",
    "    # simulated_measurements, simulated_detection_events, simulated_observable_flips, circuit = get_simulated_measurement_events(\n",
    "    #     Meta_params, distance, distance, 1, noise_params)\n",
    "    \n",
    "    circuit = get_lossless_circuit(Meta_params, distance, distance, noise_params)\n",
    "    print(circuit)\n",
    "    Pauli_DEM = circuit.detector_error_model(decompose_errors=False, approximate_disjoint_errors=True, ignore_decomposition_failures=True, allow_gauge_detectors=True) # GB: new Oct24, allow_gauge_detectors = True to allow DEM generation when meas basis is wrong. \n",
    "    print(f\"DEM from the lossless circuit: {Pauli_DEM}\")\n",
    "    \n",
    "    print(\"NOW DECODING\")\n",
    "    #raise Exception\n",
    "    # DO IT\n",
    "    predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        None,\n",
    "                                                                        None, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots=10)\n",
    "\n",
    "\n",
    "    logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "\n",
    "    print('fidelity', 1-logical_probability)\n",
    "    logical_error_rates.append(1-logical_probability)\n",
    "\n",
    "    print('all_fidelities', logical_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]\n",
      " [15]\n",
      " [17]\n",
      " [19]]\n",
      "[5]\n",
      "logical_CX__Nlayers1__NCX5\n",
      "error(0.05979961699394466951) D0\n",
      "error(0.0308516316739152717) D0 D3\n",
      "error(0.0308516316739152717) D0 D4\n",
      "error(0.05979961699394466951) D1\n",
      "error(0.0308516316739152717) D1 D4\n",
      "error(0.0308516316739152717) D1 D5\n",
      "error(0.0308516316739152717) D2\n",
      "error(0.0308516316739152717) D2 D5\n",
      "error(0.0308516316739152717) D3 D6 L0\n",
      "error(0.0308516316739152717) D4 D6 L0\n",
      "error(0.0308516316739152717) D4 D7 L0\n",
      "error(0.0308516316739152717) D5 D7 L0\n",
      "error(0.0308516316739152717) D5 D8 L0\n",
      "error(0.0308516316739152717) D6 D9\n",
      "error(0.0308516316739152717) D6 D10\n",
      "error(0.0308516316739152717) D7 D10\n",
      "error(0.0308516316739152717) D7 D11\n",
      "error(0.0308516316739152717) D8 D11\n",
      "error(0.0308516316739152717) D9\n",
      "error(0.05979961699394466951) D10\n",
      "error(0.05979961699394466951) D11\n",
      "logical_CX__Nlayers1__NCX5\n",
      "final measurement_index = 50\n",
      "Pauli_DEM inside the MLE_Loss_Decoder = error(0.05979962731993435782) D0\n",
      "error(0.03085163717643346973) D0 D3\n",
      "error(0.03085163717643346973) D0 D4\n",
      "error(0.05979962731993435782) D1\n",
      "error(0.03085163717643346973) D1 D4\n",
      "error(0.03085163717643346973) D1 D5\n",
      "error(0.03085163717643346973) D2\n",
      "error(0.03085163717643346973) D2 D5\n",
      "error(0.03085163717643346973) D3 D6 D12\n",
      "error(0.03085163717643346973) D4 D6 D12\n",
      "error(0.03085163717643346973) D4 D7 D12\n",
      "error(0.03085163717643346973) D5 D7 D12\n",
      "error(0.03085163717643346973) D5 D8 D12\n",
      "error(0.03085163717643346973) D6 D9\n",
      "error(0.03085163717643346973) D6 D10\n",
      "error(0.03085163717643346973) D7 D10\n",
      "error(0.03085163717643346973) D7 D11\n",
      "error(0.03085163717643346973) D8 D11\n",
      "error(0.03085163717643346973) D9\n",
      "error(0.05979962731993435782) D10\n",
      "error(0.05979962731993435782) D11\n",
      "final measurement_index = 50\n",
      "0 "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 0 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_53173/1016509139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#raise Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# DO IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     57\u001b[0m                                                                         \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                                                         \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     \u001b[0mreturn_matrix_with_observables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLE'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                     \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_errors_interactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dem_loss_mle_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasurement_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final_dem_hyperedges_matrix doesn't contain observables, only detectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m                     \u001b[0;31m# print(f'Total loss decoder time per shot is {time.time() - start_time:.4f}s.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_dem_loss_mle_experiment\u001b[0;34m(self, measurement_event, return_matrix_with_observables)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m11\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0;34m'independent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Independent decoder:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mstart_time_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_hyperedges_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# print(f'Summing over all relevant DEMs to generate the final DEM took {time.time() - start_time_ind:.5f}s')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0;34m(self, use_pre_processed_data, return_hyperedges_matrix, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mDEM_specific_loss_event_lil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_DEMs_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEMs_specific_loss_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_detectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProbs_specific_loss_event\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0mDEM_specific_loss_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEM_specific_loss_event_lil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mcombine_DEMs_sum\u001b[0;34m(self, DEMs_list, num_detectors, Probs_list)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern_to_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_detectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m             \u001b[0mnew_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m             \u001b[0mfinal_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mfinal_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 13 is out of bounds for axis 0 with size 13"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "num_rounds = 1\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "num_cxs_per_rounds = [1, 3, 5, 7, 9, 11, 13, 15, 17]\n",
    "#[0.96, 0.9, 0.848, 0.798, 0.742, 0.677, 0.638]\n",
    "num_CX_per_layer_lists = [[i, i+1] for i in range(1, 20)]\n",
    "num_CX_per_layer_lists = np.array([np.arange(3, 21, 2)]).T\n",
    "print(num_CX_per_layer_lists)\n",
    "num_CX_per_layer_lists = [[5]]\n",
    "#raise Exception\n",
    "logical_error_rates = []\n",
    "for num_CX_per_layer_list in num_CX_per_layer_lists:\n",
    "    noise_params = {'idle_loss_rate': 2.1462892652881424e-07, 'idle_error_rate': np.array([5.31106535e-09, 2.59649716e-08, 2.70017446e-07]), 'entangling_zone_error_rate': np.array([3.22871520e-04, 5.55115000e-06, 1.28240286e-03]), 'entangling_gate_error_rate': [1.8729598643991336e-05, 0.00016597465639499589, 0.0013401575256883555, 1.8729598643991336e-05, 0, 0, 0, 0.00016597465639499589, 0, 0, 0, 0.0013401575256883555, 0, 0, 0.0026654438378731237], 'entangling_gate_loss_rate': 0.0012268907363777474, 'single_qubit_error_rate': np.array([9.01549152e-06, 8.45064836e-04, 1.91825416e-05]), 'reset_error_rate': 0.00013112864576086654, 'measurement_error_rate': 0.003220085408683493, 'reset_loss_rate': 0.0007849977760100565, 'measurement_loss_rate': 0.06657247422436202, 'ancilla_idle_loss_rate': 1.7048289168299613e-07, 'ancilla_idle_error_rate': np.array([1.30011070e-07, 3.79578658e-08, 3.73757626e-06]), 'ancilla_reset_error_rate': 0.02267054400731952, 'ancilla_measurement_error_rate': 0.011477399332064406, 'ancilla_reset_loss_rate': 0.00014151808789913066, 'ancilla_measurement_loss_rate': 0.0004062050339110557,\n",
    "                    'gate_noise':LogicalCircuit.ancilla_data_differentiated_gate_noise,\n",
    "                'idle_noise':LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "    print(num_CX_per_layer_list)\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                'bias_preserving_gates': 'False',\n",
    "                'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                'SSR': 'True', 'cycles': len(num_CX_per_layer_list)-1,\n",
    "                'ordering': gate_ordering,\n",
    "                'decoder': 'MLE',\n",
    "                'circuit_type': 'logical_CX', 'num_CX_per_layer_list': num_CX_per_layer_list,\n",
    "                'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                'loss_decoder': 'independent',\n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "    # Load the experimental measurements\n",
    "    exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "    # Now let's decode!\n",
    "    use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "    use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "    use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "    output_dir = '.'\n",
    "    simulate_data = True\n",
    "    circuit = get_lossless_circuit(Meta_params, distance, distance, noise_params)\n",
    "    print(circuit.detector_error_model(approximate_disjoint_errors=True))\n",
    "    #raise Exception\n",
    "    #raise Exception\n",
    "    # DO IT\n",
    "    predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        None,\n",
    "                                                                        None, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots=10)\n",
    "\n",
    "\n",
    "    logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "\n",
    "    print('fidelity', 1-logical_probability)\n",
    "    logical_error_rates.append(1-logical_probability)\n",
    "\n",
    "    print('all_fidelities', logical_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.000131129) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
      "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "X_ERROR(0.000131129) 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 52 54 61 63 65 72 74 81 83 85 92 94\n",
      "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 3 5 12 14 16 23 25 32 34 36 43 45\n",
      "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(1.06221e-06, 5.19298e-06, 5.4002e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "PAULI_CHANNEL_1(2.60019e-05, 7.59154e-06, 0.000747237)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_2(1.87296e-05, 0.000165975, 0.00134016, 1.87296e-05, 0, 0, 0, 0.000165975, 0, 0, 0, 0.00134016, 0, 0, 0.00266544) 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
      "PAULI_CHANNEL_1(0.000322872, 5.55115e-06, 0.0012824)\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "SQRT_Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "PAULI_CHANNEL_1(9.01549e-06, 0.000845065, 1.91825e-05) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
      "X_ERROR(0.00322009) 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "I 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
      "DETECTOR rec[-50] rec[-49] rec[-25] rec[-24]\n",
      "DETECTOR rec[-48] rec[-47] rec[-23] rec[-22]\n",
      "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-25] rec[-24] rec[-20] rec[-19]\n",
      "DETECTOR rec[-49] rec[-48] rec[-44] rec[-43] rec[-24] rec[-23] rec[-19] rec[-18]\n",
      "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-23] rec[-22] rec[-18] rec[-17]\n",
      "DETECTOR rec[-47] rec[-46] rec[-42] rec[-41] rec[-22] rec[-21] rec[-17] rec[-16]\n",
      "DETECTOR rec[-46] rec[-41] rec[-21] rec[-16]\n",
      "DETECTOR rec[-45] rec[-40] rec[-20] rec[-15]\n",
      "DETECTOR rec[-45] rec[-44] rec[-40] rec[-39] rec[-20] rec[-19] rec[-15] rec[-14]\n",
      "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-19] rec[-18] rec[-14] rec[-13]\n",
      "DETECTOR rec[-43] rec[-42] rec[-38] rec[-37] rec[-18] rec[-17] rec[-13] rec[-12]\n",
      "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-17] rec[-16] rec[-12] rec[-11]\n",
      "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-15] rec[-14] rec[-10] rec[-9]\n",
      "DETECTOR rec[-39] rec[-38] rec[-34] rec[-33] rec[-14] rec[-13] rec[-9] rec[-8]\n",
      "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-13] rec[-12] rec[-8] rec[-7]\n",
      "DETECTOR rec[-37] rec[-36] rec[-32] rec[-31] rec[-12] rec[-11] rec[-7] rec[-6]\n",
      "DETECTOR rec[-36] rec[-31] rec[-11] rec[-6]\n",
      "DETECTOR rec[-35] rec[-30] rec[-10] rec[-5]\n",
      "DETECTOR rec[-35] rec[-34] rec[-30] rec[-29] rec[-10] rec[-9] rec[-5] rec[-4]\n",
      "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-9] rec[-8] rec[-4] rec[-3]\n",
      "DETECTOR rec[-33] rec[-32] rec[-28] rec[-27] rec[-8] rec[-7] rec[-3] rec[-2]\n",
      "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-7] rec[-6] rec[-2] rec[-1]\n",
      "DETECTOR rec[-29] rec[-28] rec[-4] rec[-3]\n",
      "DETECTOR rec[-27] rec[-26] rec[-2] rec[-1]\n",
      "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n"
     ]
    }
   ],
   "source": [
    "print(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 2],\n",
       "       [0, 1, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 2, 0, 1],\n",
       "       [1, 1, 0, ..., 0, 1, 1],\n",
       "       [1, 1, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theory measu events out:\n",
    "observable_flips.shape\n",
    "predictions.shape\n",
    "# 1 - logical error 0.085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## all theory:\n",
    "observable_flips.shape\n",
    "predictions.shape\n",
    "# 1 - logical error 0.105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### experiment:\n",
    "observable_flips.shape\n",
    "predictions.shape\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips.astype(int), predictions.astype(int)))\n",
    "logical_probability\n",
    "# observable_flips.astype(int)\n",
    "# predictions\n",
    "# 1 - logical error 0.815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93,  77,  80,  74,  71,  65,  87,  79,  87,  86,  71,  73,  67,\n",
       "        76,  68,  82,  72,  70,  86,  61,  76,  80,  91,  88,  77,  80,\n",
       "        87,  68,  75,  71,  78,  84,  72,  80,  81,  74,  87,  72,  68,\n",
       "        70,  81,  75,  90,  83,  85,  66,  80,  77,  75,  70,  68,  80,\n",
       "        78,  73,  77,  83,  74,  72,  86,  78,  66,  75,  83,  69,  81,\n",
       "        80,  66,  76,  73,  72,  76,  76,  80,  70,  65,  81,  77,  80,\n",
       "        79,  82,  74,  86,  74,  71,  73,  78,  71,  74,  87,  77,  69,\n",
       "        83,  79,  87,  68,  82,  75,  66,  78,  80,  70,  72,  78,  69,\n",
       "        74,  83,  66,  79,  78,  60,  73,  74,  82,  79,  75,  85,  84,\n",
       "        77,  79,  67,  73,  85,  80,  80,  74,  79,  82,  79,  79,  72,\n",
       "        89,  73,  76,  82,  93,  74,  69,  77,  84,  81,  73,  80,  83,\n",
       "        82,  92,  77,  90,  64,  98,  79,  88,  80,  88,  64,  77,  73,\n",
       "        85,  81,  87,  67,  63,  86,  83,  72,  76,  74,  85,  74,  76,\n",
       "        78,  81,  72,  90,  76,  71,  85,  72,  66,  74,  86,  83,  74,\n",
       "        71,  79,  83,  85,  69,  89,  69,  74,  76,  84,  75,  72,  72,\n",
       "        79,  74,  74,  84,  77,  79,  66,  71,  80,  82,  88,  87,  77,\n",
       "        67,  66,  77,  68,  74,  82,  83,  78,  68,  75,  77,  78,  68,\n",
       "        77,  78,  64,  74,  72,  67,  71,  80,  78,  78,  79,  80,  82,\n",
       "        69,  68,  83,  75,  79,  88,  74,  91,  85,  86,  80,  79,  75,\n",
       "        82,  76,  70,  79,  87,  82,  69,  67,  73,  75,  81,  70,  72,\n",
       "        66,  84,  84,  80,  74,  86,  81,  75,  62,  77,  74,  74,  77,\n",
       "        86,  82,  75,  75,  82,  73,  86,  78,  72,  82,  78,  63,  72,\n",
       "        89,  73,  81,  79,  68,  92,  67,  69,  77,  64,  76,  73,  87,\n",
       "        86,  71,  85,  68,  64,  59,  75,  80,  75,  82,  81,  74,  83,\n",
       "        90,  85,  91,  62,  72,  73,  83,  85,  76,  88,  75,  86,  80,\n",
       "        80,  81,  76,  79,  72,  86,  73,  80,  83,  57,  68,  92,  89,\n",
       "        72,  75,  74,  80,  85,  82,  75,  71,  80,  71,  77,  73,  88,\n",
       "        73,  70,  83,  86,  86,  79,  93,  77,  77,  79,  74,  75,  84,\n",
       "        85,  73,  71,  71,  76,  82,  73,  88,  88,  73,  71,  79,  86,\n",
       "        85,  72,  80,  72,  73,  78,  66,  70,  79,  71,  86,  65,  72,\n",
       "        82,  78,  86,  83,  70,  80,  69,  69,  83,  63,  88,  71,  91,\n",
       "        77,  72,  81,  85,  66,  91,  77,  74,  63,  82,  88,  79,  78,\n",
       "        78,  67,  84,  83,  80,  89,  82,  89,  76,  75,  69,  75,  71,\n",
       "        69,  78,  74,  80,  60,  79,  95,  81,  83,  74,  81,  71,  87,\n",
       "        86,  79,  81,  71,  83,  76,  76,  75,  87,  83,  83,  75,  70,\n",
       "        74,  80,  86,  75,  85,  82,  84,  72,  88,  79,  77,  87,  72,\n",
       "        68,  78,  80,  85,  67,  82,  82,  71,  84,  81,  72,  77,  73,\n",
       "        78,  76,  85,  82,  88,  88,  69,  75,  68,  69,  79,  78,  80,\n",
       "        75,  68,  77,  68,  80,  68,  81,  75,  81,  61,  76,  72,  78,\n",
       "        66,  72,  80,  88,  86,  76,  73,  73,  80,  77,  74,  85,  83,\n",
       "        81,  75,  87,  83,  91,  79,  74,  76,  78,  78,  80,  79,  87,\n",
       "        65,  85,  77,  74,  87,  79,  63,  68,  86,  88,  74,  79,  69,\n",
       "        73,  73,  79,  84,  90,  80,  81,  74,  77,  73,  68,  66,  70,\n",
       "        60,  85,  81,  80,  88,  87,  69,  79,  78,  78,  82,  79,  73,\n",
       "        81,  71,  75,  78,  82,  89,  83,  86,  74,  75,  83,  77,  77,\n",
       "        73,  72,  79,  84,  80,  79,  87,  74,  79,  88,  67,  86,  61,\n",
       "        65,  73,  74,  81,  77,  69,  77,  77,  83,  76,  83,  74,  70,\n",
       "        71,  80,  68,  85,  69,  84,  82,  72,  68,  77,  81,  70,  84,\n",
       "        61,  78,  81,  74,  77,  76,  74,  85,  81,  73,  67,  85,  81,\n",
       "        79,  84,  93,  66,  76,  77,  89,  77,  62,  81,  72,  75,  74,\n",
       "        75,  81,  58,  77,  90,  79,  85,  82,  82,  77,  71,  89,  78,\n",
       "        73,  76,  79,  69,  75,  89,  71,  83,  79,  72,  77,  86,  81,\n",
       "        82,  82,  86,  79,  71,  89,  83,  79,  77,  70,  80,  85,  84,\n",
       "        71,  85,  84,  86,  65,  67,  90,  86,  71,  80,  85,  71,  78,\n",
       "        86,  72,  78,  85,  92,  61,  74,  73,  73,  71,  82,  97,  80,\n",
       "        71,  69,  81,  70,  91,  82,  75,  65,  79,  71,  63,  77,  86,\n",
       "        85,  72,  74,  72,  92,  64,  65,  74,  70,  81,  86,  62,  62,\n",
       "        80,  61,  70,  70,  75,  76,  75,  84,  70,  77,  74,  98,  89,\n",
       "        83,  80,  70,  66,  87,  65,  78,  87,  77,  80,  83,  56,  78,\n",
       "        75,  86,  68,  84,  93,  88,  77,  73,  77,  86,  78,  83,  71,\n",
       "        84,  77,  82,  78,  90,  83,  82,  75,  90,  87,  66,  62,  76,\n",
       "        77,  77,  73,  71,  72,  79,  85,  73,  78,  78,  84,  85,  88,\n",
       "        76,  79,  67,  82,  85,  81,  75,  68,  86,  73,  85,  66,  90,\n",
       "        81,  75,  75,  65,  77,  80,  75,  64,  79,  77,  73,  60,  76,\n",
       "        85,  60,  77,  74,  79,  66,  85,  62,  83,  68,  71,  81,  77,\n",
       "        82,  78,  77,  71,  75,  76,  72,  75,  76,  70,  68,  68,  69,\n",
       "        81,  71,  75,  84,  81,  87,  77,  70,  71,  77,  75,  78,  81,\n",
       "        79,  78,  79,  89,  65,  84,  79,  70,  79,  73,  84,  74,  77,\n",
       "        83,  77,  76,  80,  80,  83,  78,  74,  94,  77,  81,  62,  89,\n",
       "        85,  75,  79,  72,  68,  74,  77,  62,  74,  71,  73,  77,  81,\n",
       "        74,  75,  74,  67,  64,  74,  90,  79,  81,  87,  71,  83,  78,\n",
       "        67,  74,  77,  84,  61,  67,  80,  81,  89,  76,  73,  79,  74,\n",
       "        71,  73,  70,  83,  81,  72,  75,  77,  67,  78,  80,  82,  64,\n",
       "        82,  70,  88,  76,  81,  74,  78,  91,  83, 101,  79,  58,  79,\n",
       "        86,  60,  85,  70,  78,  74,  77,  84,  77,  66,  84,  78,  69,\n",
       "        84,  83,  66,  84,  83,  69,  77,  89,  80,  72,  83,  78,  85,\n",
       "        93,  80,  79,  88,  73,  75,  68,  71,  74,  73,  82,  68])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theory:\n",
    "np.sum(measurement_events,axis=1)\n",
    "# 1 - logical error 0.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72, 66, 75, 84, 78, 84, 65, 87, 79, 90, 76, 80, 77, 89, 73, 72, 76,\n",
       "       73, 88, 71, 71, 77, 93, 68, 76, 74, 75, 75, 72, 67, 75, 90, 82, 77,\n",
       "       88, 83, 80, 75, 76, 77, 89, 80, 72, 86, 84, 84, 83, 85, 88, 80, 84,\n",
       "       70, 70, 83, 70, 72, 75, 85, 85, 79, 95, 80, 74, 82, 72, 76, 83, 79,\n",
       "       78, 77, 81, 61, 91, 71, 77, 76, 77, 64, 68, 85, 87, 73, 86, 71, 84,\n",
       "       77, 74, 77, 80, 77, 89, 64, 74, 72, 73, 74, 78, 74, 70, 76, 62, 70,\n",
       "       85, 82, 78, 93, 84, 75, 80, 78, 79, 79, 79, 70, 84, 70, 70, 69, 88,\n",
       "       83, 81, 67, 77, 73, 76, 83, 81, 76, 66, 82, 79, 73, 74, 79, 80, 74,\n",
       "       77, 69, 79, 81, 79, 79, 91, 75, 82, 87, 75, 74, 80, 85, 91, 83, 70,\n",
       "       90, 89, 70, 90, 83, 87, 75, 75, 87, 73, 85, 74, 85, 83, 84, 82, 66,\n",
       "       74, 72, 71, 72, 95, 65, 76, 77, 84, 77, 67, 69, 78, 71, 66, 81, 69,\n",
       "       82, 69, 80, 88, 93, 86, 75, 77, 74, 86, 73, 80, 87, 79, 76, 82, 82,\n",
       "       65, 69, 74, 74, 77, 74, 71, 84, 81, 79, 77, 69, 79, 85, 73, 69, 87,\n",
       "       79, 82, 89, 86, 69, 83, 69, 81, 80, 80, 81, 67, 72, 74, 74, 84, 79,\n",
       "       71, 84, 83, 74, 82, 77, 90, 84, 72, 82, 88, 83, 90, 79, 85, 65, 89,\n",
       "       79, 79, 76, 85, 78, 87, 76, 76, 76, 87, 87, 74, 86, 84, 86, 83, 82,\n",
       "       85, 74, 82, 80, 85, 80, 70, 77, 84, 73, 90, 74, 64, 86, 68, 92, 83,\n",
       "       75, 79, 75, 83, 79, 73, 74, 78, 80, 72, 83, 75, 83, 67, 70, 82, 73,\n",
       "       69, 71, 80, 91, 62, 68, 80, 60, 75, 76, 91, 75, 79, 74, 91, 84, 63,\n",
       "       84, 72, 89, 77, 72, 74, 73, 66, 85, 67, 84, 65, 88, 76, 93, 65, 85,\n",
       "       79, 80, 83, 78, 71, 77, 87, 97, 67, 68, 78, 83, 84, 73, 78, 92, 85,\n",
       "       85, 84, 71, 88, 77, 88, 71, 79, 72, 90, 83, 64, 75, 78, 67, 77, 76,\n",
       "       73, 82, 80, 78, 86, 80, 71, 68, 90, 79, 70, 76, 71, 91, 70, 86, 84,\n",
       "       76, 85, 79, 75, 67, 83, 81, 78, 85, 86, 70, 63, 80, 72, 83, 81, 75,\n",
       "       71, 80, 81, 75, 87, 77, 71, 73, 84, 68, 83, 70, 81, 70, 71, 77, 85,\n",
       "       84, 73, 87, 77, 78, 78, 81, 76, 64, 85, 76, 87, 77, 66, 87, 74, 93,\n",
       "       70, 68, 81, 88, 76, 92, 81, 79, 80, 81, 79, 82, 77, 84, 77, 70, 85,\n",
       "       83, 70, 72, 77, 82, 88, 77, 76, 68, 81, 67, 82, 77, 81, 65, 62, 81,\n",
       "       84, 86, 69, 79, 66, 80, 75, 79, 80, 86, 82, 85, 78, 79, 88, 73, 79,\n",
       "       80, 74, 68, 73, 76, 76, 65, 73, 81, 76, 78, 75, 75, 83, 77, 91, 80,\n",
       "       69, 80, 84, 80, 74, 80, 80, 89, 80, 77, 87, 81, 78, 83, 97, 71, 82,\n",
       "       88, 96, 75, 85, 67, 87, 80, 73, 65, 71, 86, 81, 76, 72, 58, 77, 76,\n",
       "       79, 83, 85, 81, 68, 82, 79, 73, 83, 77, 75, 85, 78, 81, 83, 75, 76,\n",
       "       73, 83, 67, 83, 89, 79, 66, 79, 72, 67, 81, 89, 63, 74, 84, 85, 66,\n",
       "       86, 80, 83, 83, 68, 81, 81, 81, 70, 85, 69, 62, 79, 67, 87, 71, 90,\n",
       "       71, 72, 82, 75, 73, 83, 74, 90, 78, 72, 82, 86, 74, 74, 85, 63, 73,\n",
       "       86, 59, 79, 76, 76, 78, 61, 87, 69, 69, 86, 86, 74, 67, 80, 80, 61,\n",
       "       71, 74, 69, 78, 89, 90, 71, 74, 80, 72, 76, 63, 79, 83, 82, 79, 87,\n",
       "       78, 79, 68, 76, 85, 73, 76, 87, 83, 90, 88, 80, 74, 87, 66, 71, 67,\n",
       "       90, 69, 74, 65, 93, 80, 78, 72, 74, 89, 74, 79, 69, 67, 81, 78, 86,\n",
       "       86, 73, 70, 79, 84, 82, 78, 89, 86, 81, 67, 68, 82, 76, 89, 77, 84,\n",
       "       82, 82, 73, 78, 77, 79, 64, 88, 70, 80, 86, 62, 77, 78, 70, 86, 88,\n",
       "       67, 78, 74, 81, 75, 85, 80, 78, 75, 67, 85, 72, 79, 73, 77, 86, 80,\n",
       "       84, 83, 85, 83, 68, 82, 81, 86, 80, 76, 81, 82, 73, 73, 77, 80, 81,\n",
       "       79, 73, 80, 73, 68, 67, 76, 74, 86, 77, 84, 71, 65, 72, 90, 79, 72,\n",
       "       78, 75, 67, 75, 79, 70, 83, 69, 75, 77, 80, 79, 77, 91, 85, 72, 89,\n",
       "       89, 75, 82, 79, 66, 72, 85, 77, 74, 83, 76, 78, 81, 73, 80, 70, 76,\n",
       "       76, 77, 75, 84, 89, 78, 71, 88, 74, 79, 82, 82, 74, 79, 79, 83, 90,\n",
       "       83, 75, 77, 87, 82, 73, 87, 76, 92, 80, 79, 78, 75, 85, 78, 84, 75,\n",
       "       75, 69, 84, 79, 93, 77, 81, 73, 79, 71, 72, 79, 85, 86, 88, 76, 68,\n",
       "       81, 86, 67, 77, 71, 88, 90, 81, 88, 82, 75, 80, 80, 75, 91, 79, 90,\n",
       "       73, 76, 88, 72, 81, 88, 71, 91, 81, 74, 82, 73, 84, 64, 66, 77, 81,\n",
       "       82, 74, 72, 79, 67, 76, 74, 69, 78, 84, 84, 79, 75, 74, 81, 86, 76,\n",
       "       79, 81, 67, 76, 85, 81, 80, 81, 80, 67, 91, 90, 78, 79, 82, 86, 70,\n",
       "       74, 68, 93, 78, 80, 83, 76, 74, 85, 81, 72, 71, 78, 83, 79, 77, 83,\n",
       "       70, 82, 92, 84, 80, 75, 78, 86, 74, 80, 79, 68, 90, 72, 67, 84, 77,\n",
       "       67, 74, 82, 76, 83, 77, 77, 75, 81, 80, 82, 68, 72, 77, 84, 80, 81,\n",
       "       72, 76, 87, 85, 70, 71, 79, 78, 73, 87, 77, 82, 72, 83, 76, 88, 74,\n",
       "       81, 65, 79, 78, 84, 77, 66, 87, 76, 90, 81, 82, 88, 78])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment:\n",
    "np.sum(measurement_events,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 2, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 146)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  8,  3,  6,  5,  4,  6,  5,  6,  8,  8,  2,  8,  6, 10,  6,  4,\n",
       "        5,  3,  4,  2,  6,  7,  5,  5,  3,  4,  5,  6,  3,  6,  7,  8,  6,\n",
       "        8,  2,  7,  7, 11,  6,  7,  5,  4,  6,  2,  5,  5,  8,  4,  5,  8,\n",
       "        6,  8,  4,  1,  1,  3,  3,  5,  9,  3,  5,  2,  5,  3,  4,  2,  1,\n",
       "        8,  7,  6,  7,  3,  2,  7,  4,  3,  5,  6,  5,  4,  7,  3,  7,  7,\n",
       "        3,  6,  3,  2,  5,  5,  5,  3,  4,  8,  8,  4,  6,  7,  7,  5,  4,\n",
       "        3,  5,  4,  7,  5,  8,  4,  5,  4,  6,  2,  5,  4,  6,  7,  7,  6,\n",
       "        5,  8,  7,  7,  4,  5,  5,  2,  6,  6,  5,  8,  6,  8,  4,  4,  6,\n",
       "        3,  8,  6,  5, 11,  9,  7,  6,  8,  7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exp_measurements[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510911424903723"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n 1 - logical error 0.14890885750962768\n"
     ]
    }
   ],
   "source": [
    "print('/n 1 - logical error',1- logical_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "hi\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "x = 4\n",
    "num_CX_per_layer = 2*x + 1\n",
    "for cx_ix in range(num_CX_per_layer):\n",
    "    print(cx_ix)\n",
    "    if cx_ix == num_CX_per_layer // 2 : # new GB - add Y pulse on all qubits:\n",
    "        print('hi')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "dict_data = {1: [1, 2], 3: [3, 4]}\n",
    "qubits_to_exclude = [q for sublist in dict_data.values() for q in sublist]\n",
    "print(qubits_to_exclude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_layers = 20\n",
    "num_cxs_per_round = 0\n",
    "circuit_type = f'logical_CX_NL{num_layers}_NCX{num_cxs_per_round}'\n",
    "num_layers, num_cxs_per_round = map(int, re.findall(r'\\d+', circuit_type))\n",
    "print(num_layers)\n",
    "print(num_cxs_per_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9553333333333334"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_16894/3841985880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# DO IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     66\u001b[0m                                                                     \u001b[0mexp_measurements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                                                                     \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mreturn_matrix_with_observables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLE'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables_errors_interactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dem_loss_mle_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasurement_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_matrix_with_observables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final_dem_hyperedges_matrix doesn't contain observables, only detectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0;31m# print(f'Total loss decoder time per shot is {time.time() - start_time:.4f}s.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_dem_loss_mle_experiment\u001b[0;34m(self, measurement_event, return_matrix_with_observables)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m11\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0;34m'independent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Independent decoder:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mstart_time_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mfinal_dem_hyperedges_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_hyperedges_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# print(f'Summing over all relevant DEMs to generate the final DEM took {time.time() - start_time_ind:.5f}s')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_all_DEMs_and_sum_over_independent_events\u001b[0;34m(self, use_pre_processed_data, return_hyperedges_matrix, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;31m# sum over all loss DEMs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0mfinal_hyperedges_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_DEMs_high_order_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEMs_loss_pauli_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_detectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProbs_loss_pauli_events\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# GB: new Probs_loss_pauli_events. TODO: change this function to also get Probs_loss_pauli_events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m         \u001b[0;31m# print(f'New method: Time to sum over all DEMS (independent, combination, Pauli) with high order equation: {time.time() - start_time:.4f}s.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mcombine_DEMs_high_order_csr\u001b[0;34m(self, DEMs_list, num_detectors, Probs_list)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0mfinal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0mprob_i_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0;31m# Consider terms where 3 specific events happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0mfinal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0mprob_i_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0;31m# Consider terms where 3 specific events happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3086\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m     \"\"\"\n\u001b[0;32m-> 3088\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3089\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     71\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     71\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0madditional_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mpydev_step_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_step_cmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0mis_stepping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydev_step_cmd\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydb_disposed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_rounds = 3\n",
    "num_cx = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                    'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                    'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                    'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                    'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                    'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                    'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': f'logical_CX_NL{num_rounds}_NCX{num_cx}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "simulate_data = True\n",
    "\n",
    "if simulate_data:\n",
    "    detection_events_signs = None\n",
    "    exp_measurements = None\n",
    "    num_shots = 1000\n",
    "\n",
    "else:\n",
    "    # Load the theory circuit\n",
    "    _, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "    # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "    detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "    # Find detection event signs\n",
    "    detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "    exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                    exp_measurements[:, 1, :distance**2-1],\n",
    "                                    exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                    exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                    exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '.'\n",
    "# DO IT\n",
    "predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                    exp_measurements,\n",
    "                                                                    detection_events_signs, use_loss_decoding,\n",
    "                                                                    use_independent_decoder,\n",
    "                                                                    use_independent_and_first_comb_decoder,\n",
    "                                                                    simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                    noise_params=noise_params, num_shots=num_shots)\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "print('/n logical error', logical_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299999999999999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-logical_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta_params['printing'] = 'False'\n",
    "\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "print(circuit.num_detectors)\n",
    "print(\"HI\")\n",
    "print(circuit.detector_error_model(approximate_disjoint_errors=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a plot of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtDklEQVR4nO3deViUVfsH8O+wI8iuLIIs7vuCG+4rqL0uaWVlqZmVPy1FssWsNHvLtHo1K61MLVvUUiozTXHNXUFxRdxASSFUFFxBhvP74zQjw8zADMwGfD/X9Vwz88yZ57mHbW7OOc+5FUIIASIiIqJqxM7aARARERFZGhMgIiIiqnaYABEREVG1wwSIiIiIqh0mQERERFTtMAEiIiKiaocJEBEREVU7DtYOwBYVFRXh8uXLqFmzJhQKhbXDISIiIgMIIXDz5k0EBQXBzq70Ph4mQDpcvnwZISEh1g6DiIiIyiEjIwPBwcGltmECpEPNmjUByC+gh4eHlaMhIiIiQ+Tl5SEkJET9OV4aJkA6qIa9PDw8mAARERFVMoZMX+EkaCIiIqp2mAARERFRtcMEiIiIiKodzgEiIqoGioqKUFBQYO0wiCrMycmpzEvcDcEEiIioiisoKEBaWhqKioqsHQpRhdnZ2SE8PBxOTk4VOg4TICKiKkwIgczMTNjb2yMkJMQk/zkTWYtqoeLMzEzUrVu3QosVMwEiIqrCCgsLcefOHQQFBaFGjRrWDoeowmrVqoXLly+jsLAQjo6O5T4O/xUgIqrClEolAFR4uIDIVqh+llU/2+XFBIiIqBpgXUOqKkz1s8whMAtSKoGdO4HMTCAwEOjWDbC3t3ZURERE1Q8TIAuJjwcmTwb+/vvBvuBg4JNPgGHDrBcXERFRdcQhMAuIjwceeUQz+QGAS5fk/vh468RFRGQopRLYvh1YsULeVnD6RZmEEHj++efh4+MDhUKB5ORk856wAk6dOoVOnTrBxcUFrVu3tnY4OoWFhWH+/PnWDsOmWD0BWrhwIcLDw+Hi4oLIyEjs3Lmz1PY7duxAZGQkXFxcEBERgS+++EKrzY0bNzBx4kQEBgbCxcUFTZo0wfr16831FkqlVMqeHyG0n1Pti401/x8TIqLyio8HwsKAXr2AJ5+Ut2Fh5v3n7c8//8Q333yDdevWITMzE82bNzffySpoxowZcHNzQ2pqKrZs2WLtcMhAVk2AVq1ahdjYWEyfPh2HDx9Gt27dMGDAAFy8eFFn+7S0NAwcOBDdunXD4cOH8cYbb2DSpElYs2aNuk1BQQH69euH9PR0rF69GqmpqVi8eDHq1KljqbelYedO7Z6f4oQAMjJkOyIiW2OtHuxz584hMDAQnTt3RkBAABwcbHfGxrlz59C1a1eEhobC19e3XMfgKt1WIKyoQ4cOYvz48Rr7GjduLF5//XWd7V999VXRuHFjjX0vvPCC6NSpk/rxokWLREREhCgoKCh3XLm5uQKAyM3NLfcxVH78UQiZ5pS+/fhjhU9FRKTl7t274uTJk+Lu3btCCCGKioS4dcuwLTdXiDp19P/dUiiECA6W7Qw5XlGRYTGPHj1aAFBvoaGhQgghNmzYILp06SI8PT2Fj4+PeOihh8TZs2fVr0tLSxMAxJo1a0TPnj2Fq6uraNmypdizZ4/G8Xft2iW6d+8uXF1dhZeXl4iOjhY5OTni22+/FT4+PuLevXsa7YcNGyaefvppnbEWjxOAmDFjhhBCiKNHj4pevXoJFxcX4ePjI5577jlx8+ZNjfc4ZMgQ8f7774vAwEARGhqqjn/VqlWia9euwsXFRbRr106kpqaKAwcOiMjISOHm5iZiYmJEdna2+lg9evQQkydP1ohryJAhYvTo0erHoaGhYt68eerHH3/8sWjevLmoUaOGCA4OFv/3f/+nEZ8tK/kzXZwxn99W6wEqKChAUlISoqOjNfZHR0djz549Ol+zd+9erfYxMTFITEzE/fv3AQBr165FVFQUJk6cCH9/fzRv3hzvv/9+qesF5OfnIy8vT2MzlcBA07YjIqqIO3cAd3fDNk9P2dOjjxCyZ8jT07Dj3bljWIyffPIJZs2aheDgYGRmZuLgwYMAgNu3byMuLg4HDx7Eli1bYGdnh4cfflirxMf06dMxdepUJCcno2HDhnjiiSdQWFgIAEhOTkafPn3QrFkz7N27F7t27cKgQYOgVCrx6KOPQqlUYu3atepjXb16FevWrcMzzzyjM9bMzEw0a9YML7/8MjIzMzF16lTcuXMH/fv3h7e3Nw4ePIiff/4Zmzdvxosvvqjx2i1btiAlJQUJCQlYt26dev+MGTPw5ptv4tChQ3BwcMATTzyBV199FZ988gl27tyJc+fO4e233zbsi6mHnZ0dFixYgOPHj+Pbb7/F1q1b8eqrr1bomJWOObIzQ1y6dEkAELt379bY/95774mGDRvqfE2DBg3Ee++9p7Fv9+7dAoC4fPmyEEKIRo0aCWdnZzF27FiRmJgoVqxYIXx8fMQ777yjN5YZM2ZoZfEwUQ9QYaH8D0mh0P8fVEiIbEdEZGol/1u+dcuwXmlzbLduGR73vHnz1D0/+mRnZwsA4tixY0KIBz1AX3/9tbrNiRMnBACRkpIihBDiiSeeEF26dNF7zP/7v/8TAwYMUD+eP3++iIiIEEWldF+1atVK3fMjhBBfffWV8Pb2FreKveE//vhD2NnZiaysLCGE7AHy9/cX+fn56ja64l+xYoUAILZs2aLeN3v2bNGoUSP14/L0AJX0008/CV9fX73P25JK3wOkUnJBIyFEqYsc6WpffH9RURFq166Nr776CpGRkXj88ccxffp0LFq0SO8xp02bhtzcXPWWkZFR3rejxd5eXuouYyz5XuTt/PlcD4iILKNGDeDWLcM2Q68dWb/esONVtBLHuXPn8OSTTyIiIgIeHh4IDw8HAK15oy1btlTfD/y3ez07OxvAgx4gfZ577jls2rQJl/7t+lq2bBnGjBlj1OJ7KSkpaNWqFdzc3NT7unTpgqKiIqSmpqr3tWjRQucK3cXj9/f3V7ctvk/1fspr27Zt6NevH+rUqYOaNWti1KhRuHbtGm7fvl2h41YmVptV5ufnB3t7e2RlZWnsz87OVn/DSwoICNDZ3sHBQT3xLDAwEI6OjrAvllE0adIEWVlZKCgo0PnD5uzsDGdn54q+Jb2GDQNWr9a9DtD8+VwHiIgsR6EAin0ulyo6Wv6dunRJ95WsCoV8PjraMv/EDRo0CCEhIVi8eDGCgoJQVFSE5s2ba00gLl4fqvg/xwDg6upa6jnatGmDVq1aYfny5YiJicGxY8fw+++/GxVnaf/IF9/vpucboSv+kvuKD/vZ2dmpOwNUVNNCdLlw4QIGDhyI8ePH491334WPjw927dqFZ599ttTXVTVW6wFycnJCZGQkEhISNPYnJCSgc+fOOl8TFRWl1X7Tpk1o166d+oejS5cuOHv2rMYPx+nTpxEYGGjVWjjDhgHp6cCGDYCqGPOOHUx+iMh22VIP9rVr15CSkoI333wTffr0QZMmTXD9+nWjj9OyZcsyL1UfN24cli1bhqVLl6Jv374ICQkx6hxNmzZFcnKyRm/K7t27YWdnh4YNGxodc1lq1aqFzMxM9WOlUonjx4/rbZ+YmIjCwkJ8/PHH6NSpExo2bIjLly+bPC5bZ9UhsLi4OHz99ddYunQpUlJSMGXKFFy8eBHjx48HIIemRo0apW4/fvx4XLhwAXFxcUhJScHSpUuxZMkSTJ06Vd3m//7v/3Dt2jVMnjwZp0+fxh9//IH3338fEydOtPj7K8neHujfH2jTRj4+cMC68RARlUXVg11yJZHgYLnfUv/EeXt7w9fXF1999RXOnj2LrVu3Ii4uzujjTJs2DQcPHsSECRNw9OhRnDp1CosWLcLVq1fVbUaOHIlLly5h8eLFGDt2rNHnGDlyJFxcXDB69GgcP34c27Ztw0svvYSnn35a7whHRfTu3Rt//PEH/vjjD5w6dQoTJkzAjRs39LavV68eCgsL8emnn+L8+fP47rvvdK6pV9VZNQEaMWIE5s+fj1mzZqF169b466+/sH79eoSGhgKQs+uLj+2Gh4dj/fr12L59O1q3bo13330XCxYswPDhw9VtQkJCsGnTJhw8eBAtW7bEpEmTMHnyZLz++usWf3/6dOokb/fts24cRESGUPVgb9sG/PijvE1Ls2wPtp2dHVauXImkpCQ0b94cU6ZMwYcffmj0cRo2bIhNmzbhyJEj6NChA6KiovDbb79prDPk4eGB4cOHw93dHUOHDjX6HDVq1MDGjRuRk5OD9u3b45FHHkGfPn3w2WefGX0sQ4wdOxajR4/GqFGj0KNHD4SHh6NXr15627du3Rr/+9//MGfOHDRv3hw//PADZs+ebZbYbJlClBw4JOTl5cHT0xO5ubnw8PAw+fF/+AF46imZCO3da/LDExGp3bt3D2lpaeoV98kw/fr1Q5MmTbBgwQJrh0IllPYzbcznt+0urVmFqXqADh0C8vMBM86/JiIiI+Tk5GDTpk3YunWr2XpsyDYwAbKCiAigVi3gyhXg8OEHCREREVlX27Ztcf36dcyZMweNGjWydjhkRkyArEChkEnP77/LITAmQEREtiE9Pd3aIZCFWH0hxOqKE6GJiIishwmQlURFyVsmQERERJbHBMhK2reXCyJevAhUw/WniIiIrIoJkJW4uwOq0i7sBSIiIrIsJkBWpJoHxLWAiIiILIsJkBVxIjQRkeF69uyJ2NhY9eOwsDDMnz+/3K/XxdhjlpSeng6FQoHk5ORyH6O6UCgU+PXXX612fl4Gb0WqidCJicD9+0CxYr9ERLZFqQR27gQyM4HAQKBbN8tUQS3FwYMH9VZU1yU+Pl6jqnplVVRUBC8vLyQmJqJhw4Zo0KABlixZgu7du1s7tEqFPUBW1KAB4O0N3LsHHDli7WiIiPSIjwfCwoBevYAnn5S3YWFyvxXVqlULNWrUMLi9j48PatasacaILOP48eNwdnZGw4YNkZ2djYsXL6J9+/ZGHeP+/ftmiq7yYAJkRXZ2HAYjIhsXHw888gjw99+a+y9dkvvNlATdvn0bo0aNgru7OwIDA/Hxxx9rtSk+XPXEE0/g8ccf13j+/v378PPzw7JlywBoD4FlZ2dj0KBBcHV1RXh4OH744Qetc+Tm5uL5559H7dq14eHhgd69e+OIAf+xnjp1Cp07d4aLiwuaNWuG7du3AwCEEKhfvz4++ugjjfbHjx+HnZ0dzp07V+ax9+zZgy5dugAAdu7ciTZt2sDV1bXU18ycOROtW7fG0qVLERERAWdnZwghcPHiRQwZMgTu7u7w8PDAY489hn/++Uf9ujFjxmgVhI2NjUXPnj3Vj3v27IlJkybh1VdfhY+PDwICAjBz5kyN15w5cwbdu3eHi4sLmjZtioSEBI3nCwoK8OKLLyIwMBAuLi4ICwsze4FWDoFZWadOwIYNciL0iy9aOxoiqvKEAO7cMaytUglMmiRfo+s4CgUweTLQt69hw2E1asjXGOCVV17Btm3b8MsvvyAgIABvvPEGkpKS0Lp1a53tR44cicceewy3bt2Cu7s7AGDjxo24ffs2hg8frvM1Y8aMQUZGBrZu3QonJydMmjQJ2dnZxd6iwEMPPQQfHx+sX78enp6e+PLLL9GnTx+cPn0aPj4+pcY/f/58NG3aFP/73/8wePBgpKWlwdfXF2PHjsWyZcswdepUdfulS5eiW7duqFevnt5jenl5AZDFQIUQ8PLyQn5+PpRKJby8vNC1a1esW7dO7+vPnj2Ln376CWvWrIH9v9+voUOHws3NDTt27EBhYSEmTJiAESNGqBM2Q3377beIi4vD/v37sXfvXowZMwZdunRBv379UFRUhGHDhsHPzw/79u1DXl6e1lysBQsWYO3atfjpp59Qt25dZGRkICMjw6gYjCZIS25urgAgcnNzzX6ujRuFAISIiDD7qYioGrp79644efKkuHv3rtxx65b8o2ON7dYtg2K+efOmcHJyEitXrlTvu3btmnB1dRWTJ09W7wsNDRXz5s0TQghRUFAg/Pz8xPLly9XPP/HEE+LRRx9VP+7Ro4f69ampqQKA2Ldvn/r5lJQUAUB9zC1btggPDw9x7949jfjq1asnvvzyS52xp6WlCQDigw8+UO+7f/++CA4OFnPmzBFCCHH58mVhb28v9u/fr469Vq1a4ptvvin165KWlibOnz8vvL29xYYNG0RaWppo0KCB+OGHH0RaWprIzMzU+9oZM2YIR0dHkZ2drd63adMmYW9vLy5evKjed+LECQFAHDhwQAghxOjRo8WQIUM0jjV58mTRo0cP9eMePXqIrl27arRp3769eO2114QQQmzcuFHY29uLjIwM9fMbNmwQAMQvv/wihBDipZdeEr179xZFRUWlfg2E0PEzXYwxn98cArOyjh3lP0TnzwPF/vEgIqq2zp07h4KCAkSprhSBnL9TWnFSR0dHPProo+phrNu3b+O3337DyJEjdbZPSUmBg4MD2rVrp97XuHFjdS8LACQlJeHWrVvw9fWFu7u7ektLSytzqKp47KrzpKSkAAACAwPx0EMPYenSpQCAdevW4d69e3j00UdLPWZYWBiuXLmCGjVqoH///nB0dMTly5cxfPhwhIWFISAgoNTXh4aGolatWhpfg5CQEISEhKj3NW3aFF5eXupYDdWyZUuNx4GBgeretJSUFNStWxfBwcHq54t/fQDZG5ecnIxGjRph0qRJ2LRpk1HnLw8OgVmZpyfQpAlw8qScBzR4sLUjIqIqrUYN4NYtw9r+9RcwcGDZ7davBwy5AsnACctC15CbAUaOHIkePXogOzsbCQkJcHFxwYABA0o9h6KUIbmioiIEBgbqHA4qnigZqvi5xo0bh6effhrz5s3DsmXLMGLEiFIndA8YMAA7d+5EYWEhCgsL4e7uDqVSifz8fPj6+gIAbpXxfS15xZwQQuf7L77fzs5O6/uhawJ1yavrFAoFioqK1McrqeR527Zti7S0NGzYsAGbN2/GY489hr59+2L16tWlvqeKYA+QDWBdMCKyGIUCcHMzbIuOBoKD9c/bUSiAkBDZzpDjGTj/p379+nB0dMS+Yn8Ur1+/jtOnT5f6us6dOyMkJASrVq3CDz/8gEcffRROTk462zZp0gSFhYVITExU70tNTcWNGzfUj9u2bYusrCw4ODigfv36Gpufn1+psRSPvbCwEElJSWjcuLF638CBA+Hm5oZFixZhw4YNGDt2bKnH+/rrr5GcnIzIyEjMmTMHycnJiImJwauvvork5ORyrTvUtGlTXLx4UWOuzcmTJ5Gbm4smTZoAkFfaZWZmarzO2HOpznO5WN2nvTpWAPbw8MCIESOwePFirFq1CmvWrEFOTo5R5zIGEyAbwBWhicgm2dsDn3wi75dMXlSP5883+XpA7u7uePbZZ/HKK69gy5YtOH78OMaMGQM7u9I/shQKBZ588kl88cUXSEhIwFNPPaW3baNGjdC/f38899xz2L9/P5KSkjBu3DiNq6n69u2LqKgoDB06FBs3bkR6ejr27NmDN998UyNx0uXzzz/HL7/8glOnTmHixIm4fv26RpJjb2+PMWPGYNq0aahfv77WkFBJderUQVhYGI4ePYphw4ahfv36OHr0KIYMGaJOyozVt29ftGzZEiNHjsShQ4dw4MABjBo1Cj169FAPDfbu3RuJiYlYvnw5zpw5gxkzZuD48eNGn6dRo0YYNWoUjhw5gp07d2L69OkabebNm4eVK1fi1KlTOH36NH7++WcEBASUq6fNUEyAbIAqATp4ECgstG4sREQahg0DVq8G6tTR3B8cLPcPG2aW03744Yfo3r07Bg8ejL59+6Jr166IjIws83UjR47EyZMnUadOHfWl4vosW7YMISEh6NGjB4YNG6a+3F1FoVBg/fr16N69O8aOHYuGDRvi8ccfR3p6Ovz9/Us99gcffIA5c+agVatW2LlzJ3777TetXqNnn30WBQUFZfb+qCQmJsLLywvh4eH4+++/8c8//2jMYTKWaiVmb29vdO/eHX379kVERARWrVqlbhMTE4O33noLr776Ktq3b4+bN29i1KhRRp3Hzs4Ov/zyC/Lz89GhQweMGzcO7733nkYbd3d3zJkzB+3atUP79u2Rnp6O9evXl5n0VoRClHewtQrLy8uDp6cncnNz4eHhYfbzFRXJBRHz8oDkZKBVK7OfkoiqiXv37iEtLQ3h4eFwcXEp/4FscCXoym737t3o2bMn/v777zITKnqgtJ9pYz6/OQnaBtjZAR06AJs3y2EwJkBEZHPs7YFii99R+eXn5yMjIwNvvfUWHnvsMSY/VsIhMBvBFaGJiKqHFStWoFGjRsjNzcXcuXOtHU61xQTIRqjmv3EiNBFR1TZmzBgolUokJSWhTsm5VWQxTIBsRMeO8vb0aeDaNevGQkREVNUxAbIRvr5Aw4by/oED1o2FiKoeXu9CVYWpfpaZANkQrgdERKamKnpZUFBg5UiITEP1s2xfwasQeRWYDenUCVi+nBOhich0HBwcUKNGDVy5cgWOjo5mXVeFyNyKiorU9dAcHCqWwjABsiGqidD798u1gfh3iogqSqFQIDAwEGlpabhw4YK1wyGqMDs7O9StW7fUOm6GYAJkQ5o3l+Vy8vKAlBSgWTNrR0REVYGTkxMaNGjAYTCqEpycnEzSk8kEyIY4OADt2wPbt8thMCZARGQqdnZ2FVsJmqiK4SCLJSmVMrtZsULeKpVaTTgRmoiIyPzYA2Qp8fHA5MnA338/2BccLCstFysmyBWhiYiIzI89QJYQHw888ohm8gMAly7J/fHx6l2qBOjkSSA314IxEhERVSNMgMxNqZQ9P7oWblLti41VD4f5+wPh4fIpLohIRERkHkyAzG3nTu2en+KEADIyZLt/qS6H5zAYERGReTABMrfMTKPbcSI0ERGReTEBMrfAQKPbFZ8IzfI9REREpscEyNy6dZNXe+lbsVKhAEJCZLt/tWoFuLgA168DZ85YKE4iIqJqhAmQudnby0vdAe0kSPV4/nzZ7l9OTkBkpLzPYTAiIiLTYwJkCcOGAatXA3XqaO4PDpb7i60DpMKJ0ERERObDBMhShg0D0tOBjRtlzQtA3teR/ACcCE1ERGROTIAsyd4eiI4GOnaUj0vp3lElQMeOAbduWSA2IiKiaoQJkDV06SJvd+/W26ROHTk3uqgISEy0UFxERETVBBMgazAgAQI4DEZERGQuTICsoXNneXvqFHDtmt5mnAhNRERkHkyArMHPD2jUSN7fs0dvs+I9QFwQkYiIyHSYAFlL167ytpRhsDZtAEdH4MoVIC3NQnERERFVA0yArMWAeUAuLkDbtvI+h8GIiIhMhwmQtagSoIMHgfx8vc04EZqIiMj0mABZS4MGQK1aMvlJStLbjBOhiYiITI8JkLUoFA+uBitlGEzVA5ScDNy9a/6wiIiIqgMmQNZkwDygunWBgACgsLDUjiIiIiIyAhMga1IlQHv26L3OXaHgMBgREZGpWT0BWrhwIcLDw+Hi4oLIyEjs3Lmz1PY7duxAZGQkXFxcEBERgS+++ELj+W+++QYKhUJru3fvnjnfRvlERgLOzvI69zNn9DbjRGgiIiLTsmoCtGrVKsTGxmL69Ok4fPgwunXrhgEDBuDixYs626elpWHgwIHo1q0bDh8+jDfeeAOTJk3CmjVrNNp5eHggMzNTY3NxcbHEWzKOszPQrp28X8owmKoHiAsiEhERmYZVE6D//e9/ePbZZzFu3Dg0adIE8+fPR0hICBYtWqSz/RdffIG6deti/vz5aNKkCcaNG4exY8fio48+0minUCgQEBCgsZUmPz8feXl5GpvFGLAgYmSkLCSfmQn8/beF4iIiIqrCrJYAFRQUICkpCdHR0Rr7o6OjsUdPeYi9e/dqtY+JiUFiYiLu37+v3nfr1i2EhoYiODgY//nPf3D48OFSY5k9ezY8PT3VW0hISDnfVTkYMBG6Rg2gVSt5n8NgREREFWe1BOjq1atQKpXw9/fX2O/v74+srCydr8nKytLZvrCwEFevXgUANG7cGN988w3Wrl2LFStWwMXFBV26dMGZUubYTJs2Dbm5ueotIyOjgu/OCCyMSkREZHFWnwStUCg0HgshtPaV1b74/k6dOuGpp55Cq1at0K1bN/z0009o2LAhPv30U73HdHZ2hoeHh8ZmMb6+QOPG8r6BhVGJiIioYqyWAPn5+cHe3l6rtyc7O1url0clICBAZ3sHBwf4+vrqfI2dnR3at29fag+Q1amGwXbt0ttE1QN06FCplTOIiIjIAFZLgJycnBAZGYmEhASN/QkJCeisGhYqISoqSqv9pk2b0K5dOzg6Oup8jRACycnJCAwMNE3g5mDAPKCICMDPDygokKtCExERUflZdQgsLi4OX3/9NZYuXYqUlBRMmTIFFy9exPjx4wHIuTmjRo1Stx8/fjwuXLiAuLg4pKSkYOnSpViyZAmmTp2qbvPOO+9g48aNOH/+PJKTk/Hss88iOTlZfUybpEqAEhP1du8oFBwGIyIiMhUHa558xIgRuHbtGmbNmoXMzEw0b94c69evR2hoKAAgMzNTY02g8PBwrF+/HlOmTMHnn3+OoKAgLFiwAMOHD1e3uXHjBp5//nlkZWXB09MTbdq0wV9//YUOHTpY/P0ZTFUY9coVWe9Cbw8YsG4dJ0ITERFVlEIILq1XUl5eHjw9PZGbm2u5CdFDhwK//QbMnQu88orOJlu3An36yPpgFy5YJiwiIqLKwpjPb6tfBUb/MmBBxPbtATs74OJF4PJlC8VFRERUBTEBshUGFEatWRNo3lze37/fQnERERFVQUyAbEXbtiyMSkREZCFMgGyFs7Mc4wIMKozKidBERETlxwTIlhiwIKKqBygxEShW/oyIiIiMwATIlhiwIGLDhoCXF3D3LnD0qGXCIiIiqmqYANkS1fo/qanAv8VdS7Kze9ALxGEwIiKi8mECZEtYGJWIiMgimADZGgOGwTgRmoiIqGKYANkaAxZEVFX1OHcOyM62QExERERVDBMgW2NAYVQvL6BJE3mfCyISEREZjwmQralfXxZGzc+XhVH14DAYERFR+TEBsjUKhUHzgDgRmoiIqPyYANkiAxZEVPUAHTgAKJUWiImIiKgKYQJkiwwojNqkiSyOevs2cOKEBWMjIiKqApgA2SJVYdSrV4HTp3U2sbd/cDUYh8GIiIiMwwTIFrEwKhERkVkxAbJVnAhNRERkNkyAbJUBCyKqEqDUVCAnxwIxERERVRFMgGyVAYVRfX2BBg3k/QMHLBQXERFRFcAEyFb5+DxY7pmFUYmIiEyKCZAtY2FUIiIis2ACZMsMWBBR1QO0fz9QVGSBmIiIiKoAJkC2rHhh1Hv3dDZp0QKoUQPIzQVOnbJgbERERJUYEyBbpiqMWlCgtzCqg8ODJYM4DEZERGQYJkC2jIVRiYiIzIIJkK3jRGgiIiKTYwJk61QLIpZSGFXVA3TihJwLRERERKVjAmTr2rYFXFxKLYzq7w+Eh8v86OBBC8dHRERUCTEBsnVOTgYVRlX1AnEYjIiIqGxMgCoDToQmIiIyKSZAlYGRE6H1TBUiIiKifzEBqgyKF0a9ckVnk1at5FShnBzgzBkLxkZERFQJMQGqDAwojOrkBERGyvucB0RERFQ6JkCVhRHzgJgAERERlY4JUGXBidBEREQmwwSoslAtiFhKYVTVROijR4Hbty0UFxERUSXEBKiyqFcPqF271MKodeoAwcFAUREXRCQiIioNE6DKwsDCqKwLRkREVDYmQJUJJ0ITERGZBBOgyqR4AlRGYdS9e7kgIhERkT5MgCoTVWHUa9fkooh6mjg6AtnZQHq6ZcMjIiKqLJgAVSYGFEZ1cQHatJH3OQxGRESkGxOgysaIidBcD4iIiEg3gxOgWbNm4c6dO+aMhQzBidBEREQVphDCsKmy9vb2yMzMRO3atc0dk9Xl5eXB09MTubm58PDwsHY4mnJyAF9feT87G6hVS6tJejoQHg44OAB5eYCrq2VDJCIisgZjPr8N7gEyME8ic/PxAZo2lff1FEYNDQUCAoDCQuDQIQvGRkREVEkYNQdIoVCYKw4yRhnDYAoFh8GIiIhK42BM4z59+sDBofSXHGKXg/l16QIsXlzmROhff+VEaCIiIl2MSoBiYmLg7u5urljIUKoeIFVhVBcXrSbsASIiItLP4EnQdnZ2yMrK4iRoWyCEnOSTnQ3s3PmgUnwxt28Dnp6AUglcvAiEhFghTiIiIgsyyyRozv+xIQYURnVzA1q1kvfZC0RERKTJ6leBLVy4EOHh4XBxcUFkZCR27txZavsdO3YgMjISLi4uiIiIwBdffKG37cqVK6FQKDB06FATR20DuB4QERFRuRmcAKWlpcHPz0/9+OrVq7h27VqFTr5q1SrExsZi+vTpOHz4MLp164YBAwbg4sWLemMYOHAgunXrhsOHD+ONN97ApEmTsGbNGq22Fy5cwNSpU9GtW7cKxWizVAnQnj0GFUYlIiKiBwyeAwQAN27cwPTp07Fq1Spcv34dAODt7Y3HH38c//3vf+Hl5WXUyTt27Ii2bdti0aJF6n1NmjTB0KFDMXv2bK32r732GtauXYuUlBT1vvHjx+PIkSPYW+xTXqlUokePHnjmmWewc+dO3LhxA7/++qveOPLz85Gfn69+nJeXh5CQENudAwQABQVyks+9e0BKCtC4sVaTs2eBBg0AZ2cgN1feEhERVVVmmQOUk5ODjh074ttvv8Xw4cPx8ccf46OPPsKwYcPwzTffICoqSp0UGaKgoABJSUmIjo7W2B8dHY09ehb427t3r1b7mJgYJCYm4v79++p9s2bNQq1atfDss88aFMvs2bPh6emp3kIqw4xhJyegQwd5X88wWL16gJ8fkJ8PJCdbLjQiIiJbZ1QtMCcnJ5w7dw5ffvklYmNjMWXKFHz11Vc4e/YsHB0dMWvWLINPfPXqVSiVSvj7+2vs9/f3R1ZWls7XZGVl6WxfWFiIq1evAgB2796NJUuWYPHixQbHMm3aNOTm5qq3jIwMg19rVVwQkYiIqFwMToB+/fVXfPTRR1oJCAAEBARg7ty5+OWXX4wOoOTVZUKIUq8409Vetf/mzZt46qmnsHjxYo35SmVxdnaGh4eHxlYpcCI0ERFRuRi8EGJmZiaaNWum9/nmzZvr7bnRxc/PD/b29lqvyc7O1plkATLR0tXewcEBvr6+OHHiBNLT0zFo0CD180VFRQAABwcHpKamol69egbHaPOiouTt6dPAlSs6C6NyIjQREZE2g3uA/Pz8kJ6ervf5tLQ0+KqqlBvAyckJkZGRSEhI0NifkJCAzp0763xNVFSUVvtNmzahXbt2cHR0ROPGjXHs2DEkJyert8GDB6NXr15ITk6uHHN7jFG8MKqeXqAOHeRQ2IULQGamBWMjIiKyYQYnQP3798f06dNRUFCg9Vx+fj7eeust9O/f36iTx8XF4euvv8bSpUuRkpKCKVOm4OLFixg/fjwAOTdn1KhR6vbjx4/HhQsXEBcXh5SUFCxduhRLlizB1KlTAQAuLi5o3ry5xubl5YWaNWuiefPmcHJyMiq+SqGMYbCaNYHmzeV9DoMRERFJBg+BvfPOO2jXrh0aNGiAiRMnovG/l12fPHkSCxcuRH5+Pr777jujTj5ixAhcu3YNs2bNQmZmJpo3b47169cjNDQUgBx2K74mUHh4ONavX48pU6bg888/R1BQEBYsWIDhw4cbdd4qxcDCqMeOyQTo4YctGBsREZGNMmodoLS0NEyYMAGbNm3SmHzcr18/fPbZZ6hfv77ZArUkm68FVpxqsR8nJ7nYj47CqMuWAWPHAt27Azt2WCFGIiIiCzDm89uoBEjl+vXrOHPmDACgfv368PHxKV+kNqpSJUAGFEZNSZFThVxdZY7k6GiFOImIiMzMLAshFuft7Y0OHTqgQ4cOVS75qXQUigdJj55hsEaNAC8v4O5dORRGRERU3Rk8B2js2LFltlEoFFiyZEmFAqJy6NIFiI/XmwDZ2QEdOwIbN8p5QG3bWjg+IiIiG2NwAlRamQulUonNmzcjPz+fCZA1lCyMqmMhyagomQDt3QtMmGDh+IiIiGyMwQmQvlWef/vtN7zxxhtwdnbG22+/bbLAyAht2sjJz9euAampOgujckVoIiKiB8o1BwiQNbe6du2KJ598Ev/5z39w/vx5vP7666aMjQxVvDDqrl06m6iePntWLhpNRERUnRmdAJ04cQKDBg1Cz5490ahRI6SmpmLOnDnw9vY2R3xkqDIWRPT2Bpo0kff377dQTERERDbK4AQoIyMDzzzzDFq3bg0HBwccPXoUS5YsQXBwsDnjI0OxMCoREZHBDJ4D1KhRIygUCrz88svo3Lkzzpw5o14LqLjBgwebNEAykKow6pkzck2g2rV1Nlm2jIVRiYiIDE6A7t27BwCYO3eu3jYKhQJKpbLiUZHxVIVRT56UV4MNHarVRNUDdOAAoFQC9vaWDZGIiMhWGDwEVlRUVObG5MfKylgQsWlTWRz11i3gxAkLxkVERGRjyn0VGNmgMuYB2ds/uBqM84CIiKg6MzgBSkpKQq9evZCXl6f1XG5uLnr16oUjR46YNDgykioBSkoC/h2yLIkToYmIiIxIgD7++GP07t1bZ3ExT09P9OvXDx9++KFJgyMjRUQA/v5AQQGQmKiziWquNCdCExFRdWZwArR//34MGTJE7/ODBg3Cnj17TBIUlZNCUeYwWMeO8vbUKaCU6iZERERVmsEJ0KVLl1CzZk29z7u7uyMzM9MkQVEFqBIgPStC+/kB9evL+1wQkYiIqiuDE6BatWohNTVV7/OnTp2Cn5+fSYKiCiheGLWoSGcT1TAY5wEREVF1ZXAC1LdvX7z33ns6nxNC4P3330ffvn1NFhiVk6owak6OLIyqAydCExFRdWdwAvTmm2/i2LFj6NixI3766SccOXIER48exapVq9CxY0ccO3YM06dPN2esZIjihVH1zAMq3gOkp5OIiIioSjM4AapXrx42b96M27dv4/HHH0fbtm3Rpk0bPPHEE7hz5w4SEhJQXzW5hKyrjAURW7QAXF2B3Fy9nURERERVmsGlMACgXbt2OH78OJKTk3HmzBkIIdCwYUO0bt3aTOFRuZRxJZiDA9C+PfDXX/JyeFWVeCIiourCqARIpXXr1kx6bJmBhVH/+ksOg40da+H4iIiIrIylMKoib2+gWTN5X8/aTJwITURE1RkToKqqjGEwVQJ0/Digo7oJERFRlcYEqKoqY0HEgAAgLAwQAjh40HJhERER2QKjEqDCwkK88847yMjIMFc8ZCrFC6PevauziaoXiHXBiIioujEqAXJwcMCHH34IpVJprnjIVFSFUe/fL7MwKucBERFRdWP0EFjfvn2xfft2M4RCJmVAYdTiE6GFsFBcRERENsDoy+AHDBiAadOm4fjx44iMjISbm5vG84MHDzZZcFRBXbsC8fF6E6DWrQFnZ+DaNeDsWaBBA8uGR0REZC0KIYz739/OTn+nkUKhqBLDY3l5efD09ERubi48PDysHU75HTgAdOwI+PgAV64AOr53XbrIK+WXLweeftoKMRIREZmIMZ/fRg+BFRUV6d2qQvJTpbRpI2tesDAqERGRhgpdBn/v3j1TxUHm4OhocGFUXglGRETVidEJkFKpxLvvvos6derA3d0d58+fBwC89dZbWLJkickDpAoycCL00aPA7dsWiomIiMjKjE6A3nvvPXzzzTeYO3cunJyc1PtbtGiBr7/+2qTBkQmUsSBicLDclEq9V8sTERFVOUYnQMuXL8dXX32FkSNHwt7eXr2/ZcuWOHXqlEmDIxNQjXGdPQv884/OJpwHRERE1Y3RCdClS5dQv359rf1FRUW4f/++SYIiE2JhVCIiIi1GJ0DNmjXDzp07tfb//PPPaNOmjUmCIhMrYx5Q8YnQXBCRiIiqA6MXQpwxYwaefvppXLp0CUVFRYiPj0dqaiqWL1+OdevWmSNGqqiuXYGvvtKbALVpIy8Y++cf4MIFWSSViIioKjO6B2jQoEFYtWoV1q9fD4VCgbfffhspKSn4/fff0a9fP3PESBVVRmFUV1e5KjTAy+GJiKh6KNc6QDExMdixYwdu3bqFO3fuYNeuXYiOjjZ1bGQq4eFAQAALoxIREf2r3AshJiYm4rvvvsP333+PpKQkU8ZEpmZkYVQiIqKqzug5QH///TeeeOIJ7N69G15eXgCAGzduoHPnzlixYgVCQkJMHSOZQpcuwJo1ZU6EPnwYuHcPcHGxYGxEREQWZnQP0NixY3H//n2kpKQgJycHOTk5SElJgRACzz77rDliJFMo3gNUVKT1dGgo4O8vR8kOHbJwbERERBZmdAK0c+dOLFq0CI0aNVLva9SoET799FOdl8eTjVAVRr1+HdCxYKVC8WAYjBOhiYioqjM6Aapbt67OBQ8LCwtRp04dkwRFZmBEYVTOAyIioqrO6ARo7ty5eOmll5CYmAjx76p5iYmJmDx5Mj766COTB0gmxInQREREAACFEMat/evt7Y07d+6gsLAQDg5yDrXqvpubm0bbnJwc00VqQXl5efD09ERubi48PDysHY7pbNgADBwI1K8PnDmj9fTt24CnpyyMmpEhi6QSERFVFsZ8fht9Fdj8+fPLGxdZW1SUnOyjKozq76/xtJsb0LKlvBJs3z7gkUesFCcREZGZGZ0AjR492hxxkCV4ecnCqMePy8KoDz+s1aRTJ5kA7d3LBIiIiKquci+ESJWUgYVROQ+IiIiqMiZA1Y2BE6GTkoCCAgvFREREZGFMgKqbMgqj1q8P+PoC+flAcrJlQyMiIrIUqydACxcuRHh4OFxcXBAZGVnmYoo7duxAZGQkXFxcEBERgS+++ELj+fj4eLRr1w5eXl5wc3ND69at8d1335nzLVQuxQujHjyo9XTxBRE5DEZERFWVUQmQ6nL348ePm+Tkq1atQmxsLKZPn47Dhw+jW7duGDBgAC5evKizfVpaGgYOHIhu3brh8OHDeOONNzBp0iSsWbNG3cbHxwfTp0/H3r17cfToUTzzzDN45plnsHHjRpPEXOkZURiVK0ITEVFVZfQ6QPXq1UN8fDxatWpV4ZN37NgRbdu2xaJFi9T7mjRpgqFDh2L27Nla7V977TWsXbsWKSkp6n3jx4/HkSNHsLeUT+u2bdvioYcewrvvvmtQXFV2HSCVefOAuDjgoYeAdeu0nt6yBejbFwgLA9LSLB8eERFReRjz+W30ENibb76JadOmVXiRw4KCAiQlJSE6Olpjf3R0NPbs2aPzNXv37tVqHxMTg8TERJ3lOYQQ2LJlC1JTU9G9e3e9seTn5yMvL09jq9JUPUB79ugsjNq+vewoSk8HsrIsGxoREZElGL0O0IIFC3D27FkEBQUhNDRUa/XnQwaWEr969SqUSiX8SyzG5+/vjyw9n7pZWVk62xcWFuLq1asIDAwEAOTm5qJOnTrIz8+Hvb09Fi5ciH79+umNZfbs2XjnnXcMirtKKFkYtWlTjac9PIDmzYFjx+Q8oKFDrRMmERGRuRidAA018aehQqHQeCyE0NpXVvuS+2vWrInk5GTcunULW7ZsQVxcHCIiItCzZ0+dx5w2bRri4uLUj/Py8hASEmLsW6k8HB2Bjh2B7dvlPKASCRAg5wExASIioqrK6ARoxowZJjmxn58f7O3ttXp7srOztXp5VAICAnS2d3BwgK+vr3qfnZ0d6tevDwBo3bo1UlJSMHv2bL0JkLOzM5ydnSvwbiqhLl0eJEDPPaf1dKdOwOLFvBKMiIiqpnJfBp+UlITvv/8eP/zwAw4fPmz0652cnBAZGYmEhASN/QkJCejcubPO10RFRWm137RpE9q1awdHR0e95xJCID8/3+gYqzQDV4Q+eBAoLLRQTERERBZidA9QdnY2Hn/8cWzfvh1eXl4QQiA3Nxe9evXCypUrUatWLYOPFRcXh6effhrt2rVDVFQUvvrqK1y8eBHjx48HIIemLl26hOXLlwOQV3x99tlniIuLw3PPPYe9e/diyZIlWLFihfqYs2fPRrt27VCvXj0UFBRg/fr1WL58ucaVZoQyC6M2aiRLh924IYfC2rSxSpRERERmYXQP0EsvvYS8vDycOHECOTk5uH79Oo4fP468vDxMmjTJqGONGDEC8+fPx6xZs9C6dWv89ddfWL9+PUJDQwEAmZmZGmsChYeHY/369di+fTtat26Nd999FwsWLMDw4cPVbW7fvo0JEyagWbNm6Ny5M1avXo3vv/8e48aNM/atVm2qwqiAzl4gOzs5TQjgekBERFT1GL0OkKenJzZv3oz27dtr7D9w4ACio6Nx48YNU8ZnFVV+HSCV8eOBL7+UawJ9/LHW0zNnAu+8Azz9NPBvJxwREZHNMus6QEVFRTrn2zg6OqJIx5oyZMMMXBGaE6GJiKiqMToB6t27NyZPnozLly+r9126dAlTpkxBnz59TBocmZkqATp0SGdhVNUQ2JkzwFdfyYvGlErLhUdERGQuRidAn332GW7evImwsDDUq1cP9evXR3h4OG7evIlPP/3UHDGSuYSHA4GBegujbtsGOPw7Tf6FF4BevWR5jPh4y4ZJRERkakZfBRYSEoJDhw4hISEBp06dghACTZs2Rd++fc0RH5mTqjDq6tVyGKxYuZD4eOCRR4CSM8QuXZL7V68Ghg2zcLxEREQmYlQCVFhYCBcXFyQnJ6Nfv36llpegSqJ4AvQvpRKYPFk7+QHkPoUCiI0FhgwB7O0tFyoREZGpGDUE5uDggNDQUCg5EaTq0FEYdedO4O+/9b9ECCAjQ7YjIiKqjKxWDZ5sROvWQI0aDwqjAsjMNOylhrYjIiKyNVarBk82wtER6NBBXuK1axfQtCkCAw17qaHtiIiIbI3Vq8GTDSheGPX559GtGxAcLCc861sms3ZtoFs3i0ZJRERkMkZPggaAsWPHIiQkxCwBkRWUWBDR3h745BN5tZdCoTsJunlTLh9UYkFwIiKiSsHoSdAfffQRJ0FXNarCqOfOycKokJe4r14N1Kmj2TQ4GGjaVK6bGB0NJCdbPlwiIqKKMnoSdJ8+fbB9+3YzhEJW4+UFNG8u7xe7HH7YMCA9XS6I+OOP8jY9XZbGiIqSleL79gWOH7dCzERERBVg9BygAQMGYNq0aTh+/DgiIyO1JkEPHjzYZMGRBXXpAhw7JhOgYisc2tsDPXtqNq1ZE9iwQSY/iYlAnz7Ajh1A48aWDZmIiKi8jK4Gb2env9NIoVBUieGxalMNvrjvv5dl3zt2NLj6aU6OTH6Sk4GgIJkE1a9v3jCJiIj0MXs1eH1bVUh+qq0yCqPq4uMDJCQAzZoBly8DvXvLITIiIiJbZ3QCRFVUWFiphVH18fMDtmwBGjWSq0P37i1viYiIbJnBCdDAgQORm5urfvzee+/hxo0b6sfXrl1D06ZNTRocWZCqMCogF0Q0gr+/TILq1QPS0uSwGFeJJiIiW2ZwArRx40bk5+erH8+ZM0ejHEZhYSFSU1NNGx1ZVon1gIxRpw6wdSsQGgqcOSOToOxsE8dHRERkIgYnQCXnShs5d5oqAx2FUY1Rt65MgoKDgZQUeZXYtWsmjpGIiMgEOAeIHlAVRr1xQ2Yw5RARIZOggAB5VX10tDwcERGRLTE4AVIoFFAoFFr7qApxdJSXwQPlGgZTadBAzgmqVUteVNa/P5CXZ6IYiYiITMDghRCFEBgzZgycnZ0BAPfu3cP48ePVCyEWnx9ElViXLnLJ538Lo5ZX06bA5s1Ar17A/v3AQw/JxRPd3U0YKxERUTkZnACNHj1a4/FTTz2l1WbUqFEVj4isqwIToUtq2VKuE9S7t7ywbPBgYN06OcpGRERkTUavBF0dVMuVoFVycwFvb1kCPitLXuNeQfv3A/36yQry0dHAb78BLi4miJWIiKgYs64ETVWcp6fOwqgV0bEjsH494OYGbNoEPPooUFBgkkMTERGVCxMg0mbCYTCVrl2B33+XPT/r1gFPPCEXnSYiIrIGJkCkrZwrQpelVy85/OXkBMTHA6NGASwfR0RE1sAEiLQVL4x6545JDx0dDaxZI6+4X7kSGDu2XGsuEhERVQgTINKmKoxaWGhUYVRD/ec/wKpVgL09sHw58MILTIKIiMiymACRNoVCTtoBTDoPqLiHHwZ++AGwswO+/hqYNEleeEZERGQJTIBINzNMhC5pxAjgm29kvvX558DUqUyCiIjIMpgAkW4VLIxqqKefBr76St7/3/+A6dOZBBERkfkxASLdWrWqcGFUQ40bB3z2mbw/ezYwa5ZZT0dERMQEiPQwUWFUQ02cKHuAAGDmTOCDD8x+SiIiqsaYAJF+FpgHVNyUKbIHCACmTQPmzbPIaYmIqBpiAkT6qRKghARgxQpg+3azr1z4+uuyBwgA4uKAhQvNejoiIqqmmACRfleuyNvMTODJJ+VSzmFhchlnM3r7bZkIAXJo7OuvzXo6IiKqhpgAkW7x8cDo0dr7L10CHnnErEmQQgG8/74cEgOA558HvvvObKcjIqJqiAkQaVMqgcmTdV+PrtoXG2vW4TCFAvj4Y9kDJAQwZoxcPZqIiMgUmACRtp07gb//1v+8EEBGhmxnRgoFsGCBvEy+qAgYORL45ReznpKIiKoJJkCkLTPTtO0qwM4O+PJLuWCiUilXj163zuynJSKiKo4JEGkLDDRtuwqyswOWLpXJz/37wPDhwKZNFjk1ERFVUUyASFu3bkBwsByD0ic4WLazEAcHORH64YeBggJgyBB5VT4REVF5MAEibfb2wCefyPv6kqDgYLOvCVSSoyOwciXwn/8A9+7JWwut0UhERFUMEyDSbdgwYPVqoE4dzf1+frI7Zt8+2R1z755Fw3JyAn7+GYiOBm7fBgYMAPbvt2gIRERUBTABIv2GDQPS04Ft24Aff5S3WVnAH38Arq7A+vWyG+b2bYuG5eIirwbr1Qu4eROIiQEOHbJoCEREVMkphNC12Ev1lpeXB09PT+Tm5sLDw8Pa4dimv/4CHnoIuHVLlsz44w/A09OiIdy6BfTvL4fBfHzknKAWLSwaAhER2RBjPr/ZA0Tl0707sHkz4OUlM5C+fYGcHIuG4O4uO6E6dpSn7tMHSEmRU5O2b7dY+TIiIqqE2AOkA3uAjJCcDPTrB1y9KrtfNm8Gate2aAg3bsjk59AhmY+5uMiROpXgYDmne9gwi4ZlFKVSriuZmSlXF+jWTc5FJyIiw7EHiCyndWtgxw4gIAA4dkz2DF26ZNEQvLzkukB168pkqHjyA1ikfFmFxMfLGrO9elm05iwRUbXGBIgqrmlTOScoJARITZVJUHq6RUPw8pKLJOpiofJl5RIfL5OzkpVHbD1pIyKq7DgEpgOHwMrpwgU5FnXunBx32rIFaNjQIqfevl32nJTFwwNwc5OX0zs6PtiKPzbkvileY28vL6L75x/dsSoU8suYlsbhMCIiQxjz+e1goZj0WrhwIT788ENkZmaiWbNmmD9/PrqVssLwjh07EBcXhxMnTiAoKAivvvoqxo8fr35+8eLFWL58OY4fPw4AiIyMxPvvv48OHTqY/b1Ue6Ghsieob185G1k1Ubp5c7Of2tCyZHl5cqsMitec7dnT2tEQEVUtVk2AVq1ahdjYWCxcuBBdunTBl19+iQEDBuDkyZOoW7euVvu0tDQMHDgQzz33HL7//nvs3r0bEyZMQK1atTB8+HAAwPbt2/HEE0+gc+fOcHFxwdy5cxEdHY0TJ06gTslF/cj0goJkd0x0NHDkiPzk3rQJaNvWrKc1tCzZ0qVAmzaynMb9+3Iz9n55XqPr9bm5cs5SWZ54Qq440LWrnBwdEVF6lRIiIiqbVYfAOnbsiLZt22LRokXqfU2aNMHQoUMxe/ZsrfavvfYa1q5di5SUFPW+8ePH48iRI9i7d6/OcyiVSnh7e+Ozzz7DqFGjDIqLQ2AmkJMjF+k5eFCuD7RhAxAVZbbTKZVy4vClSw/m/BRni8NJhg7blRQY+CAZ6toVaNnSdt4TEZE1VYqrwAoKCpCUlITo6GiN/dHR0dizZ4/O1+zdu1erfUxMDBITE3FfzwzYO3fu4P79+/Dx8dEbS35+PvLy8jQ2qiAfHzn81a2b7Oro18+s1UtLK1+mejx/vm0lCmXVnFUoZCWSX38FXn0V6NxZzh3KzJTlQCZNkh1r3t4y13zvPXlB3t27Fn0bRESVktUSoKtXr0KpVMLf319jv7+/P7JKXsf8r6ysLJ3tCwsLcfXqVZ2vef3111GnTh307dtXbyyzZ8+Gp6enegsJCTHy3ZBOHh6y56dfvweFu/7802yn01e+LDhY7re1dYAMSdoWLJCV7+fMketN5ubKJOe//5VJT82ashzIxo3Am2/KEUdPT7k492uvAevWAdevW/RtERFVCla/DF5R4i+/EEJrX1ntde0HgLlz52LFihWIj4+Hi4uL3mNOmzYNubm56i0jI8OYt0ClcXMD1q59UMJ98GDZpWEmusqXpaXZXvKjYmzS5uoq55ZPny5zy+vX5QKQCxYAjz4ql2O6fx/YsweYOxcYNEh2xrVoAUyYIL8m/PEmIrLiJGg/Pz/Y29tr9fZkZ2dr9fKoBAQE6Gzv4OAAX19fjf0fffQR3n//fWzevBktW7YsNRZnZ2c4OzuX412QQVxcgDVrgKeekmM3jzwCfP898PjjZjmdvX3lumpq2DDZy1OelaDt7eWk7jZtgJdekvOfzp8Hdu2Sx9u5Ezh9Gjh+XG6q6XZ168pzqOYRNWkC2Fn93yEiIsuxWgLk5OSEyMhIJCQk4OGHH1bvT0hIwJAhQ3S+JioqCr///rvGvk2bNqFdu3ZwdHRU7/vwww/x3//+Fxs3bkS7du3M8wbIOE5OsvvBxQX47ju55PHdu8Azz1g7MptgqqRNoQDq1ZPb6NFyX3a2TIhUSdHhw8DFi8APP8gNkL1EXbo8SIgiI+W3rDQs30FElZqwopUrVwpHR0exZMkScfLkSREbGyvc3NxEenq6EEKI119/XTz99NPq9ufPnxc1atQQU6ZMESdPnhRLliwRjo6OYvXq1eo2c+bMEU5OTmL16tUiMzNTvd28edPguHJzcwUAkZuba7o3S5JSKcQLLwghOyuE+Owza0dU7dy8KURCghAzZgjRu7cQNWo8+HaoNldXIXr2FOLNN4XYuFGIvDzNY6xZI0RwsOZrgoPlfiIiazHm89uqCZAQQnz++eciNDRUODk5ibZt24odO3aonxs9erTo0aOHRvvt27eLNm3aCCcnJxEWFiYWLVqk8XxoaKgAoLXNmDHD4JiYAJlZUZEQU6Y8+OScO9faEVVrBQVC7N8vxEcfCTF0qBB+ftoJkZ2dEG3bCjFpkhBTpwqhUGi3USjkxiTItAoLhdi2TYgff5S3hYXWjojIdhnz+c1SGDpwHSALEAJ46y157TYAzJwJvP02V/izAULIkm47dz4YNktLM+y1trjeUmUWHw9MnqxZKy44WF49aKsT+4nKYs7hc2M+v5kA6cAEyILef19e0gTIxW4++IBJkA26dEkmQytXGnYRX4MGsgJK3bqyQorqNjQU8PPjt9gQqkK5Jf9Cq752tri0A1FZzJ3UMwGqICZAFjZ/PjBlirz/4ovyN4GXJNmkFSvk/PWKcHWVCVHxpKh4ohQcLBd8NIfKMnFbtbJ58Q+J4tjTRpWRJZJ6JkAVxATICr76Chg/Xv5mjB0rH/Mvu80xtHzH++/LdTAvXgQuXHhwm5mpu1RJcQqFLCmnKzlS3Zbn19Law0lCAHfuyLWbbtyQt/q2s2eBffvKPuaWLUDv3mYPnWwYk3pNTIAqiAmQlXz3HTBmDFBUJCuAfvut+boCqFwqWnOtoED+ASyeFBW/f/EikJ9fdhxeXvqTo9BQwN9fsxPRVP95CgHcuqU7aSkrqbl+XS5SaUpubnLZgo4dgU6dgA4dgBJLolEVZu2kXqWoCMjLkyUgc3Lkz7rqvmo7cUKuWF+WbdsqtiQIE6AKYgJkRT//LMdYCguBhx+WYy5cpNKmqJIJQDOhMEU3thBy3SJ9ydGFC/KPaVmcnICQEJkMBQfLeUullfjz9ZW9Vrm5pSc0N27IH82KsLeX9dtK2/75B/joo/Idv0EDmRCpkqKWLcte04kqH3MMJ92//yB50ZXE6Etwrl+XSZAp/Pij/P+3vJgAVRATICtbt07+Zufny4JX8fFy4gjZDF3/eYaEyOlc5v7P89Yt7aSo+P1Ll0z3x1gfJyeZqHh5lZ3MlNzc3MqeBG5IT1udOvL7cPAgsH+/HDI7fVq7rbOzXNhSlRB17Ch7yjgRXVtVGk4KDAT++EMm9YYmMjdvViyuGjXkoqqqzdv7wf0bN4DFi8s+BnuArIwJkA3YvFnWh7hzR046WbsWcHe3dlRUjK1+WBQWysRBlRCtXSs7FsvSurW8cs2QJMbV1fwJRHl62nJygAMHZEKkSop0FcP193+QDHXqBLRrJwvrVme2Mpx0757srczLk8lLyfu5ubKszcqV5ovBy0t/IlNyUz3n7S0X+tenosPnhmICVEFMgGzEzp3AQw/Jf0uiooD16+VvJpERDJ24XdH/PM2hoj1tQjyYUK1KiI4c0R7Gs7MDmjXTHDpr0sQ2ElpLMMVw0v37ZScuhuwrKDDd+/LwkBcUlJXEFH/ey8t833dzDp+rMAGqICZANuTAASAmRvaftm0LbNrEWZ5kFEv952kupu5pu3tX1oMrnhRdvKjdzt1dTqpWJUUdOwIBAdaJ2ZyUSjlX7NIl/W08PIBRo+T/YvqSmLt3TRtXzZryvJ6emrceHvJ8hvRqVsWkvixMgCqICZCNOXIE6NcPuHJFjlEkJBj+l5gIlvnPszLLynqQDO3fL//vuH1bu11oqObQWZs22sMe1hhKEkLGW9bVeLqeu3bNtFfn1aihP3EpbV/x+zVrlr4UGpN6/ZgAVRATIBuUkgL07Qtcvgw0bCgXQAkOtnZUVIlYc+J2ZaNUAidPPkiI9u+XlzGX/LRwdARatXqQFOXmAi+9VL6hJCFkz0Z5kpgbN0y/xEBJQ4bIkfiykhgHB/PGocKkXjcmQBXEBMhGnTsH9OkjZ7aGhckkKCLC2lFRJVKZhmZsTV4ekJioOXSWnW3cMWrWBEaMkIlSyUTmxo2KX73n4FD65HVdV+2dOmXYZdfVcTipMmICVEFMgGzYxYsyCTp7Vl4HvGUL0KiRtaMiqnaEkP+LqJKhTZtkr1FFubiUvcSAvudq1DD+6jwOJ1UtTIAqiAmQjcvMlMNhJ08CtWvLS+ZbtLB2VETVmqF14h55BOjeXX8iU9ql1ObC4aSqw5jPbwuNVhKZUGCgvLY5OhpITpb90hs3ysVMiMgqAgMNazdxou0NJQ0bJpMcXZO3q/NwUlXHHiAd2ANUSVy/DgwYIPvgPTzkOkFdulg7KqJqqbIPJQEcTqoKjPn8LuVCOyIb5+0tL4nv3l3O0IyOBrZulX/Ftm+XffLbt8vHRGRW9vbyUndAex6O6vH8+badUNjby96pJ56Qt7YcK1UcEyCq3GrWBDZskMnPnTty0cSAALn075NPytuwMDnIT0RmpRpKqlNHc39wMOfRkO3hEJgOHAKrhPLzga5d5XW6JXEmI5FFcSiJrIWToKn6cXCQf211EUImQbGxcjUz/iUmMivVUBKRLeMQGFUNO3eWXsxHCCAjQ5ZQZqcnEVG1xwSIqgZ9vT8lPfWULI/82GPAggWyKiQnSRMRVTscAqOqwdBFSBwcZOXHn39+UE7ZwwPo3FlOVOjWDWjf3jqrsRERkcVwErQOnARdCRm6CElKCpCUJIfMdu0Cdu8Gbt7UbOvkJJMgVULUubNcspaIiGwaS2FUEBOgSqo869krlcDRozIhUm3//KPZRqEAWrZ8kBB17SqH0YiIyKYwAaogJkCVWEXLIwshC63u2vUgITp7VrtdRMSDhKhbN6BBA+OrMBIRkUkxAaogJkCVnKkXIcnMlAmRKik6cgQoKtJsU7u27BlSJUStWsn5RtaKmYioGmICVEFMgKhUubnA3r0PeogOHJALMRbn7q45sbpDB8DVVffxdPVaBQfLugJcuJGIyGBMgCqICRAZJT9frkCtSoh275ZJUnGOjrJavSoh6tJF1jJTzVsq+WvI1auJiIzGBKiCmABRhSiVwPHjD64027kTuHxZs41CATRrJktj376t+ziVoXw2EZENYQJUQUyAyKSEkEmMqodo1y4gNdXw12/bxroCREQGMObzmytBE5mbQiGvGhs9Gvj6a+DUKXmpfWysYa/ftg24f9+sIRIRVTdMgIisoXZtWZjVELNmAb6+wMMPA198IXuTiIioQjgEpgOHwMgiylq9GgBq1JBXj127prm/QQMgJkZuPXvKq86IiKo5DoERVQb29vJSd0B7EUWFQm7ffQdkZwMHDwL//a+8gszBAThzBvjsM2DQIMDHB+jdG5gzB0hOZrV7IiIDsAdIB/YAkUUZu3p1Xh6wdSuwcaPcSg6J+fsD0dGyd6hfPzncRkRUDfAqsApiAkQWV96VoFWlO1TJ0LZt2pfVt237YLgsKkoWeyUiqoKYAFUQEyCqtPLzgT17HiREycmaz7u7y+EyVUJUr55VwiQiMgcmQBXEBIiqjKwsICFBJkObNgFXrmg+X6/eg2SoVy+gZk3rxElEZAJMgCqICRBVSUVFskdI1Tu0ezdQWPjgeUdHWb9MlRC1bg3YlXKdBAu4EpGNYQJUQUyAqFq4eVPOGVIlROfOaT5fu7acRB0TIydV+/s/eI4FXInIBjEBqiAmQFQtlZxMfeuW5vOtW8tkyNUVeOcdFnAlIpvDBKiCmABRtVdQoDmZ+vBhw17HAq5EZEVcCJGIKsbJSa4wPXs2cOiQnEz93XdA376lv04IICNDluwo2YNERGRD2AOkA3uAiPRYsQJ48knD2ioUQP36QKtWcmvdWt4GB2uvfE1EZALGfH47WCgmIqoKAgMNa+fjA+TkyJIdZ87IeUHFn1MlRarEqGlTLtBIRBbFHiAd2ANEpEdZBVyLzwHKyQGOHJGX3qtuT53SvPRexcFBJkEle4v8/Mz7foioSuEk6ApiAkRUivh44JFH5P3ifz4MuQosPx84efJBUqRKjG7c0N0+KOhBMqS6rV+//BOsuXYRUZXGBKiCmAARlcHYAq6lUU2cLpkUlVyXSKVGDaBFC83eohYtyl7FmmsXEVV5TIAqiAkQkQHM3Zty8yZw7JhmYnT0KHD3ru72uiZch4TInilVrxXXLiKq0pgAVRATICIbpVTKBRtL9hZdvqy7vbc30LIlkJSk/7J8rl1EVGUwAaogJkBElczVq9oTrlNSdE+41uf994EBA4A6deTka16qT1TpVKqFEBcuXIjw8HC4uLggMjISO3fuLLX9jh07EBkZCRcXF0REROCLL77QeP7EiRMYPnw4wsLCoFAoMH/+fDNGT0Q2wc8P6NMHePllYPlyOVR265ZcwfqFFww7xhtvAG3ayBpoLi5ARIQc1nv8cXncefOAn36SRWTT0+Vq2ZagVALbt8s1mLZvl4+JqMKsug7QqlWrEBsbi4ULF6JLly748ssvMWDAAJw8eRJ169bVap+WloaBAwfiueeew/fff4/du3djwoQJqFWrFoYPHw4AuHPnDiIiIvDoo49iypQpln5LRGQrnJ3lXKDHHwe+/LLs9g0aALm5QHa2TG7S0uRWmtq1ZY9RnTpyGE3XfQ+P8vcmceI2kdlYdQisY8eOaNu2LRYtWqTe16RJEwwdOhSzZ8/Wav/aa69h7dq1SElJUe8bP348jhw5gr1792q1DwsLQ2xsLGJjY42Ki0NgRFWIMWsX2dvL5CczU7b/+295W/L+pUuG9wC5uWkmRCUTpDp1AH9/7flHnLhNZLRKsRJ0QUEBkpKS8Prrr2vsj46Oxp49e3S+Zu/evYiOjtbYFxMTgyVLluD+/ftwdHQsVyz5+fnIz89XP87LyyvXcYjIBtnbyx6TRx6RyYOutYvmz3+QgDg5AaGhctNHCDnvqHhCpCtZunEDuH0bSE2VW2kxBgY+SIiCgmTtNV0JmxAy7thYYMgQTtwmKierJUBXr16FUqmEv7+/xn5/f39kZWXpfE1WVpbO9oWFhbh69SoCDV2mv4TZs2fjnXfeKddriagSGDZM9pjoGk4qz9pFCgVQq5bcWrfW3+72bXmFWsneo+KPMzNlL9Xff2vGVhrV2kkLFsghvoAATtomMpLVa4EpSvzSCiG09pXVXtd+Y0ybNg1xcXHqx3l5eQgJCSn38YjIBg0bJntMLLkStJubnFvUoIH+NoWFwD//aCZHCQnA77+Xffy4OLl5eACNG2tv9eqxxhqRHlZLgPz8/GBvb6/V25Odna3Vy6MSEBCgs72DgwN8fX3LHYuzszOcnZ3L/XoiqiTs7YGePa0dhSYHhwdDXyotWhiWAAUFAVlZQF4ecOCA3Iqzt5dJUMnEqFEjWZSWqBqzWgLk5OSEyMhIJCQk4OGHH1bvT0hIwJAhQ3S+JioqCr+X+KOwadMmtGvXrtzzf4iIbE63bnJ4zpCJ24WFcnHIU6e0t1u3gNOn5bZ2reYxatXS3WsUGlrxXjHWXKNKwKpDYHFxcXj66afRrl07REVF4auvvsLFixcxfvx4AHJo6tKlS1i+fDkAecXXZ599hri4ODz33HPYu3cvlixZghUrVqiPWVBQgJMnT6rvX7p0CcnJyXB3d0f9+vUt/yaJiIxlzMRte3ugWTO5FSeEnH+UmqqdGGVkAFeuyK3k2mvOzkDDhtqJUcOGgLt72bHz0n2qJKy+EvTChQsxd+5cZGZmonnz5pg3bx66d+8OABgzZgzS09Oxfft2dfsdO3ZgypQpOHHiBIKCgvDaa6+pEyYASE9PR3h4uNZ5evTooXGc0vAyeCKyCaYsOlucqmeoZGJ0+jRQ7IpYLSEhunuNAgNZc41sAkthVBATICKyGZYcTlIqgQsXdA+nXbmi/3U1a8oeopQU4M4d3W1Yc40sgAlQBTEBIiIq4do1zeE01f1z54wrz9G/v5zk7eene/PyAuysVKWJc5cqPSZAFcQEiIjIQAUFMglavFjWS6soOzvA11cmQ6rbsraKlBtR4dylKoEJUAUxASIiMtL27UCvXmW3GzdOJixXr2pv5V2F38HBuITJz0+u0aRKmjh3qcpgAlRBTICIiIxkbM01XQoK5FCbKiEqfl/fdvt2+eJ1cnqQNJU1+TswEDh+HPD2tr0Vtzlsp6FS1AIjIqIqxNiaa7o4OckPcWPKGt29+yBRMiRhunJFJjsFBXKZgMuXyz5HZqZMlBwc5AKSvr4Pbg3ZzLUaN4ftKoQ9QDqwB4iIqJzMdem+qQghr1RTJUSrVwMffGDec7q7G54sqbay5jVx2E4nDoFVEBMgIqIKqEzDMobOXfrzT6B5c9nLZOiWk6N7ONAQxXubSm7e3sCHHwLXr+t+ra0vOWDGnw8mQBXEBIiIqJowxdwlfYqKgBs3jEuarl2Tw3qm0Lw5EB4uEyZvb5lQqe7r2meJwrlmHrZjAlRBTICIiKoR1XASoHvukqWHk1TzmvRtiYnaJUxMoUYN3YlSWYmTt7fssSqLBYbtmABVEBMgIqJqxtbnLhVn6LDdzJlAUJAcKsvJkbeqrfjj3NzyD9WpuLuXnjh5egJvvy3Pq4uJhu2YAFUQEyAiomqossxdMvWwnVIp12AqmSTpSpxK7ivv2k36bNsG9OxZ7pfzMngiIiJj2dtX6MPXYkyx5EDJ46l6aoxVWCjnOZWVOB09KofuypKZaXwM5cQEiIiIqLIZNkzOmdE1odiSw3aqVbj9/EpvZ+iwnTFrQFUQh8B04BAYERFVCtV12E4PDoERERFVB9V12M4E7Cx2JiIiIqq+VMN2depo7g8OtsrK1ewBIiIiIssYNgwYMsQmhu2YABEREZHl2MiwHYfAiIiIqNphAkRERETVDhMgIiIiqnaYABEREVG1wwSIiIiIqh0mQERERFTtMAEiIiKiaocJEBEREVU7TICIiIio2uFK0DqIf4u05eXlWTkSIiIiMpTqc1voqjhfAhMgHW7evAkACAkJsXIkREREZKybN2/C09Oz1DYKYUiaVM0UFRXh8uXLqFmzJhQKhUmPnZeXh5CQEGRkZMDDw8OkxzYXxmwZjNkyGLNlVMaYgcoZN2N+QAiBmzdvIigoCHZ2pc/yYQ+QDnZ2dggODjbrOTw8PCrND6oKY7YMxmwZjNkyKmPMQOWMmzFLZfX8qHASNBEREVU7TICIiIio2mECZGHOzs6YMWMGnJ2drR2KwRizZTBmy2DMllEZYwYqZ9yMuXw4CZqIiIiqHfYAERERUbXDBIiIiIiqHSZAREREVO0wASIiIqJqhwmQhfz1118YNGgQgoKCoFAo8Ouvv1o7pDItWrQILVu2VC9UFRUVhQ0bNlg7rFLNnDkTCoVCYwsICLB2WKUKCwvTilmhUGDixInWDq1UN2/eRGxsLEJDQ+Hq6orOnTvj4MGD1g5Lrazfufj4eMTExMDPzw8KhQLJyclWibO4smKeOXMmGjduDDc3N3h7e6Nv377Yv3+/dYL9V1kxjxkzRutnu1OnTtYJ9l9lxazr91GhUODDDz+0TsAoO+Z//vkHY8aMQVBQEGrUqIH+/fvjzJkz1gn2X7Nnz0b79u1Rs2ZN1K5dG0OHDkVqaqpGG2v+HjIBspDbt2+jVatW+Oyzz6wdisGCg4PxwQcfIDExEYmJiejduzeGDBmCEydOWDu0UjVr1gyZmZnq7dixY9YOqVQHDx7UiDchIQEA8Oijj1o5stKNGzcOCQkJ+O6773Ds2DFER0ejb9++uHTpkrVDA1D279zt27fRpUsXfPDBBxaOTL+yYm7YsCE+++wzHDt2DLt27UJYWBiio6Nx5coVC0f6gCF/2/r376/xM75+/XoLRqitrJiLx5qZmYmlS5dCoVBg+PDhFo70gdJiFkJg6NChOH/+PH777TccPnwYoaGh6Nu3L27fvm2FaKUdO3Zg4sSJ2LdvHxISElBYWIjo6GiNmKz6eyjI4gCIX375xdphlIu3t7f4+uuvrR2GXjNmzBCtWrWydhgVMnnyZFGvXj1RVFRk7VD0unPnjrC3txfr1q3T2N+qVSsxffp0K0WlX2m/c2lpaQKAOHz4sEVjKoshfydyc3MFALF582bLBFUGXTGPHj1aDBkyxCrxGMKQr/OQIUNE7969LROQAUrGnJqaKgCI48ePq/cVFhYKHx8fsXjxYitEqFt2drYAIHbs2KH1nDV+D9kDRAZRKpVYuXIlbt++jaioKGuHU6ozZ84gKCgI4eHhePzxx3H+/Hlrh2SwgoICfP/99xg7dqzJC/GaUmFhIZRKJVxcXDT2u7q6YteuXVaKqnopKCjAV199BU9PT7Rq1cra4ZRq+/btqF27Nho2bIjnnnsO2dnZ1g7JYP/88w/++OMPPPvss9YORa/8/HwA0Ph9tLe3h5OTk039Pubm5gIAfHx8rByJxASISnXs2DG4u7vD2dkZ48ePxy+//IKmTZtaOyy9OnbsiOXLl2Pjxo1YvHgxsrKy0LlzZ1y7ds3aoRnk119/xY0bNzBmzBhrh1KqmjVrIioqCu+++y4uX74MpVKJ77//Hvv370dmZqa1w6vS1q1bB3d3d7i4uGDevHlISEiAn5+ftcPSa8CAAfjhhx+wdetWfPzxxzh48CB69+6t/tC2dd9++y1q1qyJYcOGWTsUvRo3bozQ0FBMmzYN169fR0FBAT744ANkZWXZzO+jEAJxcXHo2rUrmjdvbu1wADABojI0atQIycnJ2LdvH/7v//4Po0ePxsmTJ60dll4DBgzA8OHD0aJFC/Tt2xd//PEHAPlHrDJYsmQJBgwYgKCgIGuHUqbvvvsOQgjUqVMHzs7OWLBgAZ588knY29tbO7QqrVevXkhOTsaePXvQv39/PPbYYzbdozJixAg89NBDaN68OQYNGoQNGzbg9OnT6t9NW7d06VKMHDlSq7fTljg6OmLNmjU4ffo0fHx8UKNGDWzfvh0DBgywmd/HF198EUePHsWKFSusHYoaEyAqlZOTE+rXr4927dph9uzZaNWqFT755BNrh2UwNzc3tGjRwupXQxjiwoUL2Lx5M8aNG2ftUAxSr1497NixA7du3UJGRgYOHDiA+/fvIzw83NqhVWlubm6oX78+OnXqhCVLlsDBwQFLliyxdlgGCwwMRGhoaKX4ndy5cydSU1Mrxe9kZGQkkpOTcePGDWRmZuLPP//EtWvXbOL38aWXXsLatWuxbds2BAcHWzscNSZAZBQhRKXpugbk2HhKSgoCAwOtHUqZli1bhtq1a+Ohhx6ydihGcXNzQ2BgIK5fv46NGzdiyJAh1g6pWqlsv5PXrl1DRkZGpfidXLJkCSIjI21+jlVxnp6eqFWrFs6cOYPExESr/j4KIfDiiy8iPj4eW7dutYlkrDgHawdQXdy6dQtnz55VP05LS0NycjJ8fHxQt25dK0am3xtvvIEBAwYgJCQEN2/exMqVK7F9+3b8+eef1g5Nr6lTp2LQoEGoW7cusrOz8d///hd5eXkYPXq0tUMrVVFREZYtW4bRo0fDwaFy/Fpu3LgRQgg0atQIZ8+exSuvvIJGjRrhmWeesXZoAMr+ncvJycHFixdx+fJlAFCvTxIQEGC1taNKi9nX1xfvvfceBg8ejMDAQFy7dg0LFy7E33//bdUlE0qL2cfHBzNnzsTw4cMRGBiI9PR0vPHGG/Dz88PDDz9skzGr/h7n5eXh559/xscff2ytMDWUFfPPP/+MWrVqoW7dujh27BgmT56MoUOHIjo62moxT5w4ET/++CN+++031KxZE1lZWQBkkubq6goA1v09tNj1ZtXctm3bBACtbfTo0dYOTa+xY8eK0NBQ4eTkJGrVqiX69OkjNm3aZO2wSjVixAgRGBgoHB0dRVBQkBg2bJg4ceKEtcMq08aNGwUAkZqaau1QDLZq1SoREREhnJycREBAgJg4caK4ceOGtcNSK+t3btmyZTqfnzFjhk3GfPfuXfHwww+LoKAg4eTkJAIDA8XgwYPFgQMHrBZvWTHfuXNHREdHi1q1aglHR0dRt25dMXr0aHHx4kWbjVnlyy+/FK6urjbzM11WzJ988okIDg5Wf53ffPNNkZ+fb9WYdcULQCxbtkzdxpq/h4p/gyQiIiKqNjgHiIiIiKodJkBERERU7TABIiIiomqHCRARERFVO0yAiIiIqNphAkRERETVDhMgIiIiqnaYABEREVG1wwSIqBpKT0+HQqFAcnKytUNRO3XqFDp16gQXFxe0bt3a2uGQmYSFhWH+/PnWDoOICRCRNYwZMwYKhQIffPCBxv5ff/0VCoXCSlFZ14wZM+Dm5obU1FRs2bJFb7usrCy89NJLiIiIgLOzM0JCQjBo0CCN14SFhUGhUGDfvn0ar42NjUXPnj019uXk5CA2NhZhYWFwcnJCYGAgnnnmGVy8eFHdRqFQlLqNGTPGJF8DIrIcJkBEVuLi4oI5c+bg+vXr1g7FZAoKCsr92nPnzqFr164IDQ2Fr6+vzjbp6emIjIzE1q1bMXfuXBw7dgx//vknevXqhYkTJ2q0dXFxwWuvvVbqOXNyctCpUyds3rwZCxcuxNmzZ7Fq1SqcO3cO7du3x/nz5wEAmZmZ6m3+/Pnw8PDQ2PfJJ5+U+32bwv379w1qp1QqUVRUZOZoiCoHJkBEVtK3b18EBARg9uzZetvMnDlTazho/vz5CAsLUz8eM2YMhg4divfffx/+/v7w8vLCO++8g8LCQrzyyivw8fFBcHAwli5dqnX8U6dOoXPnznBxcUGzZs2wfft2jedPnjyJgQMHwt3dHf7+/nj66adx9epV9fM9e/bEiy++iLi4OPj5+aFfv34630dRURFmzZqF4OBgODs7o3Xr1vjzzz/VzysUCiQlJWHWrFlQKBSYOXOmzuNMmDABCoUCBw4cwCOPPIKGDRuiWbNmiIuL0+rteeGFF7Bv3z6sX79e57EAYPr06bh8+TI2b96MgQMHom7duujevTs2btwIR0dHdVKlqkwdEBAAT09PKBQK9eP8/Hw89dRT8Pb2hpubG5o1a1bqOcPCwvDuu+/iySefhLu7O4KCgvDpp59qtMnNzcXzzz+P2rVrw8PDA71798aRI0fUz6t+LpYuXaruCdNV1vGbb76Bl5cX1q1bh6ZNm8LZ2RkXLlzA9evXMWrUKHh7e6NGjRoYMGAAzpw5o3X84vT93H300UcIDAyEr68vJk6cqJGMZWdnY9CgQXB1dUV4eDh++OEHvV8XIktjAkRkJfb29nj//ffx6aef4u+//67QsbZu3YrLly/jr7/+wv/+9z/MnDkT//nPf+Dt7Y39+/dj/PjxGD9+PDIyMjRe98orr+Dll1/G4cOH0blzZwwePBjXrl0DIHs9evTogdatWyMxMRF//vkn/vnnHzz22GMax/j222/h4OCA3bt348svv9QZ3yeffIKPP/4YH330EY4ePYqYmBgMHjxY/aGbmZmJZs2a4eWXX0ZmZiamTp2qdYycnBz8+eefmDhxItzc3LSe9/Ly0ngcFhaG8ePHY9q0aTp7PYqKirBy5UqMHDkSAQEBGs+5urpiwoQJ2LhxI3JycnS+J5WJEyciPz8ff/31F44dO4Y5c+bA3d291Nd8+OGHaNmyJQ4dOoRp06ZhypQpSEhIAAAIIfDQQw8hKysL69evR1JSEtq2bYs+ffpoxHL27Fn89NNPWLNmTalzue7cuYPZs2fj66+/xokTJ1C7dm2MGTMGiYmJWLt2Lfbu3QshBAYOHGhwT5LKtm3bcO7cOWzbtg3ffvstvvnmG3zzzTfq58eMGYP09HRs3boVq1evxsKFC5GdnW3UOYjMxuz15olIy+jRo8WQIUOEEEJ06tRJjB07VgghxC+//CKK/1rOmDFDtGrVSuO18+bNE6GhoRrHCg0NFUqlUr2vUaNGolu3burHhYWFws3NTaxYsUIIIURaWpoAID744AN1m/v374vg4GAxZ84cIYQQb731loiOjtY4d0ZGhgAgUlNThRBC9OjRQ7Ru3brM9xsUFCTee+89jX3t27cXEyZMUD9u1aqVmDFjht5j7N+/XwAQ8fHxZZ4vNDRUzJs3T2RnZ4uaNWuK5cuXCyGEmDx5sujRo4cQQoisrCwBQMybN0/nMeLj4wUAsX//fo39y5YtE56enurHLVq0EDNnziwzpuKx9e/fX2PfiBEjxIABA4QQQmzZskV4eHiIe/fuabSpV6+e+PLLL4UQ8ufC0dFRZGdnl3quZcuWCQAiOTlZve/06dMCgNi9e7d639WrV4Wrq6v46aef1Mc39OeusLBQve/RRx8VI0aMEEIIkZqaKgCIffv2qZ9PSUkp9WtOZEnsASKysjlz5uDbb7/FyZMny32MZs2awc7uwa+zv78/WrRooX5sb28PX19frf++o6Ki1PcdHBzQrl07pKSkAACSkpKwbds2uLu7q7fGjRsDkPN1VNq1a1dqbHl5ebh8+TK6dOmisb9Lly7qcxlC/DvEY8wk8Vq1amHq1Kl4++23jZ6fZOj5Jk2ahP/+97/o0qULZsyYgaNHj5Z57OJfd9Xj4l/3W7duwdfXV+Nrn5aWpvF1Dw0NRa1atco8l5OTE1q2bKl+nJKSAgcHB3Ts2FG9z9fXF40aNTLq+wHInzt7e3v148DAQPXPmOo8xX8+GjdurNVTR2QtTICIrKx79+6IiYnBG2+8ofWcnZ2d1twOXcMUjo6OGo8VCoXOfYZMgFV94BcVFWHQoEFITk7W2M6cOYPu3bur2+sajirtuCpCCKOSmQYNGkChUBj9IR0XF4e7d+9i4cKFGvtr1aoFLy8vvYnnqVOnoFAoUK9evVKPP27cOJw/fx5PP/00jh07hnbt2mnN6TFE8a97YGCg1tc9NTUVr7zyirq9oV93V1dXja9zyZ+n4vtV7Sryc6f6GStPwkpkSUyAiGzABx98gN9//x179uzR2F+rVi1kZWVpfBiZcu2e4hOHCwsLkZSUpO7ladu2LU6cOIGwsDDUr19fYzP0wxcAPDw8EBQUhF27dmns37NnD5o0aWLwcXx8fBATE4PPP/8ct2/f1nr+xo0bOl/n7u6Ot956C++99x7y8vLU++3s7PDYY4/hxx9/RFZWlsZrVAlTTEwMfHx8yowtJCQE48ePR3x8PF5++WUsXry41PYlJ2zv27dP4+uelZUFBwcHra+7n59fmbGUpWnTpigsLMT+/fvV+65du4bTp0+rvx+m+Llr0qQJCgsLkZiYqN6Xmpqq9/tEZGlMgIhsQIsWLTBy5EitnoOePXviypUrmDt3Ls6dO4fPP/8cGzZsMNl5P//8c/zyyy84deoUJk6ciOvXr2Ps2LEA5OTenJwcPPHEEzhw4ADOnz+PTZs2YezYsVAqlUad55VXXsGcOXOwatUqpKam4vXXX0dycjImT55s1HEWLlwIpVKJDh06YM2aNThz5gxSUlKwYMECrWGl4p5//nl4enpixYoVGvvfe+89BAQEoF+/ftiwYQMyMjLw119/ISYmBvfv38fnn39eZkyxsbHYuHEj0tLScOjQIWzdurXMxG737t2YO3cuTp8+jc8//xw///yz+mvRt29fREVFYejQodi4cSPS09OxZ88evPnmmxrJRHk1aNAAQ4YMwXPPPYddu3bhyJEjeOqpp1CnTh0MGTIEgGl+7ho1aoT+/fvjueeew/79+5GUlIRx48bB1dW1wu+ByBSYABHZiHfffVdr2KFJkyZYuHAhPv/8c7Rq1QoHDhzQeYVUeX3wwQeYM2cOWrVqhZ07d+K3335T9zIEBQVh9+7dUCqViImJQfPmzTF58mR4enpqzDcyxKRJk/Dyyy/j5ZdfRosWLfDnn39i7dq1aNCggVHHCQ8Px6FDh9CrVy+8/PLLaN68Ofr164ctW7Zg0aJFel/n6OiId999F/fu3dPY7+fnh3379qFXr1544YUXEBERgcceewwRERE4ePAgIiIiyoxJqVRi4sSJaNKkCfr3749GjRppDbeV9PLLLyMpKQlt2rTBu+++i48//hgxMTEA5JDR+vXr0b17d4wdOxYNGzbE448/jvT0dPj7+xvwVSrbsmXLEBkZif/85z+IioqCEALr169XD2mZ6udu2bJlCAkJQY8ePTBs2DD1pf1EtkAh9A0IExGRyYWFhSE2NhaxsbHWDoWoWmMPEBEREVU7TICIiIio2uEQGBEREVU77AEiIiKiaocJEBEREVU7TICIiIio2mECRERERNUOEyAiIiKqdpgAERERUbXDBIiIiIiqHSZAREREVO38P6W4WBl+8zTVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_rounds = 3\n",
    "num_cxs_per_round = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
    "logical_errors = np.array([0.16, 0.202, 0.234, 0.292, 0.322, 0.35, 0.384, 0.393, 0.4171, 0.436, 0.4517])\n",
    "errors_per_rounds = .5*(1-(1-logical_errors/.5)**(1/(num_rounds*num_cxs_per_round)))\n",
    "errors_per_rounds_division = logical_errors / (num_rounds*num_cxs_per_round)\n",
    "plt.plot(num_cxs_per_round, errors_per_rounds, marker='o', color='blue', label='fancy formula')\n",
    "plt.plot(num_cxs_per_round, errors_per_rounds_division, marker='o', color='red', label='divide by # rounds')\n",
    "plt.ylabel('Error per CNOT')\n",
    "plt.xlabel('Number of CNOTs per round')\n",
    "plt.xticks(num_cxs_per_round)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 1\n",
      "final measurement_index = 146\n",
      "Preprocessing is done! it took 59.61s\n",
      "0 [0.025]\n",
      "infidelity 0.975\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_cxs = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
    "num_cxs = np.array([1])\n",
    "errors = np.array([0.16, 0.202, 0.234, 0.292, 0.322, 0.35, 0.384, 0.393, 0.4171, 0.429, 0.47])\n",
    "num_rounds = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "\n",
    "\n",
    "errors = []\n",
    "for num_cx in num_cxs:\n",
    "    noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                    'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                    'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                    'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                    'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                    'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                    'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "    Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                'bias_preserving_gates': 'False',\n",
    "                'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "                'ordering': gate_ordering,\n",
    "                'decoder': 'MLE',\n",
    "                'circuit_type': f'logical_CX_NL{num_rounds}_NCX{num_cx}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                'loss_decoder': 'independent',\n",
    "                'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "    # Load the experimental measurements\n",
    "    exp_measurements = np.load('2024_10_15_measurement_events_1CNOT_XX.npy')#[:100, :]\n",
    "    exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                       exp_measurements[:, 1, :distance**2-1],\n",
    "                                       exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                       exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                       exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "    # Load the theory circuit\n",
    "    # theory_measurements, theory_detectors, theory_observables, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1000, noise_params)\n",
    "    # print(2 in theory_measurements)\n",
    "    # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "    # exp_detectors, exp_observables = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "    # Find detection event signs\n",
    "    # exp_detection_events_signs = -np.sign(2*np.nanmean(exp_detectors.astype(int), axis=0)-1).astype(int)\n",
    "\n",
    "    # Now let's decode!\n",
    "    use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "    use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "    use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "    output_dir = '.'\n",
    "    simulate_data = True\n",
    "    num_shots = 1000\n",
    "    # DO IT\n",
    "    \"\"\"exp_predictions, exp_observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        exp_measurements,\n",
    "                                                                        exp_detection_events_signs, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params)\n",
    "    \n",
    "    exp_logical_probability = np.mean(np.logical_xor(exp_observable_flips, exp_predictions))\"\"\"\n",
    "\n",
    "    #print('infidelity', 1-exp_logical_probability)\n",
    "    theory_predictions, theory_observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                        None,\n",
    "                                                                        None, use_loss_decoding,\n",
    "                                                                        use_independent_decoder,\n",
    "                                                                        use_independent_and_first_comb_decoder,\n",
    "                                                                        simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                        noise_params=noise_params, num_shots = num_shots)\n",
    "\n",
    "    theory_logical_probability = np.mean(np.logical_xor(theory_observable_flips, theory_predictions))\n",
    "    errors.append(theory_logical_probability)\n",
    "    print(errors)\n",
    "    print('infidelity', 1-theory_logical_probability)\n",
    "\n",
    "\n",
    "plt.plot(num_cxs, errors, marker='o', color='blue')\n",
    "plt.ylabel('Error per CNOT')\n",
    "plt.xlabel('Number of CNOTs per round')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 1\n",
      "final measurement_index = 146\n",
      "Preprocessing is done! it took 60.88s\n",
      "0 1000 2000 3000 4000 for num_layers = 3, num_cxs_per_round = 1 we get logical error 0.0222 +- 0.002083610328252382\n",
      "\n",
      "num_layers = 3\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_10161/761206627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0muse_independent_and_first_comb_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/gefenbaranes/Documents/CX_experiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n\u001b[0m\u001b[1;32m     71\u001b[0m                                                                             \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                                                             \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, dx, dy, output_dir, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, first_comb_weight, noise_params, logical_gaps, num_shots)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogical_gaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 predictions, observable_flips, dems_list = simulator.count_logical_errors_experiment(num_shots = num_shots, dx = dx, dy = dy,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                         \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                                         \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, dx, dy, measurement_events, detection_events_signs, use_loss_decoding, use_independent_decoder, use_independent_and_first_comb_decoder, simulate_data, noise_params)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0mMLE_Loss_Decoder_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_loss_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this part can be improved to be a bit faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Decoder initialized, it took {time.time() - start_time:.2f}s for everything'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36minitialize_loss_decoder\u001b[0;34m(self, **kargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_filename_dems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Preprocessing is done! it took {time.time() - start_time:.2f}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mpreprocess_circuit\u001b[0;34m(self, full_filename)\u001b[0m\n\u001b[1;32m    884\u001b[0m                         \u001b[0;31m#     num_potential_losses += len(losses_indices_in_round)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m                         \u001b[0mhyperedges_matrix_dem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dem_loss_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_by_instruction_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_by_instruction_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# GB: change event prob to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m                         \u001b[0;31m# save into the file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_unique_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_by_instruction_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mgenerate_dem_loss_circuit\u001b[0;34m(self, losses_by_instruction_ix, event_probability, full_filename, remove_gates_due_to_loss)\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;31m# replace final observables with detectors:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m             \u001b[0mfinal_loss_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservables_to_detectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_circuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0;31m# get the dem (with observables on columns):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/MLE_Loss_Decoder.py\u001b[0m in \u001b[0;36mobservables_to_detectors\u001b[0;34m(self, circuit)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "# num_rounds = 5\n",
    "\n",
    "P_dict = {}\n",
    "P_err_dict = {}\n",
    "num_shots_dict = {}\n",
    "num_errors_dict = {}\n",
    "\n",
    "num_layers_vec = [3,2]\n",
    "num_cxs_per_round_vec = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "for num_layers in num_layers_vec:\n",
    "    num_shots_dict[num_layers] = {}\n",
    "    num_errors_dict[num_layers] = {}\n",
    "    P_dict[num_layers] = {}\n",
    "    P_err_dict[num_layers] = {}\n",
    "    for num_cxs_per_round in num_cxs_per_round_vec:\n",
    "        distance = 5\n",
    "        decoder_basis = 'XX'\n",
    "        gate_ordering = ['N', 'Z']\n",
    "        noise_params = {'idle_loss_rate': 2.793300220405646e-07, 'idle_error_rate': np.array([6.60547942e-09, 3.38336163e-08, 2.67533789e-07]),\n",
    "                        'entangling_zone_error_rate': np.array([3.66476387e-04, 6.14732819e-06, 2.35857048e-03]),\n",
    "                        'entangling_gate_error_rate': [2.2260729018707513e-05, 0.00017139584089578063, 0.0012948317242757047, 2.2260729018707513e-05, 0, 0, 0, 0.00017139584089578063, 0, 0, 0, 0.0012948317242757047, 0, 0, 0.002621736717313752],\n",
    "                        'entangling_gate_loss_rate': 0.00039272255674060926, 'single_qubit_error_rate': np.array([1.53681034e-05, 9.93583065e-04, 1.94650113e-05]),\n",
    "                        'reset_error_rate': 5.89409983290463e-05, 'measurement_error_rate': 0.0006138700821647161, 'reset_loss_rate': 0.0007531131027610011, 'measurement_loss_rate': 0.07131074481520218, 'ancilla_idle_loss_rate': 1.6989311035347498e-07,\n",
    "                        'ancilla_idle_error_rate': np.array([1.46727589e-07, 4.60893305e-08, 2.30298714e-06]), 'ancilla_reset_error_rate': 0.024549181355318986, 'ancilla_measurement_error_rate': 0.0012815874700447462, 'ancilla_reset_loss_rate': 0.00019528486460263086, 'ancilla_measurement_loss_rate': 0.00047357577582906143,\n",
    "                        'gate_noise': LogicalCircuit.ancilla_data_differentiated_gate_noise, 'idle_noise': LogicalCircuit.ancilla_data_differentiated_idle_noise}\n",
    "\n",
    "\n",
    "\n",
    "        Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "                    'bias_preserving_gates': 'False',\n",
    "                    'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "                    'SSR': 'True', 'cycles': str(num_layers - 1),\n",
    "                    'ordering': gate_ordering,\n",
    "                    'decoder': 'MLE',\n",
    "                    'circuit_type': f'logical_CX_NL{num_layers}_NCX{num_cxs_per_round}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "                    'loss_decoder': 'independent',\n",
    "                    'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        simulate_data = True\n",
    "\n",
    "        if simulate_data:\n",
    "            detection_events_signs = None\n",
    "            measurement_events = None\n",
    "            num_shots = 5000\n",
    "\n",
    "        else:\n",
    "            # Load the experimental measurements\n",
    "            exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "            exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                            exp_measurements[:, 1, :distance**2-1],\n",
    "                                            exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                            exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                            exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                            exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "            measurement_events = exp_measurements\n",
    "            # Load the theory circuit\n",
    "            _, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "            # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "            detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "            # Find detection event signs\n",
    "            detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "\n",
    "        # Now let's decode!\n",
    "        use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "        use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "        use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "        output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "        predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                            measurement_events,\n",
    "                                                                            detection_events_signs, use_loss_decoding,\n",
    "                                                                            use_independent_decoder,\n",
    "                                                                            use_independent_and_first_comb_decoder,\n",
    "                                                                            simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                            noise_params=noise_params, num_shots=num_shots)\n",
    "        logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "        num_errors = np.sum(np.logical_xor(observable_flips, predictions))\n",
    "        logical_probability_error = (np.sqrt(logical_probability*(1-logical_probability)/num_shots))\n",
    "        print(f'for num_layers = {num_layers}, num_cxs_per_round = {num_cxs_per_round} we get logical error {logical_probability} +- {logical_probability_error}\\n')\n",
    "\n",
    "        \n",
    "        P_dict[num_layers][num_cxs_per_round] = logical_probability\n",
    "        P_err_dict[num_layers][num_cxs_per_round] = logical_probability_error\n",
    "        num_shots_dict[num_layers][num_cxs_per_round] = num_shots\n",
    "        num_errors_dict[num_layers][num_cxs_per_round] = num_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogicalCircuit' object has no attribute 'Pauli_DEM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_68890/1495820122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauli_DEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogicalCircuit' object has no attribute 'Pauli_DEM'"
     ]
    }
   ],
   "source": [
    "print(circuit.Pauli_DEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare theory to exp detection signs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_circuit_txt = \"\"\"\n",
    "    \n",
    "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
    "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 11 31\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 17 19 21 27 29 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 17 37\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 60 80\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 66 68 70 76 78 86 88 90 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 66 86\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 17 19 21 27 29 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-22]\n",
    "DETECTOR rec[-44] rec[-20]\n",
    "DETECTOR rec[-42] rec[-18]\n",
    "DETECTOR rec[-41] rec[-17]\n",
    "DETECTOR rec[-39] rec[-15]\n",
    "DETECTOR rec[-37] rec[-13]\n",
    "DETECTOR rec[-36] rec[-12]\n",
    "DETECTOR rec[-34] rec[-10]\n",
    "DETECTOR rec[-32] rec[-8]\n",
    "DETECTOR rec[-31] rec[-7]\n",
    "DETECTOR rec[-29] rec[-5]\n",
    "DETECTOR rec[-27] rec[-3]\n",
    "DETECTOR rec[-48] rec[-24]\n",
    "DETECTOR rec[-47] rec[-23]\n",
    "DETECTOR rec[-45] rec[-21]\n",
    "DETECTOR rec[-43] rec[-19]\n",
    "DETECTOR rec[-40] rec[-16]\n",
    "DETECTOR rec[-38] rec[-14]\n",
    "DETECTOR rec[-35] rec[-11]\n",
    "DETECTOR rec[-33] rec[-9]\n",
    "DETECTOR rec[-30] rec[-6]\n",
    "DETECTOR rec[-28] rec[-4]\n",
    "DETECTOR rec[-26] rec[-2]\n",
    "DETECTOR rec[-25] rec[-1]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 0 1\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 47 48\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 49 50\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 60 66 68 70 76 78 80 86 88 90 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 96 97\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 8 10 18 20 28 30 38 40 47 48 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-94] rec[-70]\n",
    "DETECTOR rec[-44] rec[-92] rec[-68]\n",
    "DETECTOR rec[-42] rec[-90] rec[-66]\n",
    "DETECTOR rec[-41] rec[-89] rec[-65]\n",
    "DETECTOR rec[-39] rec[-87] rec[-63]\n",
    "DETECTOR rec[-37] rec[-85] rec[-61]\n",
    "DETECTOR rec[-36] rec[-84] rec[-60]\n",
    "DETECTOR rec[-34] rec[-82] rec[-58]\n",
    "DETECTOR rec[-32] rec[-80] rec[-56]\n",
    "DETECTOR rec[-31] rec[-79] rec[-55]\n",
    "DETECTOR rec[-29] rec[-77] rec[-53]\n",
    "DETECTOR rec[-27] rec[-75] rec[-51]\n",
    "DETECTOR rec[-48] rec[-96]\n",
    "DETECTOR rec[-47] rec[-95]\n",
    "DETECTOR rec[-45] rec[-93]\n",
    "DETECTOR rec[-43] rec[-91]\n",
    "DETECTOR rec[-40] rec[-88]\n",
    "DETECTOR rec[-38] rec[-86]\n",
    "DETECTOR rec[-35] rec[-83]\n",
    "DETECTOR rec[-33] rec[-81]\n",
    "DETECTOR rec[-30] rec[-78]\n",
    "DETECTOR rec[-28] rec[-76]\n",
    "DETECTOR rec[-26] rec[-74]\n",
    "DETECTOR rec[-25] rec[-73]\n",
    "DETECTOR rec[-22] rec[-70]\n",
    "DETECTOR rec[-20] rec[-68]\n",
    "DETECTOR rec[-18] rec[-66]\n",
    "DETECTOR rec[-17] rec[-65]\n",
    "DETECTOR rec[-15] rec[-63]\n",
    "DETECTOR rec[-13] rec[-61]\n",
    "DETECTOR rec[-12] rec[-60]\n",
    "DETECTOR rec[-10] rec[-58]\n",
    "DETECTOR rec[-8] rec[-56]\n",
    "DETECTOR rec[-7] rec[-55]\n",
    "DETECTOR rec[-5] rec[-53]\n",
    "DETECTOR rec[-3] rec[-51]\n",
    "DETECTOR rec[-24] rec[-72] rec[-96]\n",
    "DETECTOR rec[-23] rec[-71] rec[-95]\n",
    "DETECTOR rec[-21] rec[-69] rec[-93]\n",
    "DETECTOR rec[-19] rec[-67] rec[-91]\n",
    "DETECTOR rec[-16] rec[-64] rec[-88]\n",
    "DETECTOR rec[-14] rec[-62] rec[-86]\n",
    "DETECTOR rec[-11] rec[-59] rec[-83]\n",
    "DETECTOR rec[-9] rec[-57] rec[-81]\n",
    "DETECTOR rec[-6] rec[-54] rec[-78]\n",
    "DETECTOR rec[-4] rec[-52] rec[-76]\n",
    "DETECTOR rec[-2] rec[-50] rec[-74]\n",
    "DETECTOR rec[-1] rec[-49] rec[-73]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SQRT_Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-96] rec[-72]\n",
    "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-94] rec[-70]\n",
    "DETECTOR rec[-46] rec[-41] rec[-92] rec[-68]\n",
    "DETECTOR rec[-45] rec[-40] rec[-91] rec[-67]\n",
    "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-89] rec[-65]\n",
    "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-87] rec[-63]\n",
    "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-86] rec[-62]\n",
    "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-84] rec[-60]\n",
    "DETECTOR rec[-36] rec[-31] rec[-82] rec[-58]\n",
    "DETECTOR rec[-35] rec[-30] rec[-81] rec[-57]\n",
    "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-79] rec[-55]\n",
    "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-77] rec[-53]\n",
    "DETECTOR rec[-25] rec[-24] rec[-20] rec[-19] rec[-72]\n",
    "DETECTOR rec[-23] rec[-22] rec[-18] rec[-17] rec[-70]\n",
    "DETECTOR rec[-21] rec[-16] rec[-68]\n",
    "DETECTOR rec[-20] rec[-15] rec[-67]\n",
    "DETECTOR rec[-19] rec[-18] rec[-14] rec[-13] rec[-65]\n",
    "DETECTOR rec[-17] rec[-16] rec[-12] rec[-11] rec[-63]\n",
    "DETECTOR rec[-15] rec[-14] rec[-10] rec[-9] rec[-62]\n",
    "DETECTOR rec[-13] rec[-12] rec[-8] rec[-7] rec[-60]\n",
    "DETECTOR rec[-11] rec[-6] rec[-58]\n",
    "DETECTOR rec[-10] rec[-5] rec[-57]\n",
    "DETECTOR rec[-9] rec[-8] rec[-4] rec[-3] rec[-55]\n",
    "DETECTOR rec[-7] rec[-6] rec[-2] rec[-1] rec[-53]\n",
    "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
    "        \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "num_layers = 3\n",
    "num_cxs_per_round = 3\n",
    "distance = 5\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "        'bias_preserving_gates': 'False',\n",
    "        'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "        'SSR': 'True', 'cycles': str(num_layers - 1),\n",
    "        'ordering': gate_ordering,\n",
    "        'decoder': 'MLE',\n",
    "        'circuit_type': f'logical_CX_NL{num_layers}_NCX{num_cxs_per_round}', 'Steane_type': 'None', 'printing': 'False', 'num_logicals': '2',\n",
    "        'loss_decoder': 'independent',\n",
    "        'obs_pos': 'd-1', 'n_r': '0'}\n",
    "\n",
    "\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "\n",
    "# circuit = stim.Circuit(new_circuit_txt)\n",
    "# test_measurement_events = np.ones((1,146)).astype(bool)\n",
    "\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory) # needs to be all +1\n",
    "\n",
    "# detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "#         1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "#         1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "#         1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "#         1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "#         -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "#         1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "#         -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "# print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "# detection_events_signs_exp - detection_events_signs_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sasha's circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1\n",
      "  1  1  1  1 -1  1 -1 -1  1  1 -1  1  1  1  1  1 -1  1  1  1  1 -1 -1 -1\n",
      " -1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1 -1  1  1  1  1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  0.,  0.,  0.,  0., -2., -2., -2.,  2.,  2., -2., -2.,\n",
       "        0., -2.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0., -2., -2.,  0.,\n",
       "        0.,  0.,  0., -2., -2., -2.,  0.,  0.,  2.,  2.,  2.,  0., -2.,\n",
       "        0.,  2.,  0.,  0.,  0., -2.,  0.,  2., -2., -2.,  0.,  2.,  0.,\n",
       "        0.,  2.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -2., -2., -2.,  0.,  0.,  0.,  0.,  0., -2.,\n",
       "        0.,  0.,  0., -2., -2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_txt = \"\"\"\n",
    "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "SQRT_Y 7 9 11 19 21 27 29 31 39 41 56 58 60 68 70 76 78 80 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97 66 86 17 37\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 11 31\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 17 37\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 60 80\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 66 68 70 76 78 86 88 90 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 66 86\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 19 21 27 29 39 41 56 58 68 70 76 78 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97 66 86 17 37 60 80 11 31\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-22]\n",
    "DETECTOR rec[-44] rec[-20]\n",
    "DETECTOR rec[-42] rec[-18]\n",
    "DETECTOR rec[-41] rec[-17]\n",
    "DETECTOR rec[-39] rec[-15]\n",
    "DETECTOR rec[-37] rec[-13]\n",
    "DETECTOR rec[-36] rec[-12]\n",
    "DETECTOR rec[-34] rec[-10]\n",
    "DETECTOR rec[-32] rec[-8]\n",
    "DETECTOR rec[-31] rec[-7]\n",
    "DETECTOR rec[-29] rec[-5]\n",
    "DETECTOR rec[-27] rec[-3]\n",
    "DETECTOR rec[-48] rec[-24]\n",
    "DETECTOR rec[-47] rec[-23]\n",
    "DETECTOR rec[-45] rec[-21]\n",
    "DETECTOR rec[-43] rec[-19]\n",
    "DETECTOR rec[-40] rec[-16]\n",
    "DETECTOR rec[-38] rec[-14]\n",
    "DETECTOR rec[-35] rec[-11]\n",
    "DETECTOR rec[-33] rec[-9]\n",
    "DETECTOR rec[-30] rec[-6]\n",
    "DETECTOR rec[-28] rec[-4]\n",
    "DETECTOR rec[-26] rec[-2]\n",
    "DETECTOR rec[-25] rec[-1]\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 0 1\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "Y 47 48\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 49 50\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 60 66 68 70 76 78 80 86 88 90 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "Y 96 97\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-94] rec[-70]\n",
    "DETECTOR rec[-44] rec[-92] rec[-68]\n",
    "DETECTOR rec[-42] rec[-90] rec[-66]\n",
    "DETECTOR rec[-41] rec[-89] rec[-65]\n",
    "DETECTOR rec[-39] rec[-87] rec[-63]\n",
    "DETECTOR rec[-37] rec[-85] rec[-61]\n",
    "DETECTOR rec[-36] rec[-84] rec[-60]\n",
    "DETECTOR rec[-34] rec[-82] rec[-58]\n",
    "DETECTOR rec[-32] rec[-80] rec[-56]\n",
    "DETECTOR rec[-31] rec[-79] rec[-55]\n",
    "DETECTOR rec[-29] rec[-77] rec[-53]\n",
    "DETECTOR rec[-27] rec[-75] rec[-51]\n",
    "DETECTOR rec[-48] rec[-96]\n",
    "DETECTOR rec[-47] rec[-95]\n",
    "DETECTOR rec[-45] rec[-93]\n",
    "DETECTOR rec[-43] rec[-91]\n",
    "DETECTOR rec[-40] rec[-88]\n",
    "DETECTOR rec[-38] rec[-86]\n",
    "DETECTOR rec[-35] rec[-83]\n",
    "DETECTOR rec[-33] rec[-81]\n",
    "DETECTOR rec[-30] rec[-78]\n",
    "DETECTOR rec[-28] rec[-76]\n",
    "DETECTOR rec[-26] rec[-74]\n",
    "DETECTOR rec[-25] rec[-73]\n",
    "DETECTOR rec[-22] rec[-70]\n",
    "DETECTOR rec[-20] rec[-68]\n",
    "DETECTOR rec[-18] rec[-66]\n",
    "DETECTOR rec[-17] rec[-65]\n",
    "DETECTOR rec[-15] rec[-63]\n",
    "DETECTOR rec[-13] rec[-61]\n",
    "DETECTOR rec[-12] rec[-60]\n",
    "DETECTOR rec[-10] rec[-58]\n",
    "DETECTOR rec[-8] rec[-56]\n",
    "DETECTOR rec[-7] rec[-55]\n",
    "DETECTOR rec[-5] rec[-53]\n",
    "DETECTOR rec[-3] rec[-51]\n",
    "DETECTOR rec[-24] rec[-72] rec[-96]\n",
    "DETECTOR rec[-23] rec[-71] rec[-95]\n",
    "DETECTOR rec[-21] rec[-69] rec[-93]\n",
    "DETECTOR rec[-19] rec[-67] rec[-91]\n",
    "DETECTOR rec[-16] rec[-64] rec[-88]\n",
    "DETECTOR rec[-14] rec[-62] rec[-86]\n",
    "DETECTOR rec[-11] rec[-59] rec[-83]\n",
    "DETECTOR rec[-9] rec[-57] rec[-81]\n",
    "DETECTOR rec[-6] rec[-54] rec[-78]\n",
    "DETECTOR rec[-4] rec[-52] rec[-76]\n",
    "DETECTOR rec[-2] rec[-50] rec[-74]\n",
    "DETECTOR rec[-1] rec[-49] rec[-73]\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-96] rec[-72]\n",
    "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-94] rec[-70]\n",
    "DETECTOR rec[-46] rec[-41] rec[-92] rec[-68]\n",
    "DETECTOR rec[-45] rec[-40] rec[-91] rec[-67]\n",
    "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-89] rec[-65]\n",
    "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-87] rec[-63]\n",
    "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-86] rec[-62]\n",
    "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-84] rec[-60]\n",
    "DETECTOR rec[-36] rec[-31] rec[-82] rec[-58]\n",
    "DETECTOR rec[-35] rec[-30] rec[-81] rec[-57]\n",
    "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-79] rec[-55]\n",
    "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-77] rec[-53]\n",
    "DETECTOR rec[-25] rec[-24] rec[-20] rec[-19] rec[-72]\n",
    "DETECTOR rec[-23] rec[-22] rec[-18] rec[-17] rec[-70]\n",
    "DETECTOR rec[-21] rec[-16] rec[-68]\n",
    "DETECTOR rec[-20] rec[-15] rec[-67]\n",
    "DETECTOR rec[-19] rec[-18] rec[-14] rec[-13] rec[-65]\n",
    "DETECTOR rec[-17] rec[-16] rec[-12] rec[-11] rec[-63]\n",
    "DETECTOR rec[-15] rec[-14] rec[-10] rec[-9] rec[-62]\n",
    "DETECTOR rec[-13] rec[-12] rec[-8] rec[-7] rec[-60]\n",
    "DETECTOR rec[-11] rec[-6] rec[-58]\n",
    "DETECTOR rec[-10] rec[-5] rec[-57]\n",
    "DETECTOR rec[-9] rec[-8] rec[-4] rec[-3] rec[-55]\n",
    "DETECTOR rec[-7] rec[-6] rec[-2] rec[-1] rec[-53]\n",
    "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "circuit = stim.Circuit(circuit_txt)\n",
    "# detection_events_theory, observable_flips_theory = circuit.compile_m2d_converter().convert(measurements = exp_measurements.astype(bool), separate_observables = True)\n",
    "test_measurement_events = np.ones((1,146)).astype(bool)\n",
    "test_detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=test_measurement_events, separate_observables=True)\n",
    "# print(list(test_detection_events.astype(int)))\n",
    "detection_events_circuit = 1-2*test_detection_events.astype(int).squeeze() # detection --> -1, no detection --> +1\n",
    "\n",
    "print(detection_events_circuit)\n",
    "\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_circuit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_error_model = circuit.detector_error_model(decompose_errors=False, approximate_disjoint_errors=True, ignore_decomposition_failures=True, allow_gauge_detectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1\n",
      "  1  1  1  1 -1  1 -1 -1  1  1 -1  1  1  1  1  1 -1  1  1  1  1 -1 -1 -1\n",
      " -1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1 -1 -1 -1  1  1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  0.,  0.,  0.,  0., -2., -2., -2.,  2.,  2., -2., -2.,\n",
       "        0., -2.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0., -2., -2.,  0.,\n",
       "        0.,  0.,  0., -2., -2., -2.,  0.,  0.,  2.,  2.,  2.,  0., -2.,\n",
       "        0.,  2.,  0.,  0.,  0., -2.,  0.,  2., -2., -2.,  0.,  2.,  0.,\n",
       "        0.,  2.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -2., -2., -2.,  0.,  2.,  2.,  0.,  0., -2.,\n",
       "        0.,  2.,  2., -2., -2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_txt = \"\"\"\n",
    "\n",
    "R 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46\n",
    "R 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "SQRT_Y 52 54 61 63 65 72 74 81 83 85 92 94\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 11 31\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 17 19 21 27 29 37 39 41 0 1 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 17 37\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 60 80\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 66 68 70 76 78 86 88 90 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 66 86\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 17 19 21 27 29 37 39 41 56 58 66 68 70 76 78 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-22]\n",
    "DETECTOR rec[-44] rec[-20]\n",
    "DETECTOR rec[-42] rec[-18]\n",
    "DETECTOR rec[-41] rec[-17]\n",
    "DETECTOR rec[-39] rec[-15]\n",
    "DETECTOR rec[-37] rec[-13]\n",
    "DETECTOR rec[-36] rec[-12]\n",
    "DETECTOR rec[-34] rec[-10]\n",
    "DETECTOR rec[-32] rec[-8]\n",
    "DETECTOR rec[-31] rec[-7]\n",
    "DETECTOR rec[-29] rec[-5]\n",
    "DETECTOR rec[-27] rec[-3]\n",
    "DETECTOR rec[-48] rec[-24]\n",
    "DETECTOR rec[-47] rec[-23]\n",
    "DETECTOR rec[-45] rec[-21]\n",
    "DETECTOR rec[-43] rec[-19]\n",
    "DETECTOR rec[-40] rec[-16]\n",
    "DETECTOR rec[-38] rec[-14]\n",
    "DETECTOR rec[-35] rec[-11]\n",
    "DETECTOR rec[-33] rec[-9]\n",
    "DETECTOR rec[-30] rec[-6]\n",
    "DETECTOR rec[-28] rec[-4]\n",
    "DETECTOR rec[-26] rec[-2]\n",
    "DETECTOR rec[-25] rec[-1]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "R 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "SQRT_Y 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 2 0 4 1 13 8 15 10 22 18 24 20 33 28 35 30 42 38 44 40 7 12 9 14 11 16 19 23 21 25 27 32 29 34 31 36 39 43 41 45\n",
    "\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 0 1\n",
    "\n",
    "CZ 3 0 5 1 14 8 16 10 23 18 25 20 34 28 36 30 43 38 45 40 7 13 9 15 17 22 19 24 21 26 27 33 29 35 37 42 39 44 41 46\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 7 9 11 17 19 21 27 29 31 37 39 41 8 10 18 20 28 30 38 40 47 48\n",
    "\n",
    "CZ 3 8 5 10 12 18 14 20 23 28 25 30 32 38 34 40 43 47 45 48 7 2 9 4 11 6 19 13 21 15 27 22 29 24 31 26 39 33 41 35\n",
    "\n",
    "SQRT_Y_DAG 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46\n",
    "\n",
    "Y 47 48\n",
    "\n",
    "CZ 4 8 6 10 13 18 15 20 24 28 26 30 33 38 35 40 44 47 46 48 7 3 9 5 17 12 19 14 21 16 27 23 29 25 37 32 39 34 41 36\n",
    "\n",
    "CZ 51 49 53 50 62 57 64 59 71 67 73 69 82 77 84 79 91 87 93 89 56 61 58 63 60 65 68 72 70 74 76 81 78 83 80 85 88 92 90 94\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 49 50\n",
    "\n",
    "CZ 52 49 54 50 63 57 65 59 72 67 74 69 83 77 85 79 92 87 94 89 56 62 58 64 66 71 68 73 70 75 76 82 78 84 86 91 88 93 90 95\n",
    "\n",
    "Y 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 56 58 60 66 68 70 76 78 80 86 88 90 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "CZ 52 57 54 59 61 67 63 69 72 77 74 79 81 87 83 89 92 96 94 97 56 51 58 53 60 55 68 62 70 64 76 71 78 73 80 75 88 82 90 84\n",
    "\n",
    "SQRT_Y_DAG 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "\n",
    "Y 96 97\n",
    "\n",
    "CZ 53 57 55 59 62 67 64 69 73 77 75 79 82 87 84 89 93 96 95 97 56 52 58 54 66 61 68 63 70 65 76 72 78 74 86 81 88 83 90 85\n",
    "\n",
    "SQRT_Y_DAG 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 0 1 8 10 18 20 28 30 38 40 47 48 49 50 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "Y 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95 7 9 11 17 19 21 27 29 31 37 39 41 56 58 60 66 68 70 76 78 80 86 88 90 8 10 18 20 28 30 38 40 47 48 57 59 67 69 77 79 87 89 96 97\n",
    "\n",
    "\n",
    "\n",
    "M 0 1 7 8 9 10 11 17 18 19 20 21 27 28 29 30 31 37 38 39 40 41 47 48 49 50 56 57 58 59 60 66 67 68 69 70 76 77 78 79 80 86 87 88 89 90 96 97\n",
    "DETECTOR rec[-46] rec[-94] rec[-70]\n",
    "DETECTOR rec[-44] rec[-92] rec[-68]\n",
    "DETECTOR rec[-42] rec[-90] rec[-66]\n",
    "DETECTOR rec[-41] rec[-89] rec[-65]\n",
    "DETECTOR rec[-39] rec[-87] rec[-63]\n",
    "DETECTOR rec[-37] rec[-85] rec[-61]\n",
    "DETECTOR rec[-36] rec[-84] rec[-60]\n",
    "DETECTOR rec[-34] rec[-82] rec[-58]\n",
    "DETECTOR rec[-32] rec[-80] rec[-56]\n",
    "DETECTOR rec[-31] rec[-79] rec[-55]\n",
    "DETECTOR rec[-29] rec[-77] rec[-53]\n",
    "DETECTOR rec[-27] rec[-75] rec[-51]\n",
    "DETECTOR rec[-48] rec[-96]\n",
    "DETECTOR rec[-47] rec[-95]\n",
    "DETECTOR rec[-45] rec[-93]\n",
    "DETECTOR rec[-43] rec[-91]\n",
    "DETECTOR rec[-40] rec[-88]\n",
    "DETECTOR rec[-38] rec[-86]\n",
    "DETECTOR rec[-35] rec[-83]\n",
    "DETECTOR rec[-33] rec[-81]\n",
    "DETECTOR rec[-30] rec[-78]\n",
    "DETECTOR rec[-28] rec[-76]\n",
    "DETECTOR rec[-26] rec[-74]\n",
    "DETECTOR rec[-25] rec[-73]\n",
    "DETECTOR rec[-22] rec[-70]\n",
    "DETECTOR rec[-20] rec[-68]\n",
    "DETECTOR rec[-18] rec[-66]\n",
    "DETECTOR rec[-17] rec[-65]\n",
    "DETECTOR rec[-15] rec[-63]\n",
    "DETECTOR rec[-13] rec[-61]\n",
    "DETECTOR rec[-12] rec[-60]\n",
    "DETECTOR rec[-10] rec[-58]\n",
    "DETECTOR rec[-8] rec[-56]\n",
    "DETECTOR rec[-7] rec[-55]\n",
    "DETECTOR rec[-5] rec[-53]\n",
    "DETECTOR rec[-3] rec[-51]\n",
    "DETECTOR rec[-24] rec[-72] rec[-96]\n",
    "DETECTOR rec[-23] rec[-71] rec[-95]\n",
    "DETECTOR rec[-21] rec[-69] rec[-93]\n",
    "DETECTOR rec[-19] rec[-67] rec[-91]\n",
    "DETECTOR rec[-16] rec[-64] rec[-88]\n",
    "DETECTOR rec[-14] rec[-62] rec[-86]\n",
    "DETECTOR rec[-11] rec[-59] rec[-83]\n",
    "DETECTOR rec[-9] rec[-57] rec[-81]\n",
    "DETECTOR rec[-6] rec[-54] rec[-78]\n",
    "DETECTOR rec[-4] rec[-52] rec[-76]\n",
    "DETECTOR rec[-2] rec[-50] rec[-74]\n",
    "DETECTOR rec[-1] rec[-49] rec[-73]\n",
    "\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "CZ 2 51 3 52 4 53 5 54 6 55 12 61 13 62 14 63 15 64 16 65 22 71 23 72 24 73 25 74 26 75 32 81 33 82 34 83 35 84 36 85 42 91 43 92 44 93 45 94 46 95\n",
    "\n",
    "SQRT_Y 3 5 12 14 16 23 25 32 34 36 43 45\n",
    "\n",
    "SQRT_Y 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "Y 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
    "\n",
    "SQRT_Y 2 4 6 13 15 22 24 26 33 35 42 44 46 51 53 55 62 64 71 73 75 82 84 91 93 95\n",
    "\n",
    "\n",
    "M 2 3 4 5 6 12 13 14 15 16 22 23 24 25 26 32 33 34 35 36 42 43 44 45 46 51 52 53 54 55 61 62 63 64 65 71 72 73 74 75 81 82 83 84 85 91 92 93 94 95\n",
    "DETECTOR rec[-50] rec[-49] rec[-45] rec[-44] rec[-96] rec[-72]\n",
    "DETECTOR rec[-48] rec[-47] rec[-43] rec[-42] rec[-94] rec[-70]\n",
    "DETECTOR rec[-46] rec[-41] rec[-92] rec[-68]\n",
    "DETECTOR rec[-45] rec[-40] rec[-91] rec[-67]\n",
    "DETECTOR rec[-44] rec[-43] rec[-39] rec[-38] rec[-89] rec[-65]\n",
    "DETECTOR rec[-42] rec[-41] rec[-37] rec[-36] rec[-87] rec[-63]\n",
    "DETECTOR rec[-40] rec[-39] rec[-35] rec[-34] rec[-86] rec[-62]\n",
    "DETECTOR rec[-38] rec[-37] rec[-33] rec[-32] rec[-84] rec[-60]\n",
    "DETECTOR rec[-36] rec[-31] rec[-82] rec[-58]\n",
    "DETECTOR rec[-35] rec[-30] rec[-81] rec[-57]\n",
    "DETECTOR rec[-34] rec[-33] rec[-29] rec[-28] rec[-79] rec[-55]\n",
    "DETECTOR rec[-32] rec[-31] rec[-27] rec[-26] rec[-77] rec[-53]\n",
    "DETECTOR rec[-25] rec[-24] rec[-20] rec[-19] rec[-72]\n",
    "DETECTOR rec[-23] rec[-22] rec[-18] rec[-17] rec[-70]\n",
    "DETECTOR rec[-21] rec[-16] rec[-68]\n",
    "DETECTOR rec[-20] rec[-15] rec[-67]\n",
    "DETECTOR rec[-19] rec[-18] rec[-14] rec[-13] rec[-65]\n",
    "DETECTOR rec[-17] rec[-16] rec[-12] rec[-11] rec[-63]\n",
    "DETECTOR rec[-15] rec[-14] rec[-10] rec[-9] rec[-62]\n",
    "DETECTOR rec[-13] rec[-12] rec[-8] rec[-7] rec[-60]\n",
    "DETECTOR rec[-11] rec[-6] rec[-58]\n",
    "DETECTOR rec[-10] rec[-5] rec[-57]\n",
    "DETECTOR rec[-9] rec[-8] rec[-4] rec[-3] rec[-55]\n",
    "DETECTOR rec[-7] rec[-6] rec[-2] rec[-1] rec[-53]\n",
    "OBSERVABLE_INCLUDE(0) rec[-40] rec[-39] rec[-38] rec[-37] rec[-36] rec[-15] rec[-14] rec[-13] rec[-12] rec[-11]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "circuit = stim.Circuit(circuit_txt)\n",
    "# detection_events_theory, observable_flips_theory = circuit.compile_m2d_converter().convert(measurements = exp_measurements.astype(bool), separate_observables = True)\n",
    "test_measurement_events = np.ones((1,146)).astype(bool)\n",
    "test_detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=test_measurement_events, separate_observables=True)\n",
    "# print(list(test_detection_events.astype(int)))\n",
    "detection_events_circuit = 1-2*test_detection_events.astype(int).squeeze() # detection --> -1, no detection --> +1\n",
    "\n",
    "print(detection_events_circuit)\n",
    "\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "        -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_signs_theory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with H = Rydagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 3\n",
      "num_CX_per_layer = 1\n",
      "final measurement_index = 146\n",
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  2.,  0.,  0.,  0.,  0., -2., -2.,  2.,  2., -2., -2.,\n",
       "        0., -2.,  0.,  2.,  0.,  0.,  0., -2.,  0.,  2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., -2., -2.,  0., -2.,  0.,  2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2., -2.,\n",
       "        0.,  2.,  2., -2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory)\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_signs_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,\n",
       "       -2.,  2., -2.,  0.,  0.,  0.,  0.,  2.,  2., -2., -2.,  2.,  2.,\n",
       "       -2.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  2.,  2.,  0.,  2.,  0., -2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  2.,  0., -2.,  0.,\n",
       "        0., -2., -2.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_events_signs_exp = np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "# Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "# Find detection event signs\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory)\n",
    "\n",
    "\n",
    "detection_events_signs_theory - detection_events_signs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n"
     ]
    }
   ],
   "source": [
    "num_shots = 100\n",
    "# Change #2: a function that doesn't decode, just gives you the measurements, detection events, observables and the circuit:\n",
    "measurement_events_all_shots, detection_events_all_shots, observable_flips_all_shots, LogicalCircuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "measurement_events = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                            exp_measurements[:, 1, :distance**2-1],\n",
    "                            exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                            exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                            exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                            exp_measurements[:, 1, 2*(distance**2-1):]], axis=1).astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "detection_events, observable_flips = LogicalCircuit.compile_m2d_converter().convert(measurements=measurement_events, separate_observables=True)\n",
    "detection_events_signs = -1*np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False,  True, False],\n",
       "       [False,  True, False, ..., False,  True, False],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True, False],\n",
       "       [ True,  True, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False,  True,  True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "measurement_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_events_all_shots\n",
    "\n",
    "detection_events_signs = np.sign(np.nanmean(detection_events_all_shots,axis = -1))\n",
    "\n",
    "detection_events_signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 5\n",
    "# qubit_states_nans_perlog = np.load('2024_10_15_measurement_events_1CNOT_XX.npy').astype(bool)\n",
    "qubit_states_nans_perlog = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "qubit_states_nans_perlog = qubit_states_nans_perlog.transpose(1,2,0)\n",
    "# exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "#                             exp_measurements[:, 1, :distance**2-1],\n",
    "#                             exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "#                             exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "#                             exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "#                             exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "perfect_reps = np.ones(qubit_states_nans_perlog.shape[-1]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_losses_per_stab_perlog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_62737/3085604329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_logicals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstabilizer_prod_per_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperfect_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ancillas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0merror_prob_Astabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Astabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0merror_prob_Bstabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Bstabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_62737/3085604329.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_logicals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstabilizer_prod_per_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperfect_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ancillas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0merror_prob_Astabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Astabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0merror_prob_Bstabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Bstabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_losses_per_stab_perlog' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_data_blocks = num_logicals = 2\n",
    "\n",
    "num_ancilla_blocks = 2\n",
    "num_rounds = num_ancilla_blocks + 1\n",
    "\n",
    "ancilla_grid_size = 6\n",
    "data_grid_size = d = 5\n",
    "xspc = 3\n",
    "yspc = 2\n",
    "\n",
    "num_datas = 25\n",
    "num_ancillas = 24\n",
    "total_num_ancillas = num_ancillas*num_ancilla_blocks*num_logicals\n",
    "total_num_datas = num_datas*num_data_blocks\n",
    "num_physicals = total_num_ancillas + total_num_datas\n",
    "\n",
    "\n",
    "\n",
    "stabilizer_weights = np.zeros(num_ancillas)\n",
    "stabilizer_masks = np.zeros((num_ancillas, num_datas), dtype = bool)\n",
    "\n",
    "ancilla_Astabs_mask = Zstabs_mask =  np.array([1,1,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,1,1], dtype = bool) \n",
    "ancilla_Bstabs_mask = Xstabs_mask = (1-ancilla_Astabs_mask).astype(bool)\n",
    "\n",
    "deterministic_rounds = np.ones(num_rounds).astype(bool)\n",
    "nondeterministic_rounds = np.array([0] + (num_rounds - 2)*[1] + [0]).astype(bool)\n",
    "\n",
    "\n",
    "### HARDCODE FOR NOW\n",
    "stabilizer_weights = np.array([2., 2., 4., 4., 4., 4., 2., 2., 4., 4., 4., 4., 4., 4., 4., 4., 2.,\n",
    "       2., 4., 4., 4., 4., 2., 2.])\n",
    "stabilizer_masks = np.array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]).astype(bool)\n",
    "\n",
    "\n",
    "stab2A = (ancilla_Astabs_mask & (stabilizer_weights == 2))\n",
    "stab2B = (ancilla_Bstabs_mask & (stabilizer_weights == 2))\n",
    "stab4A = (ancilla_Astabs_mask & (stabilizer_weights == 4))\n",
    "stab4B = (ancilla_Bstabs_mask & (stabilizer_weights == 4))\n",
    "\n",
    "\n",
    "vertical_string_masks = np.zeros((d,num_datas)).astype(bool)\n",
    "horizontal_string_masks = np.zeros((d,num_datas)).astype(bool)\n",
    "\n",
    "for i in range(d):\n",
    "    vertical_string_masks[i,i::d] = True\n",
    "    horizontal_string_masks[i,i*d:d*(i+1)] = True\n",
    "\n",
    "# qubit_states_nans = atoms_present_final.copy()\n",
    "\n",
    "\n",
    "# ## Reshape into per logical\n",
    "# qubit_states_nans_perlog = np.array([qubit_states_nans[logical_qubit_masks[i]] for i in range(num_logicals)])\n",
    "# qubit_states_perlog = np.nan_to_num(qubit_states_nans_perlog, nan = 3) #convert nan to 3 (so it then becomes 2 in the next line)\n",
    "# qubit_states_perlog = ((qubit_states_perlog + 1)/2).astype(int)\n",
    "\n",
    "# data_losses_perlog = np.isnan(qubit_states_nans_perlog[:,-num_datas:])\n",
    "# data_losses_per_stab_perlog = np.array([np.sum(data_losses_perlog[:,stabilizer_masks[i]], axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "# num_data_losses_perlog = np.sum(data_losses_perlog, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stabilizer_prod_per_round = []\n",
    "stabilizer_prod_per_round_withloss = []\n",
    "\n",
    "loss_sign = +1\n",
    "\n",
    "for r in range(-1,num_ancilla_blocks):\n",
    "    if r == -1:\n",
    "        stab_second = qubit_states_nans_perlog[:,num_ancillas*(r+1):num_ancillas*(r+2)]\n",
    "        stab_first = np.ones_like(stab_second)\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second_withloss = np.nan_to_num(stab_second,nan = loss_sign)\n",
    "                                            \n",
    "    elif r == num_ancilla_blocks - 1:\n",
    "        stab_first = qubit_states_nans_perlog[:,num_ancillas*r:num_ancillas*(r+1)]\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second = np.array([np.prod(qubit_states_nans_perlog[:,-num_datas:][:,stabilizer_masks[i]],axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "        stab_second_withloss = np.array([np.prod(np.nan_to_num(qubit_states_nans_perlog[:,-num_datas:][:,stabilizer_masks[i]], nan = loss_sign),axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "    else:\n",
    "        stab_first = qubit_states_nans_perlog[:,num_ancillas*r:num_ancillas*(r+1)]\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second = qubit_states_nans_perlog[:,num_ancillas*(r+1):num_ancillas*(r+2)]\n",
    "        stab_second_withloss = np.nan_to_num(stab_second, nan = loss_sign)\n",
    "\n",
    "    stab_product_per_round = stab_first*stab_second\n",
    "    stab_product_per_round_withloss = stab_first_withloss*stab_second_withloss #convert loss to qubit state |0>\n",
    "\n",
    "    stabilizer_prod_per_round.append(stab_product_per_round)\n",
    "    stabilizer_prod_per_round_withloss.append(stab_product_per_round_withloss)\n",
    "\n",
    "stabilizer_prod_per_round = np.array(stabilizer_prod_per_round)\n",
    "stabilizer_prod_per_round_withloss = np.array(stabilizer_prod_per_round_withloss)\n",
    "\n",
    "# For sublattice A, and sublattice B separately\n",
    "\n",
    "error_prob_Astabs = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Astabs_mask],axis = -1)))/2\n",
    "error_prob_Bstabs = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Bstabs_mask], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_postselected = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Astabs_mask][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Bstabs_mask][:,:,:,perfect_reps], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_fully_postselected = np.zeros_like(error_prob_Astabs_postselected)\n",
    "error_prob_Bstabs_fully_postselected = np.zeros_like(error_prob_Bstabs_postselected)\n",
    "\n",
    "stabilizer_prod_per_round_per_stab_dataloss_postselection = []\n",
    "for log in range(num_logicals):\n",
    "    stabilizer_prod_per_round_per_stab_dataloss_postselection += [[stabilizer_prod_per_round[:,log,i][:,data_losses_per_stab_perlog[log,i] == 0][:,perfect_reps[data_losses_per_stab_perlog[log,i] == 0]] for i in range(num_ancillas)]]\n",
    "    error_prob_Astabs_fully_postselected[:,log] = 1-(1+np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[-1][i],axis = -1) for i in np.where(ancilla_Astabs_mask)[0]]).T)/2\n",
    "    error_prob_Bstabs_fully_postselected[:,log] = 1-(1+np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[-1][i],axis = -1) for i in np.where(ancilla_Bstabs_mask)[0]]).T)/2\n",
    "\n",
    "plt.figure(\"Detected error per round\", figsize = (15,5))\n",
    "plt.clf()\n",
    "for log in range(num_logicals):  \n",
    "    Astab_good_rounds_thislog = deterministic_rounds if prep_basis[log] == 'vertical' else nondeterministic_rounds\n",
    "    Bstab_good_rounds_thislog = nondeterministic_rounds if prep_basis[log] == 'vertical' else deterministic_rounds\n",
    "    \n",
    "    plt.subplot(1,2,log+1)\n",
    "    plt.bar(np.arange(num_rounds)-0.2,np.nanmean(error_prob_Astabs[:,log],axis = -1),width = 0.4,label = \"A\", color = \"b\", alpha = 0.6)\n",
    "    plt.bar(np.arange(num_rounds)+0.2,np.nanmean(error_prob_Bstabs[:,log],axis = -1),width = 0.4,label = \"B\", color = \"orange\", alpha = 0.6)\n",
    "    plt.bar(np.arange(num_rounds)-0.2,np.nanmean(error_prob_Astabs_postselected[:,log],axis = -1),width = 0.4,label = \"A (post)\",color = \"b\")\n",
    "    plt.bar(np.arange(num_rounds)+0.2,np.nanmean(error_prob_Bstabs_postselected[:,log],axis = -1),width = 0.4,label = \"B (post)\", color = \"orange\")\n",
    "    \n",
    "    plt.xticks(np.arange(num_rounds))\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Detected error probability\")\n",
    "    plt.ylim(0,0.6)\n",
    "    plt.legend()\n",
    "    plt.title(f\"\"\"Average error prob (no postselection, exclude loss): {np.nanmean(np.concatenate((error_prob_Astabs[:,log][Astab_good_rounds_thislog],error_prob_Bstabs[:,log][Bstab_good_rounds_thislog]))):.4f}\n",
    "    Average error prob (postselected, exclude loss): {np.nanmean(np.concatenate((error_prob_Astabs_postselected[:,log][Astab_good_rounds_thislog],error_prob_Bstabs_postselected[:,log][Bstab_good_rounds_thislog]))):.4f}\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_prob_Astabs_postselected_weight_2 = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_weight_2  = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "error_prob_Astabs_postselected_weight_4 = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_weight_4  = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_postselected_weight_2_err = np.nanstd(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps],axis = -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Bstabs_postselected_weight_2_err  = np.nanstd(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps], axis= -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Astabs_postselected_weight_4_err = np.nanstd(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps],axis = -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Bstabs_postselected_weight_4_err  = np.nanstd(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps], axis= -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps].shape[-1])\n",
    "\n",
    "stab_mean_prod_stab2A = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab2A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab2B = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab2B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab4A = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab4A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab4B = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab4B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "\n",
    "error_prob_Astabs_fully_postselected_weight_2 = 1-(1+np.abs(stab_mean_prod_stab2A))/2\n",
    "error_prob_Bstabs_fully_postselected_weight_2  = 1-(1+np.abs(stab_mean_prod_stab2B))/2\n",
    "error_prob_Astabs_fully_postselected_weight_4 = 1-(1+np.abs(stab_mean_prod_stab4A))/2\n",
    "error_prob_Bstabs_fully_postselected_weight_4  = 1-(1+np.abs(stab_mean_prod_stab4B))/2\n",
    "\n",
    "error_prob_Astabs_fully_postselected_weight_2_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab2A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Bstabs_fully_postselected_weight_2_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab2B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Astabs_fully_postselected_weight_4_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab4A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Bstabs_fully_postselected_weight_4_err  = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab4B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "\n",
    "\n",
    "error_prob_Astabs_postselected_withloss_weight_2  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab2A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_withloss_weight_2  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab2B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "error_prob_Astabs_postselected_withloss_weight_4  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab4A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_withloss_weight_4  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab4B][:,:,:,perfect_reps], axis= -1)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "for log in range(num_logicals):  \n",
    "    Astab_good_rounds_thislog = deterministic_rounds if prep_basis[log] == 'vertical' else nondeterministic_rounds\n",
    "    Bstab_good_rounds_thislog = nondeterministic_rounds if prep_basis[log] == 'vertical' else deterministic_rounds\n",
    "    \n",
    "    plt.subplot(num_logicals,2,log*num_logicals + 1)\n",
    "\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_postselected_weight_2[Astab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_postselected_weight_2[Bstab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_postselected_weight_4[Astab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_postselected_weight_4[Bstab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_postselected_weight_2,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='steelblue')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_postselected_weight_2,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='steelblue', label='weight 2')\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_postselected_weight_4,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='firebrick')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_postselected_weight_4,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='firebrick', label='weight 4')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.xlabel('QEC cycle')\n",
    "    plt.ylabel(\"Detection probability\")\n",
    "    \n",
    "    all_good_weight2 = np.concatenate((error_prob_Astabs_postselected_weight_2[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_2[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4 =  np.concatenate((error_prob_Astabs_postselected_weight_4[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_4[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    all_good_weight2_err = np.concatenate((error_prob_Astabs_postselected_weight_2_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_2_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4_err = np.concatenate((error_prob_Astabs_postselected_weight_4_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_4_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    plt.title(f\"\"\"Logical {log+1}: Postselected on rearrangement only\n",
    "    Weight 2: {np.mean(all_good_weight2):.4f}({np.mean(all_good_weight2_err)/np.sqrt(all_good_weight2.size):.4f}), Weight 4: {np.mean(all_good_weight4):.4f}({np.mean(all_good_weight4_err)/np.sqrt(all_good_weight4.size):.4f})\n",
    "    Overall {np.mean(np.concatenate((all_good_weight2, all_good_weight4))):.4f}({np.mean(np.concatenate((all_good_weight2_err, all_good_weight4_err)))/np.sqrt(np.concatenate((all_good_weight2, all_good_weight4)).ravel().size):.4f})\"\"\")\n",
    "    \n",
    "    plt.subplot(num_logicals,2,log*num_logicals + 2)\n",
    "\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_fully_postselected_weight_2[Astab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_fully_postselected_weight_2[Bstab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_fully_postselected_weight_4[Astab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_fully_postselected_weight_4[Bstab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_fully_postselected_weight_2,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='steelblue')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_fully_postselected_weight_2,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='steelblue', label='weight 2')\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_fully_postselected_weight_4,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='firebrick')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_fully_postselected_weight_4,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='firebrick', label='weight 4')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.xlabel('QEC cycle')\n",
    "    plt.ylabel(\"Detection probability\")\n",
    "    all_good_weight2 = np.concatenate((error_prob_Astabs_fully_postselected_weight_2[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_2[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4 =  np.concatenate((error_prob_Astabs_fully_postselected_weight_4[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_4[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    all_good_weight2_err = np.concatenate((error_prob_Astabs_fully_postselected_weight_2_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_2_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4_err = np.concatenate((error_prob_Astabs_fully_postselected_weight_4_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_4_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    plt.title(f\"\"\"Logical {log + 1}: Postselected on rearrangement and no data loss\n",
    "    Weight 2: {np.mean(all_good_weight2):.4f}({np.mean(all_good_weight2_err)/np.sqrt(all_good_weight2.size):.4f}), Weight 4: {np.mean(all_good_weight4):.4f}({np.mean(all_good_weight4_err)/np.sqrt(all_good_weight4.size):.4f})\n",
    "    Overall {np.mean(np.concatenate((all_good_weight2, all_good_weight4))):.4f}({np.mean(np.concatenate((all_good_weight2_err, all_good_weight4_err)))/np.sqrt(np.concatenate((all_good_weight2, all_good_weight4)).ravel().size):.4f})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in np.arange(num_logicals):\n",
    "    fig, axs = plt.subplots(ancilla_grid_size,ancilla_grid_size)\n",
    "    # fig.canvas.set_window_title(\"Ancilla stabilizers, excluding loss\")\n",
    "    fig.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "    count = 0\n",
    "    for i in range(ancilla_grid_size**2):\n",
    "        ax = axs[i//ancilla_grid_size,i%ancilla_grid_size]\n",
    "        if ancilla_block_mask[i]:\n",
    "            mean_stab = np.nanmean(stabilizer_prod_per_round[:,log,count,perfect_reps], axis = -1)\n",
    "            # ax.bar(np.arange(num_rounds),mean_stab, color = [\"r\",\"k\"][int(ancilla_Astabs_mask[count])])\n",
    "            ax.bar(np.arange(num_rounds),mean_stab, color = [\"r\",\"k\"][int(ancilla_Astabs_mask[count])])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_ylim(-1,1)\n",
    "            count+=1 \n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    fig.suptitle(\"Logical %i stab. products (perfect rearrangement, exclude loss)\"%(log+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "A = 'logical_CX_NL1_NCX2'\n",
    "\n",
    "print(int(A[13:14]))\n",
    "\n",
    "print(int(A[18:19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
