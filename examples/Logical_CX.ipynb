{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers = 2\n",
      "num_CX_per_layer = 4\n",
      "generating the Logical circuit took: 0.312406s\n",
      "Logical circuit that will be used: \n",
      "R 1 2 3 7 8 9 13 14 15\n",
      "X_ERROR(0.000337379) 1 2 3 7 8 9 13 14 15\n",
      "I 1 2 3 7 8 9 13 14 15\n",
      "SQRT_Y_DAG 1 3 8 13 15\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 1 3 8 13 15\n",
      "R 18 19 20 24 25 26 30 31 32\n",
      "X_ERROR(0.000337379) 32 18 19 20 24 25 26 30 31\n",
      "I 32 18 19 20 24 25 26 30 31\n",
      "SQRT_Y_DAG 19 24 26 31\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 19 24 26 31\n",
      "SQRT_Y 2 7 9 14\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 2 7 9 14\n",
      "SQRT_Y 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149)\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884)\n",
      "I 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 32\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149)\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884)\n",
      "I 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 32\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149)\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884)\n",
      "I 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 32\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149)\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884)\n",
      "I 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 32\n",
      "SQRT_Y 2 7 9 14\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 2 7 9 14\n",
      "SQRT_Y 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 20 25 30 32\n",
      "R 4 6 10 12 21 23 27 29 0 5 11 16 17 22 28 33\n",
      "X_ERROR(0.0569937) 0 33 4 5 6 10 11 12 16 17 21 22 23 27 28 29\n",
      "I 0 33 4 5 6 10 11 12 16 17 21 22 23 27 28 29\n",
      "SQRT_Y 4 6 10 12 21 23 27 29 0 5 11 16 17 22 28 33\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 4 6 10 12 21 23 27 29 0 5 11 16 17 22 28 33\n",
      "CZ 1 0 8 5 13 11 4 7 6 9 12 14\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 0 8 5 13 11 4 7 6 9 12 14\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 2 3 10 15 16\n",
      "I 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n",
      "SQRT_Y 1 2 3 7 8 9 13 14 15\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 1 2 3 7 8 9 13 14 15\n",
      "Y 23\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05)\n",
      "CZ 2 5 7 11 14 16 4 1 6 3 12 8\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 2 5 7 11 14 16 4 1 6 3 12 8\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 0 9 10 13 15\n",
      "I 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 1 2 3 7 8 9 13 14 15\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 0 4 5 6 10 11 12 16\n",
      "I 1 2 3 7 8 9 13 14 15 0 4 5 6 10 11 12 16\n",
      "Y 1 2 3 7 8 9 13 14 15 4 6 10 12 0 5 11 16\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 1 2 3 7 8 9 13 14 15 4 6 10 12 0 5 11 16\n",
      "CZ 2 0 9 5 14 11 4 8 10 13 12 15\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 2 0 9 5 14 11 4 8 10 13 12 15\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 1 3 6 7 16\n",
      "I 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 1 2 3 7 8 9 13 14 15\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 0 4 5 6 10 11 12 16\n",
      "I 1 2 3 7 8 9 13 14 15 0 4 5 6 10 11 12 16\n",
      "SQRT_Y 1 2 3 7 8 9 13 14 15\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 1 2 3 7 8 9 13 14 15\n",
      "Y 27\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05)\n",
      "CZ 3 5 8 11 15 16 4 2 10 7 12 9\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 3 5 8 11 15 16 4 2 10 7 12 9\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 0 1 6 13 14\n",
      "I 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 1 2 3 7 8 9 13 14 15\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 0 4 5 6 10 11 12 16\n",
      "I 1 2 3 7 8 9 13 14 15 0 4 5 6 10 11 12 16\n",
      "CZ 18 17 25 22 30 28 21 24 23 26 29 31\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 18 17 25 22 30 28 21 24 23 26 29 31\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 32 33 19 20 27\n",
      "I 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "SQRT_Y 18 19 20 24 25 26 30 31 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 19 20 24 25 26 30 31 32\n",
      "Y 23\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 23\n",
      "CZ 19 22 24 28 31 33 21 18 23 20 29 25\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 19 22 24 28 31 33 21 18 23 20 29 25\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 32 17 26 27 30\n",
      "I 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "Y 18 19 20 24 25 26 30 31 32 21 27 29 17 22 28 33\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 19 20 24 25 26 30 31 32 21 27 29 17 22 28 33\n",
      "CZ 19 17 26 22 31 28 21 25 27 30 29 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 19 17 26 22 31 28 21 25 27 30 29 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 33 18 20 23 24\n",
      "I 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "SQRT_Y 18 19 20 24 25 26 30 31 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 19 20 24 25 26 30 31 32\n",
      "Y 27\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 27\n",
      "CZ 20 22 25 28 32 33 21 19 27 24 29 26\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 20 22 25 28 32 33 21 19 27 24 29 26\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 17 18 23 30 31\n",
      "I 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "SQRT_Y 4 6 10 12 21 23 27 29 0 5 11 16 17 22 28 33\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 21 23 27 29 17 22 28 33\n",
      "Y 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 32 4 6 10 12 21 27 29 0 5 11 16 17 22 28 33\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 19 20 24 25 26 30 31 32 21 27 29 17 22 28 33\n",
      "X_ERROR(0.00940132) 33 17 21 22 23 27 28 29\n",
      "I 33 17 21 22 23 27 28 29\n",
      "M 0 4 5 6 10 11 12 16 17 21 22 23 27 28 29 33\n",
      "DETECTOR rec[-15] rec[-7]\n",
      "DETECTOR rec[-13] rec[-5]\n",
      "DETECTOR rec[-12] rec[-4]\n",
      "DETECTOR rec[-10] rec[-2]\n",
      "DETECTOR rec[-16] rec[-8]\n",
      "DETECTOR rec[-14] rec[-6]\n",
      "DETECTOR rec[-11] rec[-3]\n",
      "DETECTOR rec[-9] rec[-1]\n",
      "SQRT_Y 2 7 9 14\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 2 7 9 14\n",
      "SQRT_Y 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 33 17 21 22 23 27 28 29\n",
      "I 1 2 3 7 8 9 13 14 15 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 33 17 21 22 23 27 28 29\n",
      "I 1 2 3 7 8 9 13 14 15 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 33 17 21 22 23 27 28 29\n",
      "I 1 2 3 7 8 9 13 14 15 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "PAULI_CHANNEL_1(1.80583e-06, 6.37008e-06, 0.000232262) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "PAULI_CHANNEL_1(7.79472e-06, 4.40972e-06, 0.00047149) 33 17 21 22 23 27 28 29\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 33 17 21 22 23 27 28 29\n",
      "CZ 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_2(1.68007e-05, 0.000359326, 0.000615737, 1.68007e-05, 0, 0, 0, 0.000359326, 0, 0, 0, 0.000615737, 0, 0, 0.00125466) 1 18 2 19 3 20 7 24 8 25 9 26 13 30 14 31 15 32\n",
      "PAULI_CHANNEL_1(0.000104139, 1.35017e-05, 0.00190884) 33 17 21 22 23 27 28 29\n",
      "I 1 2 3 7 8 9 13 14 15 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      "SQRT_Y 2 7 9 14\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 2 7 9 14\n",
      "SQRT_Y 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 18 20 25 30 32\n",
      "SQRT_Y_DAG 1 3 8 13 15 18 20 25 30 32\n",
      "PAULI_CHANNEL_1(4.44575e-05, 0.000120258, 7.48173e-05) 1 3 8 13 15 18 20 25 30 32\n",
      "X_ERROR(0.00149899) 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "I 32 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31\n",
      "M 1 2 3 7 8 9 13 14 15 18 19 20 24 25 26 30 31 32\n",
      "DETECTOR rec[-18] rec[-17] rec[-15] rec[-14] rec[-33] rec[-25]\n",
      "DETECTOR rec[-16] rec[-13] rec[-31] rec[-23]\n",
      "DETECTOR rec[-15] rec[-12] rec[-30] rec[-22]\n",
      "DETECTOR rec[-14] rec[-13] rec[-11] rec[-10] rec[-28] rec[-20]\n",
      "DETECTOR rec[-9] rec[-8] rec[-6] rec[-5] rec[-25]\n",
      "DETECTOR rec[-7] rec[-4] rec[-23]\n",
      "DETECTOR rec[-6] rec[-3] rec[-22]\n",
      "DETECTOR rec[-5] rec[-4] rec[-2] rec[-1] rec[-20]\n",
      "OBSERVABLE_INCLUDE(0) rec[-15] rec[-14] rec[-13] rec[-6] rec[-5] rec[-4]\n",
      "len potential_lost_qubits: 650\n",
      "potential_lost_qubits: [1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 32.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 32.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 32.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 32.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 32.0, 0.0, 33.0, 4.0, 5.0, 6.0, 10.0, 11.0, 12.0, 16.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 0.0, 4.0, 5.0, 6.0, 10.0, 11.0, 12.0, 16.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 0.0, 4.0, 5.0, 6.0, 10.0, 11.0, 12.0, 16.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 0.0, 4.0, 5.0, 6.0, 10.0, 11.0, 12.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0, 33.0, 17.0, 21.0, 22.0, 23.0, 27.0, 28.0, 29.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 32.0, 1.0, 2.0, 3.0, 7.0, 8.0, 9.0, 13.0, 14.0, 15.0, 18.0, 19.0, 20.0, 24.0, 25.0, 26.0, 30.0, 31.0]\n",
      "loss_probabilities: [3.10644643e-03 3.10644643e-03 3.10644643e-03 3.10644643e-03\n",
      " 3.10644643e-03 3.10644643e-03 3.10644643e-03 3.10644643e-03\n",
      " 3.10644643e-03 3.10644643e-03 3.10644643e-03 3.10644643e-03\n",
      " 3.10644643e-03 3.10644643e-03 3.10644643e-03 3.10644643e-03\n",
      " 3.10644643e-03 3.10644643e-03 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 9.45010500e-04 9.45010500e-04\n",
      " 9.45010500e-04 9.45010500e-04 9.45010500e-04 9.45010500e-04\n",
      " 9.45010500e-04 9.45010500e-04 9.45010500e-04 9.45010500e-04\n",
      " 9.45010500e-04 9.45010500e-04 9.45010500e-04 9.45010500e-04\n",
      " 9.45010500e-04 9.45010500e-04 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 1.35872200e-03 1.35872200e-03 1.35872200e-03 1.35872200e-03\n",
      " 1.35872200e-03 1.35872200e-03 1.35872200e-03 1.35872200e-03\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 1.26183073e-05 1.26183073e-05\n",
      " 1.26183073e-05 1.26183073e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 3.46168948e-05 3.46168948e-05\n",
      " 3.46168948e-05 3.46168948e-05 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 1.65985784e-03 1.65985784e-03 1.65985784e-03 1.65985784e-03\n",
      " 9.25709423e-03 9.25709423e-03 9.25709423e-03 9.25709423e-03\n",
      " 9.25709423e-03 9.25709423e-03 9.25709423e-03 9.25709423e-03\n",
      " 9.25709423e-03 9.25709423e-03 9.25709423e-03 9.25709423e-03\n",
      " 9.25709423e-03 9.25709423e-03 9.25709423e-03 9.25709423e-03\n",
      " 9.25709423e-03 9.25709423e-03]\n",
      "final measurement_index = 34\n",
      "Preprocessing is done! it took 9.16s\n",
      "Decoder initialized, it took 9.20s for everything\n",
      "Shot: 0 \n",
      "Total loss decoder time for all shots 0.0262 sec.\n",
      "new method: convert ALL hyperedge matrix into binary took 0.001240 sec.\n",
      "Loss decoder is done! Now starting to decode with MLE\n",
      "MLE decoder took 0.056073s.\n",
      "for dx = 3, dy = 3, 2 cycles, 10 shots, we had 8 errors (logical error = 8.0e-01)\n",
      "infidelity 0.19999999999999996\n"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "import numpy as np\n",
    "num_rounds = 3\n",
    "distance = 3\n",
    "decoder_basis = 'XX'\n",
    "gate_ordering = ['N', 'Z']\n",
    "noise_params = {}\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': decoder_basis,\n",
    "            'bias_preserving_gates': 'False',\n",
    "            'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1000', 'LD_method': 'None',\n",
    "            'SSR': 'True', 'cycles': str(num_rounds - 1),\n",
    "            'ordering': gate_ordering,\n",
    "            'decoder': 'MLE',\n",
    "            'circuit_type': 'logical_CX_NL2_NCX4', 'Steane_type': 'None', 'printing': 'True', 'num_logicals': '2',\n",
    "            'loss_decoder': 'independent',\n",
    "            'obs_pos': 'd-1', 'n_r': '0'}\n",
    "# Load the experimental measurements\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "simulate_data = True\n",
    "\n",
    "if simulate_data:\n",
    "    detection_events_signs = None\n",
    "\n",
    "else:\n",
    "    # Load the theory circuit\n",
    "    _, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "    # Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "    detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "    # Find detection event signs\n",
    "    detection_events_signs = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "\n",
    "# Now let's decode!\n",
    "use_loss_decoding = True  # if False: use same DEM every shot, without utilizing SSR.\n",
    "use_independent_decoder = True  # if False: in every lifecycle, we just apply supercheck at the end. If True: we count the full lifecycle with different potential loss locations and corresponding Clifford propagations.\n",
    "use_independent_and_first_comb_decoder = False  # This is relevant only if use_independent_decoder=True. If False: use only independent lifecycles. If True: adds a single combination of lifecycles to the decoder.\n",
    "output_dir = '/Users/gefenbaranes/Documents/CX_experiment'\n",
    "num_shots = 10\n",
    "# DO IT\n",
    "predictions, observable_flips, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, distance, output_dir,\n",
    "                                                                    exp_measurements,\n",
    "                                                                    detection_events_signs, use_loss_decoding,\n",
    "                                                                    use_independent_decoder,\n",
    "                                                                    use_independent_and_first_comb_decoder,\n",
    "                                                                    simulate_data=simulate_data, logical_gaps=False,\n",
    "                                                                    noise_params=noise_params, num_shots=num_shots)\n",
    "logical_probability = np.mean(np.logical_xor(observable_flips, predictions))\n",
    "print('infidelity', 1-logical_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "96\n",
      "HI\n",
      "error(0.02106384901935120721) D0\n",
      "error(0.003937585939119162166) D0 D3\n",
      "error(0.005386906040064904852) D0 D3 D16\n",
      "error(0.01308907035188520626) D0 D4\n",
      "error(0.005386906040064904852) D0 D4 D14 D16\n",
      "error(0.001613988549653402015) D0 D4 D14 D38\n",
      "error(0.001613988549653402015) D0 D4 D14 D62\n",
      "error(0.0004795087940851329531) D0 D4 D16 D38\n",
      "error(0.0004795087940851329531) D0 D4 D16 D62\n",
      "error(0.005386906040064904852) D0 D12\n",
      "error(0.005651182936004832923) D0 D12 D14\n",
      "error(0.003001812865343429261) D0 D12 D36\n",
      "error(0.0004858738341382931071) D0 D12 D38\n",
      "error(0.003001812865343429261) D0 D12 D60\n",
      "error(0.0004858738341382931071) D0 D12 D62\n",
      "error(0.001254662563259255131) D0 D14 D38\n",
      "error(0.001254662563259255131) D0 D14 D62\n",
      "error(0.001613988549653402015) D0 D16 D24\n",
      "error(0.0004839127270703265501) D0 D16 D24 D36\n",
      "error(0.001254662563259255131) D0 D16 D24 D38\n",
      "error(0.0004858738341382931071) D0 D16 D28 D38\n",
      "error(0.001613988549653402015) D0 D16 D48\n",
      "error(0.0004839127270703265501) D0 D16 D48 D60\n",
      "error(0.001254662563259255131) D0 D16 D48 D62\n",
      "error(0.0004858738341382931071) D0 D16 D52 D62\n",
      "error(0.07730519990055415014) D0 D24\n",
      "error(0.001254662563259255131) D0 D24 D36\n",
      "error(0.00161748082292403287) D0 D24 D36 D38\n",
      "error(6.306092300909809018e-05) D0 D28\n",
      "error(0.0004795087940851329531) D0 D36\n",
      "error(0.0004858738341382931071) D0 D36 D38\n",
      "error(0.07730519990055415014) D0 D48\n",
      "error(0.001254662563259255131) D0 D48 D60\n",
      "error(0.00161748082292403287) D0 D48 D60 D62\n",
      "error(6.306092300909809018e-05) D0 D52\n",
      "error(0.0004795087940851329531) D0 D60\n",
      "error(0.0004858738341382931071) D0 D60 D62\n",
      "error(0.02106384901935120721) D1\n",
      "error(0.003937585939119162166) D1 D4\n",
      "error(0.005386906040064904852) D1 D4 D14 D17\n",
      "error(0.01308907035188520626) D1 D5\n",
      "error(0.005386906040064904852) D1 D5 D15 D17\n",
      "error(0.001613988549653402015) D1 D5 D15 D39\n",
      "error(0.001613988549653402015) D1 D5 D15 D63\n",
      "error(0.0004795087940851329531) D1 D5 D17 D39\n",
      "error(0.0004795087940851329531) D1 D5 D17 D63\n",
      "error(0.005386906040064904852) D1 D13 D14\n",
      "error(0.005651182936004832923) D1 D13 D15\n",
      "error(0.003001812865343429261) D1 D13 D37\n",
      "error(0.0004858738341382931071) D1 D13 D39\n",
      "error(0.003001812865343429261) D1 D13 D61\n",
      "error(0.0004858738341382931071) D1 D13 D63\n",
      "error(0.001613988549653402015) D1 D14 D17 D25\n",
      "error(0.001613988549653402015) D1 D14 D17 D49\n",
      "error(0.001254662563259255131) D1 D14 D25 D37\n",
      "error(0.0004795087940851329531) D1 D14 D37\n",
      "error(0.001254662563259255131) D1 D14 D49 D61\n",
      "error(0.0004795087940851329531) D1 D14 D61\n",
      "error(0.001254662563259255131) D1 D15 D39\n",
      "error(0.001254662563259255131) D1 D15 D63\n",
      "error(0.0004839127270703265501) D1 D17 D25 D37\n",
      "error(0.001254662563259255131) D1 D17 D25 D39\n",
      "error(0.0004858738341382931071) D1 D17 D29 D39\n",
      "error(0.0004839127270703265501) D1 D17 D49 D61\n",
      "error(0.001254662563259255131) D1 D17 D49 D63\n",
      "error(0.0004858738341382931071) D1 D17 D53 D63\n",
      "error(0.07730519990055415014) D1 D25\n",
      "error(0.00161748082292403287) D1 D25 D37 D39\n",
      "error(6.306092300909809018e-05) D1 D29\n",
      "error(0.0004858738341382931071) D1 D37 D39\n",
      "error(0.07730519990055415014) D1 D49\n",
      "error(0.00161748082292403287) D1 D49 D61 D63\n",
      "error(6.306092300909809018e-05) D1 D53\n",
      "error(0.0004858738341382931071) D1 D61 D63\n",
      "error(0.01557525419797519371) D2\n",
      "error(0.003937585939119162166) D2 D5\n",
      "error(0.005386906040064904852) D2 D5 D15\n",
      "error(0.005651182936004832923) D2 D15\n",
      "error(0.00286460109089109894) D2 D15 D26\n",
      "error(0.002984181283519387468) D2 D15 D50\n",
      "error(0.07962276524503333897) D2 D26\n",
      "error(0.07954716375263207184) D2 D50\n",
      "error(0.001613988549653402015) D3 D6 D16 D40 L0\n",
      "error(0.001613988549653402015) D3 D6 D16 D64 L0\n",
      "error(0.005386906040064904852) D3 D6 D16 L0\n",
      "error(0.0004795087940851329531) D3 D6 D40 L0\n",
      "error(0.0004795087940851329531) D3 D6 D64 L0\n",
      "error(0.01308907035188520626) D3 D6 L0\n",
      "error(0.0004795087940851329531) D3 D16 D24\n",
      "error(0.001254662563259255131) D3 D16 D24 D40\n",
      "error(0.0004795087940851329531) D3 D16 D48\n",
      "error(0.001254662563259255131) D3 D16 D48 D64\n",
      "error(0.003194142945961864904) D3 D24\n",
      "error(0.0006257027069137232039) D3 D24 D40\n",
      "error(0.07961905903172503129) D3 D27\n",
      "error(0.002868983996137042941) D3 D27 D40\n",
      "error(0.0004858738341382931071) D3 D30 D40 L0\n",
      "error(6.306092300909809018e-05) D3 D30 L0\n",
      "error(0.003194142945961864904) D3 D48\n",
      "error(0.0006257027069137232039) D3 D48 D64\n",
      "error(0.07984595603229283078) D3 D51\n",
      "error(0.002988563134507971671) D3 D51 D64\n",
      "error(0.0004858738341382931071) D3 D54 D64 L0\n",
      "error(6.306092300909809018e-05) D3 D54 L0\n",
      "error(0.0001380939862862409046) D4\n",
      "error(0.005386906040064904852) D4 D6 D16 D18 L0\n",
      "error(0.003937585939119162166) D4 D6 L0\n",
      "error(0.005386906040064904852) D4 D7 D17 D18 L0\n",
      "error(0.001613988549653402015) D4 D7 D17 D41 L0\n",
      "error(0.001613988549653402015) D4 D7 D17 D65 L0\n",
      "error(0.0004795087940851329531) D4 D7 D18 D41 L0\n",
      "error(0.0004795087940851329531) D4 D7 D18 D65 L0\n",
      "error(0.01308907035188520626) D4 D7 L0\n",
      "error(0.0004795087940851329531) D4 D14 D17 D25\n",
      "error(0.0004795087940851329531) D4 D14 D17 D49\n",
      "error(0.001254662563259255131) D4 D14 D25 D38\n",
      "error(0.0004858738341382931071) D4 D14 D25 D41\n",
      "error(0.0004839127270703265501) D4 D14 D38\n",
      "error(0.001254662563259255131) D4 D14 D49 D62\n",
      "error(0.0004858738341382931071) D4 D14 D49 D65\n",
      "error(0.0004839127270703265501) D4 D14 D62\n",
      "error(0.001613988549653402015) D4 D16 D18 D28\n",
      "error(0.001613988549653402015) D4 D16 D18 D52\n",
      "error(0.001254662563259255131) D4 D16 D28 D38\n",
      "error(0.001254662563259255131) D4 D16 D52 D62\n",
      "error(0.001254662563259255131) D4 D17 D25 D41\n",
      "error(0.001254662563259255131) D4 D17 D49 D65\n",
      "error(0.0004839127270703265501) D4 D18 D28 D38\n",
      "error(0.001254662563259255131) D4 D18 D28 D41\n",
      "error(0.0004858738341382931071) D4 D18 D31 D41 L0\n",
      "error(0.0004839127270703265501) D4 D18 D52 D62\n",
      "error(0.001254662563259255131) D4 D18 D52 D65\n",
      "error(0.0004858738341382931071) D4 D18 D55 D65 L0\n",
      "error(0.001904153805593251621) D4 D25\n",
      "error(0.0004858738341382931071) D4 D25 D38 D41\n",
      "error(0.07730519990055415014) D4 D28\n",
      "error(0.00161748082292403287) D4 D28 D38 D41\n",
      "error(6.306092300909809018e-05) D4 D31 L0\n",
      "error(0.001904153805593251621) D4 D49\n",
      "error(0.0004858738341382931071) D4 D49 D62 D65\n",
      "error(0.07730519990055415014) D4 D52\n",
      "error(0.00161748082292403287) D4 D52 D62 D65\n",
      "error(6.306092300909809018e-05) D4 D55 L0\n",
      "error(0.0001380939862862409046) D5\n",
      "error(0.005386906040064904852) D5 D7 D17 D19 L0\n",
      "error(0.003937585939119162166) D5 D7 L0\n",
      "error(0.005651182936004832923) D5 D8 D19 L0\n",
      "error(0.01557525419797519371) D5 D8 L0\n",
      "error(0.0006193394486247398968) D5 D15 D26\n",
      "error(0.001254662563259255131) D5 D15 D26 D39\n",
      "error(0.0004839127270703265501) D5 D15 D39\n",
      "error(0.0006193394486247398968) D5 D15 D50\n",
      "error(0.001254662563259255131) D5 D15 D50 D63\n",
      "error(0.0004839127270703265501) D5 D15 D63\n",
      "error(0.001613988549653402015) D5 D17 D19 D29\n",
      "error(0.001613988549653402015) D5 D17 D19 D53\n",
      "error(0.001254662563259255131) D5 D17 D29 D39\n",
      "error(0.001254662563259255131) D5 D17 D53 D63\n",
      "error(0.001254662563259255131) D5 D19 D29\n",
      "error(0.0004839127270703265501) D5 D19 D29 D39\n",
      "error(0.0004858738341382931071) D5 D19 D32 L0\n",
      "error(0.001254662563259255131) D5 D19 D53\n",
      "error(0.0004839127270703265501) D5 D19 D53 D63\n",
      "error(0.0004858738341382931071) D5 D19 D56 L0\n",
      "error(0.003194142945961865338) D5 D26\n",
      "error(0.0004858738341382931071) D5 D26 D39\n",
      "error(0.07730519990055415014) D5 D29\n",
      "error(0.00161748082292403287) D5 D29 D39\n",
      "error(6.306092300909809018e-05) D5 D32 L0\n",
      "error(0.003194142945961865338) D5 D50\n",
      "error(0.0004858738341382931071) D5 D50 D63\n",
      "error(0.07730519990055415014) D5 D53\n",
      "error(0.00161748082292403287) D5 D53 D63\n",
      "error(6.306092300909809018e-05) D5 D56 L0\n",
      "error(0.003937585939119162166) D6 D9\n",
      "error(0.005386906040064904852) D6 D9 D20\n",
      "error(0.01308907035188520626) D6 D10\n",
      "error(0.005386906040064904852) D6 D10 D18 D20\n",
      "error(0.001613988549653402015) D6 D10 D18 D42\n",
      "error(0.001613988549653402015) D6 D10 D18 D66\n",
      "error(0.0004795087940851329531) D6 D10 D20 D42\n",
      "error(0.0004795087940851329531) D6 D10 D20 D66\n",
      "error(0.0004795087940851329531) D6 D16 D18 D28 L0\n",
      "error(0.0004795087940851329531) D6 D16 D18 D52 L0\n",
      "error(0.0004839127270703265501) D6 D16 D24 D40 L0\n",
      "error(0.001254662563259255131) D6 D16 D28 D40 L0\n",
      "error(0.0004858738341382931071) D6 D16 D28 D42 L0\n",
      "error(0.0004839127270703265501) D6 D16 D48 D64 L0\n",
      "error(0.001254662563259255131) D6 D16 D52 D64 L0\n",
      "error(0.0004858738341382931071) D6 D16 D52 D66 L0\n",
      "error(0.001254662563259255131) D6 D18 D28 D42 L0\n",
      "error(0.001254662563259255131) D6 D18 D52 D66 L0\n",
      "error(0.001613988549653402015) D6 D20 D30\n",
      "error(0.0004839127270703265501) D6 D20 D30 D40\n",
      "error(0.001254662563259255131) D6 D20 D30 D42\n",
      "error(0.0004858738341382931071) D6 D20 D34 D42\n",
      "error(0.001613988549653402015) D6 D20 D54\n",
      "error(0.0004839127270703265501) D6 D20 D54 D64\n",
      "error(0.001254662563259255131) D6 D20 D54 D66\n",
      "error(0.0004858738341382931071) D6 D20 D58 D66\n",
      "error(6.90517612888575424e-05) D6 D24 L0\n",
      "error(0.0004858738341382931071) D6 D28 D40 D42 L0\n",
      "error(0.001904153805593251621) D6 D28 L0\n",
      "error(0.07730519990055415014) D6 D30\n",
      "error(0.001254662563259255131) D6 D30 D40\n",
      "error(0.00161748082292403287) D6 D30 D40 D42\n",
      "error(6.306092300909809018e-05) D6 D34\n",
      "error(6.90517612888575424e-05) D6 D48 L0\n",
      "error(0.0004858738341382931071) D6 D52 D64 D66 L0\n",
      "error(0.001904153805593251621) D6 D52 L0\n",
      "error(0.07730519990055415014) D6 D54\n",
      "error(0.001254662563259255131) D6 D54 D64\n",
      "error(0.00161748082292403287) D6 D54 D64 D66\n",
      "error(6.306092300909809018e-05) D6 D58\n",
      "error(0.003937585939119162166) D7 D10\n",
      "error(0.005386906040064904852) D7 D10 D18 D21\n",
      "error(0.01308907035188520626) D7 D11\n",
      "error(0.005386906040064904852) D7 D11 D19 D21\n",
      "error(0.001613988549653402015) D7 D11 D19 D43\n",
      "error(0.001613988549653402015) D7 D11 D19 D67\n",
      "error(0.0004795087940851329531) D7 D11 D21 D43\n",
      "error(0.0004795087940851329531) D7 D11 D21 D67\n",
      "error(0.0004795087940851329531) D7 D17 D19 D29 L0\n",
      "error(0.0004795087940851329531) D7 D17 D19 D53 L0\n",
      "error(0.0004839127270703265501) D7 D17 D25 D41 L0\n",
      "error(0.001254662563259255131) D7 D17 D29 D41 L0\n",
      "error(0.0004858738341382931071) D7 D17 D29 D43 L0\n",
      "error(0.0004839127270703265501) D7 D17 D49 D65 L0\n",
      "error(0.001254662563259255131) D7 D17 D53 D65 L0\n",
      "error(0.0004858738341382931071) D7 D17 D53 D67 L0\n",
      "error(0.001613988549653402015) D7 D18 D21 D31\n",
      "error(0.001613988549653402015) D7 D18 D21 D55\n",
      "error(0.001254662563259255131) D7 D18 D31 D41\n",
      "error(0.001254662563259255131) D7 D18 D55 D65\n",
      "error(0.001254662563259255131) D7 D19 D29 D43 L0\n",
      "error(0.001254662563259255131) D7 D19 D53 D67 L0\n",
      "error(0.0004839127270703265501) D7 D21 D31 D41\n",
      "error(0.001254662563259255131) D7 D21 D31 D43\n",
      "error(0.0004858738341382931071) D7 D21 D35 D43\n",
      "error(0.0004839127270703265501) D7 D21 D55 D65\n",
      "error(0.001254662563259255131) D7 D21 D55 D67\n",
      "error(0.0004858738341382931071) D7 D21 D59 D67\n",
      "error(6.90517612888575424e-05) D7 D25 L0\n",
      "error(0.0004858738341382931071) D7 D29 D41 D43 L0\n",
      "error(0.001904153805593251621) D7 D29 L0\n",
      "error(0.07730519990055415014) D7 D31\n",
      "error(0.00161748082292403287) D7 D31 D41 D43\n",
      "error(6.306092300909809018e-05) D7 D35\n",
      "error(6.90517612888575424e-05) D7 D49 L0\n",
      "error(0.0004858738341382931071) D7 D53 D65 D67 L0\n",
      "error(0.001904153805593251621) D7 D53 L0\n",
      "error(0.07730519990055415014) D7 D55\n",
      "error(0.00161748082292403287) D7 D55 D65 D67\n",
      "error(6.306092300909809018e-05) D7 D59\n",
      "error(0.003937585939119162166) D8 D11\n",
      "error(0.005386906040064904852) D8 D11 D19\n",
      "error(0.00286460109089109894) D8 D19 D32\n",
      "error(0.002984181283519387468) D8 D19 D56\n",
      "error(0.07962276524503333897) D8 D32\n",
      "error(0.07954716375263207184) D8 D56\n",
      "error(0.01338227556884971289) D9\n",
      "error(0.005386906040064904852) D9 D20\n",
      "error(0.0004795087940851329531) D9 D20 D30\n",
      "error(0.001254662563259255131) D9 D20 D30 D44\n",
      "error(0.001613988549653402015) D9 D20 D44\n",
      "error(0.0004795087940851329531) D9 D20 D54\n",
      "error(0.001254662563259255131) D9 D20 D54 D68\n",
      "error(0.001613988549653402015) D9 D20 D68\n",
      "error(0.003194142945961864904) D9 D30\n",
      "error(0.0006257027069137232039) D9 D30 D44\n",
      "error(0.07961905903172503129) D9 D33\n",
      "error(0.002868983996137042941) D9 D33 D44\n",
      "error(0.0006193394486247398968) D9 D44\n",
      "error(0.003194142945961864904) D9 D54\n",
      "error(0.0006257027069137232039) D9 D54 D68\n",
      "error(0.07984595603229283078) D9 D57\n",
      "error(0.002988563134507971671) D9 D57 D68\n",
      "error(0.0006193394486247398968) D9 D68\n",
      "error(0.01721447378774223699) D10\n",
      "error(0.0004795087940851329531) D10 D18 D21 D31\n",
      "error(0.0004795087940851329531) D10 D18 D21 D55\n",
      "error(0.0004839127270703265501) D10 D18 D28 D42 L0\n",
      "error(0.001254662563259255131) D10 D18 D31 D42\n",
      "error(0.0004858738341382931071) D10 D18 D31 D45\n",
      "error(0.0004839127270703265501) D10 D18 D52 D66 L0\n",
      "error(0.001254662563259255131) D10 D18 D55 D66\n",
      "error(0.0004858738341382931071) D10 D18 D55 D69\n",
      "error(0.005386906040064904852) D10 D20 D22\n",
      "error(0.001613988549653402015) D10 D20 D22 D34\n",
      "error(0.001613988549653402015) D10 D20 D22 D58\n",
      "error(0.001254662563259255131) D10 D20 D34 D42\n",
      "error(0.001254662563259255131) D10 D20 D58 D66\n",
      "error(0.005386906040064904852) D10 D21 D22\n",
      "error(0.001254662563259255131) D10 D21 D31 D45\n",
      "error(0.001613988549653402015) D10 D21 D45\n",
      "error(0.001254662563259255131) D10 D21 D55 D69\n",
      "error(0.001613988549653402015) D10 D21 D69\n",
      "error(0.0004839127270703265501) D10 D22 D34 D42\n",
      "error(0.001254662563259255131) D10 D22 D34 D45\n",
      "error(0.0006193394486247398968) D10 D22 D45\n",
      "error(0.0004839127270703265501) D10 D22 D58 D66\n",
      "error(0.001254662563259255131) D10 D22 D58 D69\n",
      "error(0.0006193394486247398968) D10 D22 D69\n",
      "error(6.90517612888575424e-05) D10 D28 L0\n",
      "error(0.001904153805593251621) D10 D31\n",
      "error(0.0004858738341382931071) D10 D31 D42 D45\n",
      "error(0.07730519990055415014) D10 D34\n",
      "error(0.00161748082292403287) D10 D34 D42 D45\n",
      "error(6.90517612888575424e-05) D10 D52 L0\n",
      "error(0.001904153805593251621) D10 D55\n",
      "error(0.0004858738341382931071) D10 D55 D66 D69\n",
      "error(0.07730519990055415014) D10 D58\n",
      "error(0.00161748082292403287) D10 D58 D66 D69\n",
      "error(0.01967959318291046325) D11\n",
      "error(0.0004839127270703265501) D11 D19 D29 D43 L0\n",
      "error(0.0006193394486247398968) D11 D19 D32\n",
      "error(0.001254662563259255131) D11 D19 D32 D43\n",
      "error(0.0004839127270703265501) D11 D19 D53 D67 L0\n",
      "error(0.0006193394486247398968) D11 D19 D56\n",
      "error(0.001254662563259255131) D11 D19 D56 D67\n",
      "error(0.005386906040064904852) D11 D21 D23\n",
      "error(0.001613988549653402015) D11 D21 D23 D35\n",
      "error(0.001613988549653402015) D11 D21 D23 D59\n",
      "error(0.001254662563259255131) D11 D21 D35 D43\n",
      "error(0.001254662563259255131) D11 D21 D59 D67\n",
      "error(0.005927910096505960118) D11 D23\n",
      "error(0.001254662563259255131) D11 D23 D35\n",
      "error(0.0004839127270703265501) D11 D23 D35 D43\n",
      "error(0.001254662563259255131) D11 D23 D59\n",
      "error(0.0004839127270703265501) D11 D23 D59 D67\n",
      "error(6.90517612888575424e-05) D11 D29 L0\n",
      "error(0.003194142945961865338) D11 D32\n",
      "error(0.0004858738341382931071) D11 D32 D43\n",
      "error(0.07730519990055415014) D11 D35\n",
      "error(0.00161748082292403287) D11 D35 D43\n",
      "error(6.90517612888575424e-05) D11 D53 L0\n",
      "error(0.003194142945961865338) D11 D56\n",
      "error(0.0004858738341382931071) D11 D56 D67\n",
      "error(0.07730519990055415014) D11 D59\n",
      "error(0.00161748082292403287) D11 D59 D67\n",
      "error(0.003937585939119163034) D12\n",
      "error(0.01557525419797519024) D12 D14\n",
      "error(0.07950670706250226316) D12 D36\n",
      "error(6.306092300909809018e-05) D12 D38\n",
      "error(0.07950670706250226316) D12 D60\n",
      "error(6.306092300909809018e-05) D12 D62\n",
      "error(0.003937585939119163034) D13 D14\n",
      "error(0.01557525419797519024) D13 D15\n",
      "error(0.07950670706250226316) D13 D37\n",
      "error(6.306092300909809018e-05) D13 D39\n",
      "error(0.07950670706250226316) D13 D61\n",
      "error(6.306092300909809018e-05) D13 D63\n",
      "error(0.003937585939119163034) D14 D16\n",
      "error(0.01308907035188520626) D14 D17\n",
      "error(0.0006257027069137232039) D14 D25 D37\n",
      "error(0.00161748082292403287) D14 D25 D38\n",
      "error(0.003194142945961864904) D14 D37\n",
      "error(0.07730519990055415014) D14 D38\n",
      "error(6.306092300909809018e-05) D14 D41\n",
      "error(0.0006257027069137232039) D14 D49 D61\n",
      "error(0.00161748082292403287) D14 D49 D62\n",
      "error(0.003194142945961864904) D14 D61\n",
      "error(0.07730519990055415014) D14 D62\n",
      "error(6.306092300909809018e-05) D14 D65\n",
      "error(0.02357231963504426847) D15\n",
      "error(0.003937585939119163034) D15 D17\n",
      "error(0.0006257027069137232039) D15 D26\n",
      "error(0.00161748082292403287) D15 D26 D39\n",
      "error(0.07730519990055415014) D15 D39\n",
      "error(0.0006257027069137232039) D15 D50\n",
      "error(0.00161748082292403287) D15 D50 D63\n",
      "error(0.07730519990055415014) D15 D63\n",
      "error(0.01692357761225692092) D16\n",
      "error(0.01308907035188520626) D16 D18\n",
      "error(0.0004858738341382931071) D16 D24 D28 D38\n",
      "error(0.00161748082292403287) D16 D24 D28 D40\n",
      "error(6.90517612888575424e-05) D16 D36\n",
      "error(0.001904153805593251621) D16 D38\n",
      "error(0.07730519990055415014) D16 D40\n",
      "error(6.306092300909809018e-05) D16 D42\n",
      "error(0.0004858738341382931071) D16 D48 D52 D62\n",
      "error(0.00161748082292403287) D16 D48 D52 D64\n",
      "error(6.90517612888575424e-05) D16 D60\n",
      "error(0.001904153805593251621) D16 D62\n",
      "error(0.07730519990055415014) D16 D64\n",
      "error(6.306092300909809018e-05) D16 D66\n",
      "error(0.003937585939119163034) D17 D18\n",
      "error(0.01308907035188520626) D17 D19\n",
      "error(0.0004858738341382931071) D17 D25 D29 D39\n",
      "error(0.00161748082292403287) D17 D25 D29 D41\n",
      "error(6.90517612888575424e-05) D17 D37\n",
      "error(0.001904153805593251621) D17 D39\n",
      "error(0.07730519990055415014) D17 D41\n",
      "error(6.306092300909809018e-05) D17 D43\n",
      "error(0.0004858738341382931071) D17 D49 D53 D63\n",
      "error(0.00161748082292403287) D17 D49 D53 D65\n",
      "error(6.90517612888575424e-05) D17 D61\n",
      "error(0.001904153805593251621) D17 D63\n",
      "error(0.07730519990055415014) D17 D65\n",
      "error(6.306092300909809018e-05) D17 D67\n",
      "error(0.003937585939119163034) D18 D20\n",
      "error(0.01308907035188520626) D18 D21\n",
      "error(0.0004858738341382931071) D18 D28 D31 D41 L0\n",
      "error(0.00161748082292403287) D18 D28 D31 D42 L0\n",
      "error(6.90517612888575424e-05) D18 D38\n",
      "error(0.001904153805593251621) D18 D41\n",
      "error(0.07730519990055415014) D18 D42\n",
      "error(6.306092300909809018e-05) D18 D45\n",
      "error(0.0004858738341382931071) D18 D52 D55 D65 L0\n",
      "error(0.00161748082292403287) D18 D52 D55 D66 L0\n",
      "error(6.90517612888575424e-05) D18 D62\n",
      "error(0.001904153805593251621) D18 D65\n",
      "error(0.07730519990055415014) D18 D66\n",
      "error(6.306092300909809018e-05) D18 D69\n",
      "error(0.02109495576214315965) D19\n",
      "error(0.003937585939119163034) D19 D21\n",
      "error(0.00161748082292403287) D19 D29 D32 D43 L0\n",
      "error(0.0004858738341382931071) D19 D29 D32 L0\n",
      "error(6.90517612888575424e-05) D19 D39\n",
      "error(0.07730519990055415014) D19 D43\n",
      "error(0.00161748082292403287) D19 D53 D56 D67 L0\n",
      "error(0.0004858738341382931071) D19 D53 D56 L0\n",
      "error(6.90517612888575424e-05) D19 D63\n",
      "error(0.07730519990055415014) D19 D67\n",
      "error(0.01692357761225692092) D20\n",
      "error(0.01308907035188520626) D20 D22\n",
      "error(0.0004795087940851329531) D20 D22 D34\n",
      "error(0.0004795087940851329531) D20 D22 D58\n",
      "error(0.0004858738341382931071) D20 D30 D34 D42\n",
      "error(0.00161748082292403287) D20 D30 D34 D44\n",
      "error(0.0004839127270703265501) D20 D30 D44\n",
      "error(0.001254662563259255131) D20 D34 D44\n",
      "error(0.0004858738341382931071) D20 D34 D46\n",
      "error(6.90517612888575424e-05) D20 D40\n",
      "error(0.001904153805593251621) D20 D42\n",
      "error(0.07730519990055415014) D20 D44\n",
      "error(6.306092300909809018e-05) D20 D46\n",
      "error(0.0004858738341382931071) D20 D54 D58 D66\n",
      "error(0.00161748082292403287) D20 D54 D58 D68\n",
      "error(0.0004839127270703265501) D20 D54 D68\n",
      "error(0.001254662563259255131) D20 D58 D68\n",
      "error(0.0004858738341382931071) D20 D58 D70\n",
      "error(6.90517612888575424e-05) D20 D64\n",
      "error(0.001904153805593251621) D20 D66\n",
      "error(0.07730519990055415014) D20 D68\n",
      "error(6.306092300909809018e-05) D20 D70\n",
      "error(0.003937585939119163034) D21 D22\n",
      "error(0.01308907035188520626) D21 D23\n",
      "error(0.0004795087940851329531) D21 D23 D35\n",
      "error(0.0004795087940851329531) D21 D23 D59\n",
      "error(0.0004858738341382931071) D21 D31 D35 D43\n",
      "error(0.00161748082292403287) D21 D31 D35 D45\n",
      "error(0.0004839127270703265501) D21 D31 D45\n",
      "error(0.001254662563259255131) D21 D35 D45\n",
      "error(0.0004858738341382931071) D21 D35 D47\n",
      "error(6.90517612888575424e-05) D21 D41\n",
      "error(0.001904153805593251621) D21 D43\n",
      "error(0.07730519990055415014) D21 D45\n",
      "error(6.306092300909809018e-05) D21 D47\n",
      "error(0.0004858738341382931071) D21 D55 D59 D67\n",
      "error(0.00161748082292403287) D21 D55 D59 D69\n",
      "error(0.0004839127270703265501) D21 D55 D69\n",
      "error(0.001254662563259255131) D21 D59 D69\n",
      "error(0.0004858738341382931071) D21 D59 D71\n",
      "error(6.90517612888575424e-05) D21 D65\n",
      "error(0.001904153805593251621) D21 D67\n",
      "error(0.07730519990055415014) D21 D69\n",
      "error(6.306092300909809018e-05) D21 D71\n",
      "error(0.0004858738341382931071) D22 D34 D45\n",
      "error(0.003006194560886328061) D22 D34 D46\n",
      "error(6.90517612888575424e-05) D22 D42\n",
      "error(0.003194142945961865338) D22 D45\n",
      "error(0.07950299982597874848) D22 D46\n",
      "error(0.0004858738341382931071) D22 D58 D69\n",
      "error(0.003006194560886328061) D22 D58 D70\n",
      "error(6.90517612888575424e-05) D22 D66\n",
      "error(0.003194142945961865338) D22 D69\n",
      "error(0.07950299982597874848) D22 D70\n",
      "error(0.01042674622869979931) D23\n",
      "error(0.0004858738341382931071) D23 D35\n",
      "error(0.003006194560886328061) D23 D35 D47\n",
      "error(6.90517612888575424e-05) D23 D43\n",
      "error(0.07950299982597874848) D23 D47\n",
      "error(0.0004858738341382931071) D23 D59\n",
      "error(0.003006194560886328061) D23 D59 D71\n",
      "error(6.90517612888575424e-05) D23 D67\n",
      "error(0.07950299982597874848) D23 D71\n",
      "error(0.02002536136475245934) D24\n",
      "error(0.003140467490475105927) D24 D27\n",
      "error(0.001049919327853609998) D24 D27 D40\n",
      "error(0.0008448506463430102177) D24 D27 D40 D64\n",
      "error(0.0004579111624201266922) D24 D27 D48 D51\n",
      "error(0.0007970774013887247603) D24 D27 D48 D51 D64\n",
      "error(0.003754550521141458708) D24 D27 D64\n",
      "error(0.01245408967105934503) D24 D28\n",
      "error(0.0009298737588559140939) D24 D28 D38 D40\n",
      "error(0.0007247557385687331856) D24 D28 D38 D40 D62 D64\n",
      "error(0.001613988549653402015) D24 D28 D38 D62\n",
      "error(0.0004795087940851329531) D24 D28 D40 D64\n",
      "error(0.009052504056019740342) D24 D28 D48 D52\n",
      "error(0.001613988549653402015) D24 D28 D48 D52 D62\n",
      "error(0.0009171549130202406776) D24 D28 D48 D52 D62 D64\n",
      "error(0.0004795087940851329531) D24 D28 D48 D52 D64\n",
      "error(0.003754550521141458708) D24 D28 D62 D64\n",
      "error(0.001209243819344544505) D24 D36\n",
      "error(0.001049919327853609998) D24 D36 D38\n",
      "error(0.000978220345502307017) D24 D36 D38 D60 D62\n",
      "error(0.003585204557301164673) D24 D36 D60\n",
      "error(0.001739317181977227331) D24 D38 D62\n",
      "error(0.0004839127270703265501) D24 D38 D62 D73\n",
      "error(0.00286460109089109894) D24 D40 D64 D72\n",
      "error(0.01272591826735349797) D24 D48\n",
      "error(0.003895862283488581938) D24 D48 D60\n",
      "error(0.0009304598651229550616) D24 D48 D60 D62\n",
      "error(0.001739317181977227331) D24 D48 D62\n",
      "error(0.0004839127270703265501) D24 D48 D62 D73 D85\n",
      "error(0.00286460109089109894) D24 D48 D64 D72 D84\n",
      "error(0.08014146912642822196) D24 D48 D72 D84\n",
      "error(6.90517612888575424e-05) D24 D48 D73 D85\n",
      "error(0.003754550521141458708) D24 D60\n",
      "error(0.003754550521141458708) D24 D60 D62\n",
      "error(0.08014146912642822196) D24 D72\n",
      "error(6.90517612888575424e-05) D24 D73\n",
      "error(0.01820552155752825155) D25\n",
      "error(0.003140467490475105927) D25 D28\n",
      "error(0.001049919327853609998) D25 D28 D38 D41\n",
      "error(0.0008448506463430102177) D25 D28 D38 D41 D62 D65\n",
      "error(0.0004579111624201266922) D25 D28 D49 D52\n",
      "error(0.0007970774013887247603) D25 D28 D49 D52 D62 D65\n",
      "error(0.003754550521141458708) D25 D28 D62 D65\n",
      "error(0.01245408967105934503) D25 D29\n",
      "error(0.0009298737588559140939) D25 D29 D39 D41\n",
      "error(0.0007247557385687331856) D25 D29 D39 D41 D63 D65\n",
      "error(0.001613988549653402015) D25 D29 D39 D63\n",
      "error(0.0004795087940851329531) D25 D29 D41 D65\n",
      "error(0.009052504056019740342) D25 D29 D49 D53\n",
      "error(0.001613988549653402015) D25 D29 D49 D53 D63\n",
      "error(0.0009171549130202406776) D25 D29 D49 D53 D63 D65\n",
      "error(0.0004795087940851329531) D25 D29 D49 D53 D65\n",
      "error(0.003754550521141458708) D25 D29 D63 D65\n",
      "error(0.0009298737588559140939) D25 D37 D38\n",
      "error(0.0007247557385687331856) D25 D37 D38 D61 D62\n",
      "error(0.001049919327853609998) D25 D37 D39\n",
      "error(0.000978220345502307017) D25 D37 D39 D61 D63\n",
      "error(0.00286460109089109894) D25 D37 D61\n",
      "error(0.001613988549653402015) D25 D38 D41 D62 D65 D73\n",
      "error(0.0006193394486247398968) D25 D38 D62\n",
      "error(0.001737360995964502353) D25 D38 D62 D73\n",
      "error(0.001739317181977227331) D25 D39 D63\n",
      "error(0.0004839127270703265501) D25 D39 D63 D74\n",
      "error(0.001254662563259255131) D25 D41 D65 D73\n",
      "error(0.01212114914524411828) D25 D49\n",
      "error(0.002984181283519387468) D25 D49 D61\n",
      "error(0.0009171549130202406776) D25 D49 D61 D62\n",
      "error(0.0009304598651229550616) D25 D49 D61 D63\n",
      "error(0.0006193394486247398968) D25 D49 D62\n",
      "error(0.001613988549653402015) D25 D49 D62 D65 D73 D85\n",
      "error(0.001737360995964502353) D25 D49 D62 D73 D85\n",
      "error(0.001739317181977227331) D25 D49 D63\n",
      "error(0.0004839127270703265501) D25 D49 D63 D74 D86\n",
      "error(0.001254662563259255131) D25 D49 D65 D73 D85\n",
      "error(0.078675045959030937) D25 D49 D73 D85\n",
      "error(6.90517612888575424e-05) D25 D49 D74 D86\n",
      "error(0.003754550521141458708) D25 D61 D62\n",
      "error(0.003754550521141458708) D25 D61 D63\n",
      "error(0.07867504595903092313) D25 D73\n",
      "error(6.90517612888575424e-05) D25 D74\n",
      "error(0.0139932327595181389) D26\n",
      "error(0.003140467490475105927) D26 D29\n",
      "error(0.001049919327853609998) D26 D29 D39\n",
      "error(0.0008448506463430102177) D26 D29 D39 D63\n",
      "error(0.0004579111624201266922) D26 D29 D50 D53\n",
      "error(0.0007970774013887247603) D26 D29 D50 D53 D63\n",
      "error(0.003754550521141458708) D26 D29 D63\n",
      "error(0.0009298737588559140939) D26 D39\n",
      "error(0.0009978821854794927247) D26 D39 D63\n",
      "error(0.003001812865343429261) D26 D39 D63 D74\n",
      "error(0.01045496777672690232) D26 D50\n",
      "error(0.001190176108762410357) D26 D50 D63\n",
      "error(0.003001812865343429261) D26 D50 D63 D74 D86\n",
      "error(0.07950670706250226316) D26 D50 D74 D86\n",
      "error(0.003754550521141458708) D26 D63\n",
      "error(0.07950670706250226316) D26 D74\n",
      "error(0.002336404793295443483) D27 D30 D40 D64 L0\n",
      "error(0.001069578342836026126) D27 D30 D40 L0\n",
      "error(0.009523778141647495921) D27 D30 D51 D54\n",
      "error(0.00252818290761789655) D27 D30 D51 D54 D64\n",
      "error(0.003754550521141458708) D27 D30 D64 L0\n",
      "error(0.01415965267983385935) D27 D30 L0\n",
      "error(0.001872447887843717339) D27 D40 D64 D72\n",
      "error(0.0004839127270703265501) D27 D40 D64 D76\n",
      "error(0.001872447887843717339) D27 D51 D64 D72 D84\n",
      "error(0.0004839127270703265501) D27 D51 D64 D76 D88\n",
      "error(0.00367735298343462285) D27 D51 D72 D84\n",
      "error(0.08203491482172298177) D27 D51 D75 D87\n",
      "error(6.90517612888575424e-05) D27 D51 D76 D88\n",
      "error(0.00367735298343462285) D27 D72\n",
      "error(0.08203491482172299565) D27 D75\n",
      "error(6.90517612888575424e-05) D27 D76\n",
      "error(0.0008448506463430102177) D28 D30 D40 D42 D64 D66 L0\n",
      "error(0.001049919327853609998) D28 D30 D40 D42 L0\n",
      "error(0.0004579111624201266922) D28 D30 D52 D54\n",
      "error(0.0007970774013887247603) D28 D30 D52 D54 D64 D66\n",
      "error(0.003754550521141458708) D28 D30 D64 D66 L0\n",
      "error(0.003140467490475105927) D28 D30 L0\n",
      "error(0.0007247557385687331856) D28 D31 D41 D42 D65 D66 L0\n",
      "error(0.0009298737588559140939) D28 D31 D41 D42 L0\n",
      "error(0.001613988549653402015) D28 D31 D41 D65 L0\n",
      "error(0.0004795087940851329531) D28 D31 D42 D66 L0\n",
      "error(0.009052504056019740342) D28 D31 D52 D55\n",
      "error(0.001613988549653402015) D28 D31 D52 D55 D65\n",
      "error(0.0009171549130202406776) D28 D31 D52 D55 D65 D66\n",
      "error(0.0004795087940851329531) D28 D31 D52 D55 D66\n",
      "error(0.003754550521141458708) D28 D31 D65 D66 L0\n",
      "error(0.01245408967105934503) D28 D31 L0\n",
      "error(0.0004795087940851329531) D28 D38 D41 D62 D65 D73\n",
      "error(0.001254662563259255131) D28 D38 D62 D73\n",
      "error(0.001613988549653402015) D28 D40 D42 D64 D66 D76\n",
      "error(0.0004858738341382931071) D28 D40 D64 D72\n",
      "error(0.001737360995964502353) D28 D40 D64 D76\n",
      "error(0.001739317181977227331) D28 D41 D65 D73\n",
      "error(0.0004839127270703265501) D28 D41 D65 D77\n",
      "error(0.001254662563259255131) D28 D42 D66 D76\n",
      "error(0.0004795087940851329531) D28 D52 D62 D65 D73 D85\n",
      "error(0.001254662563259255131) D28 D52 D62 D73 D85\n",
      "error(0.001613988549653402015) D28 D52 D64 D66 D76 D88\n",
      "error(0.0004858738341382931071) D28 D52 D64 D72 D84\n",
      "error(0.001737360995964502353) D28 D52 D64 D76 D88\n",
      "error(0.001739317181977227331) D28 D52 D65 D73 D85\n",
      "error(0.0004839127270703265501) D28 D52 D65 D77 D89\n",
      "error(0.001254662563259255131) D28 D52 D66 D76 D88\n",
      "error(6.306092300909809018e-05) D28 D52 D72 D84\n",
      "error(0.002388618529765062018) D28 D52 D73 D85\n",
      "error(0.078675045959030937) D28 D52 D76 D88\n",
      "error(6.90517612888575424e-05) D28 D52 D77 D89\n",
      "error(6.306092300909809018e-05) D28 D72\n",
      "error(0.002388618529765062018) D28 D73\n",
      "error(0.07867504595903092313) D28 D76\n",
      "error(6.90517612888575424e-05) D28 D77\n",
      "error(0.0008448506463430102177) D29 D31 D41 D43 D65 D67 L0\n",
      "error(0.001049919327853609998) D29 D31 D41 D43 L0\n",
      "error(0.0004579111624201266922) D29 D31 D53 D55\n",
      "error(0.0007970774013887247603) D29 D31 D53 D55 D65 D67\n",
      "error(0.003754550521141458708) D29 D31 D65 D67 L0\n",
      "error(0.003140467490475105927) D29 D31 L0\n",
      "error(0.0008581575259910502115) D29 D32 D43 D67 L0\n",
      "error(0.0009298737588559140939) D29 D32 D43 L0\n",
      "error(0.01030750547204857537) D29 D32 D53 D56\n",
      "error(0.001050505293139540825) D29 D32 D53 D56 D67\n",
      "error(0.003754550521141458708) D29 D32 D67 L0\n",
      "error(0.01370039566690803116) D29 D32 L0\n",
      "error(0.001732968113879003761) D29 D39 D63 D74\n",
      "error(0.001613988549653402015) D29 D41 D43 D65 D67 D77\n",
      "error(0.0004858738341382931071) D29 D41 D65 D73\n",
      "error(0.001737360995964502353) D29 D41 D65 D77\n",
      "error(0.001254662563259255131) D29 D43 D67 D77\n",
      "error(0.001732968113879003761) D29 D53 D63 D74 D86\n",
      "error(0.001613988549653402015) D29 D53 D65 D67 D77 D89\n",
      "error(0.0004858738341382931071) D29 D53 D65 D73 D85\n",
      "error(0.001737360995964502353) D29 D53 D65 D77 D89\n",
      "error(0.001254662563259255131) D29 D53 D67 D77 D89\n",
      "error(6.306092300909809018e-05) D29 D53 D73 D85\n",
      "error(0.003816288466196525973) D29 D53 D74 D86\n",
      "error(0.078675045959030937) D29 D53 D77 D89\n",
      "error(6.306092300909809018e-05) D29 D73\n",
      "error(0.003816288466196525973) D29 D74\n",
      "error(0.07867504595903092313) D29 D77\n",
      "error(6.90517612888575424e-05) D30\n",
      "error(0.003140467490475105927) D30 D33\n",
      "error(0.001049919327853609998) D30 D33 D44\n",
      "error(0.0008448506463430102177) D30 D33 D44 D68\n",
      "error(0.0004579111624201266922) D30 D33 D54 D57\n",
      "error(0.0007970774013887247603) D30 D33 D54 D57 D68\n",
      "error(0.003754550521141458708) D30 D33 D68\n",
      "error(0.01245408967105934503) D30 D34\n",
      "error(0.0009298737588559140939) D30 D34 D42 D44\n",
      "error(0.0007247557385687331856) D30 D34 D42 D44 D66 D68\n",
      "error(0.001613988549653402015) D30 D34 D42 D66\n",
      "error(0.0004795087940851329531) D30 D34 D44 D68\n",
      "error(0.009052504056019740342) D30 D34 D54 D58\n",
      "error(0.001613988549653402015) D30 D34 D54 D58 D66\n",
      "error(0.0009171549130202406776) D30 D34 D54 D58 D66 D68\n",
      "error(0.0004795087940851329531) D30 D34 D54 D58 D68\n",
      "error(0.003754550521141458708) D30 D34 D66 D68\n",
      "error(0.0004795087940851329531) D30 D40 D42 D64 D66 D76 L0\n",
      "error(0.001254662563259255131) D30 D40 D64 D76 L0\n",
      "error(0.001739317181977227331) D30 D42 D66 D76 L0\n",
      "error(0.0004839127270703265501) D30 D42 D66 D79\n",
      "error(0.00286460109089109894) D30 D44 D68 D78\n",
      "error(0.0004795087940851329531) D30 D54 D64 D66 D76 D88\n",
      "error(0.001254662563259255131) D30 D54 D64 D76 D88\n",
      "error(0.001739317181977227331) D30 D54 D66 D76 D88\n",
      "error(0.0004839127270703265501) D30 D54 D66 D79 D91\n",
      "error(0.00286460109089109894) D30 D54 D68 D78 D90\n",
      "error(0.0005488855475171788801) D30 D54 D75 D87\n",
      "error(0.002388618529765062018) D30 D54 D76 D88\n",
      "error(0.08014146912642822196) D30 D54 D78 D90\n",
      "error(6.90517612888575424e-05) D30 D54 D79 D91\n",
      "error(0.0005488855475171788801) D30 D75 L0\n",
      "error(0.002388618529765062018) D30 D76 L0\n",
      "error(0.08014146912642822196) D30 D78\n",
      "error(6.90517612888575424e-05) D30 D79\n",
      "error(6.90517612888575424e-05) D31\n",
      "error(0.003140467490475105927) D31 D34\n",
      "error(0.001049919327853609998) D31 D34 D42 D45\n",
      "error(0.0008448506463430102177) D31 D34 D42 D45 D66 D69\n",
      "error(0.0004579111624201266922) D31 D34 D55 D58\n",
      "error(0.0007970774013887247603) D31 D34 D55 D58 D66 D69\n",
      "error(0.003754550521141458708) D31 D34 D66 D69\n",
      "error(0.01245408967105934503) D31 D35\n",
      "error(0.0009298737588559140939) D31 D35 D43 D45\n",
      "error(0.0007247557385687331856) D31 D35 D43 D45 D67 D69\n",
      "error(0.001613988549653402015) D31 D35 D43 D67\n",
      "error(0.0004795087940851329531) D31 D35 D45 D69\n",
      "error(0.009052504056019740342) D31 D35 D55 D59\n",
      "error(0.001613988549653402015) D31 D35 D55 D59 D67\n",
      "error(0.0009171549130202406776) D31 D35 D55 D59 D67 D69\n",
      "error(0.0004795087940851329531) D31 D35 D55 D59 D69\n",
      "error(0.003754550521141458708) D31 D35 D67 D69\n",
      "error(0.0004795087940851329531) D31 D41 D43 D65 D67 D77 L0\n",
      "error(0.001254662563259255131) D31 D41 D65 D77 L0\n",
      "error(0.001613988549653402015) D31 D42 D45 D66 D69 D79\n",
      "error(0.0004858738341382931071) D31 D42 D66 D76 L0\n",
      "error(0.001737360995964502353) D31 D42 D66 D79\n",
      "error(0.001739317181977227331) D31 D43 D67 D77 L0\n",
      "error(0.0004839127270703265501) D31 D43 D67 D80\n",
      "error(0.001254662563259255131) D31 D45 D69 D79\n",
      "error(0.0004795087940851329531) D31 D55 D65 D67 D77 D89\n",
      "error(0.001254662563259255131) D31 D55 D65 D77 D89\n",
      "error(0.001613988549653402015) D31 D55 D66 D69 D79 D91\n",
      "error(0.0004858738341382931071) D31 D55 D66 D76 D88\n",
      "error(0.001737360995964502353) D31 D55 D66 D79 D91\n",
      "error(0.001739317181977227331) D31 D55 D67 D77 D89\n",
      "error(0.0004839127270703265501) D31 D55 D67 D80 D92\n",
      "error(0.001254662563259255131) D31 D55 D69 D79 D91\n",
      "error(6.306092300909809018e-05) D31 D55 D76 D88\n",
      "error(0.002388618529765062018) D31 D55 D77 D89\n",
      "error(0.078675045959030937) D31 D55 D79 D91\n",
      "error(6.90517612888575424e-05) D31 D55 D80 D92\n",
      "error(6.306092300909809018e-05) D31 D76 L0\n",
      "error(0.002388618529765062018) D31 D77 L0\n",
      "error(0.07867504595903092313) D31 D79\n",
      "error(6.90517612888575424e-05) D31 D80\n",
      "error(0.003140467490475105927) D32 D35\n",
      "error(0.001049919327853609998) D32 D35 D43\n",
      "error(0.0008448506463430102177) D32 D35 D43 D67\n",
      "error(0.0004579111624201266922) D32 D35 D56 D59\n",
      "error(0.0007970774013887247603) D32 D35 D56 D59 D67\n",
      "error(0.003754550521141458708) D32 D35 D67\n",
      "error(0.0004858738341382931071) D32 D43 D67 D77 L0\n",
      "error(0.003001812865343429261) D32 D43 D67 D80\n",
      "error(0.0004858738341382931071) D32 D56 D67 D77 D89\n",
      "error(0.003001812865343429261) D32 D56 D67 D80 D92\n",
      "error(6.306092300909809018e-05) D32 D56 D77 D89\n",
      "error(0.07950670706250226316) D32 D56 D80 D92\n",
      "error(6.306092300909809018e-05) D32 D77 L0\n",
      "error(0.07950670706250226316) D32 D80\n",
      "error(0.01415965267983385935) D33\n",
      "error(0.001069578342836026126) D33 D44\n",
      "error(0.002336404793295443483) D33 D44 D68\n",
      "error(0.001872447887843717339) D33 D44 D68 D78\n",
      "error(0.0004839127270703265501) D33 D44 D68 D82\n",
      "error(0.009523778141647495921) D33 D57\n",
      "error(0.00252818290761789655) D33 D57 D68\n",
      "error(0.001872447887843717339) D33 D57 D68 D78 D90\n",
      "error(0.0004839127270703265501) D33 D57 D68 D82 D94\n",
      "error(0.00367735298343462285) D33 D57 D78 D90\n",
      "error(0.08203491482172298177) D33 D57 D81 D93\n",
      "error(6.90517612888575424e-05) D33 D57 D82 D94\n",
      "error(0.003754550521141458708) D33 D68\n",
      "error(0.00367735298343462285) D33 D78\n",
      "error(0.08203491482172299565) D33 D81\n",
      "error(6.90517612888575424e-05) D33 D82\n",
      "error(0.01759698769170302962) D34\n",
      "error(0.0004795087940851329531) D34 D42 D45 D66 D69 D79\n",
      "error(0.001254662563259255131) D34 D42 D66 D79\n",
      "error(0.001189590307505605099) D34 D44 D46\n",
      "error(0.0008448506463430102177) D34 D44 D46 D68 D70\n",
      "error(0.001613988549653402015) D34 D44 D46 D68 D70 D82\n",
      "error(0.0004858738341382931071) D34 D44 D68 D78\n",
      "error(0.001737360995964502353) D34 D44 D68 D82\n",
      "error(0.0009298737588559140939) D34 D45 D46\n",
      "error(0.0007247557385687331856) D34 D45 D46 D69 D70\n",
      "error(0.001613988549653402015) D34 D45 D69\n",
      "error(0.001739317181977227331) D34 D45 D69 D79\n",
      "error(0.0004839127270703265501) D34 D45 D69 D83\n",
      "error(0.0004795087940851329531) D34 D46 D70\n",
      "error(0.001254662563259255131) D34 D46 D70 D82\n",
      "error(0.009502124733129660092) D34 D58\n",
      "error(0.0004795087940851329531) D34 D58 D66 D69 D79 D91\n",
      "error(0.001254662563259255131) D34 D58 D66 D79 D91\n",
      "error(0.0007970774013887247603) D34 D58 D68 D70\n",
      "error(0.001613988549653402015) D34 D58 D68 D70 D82 D94\n",
      "error(0.0004858738341382931071) D34 D58 D68 D78 D90\n",
      "error(0.001737360995964502353) D34 D58 D68 D82 D94\n",
      "error(0.001613988549653402015) D34 D58 D69\n",
      "error(0.0009171549130202406776) D34 D58 D69 D70\n",
      "error(0.001739317181977227331) D34 D58 D69 D79 D91\n",
      "error(0.0004839127270703265501) D34 D58 D69 D83 D95\n",
      "error(0.0004795087940851329531) D34 D58 D70\n",
      "error(0.001254662563259255131) D34 D58 D70 D82 D94\n",
      "error(6.306092300909809018e-05) D34 D58 D78 D90\n",
      "error(0.002388618529765062018) D34 D58 D79 D91\n",
      "error(0.078675045959030937) D34 D58 D82 D94\n",
      "error(6.90517612888575424e-05) D34 D58 D83 D95\n",
      "error(0.003754550521141458708) D34 D68 D70\n",
      "error(0.003754550521141458708) D34 D69 D70\n",
      "error(6.306092300909809018e-05) D34 D78\n",
      "error(0.002388618529765062018) D34 D79\n",
      "error(0.07867504595903092313) D34 D82\n",
      "error(6.90517612888575424e-05) D34 D83\n",
      "error(0.0188301469776657876) D35\n",
      "error(0.001732968113879003761) D35 D43 D67 D80\n",
      "error(0.001189590307505605099) D35 D45 D47\n",
      "error(0.0008448506463430102177) D35 D45 D47 D69 D71\n",
      "error(0.001613988549653402015) D35 D45 D47 D69 D71 D83\n",
      "error(0.0004858738341382931071) D35 D45 D69 D79\n",
      "error(0.001737360995964502353) D35 D45 D69 D83\n",
      "error(0.0009298737588559140939) D35 D47\n",
      "error(0.0008581575259910502115) D35 D47 D71\n",
      "error(0.001254662563259255131) D35 D47 D71 D83\n",
      "error(0.01075597679084398101) D35 D59\n",
      "error(0.001732968113879003761) D35 D59 D67 D80 D92\n",
      "error(0.0007970774013887247603) D35 D59 D69 D71\n",
      "error(0.001613988549653402015) D35 D59 D69 D71 D83 D95\n",
      "error(0.0004858738341382931071) D35 D59 D69 D79 D91\n",
      "error(0.001737360995964502353) D35 D59 D69 D83 D95\n",
      "error(0.001050505293139540825) D35 D59 D71\n",
      "error(0.001254662563259255131) D35 D59 D71 D83 D95\n",
      "error(6.306092300909809018e-05) D35 D59 D79 D91\n",
      "error(0.003816288466196525973) D35 D59 D80 D92\n",
      "error(0.078675045959030937) D35 D59 D83 D95\n",
      "error(0.003754550521141458708) D35 D69 D71\n",
      "error(0.003754550521141458708) D35 D71\n",
      "error(6.306092300909809018e-05) D35 D79\n",
      "error(0.003816288466196525973) D35 D80\n",
      "error(0.07867504595903092313) D35 D83\n",
      "error(0.003783713711635772626) D36\n",
      "error(0.009365170729379965198) D36 D38\n",
      "error(0.002063144093220724371) D36 D38 D60 D62\n",
      "error(0.07965253255414432576) D36 D60\n",
      "error(0.000505933538524447118) D37 D38\n",
      "error(3.540547233527232553e-05) D37 D38 D61 D62\n",
      "error(0.009365170729379965198) D37 D39\n",
      "error(0.002063144093220724371) D37 D39 D61 D63\n",
      "error(0.07962276524503333897) D37 D61\n",
      "error(0.000505933538524447118) D38 D40\n",
      "error(3.540547233527232553e-05) D38 D40 D62 D64\n",
      "error(0.009365170729379965198) D38 D41\n",
      "error(0.0007870137333744988599) D38 D41 D62 D65\n",
      "error(0.08011646101606667569) D38 D62\n",
      "error(0.002101782873844167988) D38 D62 D73\n",
      "error(0.009861627959972411872) D39\n",
      "error(0.000505933538524447118) D39 D41\n",
      "error(3.540547233527232553e-05) D39 D41 D63 D65\n",
      "error(0.0809537868829304369) D39 D63\n",
      "error(0.002101782873844167988) D39 D63 D74\n",
      "error(0.01196071813788375342) D40\n",
      "error(0.009365170729379965198) D40 D42\n",
      "error(0.0007870137333744988599) D40 D42 D64 D66\n",
      "error(0.0797921556729242476) D40 D64\n",
      "error(0.002101782873844167988) D40 D64 D72 D76\n",
      "error(0.000505933538524447118) D41 D42\n",
      "error(3.540547233527232553e-05) D41 D42 D65 D66\n",
      "error(0.009365170729379965198) D41 D43\n",
      "error(0.0007870137333744988599) D41 D43 D65 D67\n",
      "error(0.07902620574266738807) D41 D65\n",
      "error(0.002101782873844167988) D41 D65 D73 D77\n",
      "error(0.000505933538524447118) D42 D44\n",
      "error(3.540547233527232553e-05) D42 D44 D66 D68\n",
      "error(0.009365170729379965198) D42 D45\n",
      "error(0.0007870137333744988599) D42 D45 D66 D69\n",
      "error(0.07902620574266738807) D42 D66\n",
      "error(0.002101782873844167988) D42 D66 D76 D79 L0\n",
      "error(0.009861627959972411872) D43\n",
      "error(0.000505933538524447118) D43 D45\n",
      "error(3.540547233527232553e-05) D43 D45 D67 D69\n",
      "error(0.07986570578131246823) D43 D67\n",
      "error(0.002101782873844167988) D43 D67 D77 D80 L0\n",
      "error(0.01322466237368793464) D44\n",
      "error(0.01061176227334441509) D44 D46\n",
      "error(0.0007870137333744988599) D44 D46 D68 D70\n",
      "error(0.0004795087940851329531) D44 D46 D68 D70 D82\n",
      "error(0.0797921556729242476) D44 D68\n",
      "error(0.002101782873844167988) D44 D68 D78 D82\n",
      "error(0.001254662563259255131) D44 D68 D82\n",
      "error(0.000505933538524447118) D45 D46\n",
      "error(3.540547233527232553e-05) D45 D46 D69 D70\n",
      "error(0.01061176227334441509) D45 D47\n",
      "error(0.0007870137333744988599) D45 D47 D69 D71\n",
      "error(0.0004795087940851329531) D45 D47 D69 D71 D83\n",
      "error(0.07902620574266738807) D45 D69\n",
      "error(0.002101782873844167988) D45 D69 D79 D83\n",
      "error(0.001254662563259255131) D45 D69 D83\n",
      "error(0.08235725318451499188) D46 D70\n",
      "error(0.003973577810257892737) D46 D70 D82\n",
      "error(0.000505933538524447118) D47\n",
      "error(0.08245992281806807656) D47 D71\n",
      "error(0.003973577810257892737) D47 D71 D83\n",
      "error(0.00260542247188913197) D48\n",
      "error(8.346846509154023951e-05) D48 D51\n",
      "error(0.0008575713348122871674) D48 D51 D64\n",
      "error(0.001104944398066224145) D48 D52\n",
      "error(0.0009776342953250786397) D48 D52 D62 D64\n",
      "error(0.001256977620364599152) D48 D60\n",
      "error(0.0008575713348122871674) D48 D60 D62\n",
      "error(0.001338436822130552144) D49\n",
      "error(8.346846509154023951e-05) D49 D52\n",
      "error(0.0008575713348122871674) D49 D52 D62 D65\n",
      "error(0.001104944398066224145) D49 D53\n",
      "error(0.0009776342953250786397) D49 D53 D63 D65\n",
      "error(0.0009776342953250786397) D49 D61 D62\n",
      "error(0.0008575713348122871674) D49 D61 D63\n",
      "error(0.001255177892583233569) D50\n",
      "error(8.346846509154023951e-05) D50 D53\n",
      "error(0.0008575713348122871674) D50 D53 D63\n",
      "error(0.0009776342953250786397) D50 D63\n",
      "error(0.001117325509709361699) D51 D54 D64 L0\n",
      "error(0.002372523298984431477) D51 D54 L0\n",
      "error(0.0008575713348122871674) D52 D54 D64 D66 L0\n",
      "error(8.346846509154023951e-05) D52 D54 L0\n",
      "error(0.0009776342953250786397) D52 D55 D65 D66 L0\n",
      "error(0.001104944398066224145) D52 D55 L0\n",
      "error(0.0008575713348122871674) D53 D55 D65 D67 L0\n",
      "error(8.346846509154023951e-05) D53 D55 L0\n",
      "error(0.0009776342953250786397) D53 D56 D67 L0\n",
      "error(0.001104944398066224145) D53 D56 L0\n",
      "error(6.90517612888575424e-05) D54\n",
      "error(8.346846509154023951e-05) D54 D57\n",
      "error(0.0008575713348122871674) D54 D57 D68\n",
      "error(0.001104944398066224145) D54 D58\n",
      "error(0.0009776342953250786397) D54 D58 D66 D68\n",
      "error(6.90517612888575424e-05) D55\n",
      "error(8.346846509154023951e-05) D55 D58\n",
      "error(0.0008575713348122871674) D55 D58 D66 D69\n",
      "error(0.001104944398066224145) D55 D59\n",
      "error(0.0009776342953250786397) D55 D59 D67 D69\n",
      "error(8.346846509154023951e-05) D56 D59\n",
      "error(0.0008575713348122871674) D56 D59 D67\n",
      "error(0.002372523298984431477) D57\n",
      "error(0.001117325509709361699) D57 D68\n",
      "error(0.003330415459615939256) D58\n",
      "error(0.0009972961583930896063) D58 D68 D70\n",
      "error(0.0009776342953250786397) D58 D69 D70\n",
      "error(0.003330415459615939256) D59\n",
      "error(0.0009972961583930896063) D59 D69 D71\n",
      "error(0.0009776342953250786397) D59 D71\n",
      "error(0.08492976675740541992) D60\n",
      "error(0.01370039566690803984) D60 D62\n",
      "error(0.07954716375263207184) D61\n",
      "error(0.003140467490475105494) D61 D62\n",
      "error(0.01370039566690803984) D61 D63\n",
      "error(0.08011646101606667569) D62\n",
      "error(0.003140467490475105494) D62 D64\n",
      "error(0.01245408967105934156) D62 D65\n",
      "error(0.002101782873844167988) D62 D73 D85\n",
      "error(0.09328898017577323676) D63\n",
      "error(0.003140467490475105494) D63 D65\n",
      "error(0.002101782873844167988) D63 D74 D86\n",
      "error(0.09394427914309862182) D64\n",
      "error(0.01245408967105934156) D64 D66\n",
      "error(0.002101782873844167988) D64 D72 D76 D84 D88\n",
      "error(0.07902620574266738807) D65\n",
      "error(0.003140467490475105494) D65 D66\n",
      "error(0.01245408967105934156) D65 D67\n",
      "error(0.002101782873844167988) D65 D73 D77 D85 D89\n",
      "error(0.07902620574266738807) D66\n",
      "error(0.003140467490475105494) D66 D68\n",
      "error(0.01245408967105934156) D66 D69\n",
      "error(0.002101782873844167988) D66 D76 D79 D88 D91\n",
      "error(0.09223292821625612981) D67\n",
      "error(0.003140467490475105494) D67 D69\n",
      "error(0.002101782873844167988) D67 D77 D80 D89 D92\n",
      "error(0.09499589897549032269) D68\n",
      "error(0.01369283297433037533) D68 D70\n",
      "error(0.0004795087940851329531) D68 D70 D82 D94\n",
      "error(0.002101782873844167988) D68 D78 D82 D90 D94\n",
      "error(0.001254662563259255131) D68 D82 D94\n",
      "error(0.07902620574266738807) D69\n",
      "error(0.003140467490475105494) D69 D70\n",
      "error(0.01369283297433037533) D69 D71\n",
      "error(0.0004795087940851329531) D69 D71 D83 D95\n",
      "error(0.002101782873844167988) D69 D79 D83 D91 D95\n",
      "error(0.001254662563259255131) D69 D83 D95\n",
      "error(0.0825826722683180442) D70\n",
      "error(0.004092891251313041968) D70 D82 D94\n",
      "error(0.0852770461448498357) D71\n",
      "error(0.004092891251313041968) D71 D83 D95\n",
      "error(0.02984372473411167626) D72\n",
      "error(0.01021974461681169309) D72 D75\n",
      "error(0.0009409207599796844731) D72 D75 D84 D87\n",
      "error(0.01867653977894434547) D72 D76\n",
      "error(0.00208087178292139241) D72 D76 D84 D88\n",
      "error(0.004418934394056748399) D72 D84\n",
      "error(0.02851454546202298115) D73\n",
      "error(0.01021974461681169309) D73 D76\n",
      "error(0.0009409207599796844731) D73 D76 D85 D88\n",
      "error(0.01867653977894434547) D73 D77\n",
      "error(0.00208087178292139241) D73 D77 D85 D89\n",
      "error(0.003017876671982264603) D73 D85\n",
      "error(0.01867653977894434547) D74\n",
      "error(0.01021974461681169309) D74 D77\n",
      "error(0.0009409207599796844731) D74 D77 D86 D89\n",
      "error(0.00208087178292139241) D74 D86\n",
      "error(0.003484571044547940099) D75 D78 D87 D90\n",
      "error(0.02003345367806507252) D75 D78 L0\n",
      "error(0.0009409207599796844731) D76 D78 D88 D90\n",
      "error(0.01021974461681169309) D76 D78 L0\n",
      "error(0.00208087178292139241) D76 D79 D88 D91\n",
      "error(0.01867653977894434547) D76 D79 L0\n",
      "error(0.0009409207599796844731) D77 D79 D89 D91\n",
      "error(0.01021974461681169309) D77 D79 L0\n",
      "error(0.00208087178292139241) D77 D80 D89 D92\n",
      "error(0.01867653977894434547) D77 D80 L0\n",
      "error(0.01021974461681169309) D78 D81\n",
      "error(0.0009409207599796844731) D78 D81 D90 D93\n",
      "error(0.01867653977894434547) D78 D82\n",
      "error(0.00208087178292139241) D78 D82 D90 D94\n",
      "error(0.01021974461681169309) D79 D82\n",
      "error(0.0009409207599796844731) D79 D82 D91 D94\n",
      "error(0.01867653977894434547) D79 D83\n",
      "error(0.00208087178292139241) D79 D83 D91 D95\n",
      "error(0.01021974461681169309) D80 D83\n",
      "error(0.0009409207599796844731) D80 D83 D92 D95\n",
      "error(0.02031230364813159384) D81\n",
      "error(0.003773035550173974625) D81 D93\n",
      "error(0.0306655855361775663) D82\n",
      "error(0.005329226460930098185) D82 D94\n",
      "error(0.0306655855361775663) D83\n",
      "error(0.005329226460930098185) D83 D95\n",
      "error(0.004859987207450901583) D84\n",
      "error(0.002256843466347710579) D84 D87\n",
      "error(0.002614946792269149528) D84 D88\n",
      "error(0.004859987207450901583) D85\n",
      "error(0.002256843466347710579) D85 D88\n",
      "error(0.002614946792269149528) D85 D89\n",
      "error(0.002614946792269149528) D86\n",
      "error(0.002256843466347710579) D86 D89\n",
      "error(0.002614946792269149528) D87 D90 L0\n",
      "error(0.002256843466347710579) D88 D90 L0\n",
      "error(0.002614946792269149528) D88 D91 L0\n",
      "error(0.002256843466347710579) D89 D91 L0\n",
      "error(0.002614946792269149528) D89 D92 L0\n",
      "error(0.002256843466347710579) D90 D93\n",
      "error(0.002614946792269149528) D90 D94\n",
      "error(0.002256843466347710579) D91 D94\n",
      "error(0.002614946792269149528) D91 D95\n",
      "error(0.002256843466347710579) D92 D95\n",
      "error(0.002614946792269149528) D93\n",
      "error(0.004859987207450901583) D94\n",
      "error(0.004859987207450901583) D95\n"
     ]
    }
   ],
   "source": [
    "Meta_params['printing'] = 'False'\n",
    "\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "print(circuit.num_detectors)\n",
    "print(\"HI\")\n",
    "print(circuit.detector_error_model(approximate_disjoint_errors=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogicalCircuit' object has no attribute 'Pauli_DEM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_68890/1495820122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauli_DEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogicalCircuit' object has no attribute 'Pauli_DEM'"
     ]
    }
   ],
   "source": [
    "print(circuit.Pauli_DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "        2., -2.,  2.,  0.,  0.,  0.,  0., -2., -2.,  2.,  2., -2., -2.,\n",
       "        2.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., -2., -2.,  0., -2.,  0.,  2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,  0.,  2.,  0.,\n",
       "        0.,  2.,  2.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory)\n",
    "\n",
    "detection_events_signs_exp =  np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "\n",
    "\n",
    "detection_events_signs_exp - detection_events_signs_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.]\n",
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n",
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,\n",
       "       -2.,  2., -2.,  0.,  0.,  0.,  0.,  2.,  2., -2., -2.,  2.,  2.,\n",
       "       -2.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  2.,  2.,  0.,  2.,  0., -2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  2.,  0., -2.,  0.,\n",
       "        0., -2., -2.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_events_signs_exp = np.array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
    "        1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
    "        1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
    "        1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "        1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
    "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "       -1.,  1.,  1., -1., -1.])\n",
    "\n",
    "print(detection_events_signs_exp)\n",
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                                exp_measurements[:, 1, :distance**2-1],\n",
    "                                exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                                exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                                exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "_, _, _, circuit = get_simulated_measurement_events(Meta_params, distance, distance, 1, noise_params)\n",
    "# Use the theory circuit to get the detection events and observable flips corresponding to the exp data\n",
    "detection_events, observable_flips = circuit.compile_m2d_converter().convert(measurements=exp_measurements.astype(bool), separate_observables=True)\n",
    "# Find detection event signs\n",
    "detection_events_signs_theory = -np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs_theory)\n",
    "\n",
    "\n",
    "detection_events_signs_theory - detection_events_signs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_CX_per_layer = 3\n",
      "final measurement_index = 146\n"
     ]
    }
   ],
   "source": [
    "num_shots = 100\n",
    "# Change #2: a function that doesn't decode, just gives you the measurements, detection events, observables and the circuit:\n",
    "measurement_events_all_shots, detection_events_all_shots, observable_flips_all_shots, LogicalCircuit = get_simulated_measurement_events(Meta_params, distance, distance, num_shots, noise_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "exp_measurements = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "measurement_events = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "                            exp_measurements[:, 1, :distance**2-1],\n",
    "                            exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "                            exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "                            exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "                            exp_measurements[:, 1, 2*(distance**2-1):]], axis=1).astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "detection_events, observable_flips = LogicalCircuit.compile_m2d_converter().convert(measurements=measurement_events, separate_observables=True)\n",
    "detection_events_signs = -1*np.sign(2*np.nanmean(detection_events.astype(int), axis=0)-1).astype(int)\n",
    "print(detection_events_signs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False,  True, False],\n",
       "       [False,  True, False, ..., False,  True, False],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True, False],\n",
       "       [ True,  True, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False,  True,  True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "measurement_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_events_all_shots\n",
    "\n",
    "detection_events_signs = np.sign(np.nanmean(detection_events_all_shots,axis = -1))\n",
    "\n",
    "detection_events_signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 5\n",
    "# qubit_states_nans_perlog = np.load('2024_10_15_measurement_events_1CNOT_XX.npy').astype(bool)\n",
    "qubit_states_nans_perlog = np.load(f'/Users/gefenbaranes/Documents/2024_10_15_measurement_events_1CNOT_XX.npy')\n",
    "qubit_states_nans_perlog = qubit_states_nans_perlog.transpose(1,2,0)\n",
    "# exp_measurements = np.concatenate([exp_measurements[:, 0, :distance**2-1],\n",
    "#                             exp_measurements[:, 1, :distance**2-1],\n",
    "#                             exp_measurements[:, 0, distance**2-1:2*(distance**2-1)],\n",
    "#                             exp_measurements[:, 1, distance**2-1:2*(distance**2-1)],\n",
    "#                             exp_measurements[:, 0, 2*(distance**2-1):],\n",
    "#                             exp_measurements[:, 1, 2*(distance**2-1):]], axis=1)\n",
    "\n",
    "\n",
    "perfect_reps = np.ones(qubit_states_nans_perlog.shape[-1]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_losses_per_stab_perlog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_62737/3085604329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_logicals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstabilizer_prod_per_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperfect_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ancillas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0merror_prob_Astabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Astabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0merror_prob_Bstabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Bstabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_62737/3085604329.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_logicals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstabilizer_prod_per_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperfect_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_losses_per_stab_perlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ancillas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0merror_prob_Astabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Astabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0merror_prob_Bstabs_fully_postselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilizer_prod_per_round_per_stab_dataloss_postselection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_Bstabs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_losses_per_stab_perlog' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_data_blocks = num_logicals = 2\n",
    "\n",
    "num_ancilla_blocks = 2\n",
    "num_rounds = num_ancilla_blocks + 1\n",
    "\n",
    "ancilla_grid_size = 6\n",
    "data_grid_size = d = 5\n",
    "xspc = 3\n",
    "yspc = 2\n",
    "\n",
    "num_datas = 25\n",
    "num_ancillas = 24\n",
    "total_num_ancillas = num_ancillas*num_ancilla_blocks*num_logicals\n",
    "total_num_datas = num_datas*num_data_blocks\n",
    "num_physicals = total_num_ancillas + total_num_datas\n",
    "\n",
    "\n",
    "\n",
    "stabilizer_weights = np.zeros(num_ancillas)\n",
    "stabilizer_masks = np.zeros((num_ancillas, num_datas), dtype = bool)\n",
    "\n",
    "ancilla_Astabs_mask = Zstabs_mask =  np.array([1,1,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,1,1], dtype = bool) \n",
    "ancilla_Bstabs_mask = Xstabs_mask = (1-ancilla_Astabs_mask).astype(bool)\n",
    "\n",
    "deterministic_rounds = np.ones(num_rounds).astype(bool)\n",
    "nondeterministic_rounds = np.array([0] + (num_rounds - 2)*[1] + [0]).astype(bool)\n",
    "\n",
    "\n",
    "### HARDCODE FOR NOW\n",
    "stabilizer_weights = np.array([2., 2., 4., 4., 4., 4., 2., 2., 4., 4., 4., 4., 4., 4., 4., 4., 2.,\n",
    "       2., 4., 4., 4., 4., 2., 2.])\n",
    "stabilizer_masks = np.array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]).astype(bool)\n",
    "\n",
    "\n",
    "stab2A = (ancilla_Astabs_mask & (stabilizer_weights == 2))\n",
    "stab2B = (ancilla_Bstabs_mask & (stabilizer_weights == 2))\n",
    "stab4A = (ancilla_Astabs_mask & (stabilizer_weights == 4))\n",
    "stab4B = (ancilla_Bstabs_mask & (stabilizer_weights == 4))\n",
    "\n",
    "\n",
    "vertical_string_masks = np.zeros((d,num_datas)).astype(bool)\n",
    "horizontal_string_masks = np.zeros((d,num_datas)).astype(bool)\n",
    "\n",
    "for i in range(d):\n",
    "    vertical_string_masks[i,i::d] = True\n",
    "    horizontal_string_masks[i,i*d:d*(i+1)] = True\n",
    "\n",
    "# qubit_states_nans = atoms_present_final.copy()\n",
    "\n",
    "\n",
    "# ## Reshape into per logical\n",
    "# qubit_states_nans_perlog = np.array([qubit_states_nans[logical_qubit_masks[i]] for i in range(num_logicals)])\n",
    "# qubit_states_perlog = np.nan_to_num(qubit_states_nans_perlog, nan = 3) #convert nan to 3 (so it then becomes 2 in the next line)\n",
    "# qubit_states_perlog = ((qubit_states_perlog + 1)/2).astype(int)\n",
    "\n",
    "# data_losses_perlog = np.isnan(qubit_states_nans_perlog[:,-num_datas:])\n",
    "# data_losses_per_stab_perlog = np.array([np.sum(data_losses_perlog[:,stabilizer_masks[i]], axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "# num_data_losses_perlog = np.sum(data_losses_perlog, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stabilizer_prod_per_round = []\n",
    "stabilizer_prod_per_round_withloss = []\n",
    "\n",
    "loss_sign = +1\n",
    "\n",
    "for r in range(-1,num_ancilla_blocks):\n",
    "    if r == -1:\n",
    "        stab_second = qubit_states_nans_perlog[:,num_ancillas*(r+1):num_ancillas*(r+2)]\n",
    "        stab_first = np.ones_like(stab_second)\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second_withloss = np.nan_to_num(stab_second,nan = loss_sign)\n",
    "                                            \n",
    "    elif r == num_ancilla_blocks - 1:\n",
    "        stab_first = qubit_states_nans_perlog[:,num_ancillas*r:num_ancillas*(r+1)]\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second = np.array([np.prod(qubit_states_nans_perlog[:,-num_datas:][:,stabilizer_masks[i]],axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "        stab_second_withloss = np.array([np.prod(np.nan_to_num(qubit_states_nans_perlog[:,-num_datas:][:,stabilizer_masks[i]], nan = loss_sign),axis = 1) for i in range(num_ancillas)]).transpose(1,0,2)\n",
    "    else:\n",
    "        stab_first = qubit_states_nans_perlog[:,num_ancillas*r:num_ancillas*(r+1)]\n",
    "        stab_first_withloss = np.nan_to_num(stab_first,nan = loss_sign)\n",
    "        stab_second = qubit_states_nans_perlog[:,num_ancillas*(r+1):num_ancillas*(r+2)]\n",
    "        stab_second_withloss = np.nan_to_num(stab_second, nan = loss_sign)\n",
    "\n",
    "    stab_product_per_round = stab_first*stab_second\n",
    "    stab_product_per_round_withloss = stab_first_withloss*stab_second_withloss #convert loss to qubit state |0>\n",
    "\n",
    "    stabilizer_prod_per_round.append(stab_product_per_round)\n",
    "    stabilizer_prod_per_round_withloss.append(stab_product_per_round_withloss)\n",
    "\n",
    "stabilizer_prod_per_round = np.array(stabilizer_prod_per_round)\n",
    "stabilizer_prod_per_round_withloss = np.array(stabilizer_prod_per_round_withloss)\n",
    "\n",
    "# For sublattice A, and sublattice B separately\n",
    "\n",
    "error_prob_Astabs = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Astabs_mask],axis = -1)))/2\n",
    "error_prob_Bstabs = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Bstabs_mask], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_postselected = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Astabs_mask][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,ancilla_Bstabs_mask][:,:,:,perfect_reps], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_fully_postselected = np.zeros_like(error_prob_Astabs_postselected)\n",
    "error_prob_Bstabs_fully_postselected = np.zeros_like(error_prob_Bstabs_postselected)\n",
    "\n",
    "stabilizer_prod_per_round_per_stab_dataloss_postselection = []\n",
    "for log in range(num_logicals):\n",
    "    stabilizer_prod_per_round_per_stab_dataloss_postselection += [[stabilizer_prod_per_round[:,log,i][:,data_losses_per_stab_perlog[log,i] == 0][:,perfect_reps[data_losses_per_stab_perlog[log,i] == 0]] for i in range(num_ancillas)]]\n",
    "    error_prob_Astabs_fully_postselected[:,log] = 1-(1+np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[-1][i],axis = -1) for i in np.where(ancilla_Astabs_mask)[0]]).T)/2\n",
    "    error_prob_Bstabs_fully_postselected[:,log] = 1-(1+np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[-1][i],axis = -1) for i in np.where(ancilla_Bstabs_mask)[0]]).T)/2\n",
    "\n",
    "plt.figure(\"Detected error per round\", figsize = (15,5))\n",
    "plt.clf()\n",
    "for log in range(num_logicals):  \n",
    "    Astab_good_rounds_thislog = deterministic_rounds if prep_basis[log] == 'vertical' else nondeterministic_rounds\n",
    "    Bstab_good_rounds_thislog = nondeterministic_rounds if prep_basis[log] == 'vertical' else deterministic_rounds\n",
    "    \n",
    "    plt.subplot(1,2,log+1)\n",
    "    plt.bar(np.arange(num_rounds)-0.2,np.nanmean(error_prob_Astabs[:,log],axis = -1),width = 0.4,label = \"A\", color = \"b\", alpha = 0.6)\n",
    "    plt.bar(np.arange(num_rounds)+0.2,np.nanmean(error_prob_Bstabs[:,log],axis = -1),width = 0.4,label = \"B\", color = \"orange\", alpha = 0.6)\n",
    "    plt.bar(np.arange(num_rounds)-0.2,np.nanmean(error_prob_Astabs_postselected[:,log],axis = -1),width = 0.4,label = \"A (post)\",color = \"b\")\n",
    "    plt.bar(np.arange(num_rounds)+0.2,np.nanmean(error_prob_Bstabs_postselected[:,log],axis = -1),width = 0.4,label = \"B (post)\", color = \"orange\")\n",
    "    \n",
    "    plt.xticks(np.arange(num_rounds))\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Detected error probability\")\n",
    "    plt.ylim(0,0.6)\n",
    "    plt.legend()\n",
    "    plt.title(f\"\"\"Average error prob (no postselection, exclude loss): {np.nanmean(np.concatenate((error_prob_Astabs[:,log][Astab_good_rounds_thislog],error_prob_Bstabs[:,log][Bstab_good_rounds_thislog]))):.4f}\n",
    "    Average error prob (postselected, exclude loss): {np.nanmean(np.concatenate((error_prob_Astabs_postselected[:,log][Astab_good_rounds_thislog],error_prob_Bstabs_postselected[:,log][Bstab_good_rounds_thislog]))):.4f}\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_prob_Astabs_postselected_weight_2 = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_weight_2  = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "error_prob_Astabs_postselected_weight_4 = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_weight_4  = 1-(1+np.abs(np.nanmean(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "\n",
    "error_prob_Astabs_postselected_weight_2_err = np.nanstd(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps],axis = -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab2A][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Bstabs_postselected_weight_2_err  = np.nanstd(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps], axis= -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab2B][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Astabs_postselected_weight_4_err = np.nanstd(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps],axis = -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab4A][:,:,:,perfect_reps].shape[-1])\n",
    "error_prob_Bstabs_postselected_weight_4_err  = np.nanstd(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps], axis= -1)/2/np.sqrt(stabilizer_prod_per_round[:,:,stab4B][:,:,:,perfect_reps].shape[-1])\n",
    "\n",
    "stab_mean_prod_stab2A = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab2A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab2B = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab2B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab4A = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab4A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "stab_mean_prod_stab4B = np.array([np.abs([np.nanmean(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1) for i in np.where(stab4B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "\n",
    "error_prob_Astabs_fully_postselected_weight_2 = 1-(1+np.abs(stab_mean_prod_stab2A))/2\n",
    "error_prob_Bstabs_fully_postselected_weight_2  = 1-(1+np.abs(stab_mean_prod_stab2B))/2\n",
    "error_prob_Astabs_fully_postselected_weight_4 = 1-(1+np.abs(stab_mean_prod_stab4A))/2\n",
    "error_prob_Bstabs_fully_postselected_weight_4  = 1-(1+np.abs(stab_mean_prod_stab4B))/2\n",
    "\n",
    "error_prob_Astabs_fully_postselected_weight_2_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab2A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Bstabs_fully_postselected_weight_2_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab2B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Astabs_fully_postselected_weight_4_err = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab4A)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "error_prob_Bstabs_fully_postselected_weight_4_err  = np.array([0.5 * np.array([np.nanstd(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i],axis = -1)/np.sqrt(stabilizer_prod_per_round_per_stab_dataloss_postselection[log][i].shape[-1]) \n",
    "                                                                              for i in np.where(stab4B)[0]]).T for log in range(num_logicals)]).transpose(1,0,2)\n",
    "\n",
    "\n",
    "error_prob_Astabs_postselected_withloss_weight_2  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab2A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_withloss_weight_2  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab2B][:,:,:,perfect_reps], axis= -1)))/2\n",
    "error_prob_Astabs_postselected_withloss_weight_4  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab4A][:,:,:,perfect_reps],axis = -1)))/2\n",
    "error_prob_Bstabs_postselected_withloss_weight_4  = 1-(1+np.abs(np.mean(stabilizer_prod_per_round_withloss[:,:,stab4B][:,:,:,perfect_reps], axis= -1)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "for log in range(num_logicals):  \n",
    "    Astab_good_rounds_thislog = deterministic_rounds if prep_basis[log] == 'vertical' else nondeterministic_rounds\n",
    "    Bstab_good_rounds_thislog = nondeterministic_rounds if prep_basis[log] == 'vertical' else deterministic_rounds\n",
    "    \n",
    "    plt.subplot(num_logicals,2,log*num_logicals + 1)\n",
    "\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_postselected_weight_2[Astab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_postselected_weight_2[Bstab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_postselected_weight_4[Astab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_postselected_weight_4[Bstab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_postselected_weight_2,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='steelblue')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_postselected_weight_2,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='steelblue', label='weight 2')\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_postselected_weight_4,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='firebrick')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_postselected_weight_4,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='firebrick', label='weight 4')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.xlabel('QEC cycle')\n",
    "    plt.ylabel(\"Detection probability\")\n",
    "    \n",
    "    all_good_weight2 = np.concatenate((error_prob_Astabs_postselected_weight_2[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_2[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4 =  np.concatenate((error_prob_Astabs_postselected_weight_4[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_4[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    all_good_weight2_err = np.concatenate((error_prob_Astabs_postselected_weight_2_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_2_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4_err = np.concatenate((error_prob_Astabs_postselected_weight_4_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_postselected_weight_4_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    plt.title(f\"\"\"Logical {log+1}: Postselected on rearrangement only\n",
    "    Weight 2: {np.mean(all_good_weight2):.4f}({np.mean(all_good_weight2_err)/np.sqrt(all_good_weight2.size):.4f}), Weight 4: {np.mean(all_good_weight4):.4f}({np.mean(all_good_weight4_err)/np.sqrt(all_good_weight4.size):.4f})\n",
    "    Overall {np.mean(np.concatenate((all_good_weight2, all_good_weight4))):.4f}({np.mean(np.concatenate((all_good_weight2_err, all_good_weight4_err)))/np.sqrt(np.concatenate((all_good_weight2, all_good_weight4)).ravel().size):.4f})\"\"\")\n",
    "    \n",
    "    plt.subplot(num_logicals,2,log*num_logicals + 2)\n",
    "\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_fully_postselected_weight_2[Astab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_fully_postselected_weight_2[Bstab_good_rounds_thislog, log],'o--',color='steelblue', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], error_prob_Astabs_fully_postselected_weight_4[Astab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], error_prob_Bstabs_fully_postselected_weight_4[Bstab_good_rounds_thislog, log],'o--',color='firebrick', alpha = 0.2, zorder = -20)\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_fully_postselected_weight_2,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='steelblue')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_fully_postselected_weight_2,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='steelblue', label='weight 2')\n",
    "    plt.plot(np.arange(num_rounds)[Astab_good_rounds_thislog], np.mean(error_prob_Astabs_fully_postselected_weight_4,axis=-1)[Astab_good_rounds_thislog, log],'o-',color='firebrick')\n",
    "    plt.plot(np.arange(num_rounds)[Bstab_good_rounds_thislog], np.mean(error_prob_Bstabs_fully_postselected_weight_4,axis=-1)[Bstab_good_rounds_thislog, log],'o-',color='firebrick', label='weight 4')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.xlabel('QEC cycle')\n",
    "    plt.ylabel(\"Detection probability\")\n",
    "    all_good_weight2 = np.concatenate((error_prob_Astabs_fully_postselected_weight_2[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_2[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4 =  np.concatenate((error_prob_Astabs_fully_postselected_weight_4[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_4[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    all_good_weight2_err = np.concatenate((error_prob_Astabs_fully_postselected_weight_2_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_2_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    all_good_weight4_err = np.concatenate((error_prob_Astabs_fully_postselected_weight_4_err[Astab_good_rounds_thislog, log], error_prob_Bstabs_fully_postselected_weight_4_err[Bstab_good_rounds_thislog, log])).ravel()\n",
    "    \n",
    "    plt.title(f\"\"\"Logical {log + 1}: Postselected on rearrangement and no data loss\n",
    "    Weight 2: {np.mean(all_good_weight2):.4f}({np.mean(all_good_weight2_err)/np.sqrt(all_good_weight2.size):.4f}), Weight 4: {np.mean(all_good_weight4):.4f}({np.mean(all_good_weight4_err)/np.sqrt(all_good_weight4.size):.4f})\n",
    "    Overall {np.mean(np.concatenate((all_good_weight2, all_good_weight4))):.4f}({np.mean(np.concatenate((all_good_weight2_err, all_good_weight4_err)))/np.sqrt(np.concatenate((all_good_weight2, all_good_weight4)).ravel().size):.4f})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in np.arange(num_logicals):\n",
    "    fig, axs = plt.subplots(ancilla_grid_size,ancilla_grid_size)\n",
    "    # fig.canvas.set_window_title(\"Ancilla stabilizers, excluding loss\")\n",
    "    fig.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "    count = 0\n",
    "    for i in range(ancilla_grid_size**2):\n",
    "        ax = axs[i//ancilla_grid_size,i%ancilla_grid_size]\n",
    "        if ancilla_block_mask[i]:\n",
    "            mean_stab = np.nanmean(stabilizer_prod_per_round[:,log,count,perfect_reps], axis = -1)\n",
    "            # ax.bar(np.arange(num_rounds),mean_stab, color = [\"r\",\"k\"][int(ancilla_Astabs_mask[count])])\n",
    "            ax.bar(np.arange(num_rounds),mean_stab, color = [\"r\",\"k\"][int(ancilla_Astabs_mask[count])])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_ylim(-1,1)\n",
    "            count+=1 \n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    fig.suptitle(\"Logical %i stab. products (perfect rearrangement, exclude loss)\"%(log+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "A = 'logical_CX_NL1_NCX2'\n",
    "\n",
    "print(int(A[13:14]))\n",
    "\n",
    "print(int(A[18:19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
