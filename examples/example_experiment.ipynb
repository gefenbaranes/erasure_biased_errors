{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entangling Pauli error rate = None, entangling loss rate = None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`shots` array should have two dimensions, not 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/9b4nnp7x0s7c1fp6wn1qhrnm0000gn/T/ipykernel_56786/2161046223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# The main function to use:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mpredictions_bool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdems_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss_MLE_Decoder_Experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeta_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m# dems_list will be a list is we use loss decoding, because for every shot we got a different DEM according to measurement events. Without any loss it will be a single DEM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/delayed_erasure_decoders/Experimental_Loss_Decoder.py\u001b[0m in \u001b[0;36mLoss_MLE_Decoder_Experiment\u001b[0;34m(Meta_params, distance, output_dir, measurement_events, detection_events_signs, use_loss_decoding)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Step 1 - decode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mpredictions_bool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdems_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_logical_errors_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_shots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_shots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasurement_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_events_signs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_loss_decoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_erasure_biased_errors/BiasedErasure/main_code/Simulator.py\u001b[0m in \u001b[0;36mcount_logical_errors_experiment\u001b[0;34m(self, num_shots, distance, measurement_events, detection_events_signs, use_loss_decoding)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0mdetector_error_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdems_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0mmatching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_detector_error_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector_error_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_event\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymatching/matching.py\u001b[0m in \u001b[0;36mdecode_batch\u001b[0;34m(self, shots, return_weights, bit_packed_shots, bit_packed_predictions)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mnum_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_observables\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_observables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \"\"\"\n\u001b[0;32m--> 415\u001b[0;31m         predictions, weights = self._matching_graph.decode_batch(\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0mshots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mbit_packed_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbit_packed_predictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `shots` array should have two dimensions, not 1"
     ]
    }
   ],
   "source": [
    "from BiasedErasure.delayed_erasure_decoders.Experimental_Loss_Decoder import *\n",
    "\n",
    "Meta_params = {'architecture': 'CBQC', 'code': 'Rotated_Surface', 'logical_basis': 'X', 'bias_preserving_gates': 'False', \n",
    "        'noise': 'atom_array', 'is_erasure_biased': 'False', 'LD_freq': '1', 'LD_method': 'FREE', 'SSR': 'True', 'cycles': '2', 'ordering': 'bad', 'decoder': 'MWPM',\n",
    "        'circuit_type': 'memory', 'Steane_type': 'regular', 'printing': 'False', 'num_logicals': '1', 'loss_decoder': 'independent'}\n",
    "\n",
    "\"\"\" Meta params:\n",
    "architecture: CBQC or MBQC. For now we will choose CBQC.\n",
    "code: Rotated_Surface or Surface.\n",
    "logical_basis: X or Z\n",
    "bias_preserving_gates: True or False. False means we dont have a native CX gate and we must use H*CZ*H\n",
    "noise: always choose atom_array\n",
    "is_erasure_biased: For now it is only compatible with False. Meaning after erasure we assume a depolarizing channel.\n",
    "LD_freq: int. how often we want to do the SWAP cycles? 1 means every round, 2 means every 2 rounds and so on.\n",
    "LD_method: loss detection method. SWAP means our SWAP method. FREE means now adding anything to the circuit (for erasure conversion)\n",
    "SSR: Set True\n",
    "cycles: How many QEC cycles are they? not that we count initialization circuit as a cycle. So if you want init + 2 QEC cycles, set cycles=3\n",
    "ordering: bad or fowler. bad means same ordering for both bases X and Z\n",
    "decoder: MLE or MWPM.\n",
    "circuit_type: for now choose only memory.\n",
    "Steane_type: not relevant for now.\n",
    "printing: True or False\n",
    "num_logicals: for now choose 1.\n",
    "loss_decoder: independent or comb. For now we will use only independent (meaning every loss event is counted independently + adding a single combination of losses)\n",
    "\"\"\"\n",
    "\n",
    "# Example data, change this:\n",
    "distance = 3\n",
    "output_dir = \"/Users/gefenbaranes/Documents/results\"\n",
    "num_shots = 2\n",
    "measurement_events = np.zeros((num_shots, 25), dtype=np.int64)\n",
    "measurement_events[0][10] = 2\n",
    "detection_events_signs = np.ones((num_shots, 12))\n",
    "use_loss_decoding = True\n",
    "\n",
    "# The main function to use:\n",
    "predictions_bool, dems_list = Loss_MLE_Decoder_Experiment(Meta_params, distance, output_dir, measurement_events, detection_events_signs, use_loss_decoding)\n",
    "# dems_list will be a list is we use loss decoding, because for every shot we got a different DEM according to measurement events. Without any loss it will be a single DEM.\n",
    "\n",
    "\n",
    "print(predictions_bool)\n",
    "print(dems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
